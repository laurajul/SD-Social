{
    "items": [
        {
            "id": 27128053,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7a7fed06-6966-4540-8468-fc5d758ef7f6/width=832/7a7fed06-6966-4540-8468-fc5d758ef7f6.jpeg",
            "hash": "U9Fo.Vs.0BEj}:xF0*Ej1cw{]*J9MmsBy9OW",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-31T23:38:04.813Z",
            "postId": 6067258,
            "stats": {
                "cryCount": 4,
                "laughCount": 54,
                "likeCount": 428,
                "dislikeCount": 0,
                "heartCount": 108,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1170204583,
                "steps": 10,
                "prompt": "A fire hydrant, completely engulfed in flames, inferno, blazing, concept art, masterpiece, perfect lighting, purple flames, 4k, absurdres,",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-31T2336:59.6529086Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    }
                ]
            },
            "username": "StuffOnFireForNoReason",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 26778224,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b3b3abb9-50fb-4324-86d7-1aee8b7ad619/width=752/b3b3abb9-50fb-4324-86d7-1aee8b7ad619.jpeg",
            "hash": "UKI_oQ1M13}nxGE%5:=H0,xZ=]nQ=cof$$Nw",
            "width": 752,
            "height": 1360,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-29T20:09:30.348Z",
            "postId": 5987513,
            "stats": {
                "cryCount": 8,
                "laughCount": 57,
                "likeCount": 390,
                "dislikeCount": 0,
                "heartCount": 139,
                "commentCount": 3
            },
            "meta": null,
            "username": "kitsunebilamp849",
            "baseModel": ""
        },
        {
            "id": 21746072,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f64849d1-2f05-4ce2-925c-b91484ff09b2/width=1152/f64849d1-2f05-4ce2-925c-b91484ff09b2.jpeg",
            "hash": "UOGIAS9Z-.RP_LIUtRn+^*M_R:NGT1oaICtP",
            "width": 1152,
            "height": 2048,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-07-28T16:49:44.613Z",
            "postId": 4846320,
            "stats": {
                "cryCount": 17,
                "laughCount": 30,
                "likeCount": 382,
                "dislikeCount": 0,
                "heartCount": 165,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "vae-ft-mse-840000-ema-pruned.safetensors",
                "Size": "576x1024",
                "seed": 3693959098,
                "Model": "realcartoon3d_v17",
                "steps": 45,
                "hashes": {
                    "vae": "6aa6483178",
                    "model": "2744d1e68c",
                    "lora:add_detail": "7c6bad76eb54",
                    "lora:backlight_slider_v10": "bce77b76fba3"
                },
                "prompt": "super high detail, beautiful girl, sitting on window sill, intense gaze, long brown hair with soft curls, detailed face, sparkling blue eyes, red off-shoulder top, denim shorts, green pendant necklace, sunlit room with leafy backdrop, soft glowing light, perfect hands, flawless body proportions, vibrant and exaggerated colors\n<lora:add_detail:0.4>     <lora:backlight_slider_v10:-1.5>",
                "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 5,
                "clipSkip": 2,
                "TI hashes": {
                    "badhandv4": "5e40d722fc3d",
                    "FastNegativeV2": "a7465e7cc2a2"
                },
                "resources": [
                    {
                        "hash": "7c6bad76eb54",
                        "name": "add_detail",
                        "type": "lora",
                        "weight": 0.4
                    },
                    {
                        "hash": "bce77b76fba3",
                        "name": "backlight_slider_v10",
                        "type": "lora"
                    },
                    {
                        "hash": "2744d1e68c",
                        "name": "realcartoon3d_v17",
                        "type": "model"
                    }
                ],
                "Model hash": "2744d1e68c",
                "Extra noise": "0.02",
                "Hires steps": "20",
                "Hires upscale": "2",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "(FastNegativeV2:1.3), badhandv4, artistic error, \nlow quality, sketch, black and white, male character, sitting, simple pose, no detail, short hair, plain background, no neon lights, no cityscape, poor anatomy, unrealistic hands, low detail",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.5.1",
                "Denoising strength": "0.4",
                "ADetailer mask blur": "32",
                "ADetailer model 2nd": "full_eyes_detect_v1.pt",
                "ADetailer model 3rd": "lips_v1.pt",
                "ADetailer model 4th": "hand_yolov8n.pt",
                "ADetailer steps 4th": "100",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer mask blur 2nd": "32",
                "ADetailer mask blur 3rd": "32",
                "ADetailer mask blur 4th": "32",
                "ADetailer confidence 2nd": "0.3",
                "ADetailer confidence 3rd": "0.3",
                "ADetailer confidence 4th": "0.3",
                "ADetailer inpaint padding": "32",
                "ADetailer ControlNet model": "control_v11f1e_sd15_tile [a371b31b]",
                "ADetailer dilate erode 2nd": "4",
                "ADetailer dilate erode 3rd": "4",
                "ADetailer dilate erode 4th": "4",
                "ADetailer ControlNet module": "tile_resample",
                "ADetailer denoising strength": "0.5",
                "ADetailer inpaint only masked": "True",
                "ADetailer inpaint padding 2nd": "32",
                "ADetailer inpaint padding 3rd": "32",
                "ADetailer inpaint padding 4th": "32",
                "ADetailer ControlNet model 2nd": "control_v11f1e_sd15_tile [a371b31b]",
                "ADetailer ControlNet model 3rd": "control_v11f1e_sd15_tile [a371b31b]",
                "ADetailer ControlNet model 4th": "control_v11p_sd15_openpose [cab727d4]",
                "ADetailer ControlNet module 2nd": "tile_resample",
                "ADetailer ControlNet module 3rd": "tile_resample",
                "ADetailer ControlNet module 4th": "dw_openpose_full",
                "ADetailer denoising strength 2nd": "0.5",
                "ADetailer denoising strength 3rd": "0.5",
                "ADetailer denoising strength 4th": "0.4",
                "ADetailer use separate steps 4th": "True",
                "ADetailer inpaint only masked 2nd": "True",
                "ADetailer inpaint only masked 3rd": "True",
                "ADetailer inpaint only masked 4th": "True"
            },
            "username": "salammy",
            "baseModel": "SD 1.5"
        },
        {
            "id": 8341811,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/db33e49a-d493-44ce-b7c1-5ecae0fb23ba/width=832/db33e49a-d493-44ce-b7c1-5ecae0fb23ba.jpeg",
            "hash": "UKGRJ4oz0Lw{~BoyM{oLTdR*IUaeDjR*OrjF",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-03-21T22:42:05.036Z",
            "postId": 1805667,
            "stats": {
                "cryCount": 14,
                "laughCount": 38,
                "likeCount": 334,
                "dislikeCount": 0,
                "heartCount": 208,
                "commentCount": 4
            },
            "meta": null,
            "username": "3mcg33",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 7567696,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d01946cc-5d69-4f9f-8541-59ae550b265c/width=832/d01946cc-5d69-4f9f-8541-59ae550b265c.jpeg",
            "hash": "UBB:To$*9aNH~TRQDk%eOlM|w0-.O?NH#mxt",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-03-07T09:38:24.960Z",
            "postId": 1639413,
            "stats": {
                "cryCount": 23,
                "laughCount": 106,
                "likeCount": 272,
                "dislikeCount": 0,
                "heartCount": 193,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 263071617,
                "steps": 38,
                "prompt": "Close shot of fantasy animal named \"tiger-butterfly\"staring at viewer, surprised, half frog, half monkey, Nick Knight,Patricia Piccinini, Robert Rauschenberg,AES+F,hyper detailed,intricate, poster,artstation, Dark Jungle out of focus background, depth of field, bokeh",
                "sampler": "DPM++ 2M",
                "cfgScale": 3,
                "clipSkip": 2,
                "resources": [],
                "negativePrompt": "negativeXL_D,nude,asian",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 234137
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 293991
                    }
                ]
            },
            "username": "Arty_Ficial",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 36465828,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/06c35afc-ee21-4091-904f-35c4945b8d31/width=1800/06c35afc-ee21-4091-904f-35c4945b8d31.jpeg",
            "hash": "U9AvOW~U?a?FcY-oyCS~EMX8%1oziwNdr?s:",
            "width": 2304,
            "height": 3456,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-25T09:30:00.000Z",
            "postId": 8329200,
            "stats": {
                "cryCount": 22,
                "laughCount": 70,
                "likeCount": 382,
                "dislikeCount": 0,
                "heartCount": 119,
                "commentCount": 0
            },
            "meta": {
                "steps": 25,
                "prompt": "(Best Quality,4k,8k,High resolution,masterpiece:1.2),ultra detailed,(realist,photorealist,photo-realist:1.37),1 girl,hip-hop style suit,High ponytail,incredibly long hair,cowgirl pose,looking at the viewer,Leaning forward,by Santiago Caruso,by Mike Azevedo,detailed eyes,detailed lips,extremely detailed face,long eyelashes,dynamic pose,showy,vibrant colors,warm lighting",
                "sampler": "Euler",
                "cfgScale": 1,
                "negativePrompt": "verybadimagenegative_v1.3, unaestheticXLv13, bad quality, low resolution, poorly drawn hands, poorly drawn face, out of frame, extra limbs, disfigured, bad anatomy, distorted face, tiling, watermark, signature, cut off, low , contrast, underexposed, overexposed, text, beginner, amateur,  ((blurry)), logo, watermark, text, ((username)), 3d, 3d rendering, painting,"
            },
            "username": "HicKee",
            "baseModel": ""
        },
        {
            "id": 36249618,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/471507a4-5f50-4b24-9a04-42c717267fee/width=832/471507a4-5f50-4b24-9a04-42c717267fee.jpeg",
            "hash": "U8CG*__N4nRk-oRP4TIAslx]8_IA^*xuD%D%",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-24T04:58:28.208Z",
            "postId": 8281304,
            "stats": {
                "cryCount": 32,
                "laughCount": 72,
                "likeCount": 391,
                "dislikeCount": 0,
                "heartCount": 99,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1062412672,
                "extra": {
                    "remixOfId": 34762034
                },
                "steps": 24,
                "prompt": "a small, black-and-white spotted kitten walks alone in the rain, its fragile body drenched as water pours down, with wide, anxious eyes scanning the empty, dry street around it. next to it, a slightly larger tabby kitten holds a tiny umbrella over the black-and-white kitten, shielding it from the downpour. the contrast between the dry street and the isolated rain enhances the sense of vulnerability, while the soft lighting and gentle shadows highlight the tender moment between the two kittens. the scene evokes deep sympathy, capturing the bond between them as they seek shelter together. emotional lighting, cinematic focus, soft contrast, melancholic yet heartwarming tone",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-23T1050:37.4509095Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 720252,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "White_Rabbit_A",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 32931409,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0d482d31-709c-4770-b0e0-1aead1bf8d2d/width=832/0d482d31-709c-4770-b0e0-1aead1bf8d2d.jpeg",
            "hash": "UIJQm1M{_NogP9%1%1kWtRM|~Bof_NWB^*xu",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-05T09:32:52.915Z",
            "postId": 7535958,
            "stats": {
                "cryCount": 45,
                "laughCount": 30,
                "likeCount": 379,
                "dislikeCount": 0,
                "heartCount": 139,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 392192633,
                "steps": 14,
                "prompt": "score_4,score_5,score_6,score_7_up,score_8_up,score_9 ((masterpiece,best quality,ultra detailed,highres,HD,4k:1.2)), \n1girl, solo,solo focus,girl focus,face focus,\nmedium hair, dark green hair, braids, two braids, hair ornament,yellow eyes,\npov,from the front, front view, front angle, \nHappy Valentine's Day, Valentine's chocolate, holding wrapped chocolate, \nheart background, \nblush,happy,smile,((closed eyes,open mouth:1.1)),",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-05T0923:06.1045220Z",
                "negativePrompt": "(teeth,Macho, muscular, old man, fat man,Nostrils,\n,text,yuri,roll one \u0019s eyes:1.5),(worst quality, low quality:1.4), (patreon username, patreon logo, signature, watermark,easynegative,negative_hand-neg, bad-hands-5,low quality,bad-hands-5,extra limbs,missing limb,extra digit,fewer digit,missing digit,missing fingers,mutated hands and fingers,fused limb,bad hands,long neck,long body,bad anatomy,disfigured,deformed,poorly drawn,mutation,extra nippless,extra breasts,disembodied penis,:1.4)",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 828380,
                        "modelVersionName": "v3"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 808954,
                        "modelVersionName": "V1"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "nagareboshiryusei081612",
            "baseModel": "Pony"
        },
        {
            "id": 31617578,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2b0169ca-2ca7-4e05-8ed4-ef49903ecbfe/width=832/2b0169ca-2ca7-4e05-8ed4-ef49903ecbfe.jpeg",
            "hash": "U05#b6~p_NS0TJ9G-QV@00M|9G%LxW%L4;WF",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-27T17:33:53.029Z",
            "postId": 7120182,
            "stats": {
                "cryCount": 13,
                "laughCount": 47,
                "likeCount": 419,
                "dislikeCount": 0,
                "heartCount": 114,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3487597242,
                "steps": 25,
                "prompt": "full body shot, a four-armed fully anthropomorphic wolf with a third eye and black fur, wearing a necklace of human skulls, holding a skull shaped bowl in one hand, a short ritual kukri in another hand, the eyes all glow red,",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-09-27T1716:01.8948704Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.75,
                        "modelVersionId": 748413,
                        "modelVersionName": "V1"
                    },
                    {
                        "type": "lora",
                        "weight": 0.75,
                        "modelVersionId": 890590,
                        "modelVersionName": "V2"
                    }
                ]
            },
            "username": "Surreal_Cruelty",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 29926334,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3e9b7be7-1d45-4c14-9544-4ae0516936ba/width=832/3e9b7be7-1d45-4c14-9544-4ae0516936ba.jpeg",
            "hash": "UcEy#zIpa}xtPXs+oLWrJE$~SOR--pWXWYs.",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-17T18:05:10.414Z",
            "postId": 6696643,
            "stats": {
                "cryCount": 0,
                "laughCount": 9,
                "likeCount": 468,
                "dislikeCount": 0,
                "heartCount": 116,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3640852770,
                "steps": 30,
                "prompt": "sc3n1ch0r1s0ns, the image is a ultra_detailed digital rendering of a slender and fit hero man wearing tribal buckskin tattered clothing, standing dynamically on a mountain ridge, he's brandishing a spear, The character is overlooking a vast dynamic landscape of rugged mountainous terrain, across the image the landscape varies to show all four seasons, from snowy a barren to lush forested and sandy desert, the vibrant colours pop and the scene looks three dimensional, Above the mountains the words: \"QUEST FOR BUZZ\" are written in 3D textured lettering, Along the bottom third of the image is the subheading: \"where tf is it?\"",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-09-17T1800:52.5605357Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.85,
                        "modelVersionId": 827309,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 823881,
                        "modelVersionName": "character_flux_v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 747385,
                        "modelVersionName": "flux v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 737325,
                        "modelVersionName": "V1"
                    },
                    {
                        "type": "lora",
                        "weight": 1.1,
                        "modelVersionId": 847401,
                        "modelVersionName": "Flux v1.0"
                    }
                ]
            },
            "username": "FattyGhost",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 29171406,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/581c8741-e786-4dab-905d-30e7177eb98d/width=832/581c8741-e786-4dab-905d-30e7177eb98d.jpeg",
            "hash": "ULGj]V$z0#5S}]r?f9WX^jslI[NLbJRjt7t6",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-13T06:32:16.887Z",
            "postId": 6526867,
            "stats": {
                "cryCount": 20,
                "laughCount": 48,
                "likeCount": 394,
                "dislikeCount": 0,
                "heartCount": 131,
                "commentCount": 0
            },
            "meta": null,
            "username": "Lady_Luminous",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 26110809,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a6b15bf9-042f-4dcf-b711-256be6cd3876/width=864/a6b15bf9-042f-4dcf-b711-256be6cd3876.jpeg",
            "hash": "UTJ%a*?F?^ba?GbvJAV@o}oeV@nikXV@-UWW",
            "width": 864,
            "height": 1152,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-08-25T18:00:49.709Z",
            "postId": 5836474,
            "stats": {
                "cryCount": 15,
                "laughCount": 22,
                "likeCount": 391,
                "dislikeCount": 0,
                "heartCount": 165,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "sdxl_vae.safetensors",
                "Size": "864x1152",
                "seed": 2715789882,
                "Model": "autismmixSDXL_autismmixPony",
                "steps": 30,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "821aa5537f",
                    "lora:jessicarabbitXLP": "c516c20fac7f"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up,   <lora:jessicarabbitXLP:0.6> jessica rabbit, 1girl, red hair, hair over one eye, long hair, cleavage, lipstick, green eyes, elbow gloves, makeup, red dress,full body,",
                "Version": "v1.10.1",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "c516c20fac7f",
                        "name": "jessicarabbitXLP",
                        "type": "lora",
                        "weight": 0.6
                    },
                    {
                        "hash": "821aa5537f",
                        "name": "autismmixSDXL_autismmixPony",
                        "type": "model"
                    }
                ],
                "Model hash": "821aa5537f",
                "Schedule type": "Automatic",
                "negativePrompt": "watermark, signature, artist name, twitter username,"
            },
            "username": "freckledvixon",
            "baseModel": "Pony"
        },
        {
            "id": 24647688,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/38551c23-30d3-4c4d-84cd-7a897c2dff97/width=896/38551c23-30d3-4c4d-84cd-7a897c2dff97.jpeg",
            "hash": "U8AvnH-p4:D*~pxunOIUAIX9xCV?^*oz57V@",
            "width": 896,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-16T21:48:58.392Z",
            "postId": 5507405,
            "stats": {
                "cryCount": 15,
                "laughCount": 101,
                "likeCount": 366,
                "dislikeCount": 0,
                "heartCount": 111,
                "commentCount": 1
            },
            "meta": {
                "Size": "896x1152",
                "seed": 2267459212,
                "Model": "outputbf16",
                "steps": 22,
                "hashes": {
                    "model": "4868d63b8c"
                },
                "prompt": "A rugged middle-aged adventurer stands holding a hand-made sign that reads \u2018Give Me Money\u2019 in bold, rough letters. The man has a scruffy beard, unkempt hair, and wears a worn-out adventurer\u2019s outfit with patched armor and a tattered cloak. His expression is a mix of desperation and determination as he clutches the sign with both hands. The scene is set in a dimly lit tavern or a rundown marketplace, with the sign prominently displayed as he tries to get attention. The background hints at a life of hardship and rough adventures, now reduced to begging in a gritty and harsh world",
                "Version": "f2.0.1v1.10.1-previous-306-g2f0555f7",
                "sampler": "Euler",
                "Module 1": "ae",
                "Module 2": "clip_l",
                "Module 3": "t5xxl_fp16",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "4868d63b8c",
                        "name": "outputbf16",
                        "type": "model"
                    }
                ],
                "Model hash": "4868d63b8c",
                "Schedule type": "Simple",
                "Distilled CFG Scale": "3.5"
            },
            "username": "Aikimi",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 20809482,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cbd9c027-8c9b-4f8f-a039-b2cdde1adb3a/width=1280/cbd9c027-8c9b-4f8f-a039-b2cdde1adb3a.jpeg",
            "hash": "UQE_Ewvg}G-B%2=KRj$*bcOBRjODxuWBoJoL",
            "width": 1280,
            "height": 1856,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-21T21:51:00.872Z",
            "postId": 4641173,
            "stats": {
                "cryCount": 11,
                "laughCount": 28,
                "likeCount": 393,
                "dislikeCount": 0,
                "heartCount": 161,
                "commentCount": 1
            },
            "meta": {
                "seed": 3135080638,
                "vaes": [],
                "Model": "urn:air:sdxl:checkpoint:civitai:128607@577919",
                "steps": 59,
                "width": 832,
                "height": 1216,
                "models": [
                    "urn:air:sdxl:checkpoint:civitai:128607@577919"
                ],
                "prompt": "Create a extrahart, mystical, and high-resolution image of an busty female anthropomorphic a humanoid robot with intricate mechanical components named c3po. The character should be depicted in a manga cover style with wealthy portraiture and poster art elements. The image should feature rich colors and high contrast, focusing on the best quality, official art, and a beautiful and aesthetic appearance. Include fractal art elements and a colorful background with a splash of color. Use a movie perspective and an advertising style, similar to a magazine cover. C3po samurai should be shown solo, wearing Japanese clothes and armor, holding a sheathed katana, and standing in a cowboy shot pose. The robot should have neon green and yellow hip-hop clothes, tattoos, muscular abs, shoulder armor, and a metallic blue flowers in the background. Emphasize a samurai theme with a red background and starwars elements.",
                "denoise": 1,
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 5,
                "modelIds": [],
                "scheduler": "karras",
                "upscalers": [
                    "urn:air:multi:upscaler:civitai:147759@164821"
                ],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "NSFW,low quality,lowres,worst quality,bad anatomy,bad hands,bad feet,logo,text,extra arms,extra ears,extra eyes,extra mouth,multiple wings,extra face,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 577919
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 507973
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 532490
                    },
                    {
                        "type": "lora",
                        "weight": 0.45,
                        "modelVersionId": 296637
                    },
                    {
                        "type": "lora",
                        "weight": 0.65,
                        "modelVersionId": 657273
                    },
                    {
                        "type": "lora",
                        "weight": 0.25,
                        "modelVersionId": 464943
                    },
                    {
                        "type": "upscaler",
                        "modelVersionId": 164821
                    }
                ],
                "additionalResources": [
                    {
                        "name": "urn:air:sdxl:lora:civitai:456315@507973",
                        "type": "lora",
                        "strength": 0.4,
                        "strengthClip": 1
                    },
                    {
                        "name": "urn:air:sdxl:lora:civitai:478819@532490",
                        "type": "lora",
                        "strength": 0.4,
                        "strengthClip": 1
                    },
                    {
                        "name": "urn:air:sdxl:lora:civitai:263107@296637",
                        "type": "lora",
                        "strength": 0.45,
                        "strengthClip": 1
                    },
                    {
                        "name": "urn:air:sdxl:lora:civitai:588698@657273",
                        "type": "lora",
                        "strength": 0.65,
                        "strengthClip": 1
                    },
                    {
                        "name": "urn:air:sdxl:lora:civitai:282753@464943",
                        "type": "lora",
                        "strength": 0.25,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "Ajuro",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 13552251,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/eca29f9d-f534-4cb5-8948-06fc20bbc3af/width=1800/eca29f9d-f534-4cb5-8948-06fc20bbc3af.jpeg",
            "hash": "UA8XLYazM_M{_4RjD$WBIUofIAt7IUxvt8j[",
            "width": 2496,
            "height": 3648,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-05-25T16:25:27.974Z",
            "postId": 3000704,
            "stats": {
                "cryCount": 61,
                "laughCount": 70,
                "likeCount": 323,
                "dislikeCount": 0,
                "heartCount": 139,
                "commentCount": 1
            },
            "meta": null,
            "username": "Hizumi___",
            "baseModel": ""
        },
        {
            "id": 8223900,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/619fecb5-ff76-4347-8407-259dae63fac5/width=1408/619fecb5-ff76-4347-8407-259dae63fac5.jpeg",
            "hash": "UHC$=bypxcR*~otkxaIpNGk9k9RkE2w{WUxt",
            "width": 1408,
            "height": 2048,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-03-19T19:01:50.379Z",
            "postId": 1780504,
            "stats": {
                "cryCount": 14,
                "laughCount": 29,
                "likeCount": 338,
                "dislikeCount": 0,
                "heartCount": 212,
                "commentCount": 2
            },
            "meta": {
                "RNG": "CPU",
                "Size": "704x1024",
                "seed": 899198461,
                "Model": "DucHaiten-Journey-XL_v1.5-TCD+Lightning",
                "steps": 12,
                "hashes": {
                    "model": "04df396d93"
                },
                "prompt": "beautiful charming geisha in cyberpunk style, 8bit pixel art with greenish feeling",
                "Version": "v1.8.0",
                "sampler": "Euler a",
                "cfgScale": 1.5,
                "Mask blur": "4",
                "resources": [
                    {
                        "hash": "04df396d93",
                        "name": "DucHaiten-Journey-XL_v1.5-TCD+Lightning",
                        "type": "model"
                    }
                ],
                "Model hash": "04df396d93",
                "Hires steps": "8",
                "Inpaint area": "Only masked",
                "Hires upscale": "2",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "(worst quality:1.5), (low quality:1.5), (normal quality:1.5), lowres, bad anatomy, bad hands, multiple eyebrow, (cropped), extra limb, missing limbs, deformed hands, long neck, long body, (bad hands), signature, username, artist name, conjoined fingers, deformed fingers, ugly eyes, imperfect eyes, skewed eyes, unnatural face, unnatural body, error, painting by bad-artist",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "23.7.11",
                "Denoising strength": "0.4",
                "ADetailer mask blur": "4",
                "Masked area padding": "32",
                "ADetailer confidence": "0.3",
                "ADetailer dilate/erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "DucHaiten",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 41725239,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/83a825fa-7765-415e-92fc-033ff9415aac/width=1200/83a825fa-7765-415e-92fc-033ff9415aac.jpeg",
            "hash": "UWH0hmwI0#kD}rofE*e-,pn$bwofWVjFxZoy",
            "width": 1200,
            "height": 2400,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-23T23:51:00.000Z",
            "postId": 9500016,
            "stats": {
                "cryCount": 9,
                "laughCount": 7,
                "likeCount": 485,
                "dislikeCount": 0,
                "heartCount": 91,
                "commentCount": 1
            },
            "meta": null,
            "username": "Dan81mai",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 39982185,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e2cee808-3c12-4d44-ab7c-f0e904625a62/width=832/e2cee808-3c12-4d44-ab7c-f0e904625a62.jpeg",
            "hash": "U75Ys88x.kHt%}Q.%yMeoyj[j?oyIBx[V[oy",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-14T00:27:01.897Z",
            "postId": 9114831,
            "stats": {
                "cryCount": 8,
                "laughCount": 21,
                "likeCount": 471,
                "dislikeCount": 0,
                "heartCount": 92,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1735801902,
                "Model": "flux1-dev-bnb-nf4-v2",
                "steps": 30,
                "hashes": {
                    "model": "bea01d51bd",
                    "lora:FluxMythP0rtr4itStyle": "8ea428b224a8",
                    "lora:Elden_Ring_-_Yoshitaka_Amano": "dd42bab761bd",
                    "lora:flux.1_lora_flyway_Epic-Characters_v1": "B73E077D02BF"
                },
                "prompt": "a line of medieval archers standing in formation along a stone wall. The style is dark and atmospheric, with a focus on detailed armor and weaponry. The archers are clad in green and metallic armor, with helmets obscuring their faces, giving them an anonymous and uniform appearance. Each archer holds a longbow and has a quiver of arrows slung over their back. The background features a towering, shadowy castle, adding to the ominous and foreboding mood. The color palette is dominated by dark greens and grays, enhancing the medieval and mysterious theme of the scene. <lora:FluxMythP0rtr4itStyle:0.6> <lora:flux.1_lora_flyway_Epic-Characters_v1:0.6> <lora:Elden_Ring_-_Yoshitaka_Amano:0.33>",
                "Version": "f2.0.1v1.10.1-previous-519-g44eb4ea8",
                "sampler": "Euler",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "8ea428b224a8",
                        "name": "FluxMythP0rtr4itStyle",
                        "type": "lora",
                        "weight": 0.6
                    },
                    {
                        "hash": "B73E077D02BF",
                        "name": "flux.1_lora_flyway_Epic-Characters_v1",
                        "type": "lora",
                        "weight": 0.6
                    },
                    {
                        "hash": "dd42bab761bd",
                        "name": "Elden_Ring_-_Yoshitaka_Amano",
                        "type": "lora",
                        "weight": 0.33
                    },
                    {
                        "hash": "bea01d51bd",
                        "name": "flux1-dev-bnb-nf4-v2",
                        "type": "model"
                    }
                ],
                "Model hash": "bea01d51bd",
                "Schedule type": "Simple",
                "Distilled CFG Scale": "3.5",
                "Diffusion in Low Bits": "Automatic (fp16 LoRA)"
            },
            "username": "VelvetS",
            "baseModel": null
        },
        {
            "id": 39533963,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0d827c68-3cf6-4b51-ad39-5c32b9d0336f/width=768/0d827c68-3cf6-4b51-ad39-5c32b9d0336f.jpeg",
            "hash": "U6Ndm^~q00_3xWj[-:xabwWB?HjZIUj[4nWB",
            "width": 768,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-11T11:04:09.150Z",
            "postId": 9016861,
            "stats": {
                "cryCount": 17,
                "laughCount": 26,
                "likeCount": 417,
                "dislikeCount": 0,
                "heartCount": 133,
                "commentCount": 1
            },
            "meta": null,
            "username": "andux",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 36213916,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6e9eac0e-682d-4eaf-9717-72afabea9245/width=832/6e9eac0e-682d-4eaf-9717-72afabea9245.jpeg",
            "hash": "UEGHDZ]wHb=#0cESI+F;.pFg?s;n+[}lXVE3",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-24T00:48:04.145Z",
            "postId": 8273541,
            "stats": {
                "cryCount": 22,
                "laughCount": 35,
                "likeCount": 432,
                "dislikeCount": 0,
                "heartCount": 103,
                "commentCount": 1
            },
            "meta": {
                "seed": 94,
                "vaes": [],
                "Model": "sd3.5_large",
                "comfy": "{\"prompt\": {\"4\": {\"inputs\": {\"ckpt_name\": \"sd3.5_large.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"6\": {\"inputs\": {\"text\": [\"313\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"294\", 0], \"vae\": [\"4\", 2]}, \"class_type\": \"VAEDecode\"}, \"11\": {\"inputs\": {\"clip_name1\": \"clip_g.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"clip_name3\": \"t5xxl_fp16.safetensors\"}, \"class_type\": \"TripleCLIPLoader\"}, \"13\": {\"inputs\": {\"shift\": 3.0, \"model\": [\"4\", 0]}, \"class_type\": \"ModelSamplingSD3\"}, \"67\": {\"inputs\": {\"conditioning\": [\"71\", 0]}, \"class_type\": \"ConditioningZeroOut\"}, \"68\": {\"inputs\": {\"start\": 0.1, \"end\": 1.0, \"conditioning\": [\"67\", 0]}, \"class_type\": \"ConditioningSetTimestepRange\"}, \"69\": {\"inputs\": {\"conditioning_1\": [\"68\", 0], \"conditioning_2\": [\"70\", 0]}, \"class_type\": \"ConditioningCombine\"}, \"70\": {\"inputs\": {\"start\": 0.0, \"end\": 0.1, \"conditioning\": [\"71\", 0]}, \"class_type\": \"ConditioningSetTimestepRange\"}, \"71\": {\"inputs\": {\"text\": \"\", \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"135\": {\"inputs\": {\"width\": [\"303\", 0], \"height\": [\"303\", 1], \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"294\": {\"inputs\": {\"seed\": 94, \"steps\": 32, \"cfg\": 4.0, \"sampler_name\": \"deis\", \"scheduler\": \"ddim_uniform\", \"denoise\": 1.0, \"model\": [\"304\", 0], \"positive\": [\"6\", 0], \"negative\": [\"69\", 0], \"latent_image\": [\"135\", 0]}, \"class_type\": \"KSampler\"}, \"301\": {\"inputs\": {\"filename_prefix\": \"ComfyUI/SD3.5/Output-deis-ddim_uniform-4-32S\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"303\": {\"inputs\": {\"resolution\": \"portrait - 832x1216 (2:3)\"}, \"class_type\": \"SDXL Resolutions (JPS)\"}, \"304\": {\"inputs\": {\"backend\": \"inductor\", \"model\": [\"13\", 0]}, \"class_type\": \"TorchCompileModel\"}, \"308\": {\"inputs\": {\"grid_spacing\": 0, \"save_individuals\": false, \"flip_xy\": false, \"x_plot\": \"\", \"y_plot\": \"\", \"z_plot\": \"\"}, \"class_type\": \"ttN advanced xyPlot\"}, \"309\": {\"inputs\": {\"grid_spacing\": 5, \"save_individuals\": true, \"flip_xy\": false, \"x_plot\": \"\", \"y_plot\": \"\", \"z_plot\": \"\"}, \"class_type\": \"ttN advanced xyPlot\"}, \"312\": {\"inputs\": {\"shotstyle\": \"body shot\\n\", \"haircuts_Thomas_Buyle\": \"Double Bun\\n\", \"image_quality\": \"disabled\", \"Special_Places_Malapris\": \"disabled\", \"Cameras\": \"disabled\", \"Places\": \"in a bustling city\\n\", \"Woman\": \"a voluptuous woman\\n\", \"lighting\": \"cinematic lighting\\n\", \"Artists\": \"disabled\", \"Woman_Dress_Malapris_PJ\": \"Swimwear High-waisted bikini with a ruffle top and matching bottoms\\n\", \"haircolors_Thomas_Buyle\": \"Ginger hair\\n\", \"Celebrity_Woman\": \"disabled\", \"Prompt_count\": 1, \"CreaPrompt_Collection\": \"enabled\", \"seed\": 2}, \"class_type\": \"CreaPrompt_1\", \"is_changed\": NaN}, \"313\": {\"inputs\": {\"delimiter\": \"none\", \"text1\": [\"312\", 0]}, \"class_type\": \"Text Concatenate (JPS)\"}}, \"workflow\": {\"last_node_id\": 314, \"last_link_id\": 617, \"nodes\": [{\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1183, \"1\": -586}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 572}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 605}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [606], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 135, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 471, \"1\": -422}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 607, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 608, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [598], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [1024, 1024, 1], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 105, \"type\": \"Note\", \"pos\": {\"0\": 570, \"1\": -105}, \"size\": {\"0\": 210, \"1\": 110.18948364257812}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"Make sure the resolution is multiple of 64 pixels and adds up to around 1 megapixel. \"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 4, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": 74, \"1\": -600}, \"size\": {\"0\": 632.6060180664062, \"1\": 98}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [611], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": null, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [605], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"sd3.5_large.safetensors\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 306, \"type\": \"OllamaAPI\", \"pos\": {\"0\": 716, \"1\": 388}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {}, \"order\": 2, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"OllamaAPI\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"What is the meaning of life?\", \"llama2\", 0], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 308, \"type\": \"ttN advanced xyPlot\", \"pos\": {\"0\": 1325, \"1\": 671}, \"size\": {\"0\": 400, \"1\": 248}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"adv_xyPlot\", \"type\": \"ADV_XYPLOT\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"ttN advanced xyPlot\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}, \"ttNnodeVersion\": \"1.2.0\"}, \"widgets_values\": [0, false, false, \"\", \"\", \"\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 310, \"type\": \"GetNode\", \"pos\": {\"0\": 708, \"1\": 727}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"*\", \"type\": \"*\", \"links\": null}], \"properties\": {\"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 309, \"type\": \"ttN advanced xyPlot\", \"pos\": {\"0\": 916, \"1\": 688}, \"size\": {\"0\": 400, \"1\": 248}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"adv_xyPlot\", \"type\": \"ADV_XYPLOT\", \"links\": null, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"ttN advanced xyPlot\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}, \"ttNnodeVersion\": \"1.2.0\"}, \"widgets_values\": [5, true, false, \"\", \"\", \"\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 11, \"type\": \"TripleCLIPLoader\", \"pos\": {\"0\": 93, \"1\": -432}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [5, 94], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"TripleCLIPLoader\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"clip_g.safetensors\", \"clip_l.safetensors\", \"t5xxl_fp16.safetensors\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 304, \"type\": \"TorchCompileModel\", \"pos\": {\"0\": 755, \"1\": -638}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 612}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [613], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"TorchCompileModel\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"inductor\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 67, \"type\": \"ConditioningZeroOut\", \"pos\": {\"0\": 580, \"1\": 46}, \"size\": {\"0\": 211.60000610351562, \"1\": 26}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 597}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [90], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningZeroOut\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 69, \"type\": \"ConditioningCombine\", \"pos\": {\"0\": 967, \"1\": 164}, \"size\": {\"0\": 228.39999389648438, \"1\": 46}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning_1\", \"type\": \"CONDITIONING\", \"link\": 91}, {\"name\": \"conditioning_2\", \"type\": \"CONDITIONING\", \"link\": 92}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [604], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningCombine\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 68, \"type\": \"ConditioningSetTimestepRange\", \"pos\": {\"0\": 807, \"1\": 25}, \"size\": {\"0\": 317.4000244140625, \"1\": 82}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 90}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [91], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningSetTimestepRange\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [0.1, 1], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 389, \"1\": -276}, \"size\": {\"0\": 342.8335266113281, \"1\": 177.20867919921875}, \"flags\": {\"collapsed\": true}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 5}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 615, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [569], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"A photorealistic 4K image of a woman with transparent, crystal-like skin, glowing from within with a soft golden light, her hair flowing like liquid metal, surrounded by an aura of shimmering particles. , RAW photo, subject, 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3, 4K, photorealistic, High dynamic range, vivid, rich details, clear shadows and highlights, realistic, intense, enhanced contrast, highly detailed, long shot scenic professional photograph of , perfect viewpoint, highly detailed, wide-angle lens, hyper realistic, with dramatic sky, polarizing filter, natural lighting, vivid colors, everything in sharp focus, HDR, UHD, 64K\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 313, \"type\": \"Text Concatenate (JPS)\", \"pos\": {\"0\": 65, \"1\": -255}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"text1\", \"type\": \"STRING\", \"link\": 616, \"widget\": {\"name\": \"text1\"}, \"shape\": 7}, {\"name\": \"text2\", \"type\": \"STRING\", \"link\": 617, \"widget\": {\"name\": \"text2\"}, \"shape\": 7}, {\"name\": \"text3\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"text3\"}, \"shape\": 7}, {\"name\": \"text4\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"text4\"}, \"shape\": 7}, {\"name\": \"text5\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"text5\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"links\": [615], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"Text Concatenate (JPS)\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"none\", \"\", \"\", \"\", \"\", \"\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 311, \"type\": \"Note\", \"pos\": {\"0\": -485, \"1\": 113}, \"size\": {\"0\": 351.35546875, \"1\": 474.9572448730469}, \"flags\": {\"collapsed\": false}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"HDR Photography of a ginger haired man smoking a spliff in his dim bedroom\\n\\n\\nGlossy, shiny, Armor, helmet, easynegative, BadDream, missing limbs, missing legs, atrocity, boring, camera, Watermark, Text, censored, deformed, bad anatomy, disfigured, poorly drawn face, mutated, extra limb, ugly, poorly drawn hands, missing limb, floating limbs, disconnected limbs, disconnected head, malformed hands, long neck, mutated hands and fingers, bad hands, missing fingers, cropped, worst quality, low quality, mutation, poorly drawn, huge calf, bad hands, fused hand, missing hand, disappearing arms, disappearing thigh, disappearing calf, disappearing legs, missing fingers, fused fingers, abnormal eye proportion, Abnormal hands, abnormal legs, abnormal feet, abnormal fingers, cartoon, painting, illustration, (worst quality, low quality, normal quality:2)\\n\\n\\nAn Abstract surreal symbolic portrait, made of intertwining religions, weaving over and under each other, emphasis effect, moire effect, awash in colorful shades, seamlessly extends the lines,\\nA high-resolution photograph of a curvy sexy trashy 18-year-old black woman with dark skin. The woman is wearing tight gaudy gold jewelry and tight yoga leggings and high-heeled half-boots and heavy makeup and hoop earrings. The woman is topless and shirtless and braless and fully exposing her huge, saggy breasts and nipples, and she also has pouty glossy lips and a big round ass. The woman is wearing her hair in a high ponytail. The woman is a sultry and alluring. The woman is standing outdoors in front of a tree with a suggestive smirk on her face. The woman is directly facing the camera.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 305, \"type\": \"SDXL Prompt Styler (JPS)\", \"pos\": {\"0\": 336, \"1\": 303}, \"size\": {\"0\": 400, \"1\": 380}, \"flags\": {}, \"order\": 8, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"text_positive_g\", \"type\": \"STRING\", \"links\": null, \"slot_index\": 0}, {\"name\": \"text_positive_l\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"text_positive\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"text_negative\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"SDXL Prompt Styler (JPS)\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"dripping dark pink and Tech, Welkin Guide, Masquerade, \\\"Through the lens of poetry, ordinary moments transform into extraordinary tales of the human experience.\\\", \\\"Baby, you're a firework, come on, show 'em what you're worth.\\\", luxurious, dynamic background, beautiful detailed, romantic, original, vibrant\", \"dripping dark pink and Tech, Welkin Guide, Masquerade, \\\"Through the lens of poetry, ordinary moments transform into extraordinary tales of the human experience.\\\", \\\"Baby, you're a firework, come on, show 'em what you're worth.\\\", luxurious, dynamic background, beautiful detailed, romantic, original, vibrant\", \"Low quality, blurry, distorted\", \"none\", \"none\", \"Hyperrealism\", \"ON\", \"ON\", \"ON\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 13, \"type\": \"ModelSamplingSD3\", \"pos\": {\"0\": 426, \"1\": -728}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {\"collapsed\": false}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 611}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [612], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingSD3\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [3], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 301, \"type\": \"SaveImage\", \"pos\": {\"0\": 1244, \"1\": -301}, \"size\": {\"0\": 688.912109375, \"1\": 801.5050048828125}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 606}], \"outputs\": [], \"properties\": {\"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"ComfyUI/SD3.5/Output-%SAMPLER.sampler_name%-%SAMPLER.scheduler%-%SAMPLER.cfg%-%SAMPLER.steps%S\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 71, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 221, \"1\": -19}, \"size\": {\"0\": 351.8130798339844, \"1\": 195.57545471191406}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 94}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [93, 597], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 70, \"type\": \"ConditioningSetTimestepRange\", \"pos\": {\"0\": 596, \"1\": 154}, \"size\": [235.1999969482422, 88.18728770894012], \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 93, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [92], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningSetTimestepRange\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [0, 0.1], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 314, \"type\": \"ttN text\", \"pos\": {\"0\": -352, \"1\": -135}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {}, \"order\": 9, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"links\": [617], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"ttN text\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}, \"ttNnodeVersion\": \"1.0.0\"}, \"widgets_values\": [\"Candid photo of a beautiful British ginger instagram girl lying in bed, wearing skimpy red lingerie, with huge breasts.\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 312, \"type\": \"CreaPrompt_1\", \"pos\": {\"0\": -343, \"1\": -641}, \"size\": {\"0\": 315, \"1\": 438}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [616], \"slot_index\": 0}, {\"name\": \"seed\", \"type\": \"INT\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"CreaPrompt_1\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"body shot\\n\", \"Double Bun\\n\", \"disabled\", \"disabled\", \"disabled\", \"in a bustling city\\n\", \"a voluptuous woman\\n\", \"cinematic lighting\\n\", \"disabled\", \"Swimwear High-waisted bikini with a ruffle top and matching bottoms\\n\", \"Ginger hair\\n\", \"disabled\", 1, \"enabled\", 2, \"fixed\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 303, \"type\": \"SDXL Resolutions (JPS)\", \"pos\": {\"0\": 464, \"1\": -239}, \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [607], \"slot_index\": 0}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [608], \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"SDXL Resolutions (JPS)\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [\"portrait - 832x1216 (2:3)\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 294, \"type\": \"KSampler\", \"pos\": {\"0\": 814, \"1\": -558}, \"size\": {\"0\": 378, \"1\": 504}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 613}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 569}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 604}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 598}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [572], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMPLER\", \"ttNbgOverride\": {\"color\": \"#233\", \"bgcolor\": \"#355\", \"groupcolor\": \"#8AA\"}}, \"widgets_values\": [94, \"increment\", 32, 4, \"deis\", \"ddim_uniform\", 1], \"color\": \"#233\", \"bgcolor\": \"#355\"}], \"links\": [[5, 11, 0, 6, 0, \"CLIP\"], [90, 67, 0, 68, 0, \"CONDITIONING\"], [91, 68, 0, 69, 0, \"CONDITIONING\"], [92, 70, 0, 69, 1, \"CONDITIONING\"], [93, 71, 0, 70, 0, \"CONDITIONING\"], [94, 11, 0, 71, 0, \"CLIP\"], [569, 6, 0, 294, 1, \"CONDITIONING\"], [572, 294, 0, 8, 0, \"LATENT\"], [597, 71, 0, 67, 0, \"CONDITIONING\"], [598, 135, 0, 294, 3, \"LATENT\"], [604, 69, 0, 294, 2, \"CONDITIONING\"], [605, 4, 2, 8, 1, \"VAE\"], [606, 8, 0, 301, 0, \"IMAGE\"], [607, 303, 0, 135, 0, \"INT\"], [608, 303, 1, 135, 1, \"INT\"], [611, 4, 0, 13, 0, \"MODEL\"], [612, 13, 0, 304, 0, \"MODEL\"], [613, 304, 0, 294, 0, \"MODEL\"], [615, 313, 0, 6, 1, \"STRING\"], [616, 312, 0, 313, 0, \"STRING\"], [617, 314, 0, 313, 1, \"STRING\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.922959981770655, \"offset\": [-714.1309701441364, 474.47069839387365]}}, \"version\": 0.4}}",
                "steps": 32,
                "width": {
                    "inputs": {
                        "resolution": "portrait - 832x1216 (2:3)"
                    },
                    "class_type": "SDXL Resolutions (JPS)"
                },
                "height": {
                    "inputs": {
                        "resolution": "portrait - 832x1216 (2:3)"
                    },
                    "class_type": "SDXL Resolutions (JPS)"
                },
                "models": [
                    "sd3.5_large.safetensors"
                ],
                "denoise": 1,
                "sampler": "deis",
                "cfgScale": 4,
                "modelIds": [],
                "scheduler": "ddim_uniform",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": []
            },
            "username": "Solid_Supermarket974321",
            "baseModel": "SD 3.5"
        },
        {
            "id": 35736330,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1fd28dbf-aa39-4972-9eac-945f6db7f4ab/width=832/1fd28dbf-aa39-4972-9eac-945f6db7f4ab.jpeg",
            "hash": "UYKA.:EL0L$%}]Rjs:WB=|RPWqxH=ebHE2xa",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-21T07:08:10.299Z",
            "postId": 8166012,
            "stats": {
                "cryCount": 22,
                "laughCount": 47,
                "likeCount": 407,
                "dislikeCount": 0,
                "heartCount": 116,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 204062223,
                "steps": 14,
                "prompt": "serene mystical scene, lake, an ancient magical glowing temple stands top of a small island, focus temple, pink white mist. elegance. Cherry blossom trees in full bloom line the shore, soft, weak sunlight, ethereal glow, peaceful solitude,natural beauty, vivid colors, pastel colors, Gorgeous splash of vibrant paint,, masterpiece, award winning, Ukiyo-e Art, Style-Japan, John Martin Style page",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-20T1024:09.6394634Z",
                "negativePrompt": "ugly,  deformed, low quality, worst quality, normal quality, watermark, logo, signature",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 128078,
                        "modelVersionName": "v1.0 VAE fix"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 135867,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 154278,
                        "modelVersionName": "SD XL"
                    },
                    {
                        "type": "lora",
                        "weight": 0.85,
                        "modelVersionId": 747171,
                        "modelVersionName": "SDXL v3.0"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 6046,
                        "modelVersionName": "1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 153845,
                        "modelVersionName": "SD XL"
                    },
                    {
                        "type": "dora",
                        "weight": 1,
                        "modelVersionId": 492278,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.6,
                        "modelVersionId": 665638,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Lady_Luminous",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 35725092,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/07b85aef-b106-4732-b710-3d943f6d508f/width=832/07b85aef-b106-4732-b710-3d943f6d508f.jpeg",
            "hash": "UTFrha?GD*Io~V-SbFW?r=r=oet7RPRkt7xa",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-21T05:20:53.467Z",
            "postId": 8163368,
            "stats": {
                "cryCount": 21,
                "laughCount": 44,
                "likeCount": 418,
                "dislikeCount": 0,
                "heartCount": 109,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3379471303,
                "extra": {
                    "remixOfId": 32748172
                },
                "steps": 17,
                "prompt": "Create an amazing oil painting Pic of the following situation: a giant white fog appears high above an Asian landscape, some Houses,vivid natural colors, bright, amazing landscape, perfect composition, a rich and complex image of nature, a vibrant tissue of hues and textures captured digitally, best quality, double exposure, realistic, captivating, fantastical, splash art, intricately detailed, hyper detailed, maximalist style, photorealistic, concept art, sharp focus, harmony, serenity, calm, mysterious glow, dynamic lighting, masterpiece, superb composition, finest details, highest aesthetics, strong muted highlighter of fantastical beach rock scenery, mystical glow, best quality, sharp focus, high contrast, stylized, clear, colorful, ultra quality, 8k, best quality, masterpiece,midjourneyv6.1",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 3.4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-20T1403:14.2836699Z",
                "negativePrompt": "text, logo, watermark, signature, bad quality, low quality, deformed",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 291443,
                        "modelVersionName": "v24"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 723149,
                        "modelVersionName": "SDXL"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Lady_Luminous",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 35141532,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f4f0d72e-5863-49a9-84c8-a1a60a43a4ec/width=1536/f4f0d72e-5863-49a9-84c8-a1a60a43a4ec.jpeg",
            "hash": "U5A0zT~W00bH1QtSvxi^KSD*DiM{+rs:NyM{",
            "width": 1536,
            "height": 2304,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-17T22:23:14.705Z",
            "postId": 8031748,
            "stats": {
                "cryCount": 12,
                "laughCount": 39,
                "likeCount": 428,
                "dislikeCount": 0,
                "heartCount": 113,
                "commentCount": 12
            },
            "meta": {
                "Size": "1024x1536",
                "seed": 4234843566,
                "Model": "wildcardxXLFusion_fusionOG",
                "steps": 20,
                "hashes": {
                    "model": "22ebc61141"
                },
                "Version": "v1.10.1",
                "sampler": "Euler a",
                "cfgScale": 7,
                "Mask blur": "4",
                "resources": [
                    {
                        "hash": "22ebc61141",
                        "name": "wildcardxXLFusion_fusionOG",
                        "type": "model"
                    }
                ],
                "Model hash": "22ebc61141",
                "Schedule type": "Automatic",
                "Denoising strength": "0"
            },
            "username": "Castr0",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 33805171,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/87f77a5a-e50b-46ac-b9ca-3cfd3f13d55a/width=896/87f77a5a-e50b-46ac-b9ca-3cfd3f13d55a.jpeg",
            "hash": "UMG+5B~o?atQ5p%Kx[t700IBR6s,xsNHMyWB",
            "width": 896,
            "height": 1344,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-10T12:45:11.212Z",
            "postId": 7727807,
            "stats": {
                "cryCount": 16,
                "laughCount": 53,
                "likeCount": 409,
                "dislikeCount": 0,
                "heartCount": 114,
                "commentCount": 0
            },
            "meta": {
                "Size": "896x1344",
                "seed": 259203927,
                "Model": "flux1-dev-fp8",
                "steps": 20,
                "hashes": {
                    "model": "275ef623d3",
                    "lora:qihuan222 (1)": "5ab12a96f099",
                    "lora:qihuan222 (2)": "cfa60fe5766d"
                },
                "prompt": "This is a highly detailed, CGI-rendered image depicting a chaotic and dramatic scene. The central focus is a massive, swirling tornado that dominates the upper half of the image, engulfing a UFO. The UFO is a metallic, disc-shaped object with a smooth, reflective surface, and it is being violently sucked into the tornado. The tornado is a swirling mass of dark grey and brown clouds with a turbulent, swirling texture, creating a sense of immense power and destruction.\nIn the foreground, a classic, 1960s-era American sedan with a beige body and a black roof is driving down a dusty, barren road. The car is moving at high speed, with a cloud of dust and debris trailing behind it. Surrounding the car are other vehicles, including a blue sedan, a red pickup truck, and a yellow convertible, all of which are also in motion and being thrown around by the tornado.\nThe background features a vast, open desert landscape with sparse vegetation, and the sky is a mix of dark, ominous clouds and patches of sunlight, suggesting either a stormy or post-storm setting. The overall mood of the image is intense and chaotic, with a sense of urgency and danger.\n  <lora:qihuan222 (1):0.2> <lora:qihuan222 (2):1>",
                "Version": "f2.0.1v1.10.1-previous-545-gf5190349",
                "sampler": "Euler",
                "Module 1": "t5xxl_fp8_e4m3fn",
                "Module 2": "clip_l",
                "Module 3": "ae",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "5ab12a96f099",
                        "name": "qihuan222 (1)",
                        "type": "lora"
                    },
                    {
                        "hash": "cfa60fe5766d",
                        "name": "qihuan222 (2)",
                        "type": "lora"
                    },
                    {
                        "hash": "275ef623d3",
                        "name": "flux1-dev-fp8",
                        "type": "model"
                    }
                ],
                "Model hash": "275ef623d3",
                "Schedule type": "Simple",
                "Distilled CFG Scale": "3.5"
            },
            "username": "FellowTaoists",
            "baseModel": ""
        },
        {
            "id": 33769477,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ccb092ce-6c30-4d31-a667-7d7624d34b12/width=864/ccb092ce-6c30-4d31-a667-7d7624d34b12.jpeg",
            "hash": "UmMQV2t7yCx[~pofoeoeEMoz$jjG-:WVtQj[",
            "width": 864,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-10T03:15:45.116Z",
            "postId": 7720906,
            "stats": {
                "cryCount": 19,
                "laughCount": 53,
                "likeCount": 377,
                "dislikeCount": 0,
                "heartCount": 143,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "sdxl_vae.safetensors",
                "Size": "864x1152",
                "seed": 632245532,
                "Model": "autismmixSDXL_autismmixPony",
                "steps": 30,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "821aa5537f",
                    "lora:HaranikalaXLP": "5b9ddcd2c300"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up,  <lora:HaranikalaXLP:1> hara, 1girl, fish, solo, goldfish, skirt, bag, black hair, from behind, shirt, black skirt, short sleeves, arms behind back, white shirt",
                "Version": "v1.10.1",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "5b9ddcd2c300",
                        "name": "HaranikalaXLP",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "821aa5537f",
                        "name": "autismmixSDXL_autismmixPony",
                        "type": "model"
                    }
                ],
                "Model hash": "821aa5537f",
                "Schedule type": "Automatic",
                "negativePrompt": "watermark, signature, artist name, twitter username, censored, realistic,",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.9.0",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.3",
                "ADetailer inpaint only masked": "True"
            },
            "username": "freckledvixon",
            "baseModel": "Pony"
        },
        {
            "id": 33608079,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4ae4f64b-bfa1-491a-9cea-d8d855c98877/width=832/4ae4f64b-bfa1-491a-9cea-d8d855c98877.jpeg",
            "hash": "UYIg+Uf+D%sT}ts:kWWWrwbas.oLs.V[o2t6",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-09T04:28:48.851Z",
            "postId": 7686061,
            "stats": {
                "cryCount": 17,
                "laughCount": 44,
                "likeCount": 421,
                "dislikeCount": 0,
                "heartCount": 110,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 4278794043,
                "steps": 24,
                "prompt": "stunning artwork, psychodelic scenic japan night landscape, sakura garden, mountains, lake, perfect composition, full moon, haze, low angle, masterpiece, award winning,, ultra detailed, highly detailed, 8k, uhd",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 3.8,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-08T1542:59.7531964Z",
                "negativePrompt": "ugly,  deformed, low quality, worst quality, normal quality, watermark, logo, signature",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 128078,
                        "modelVersionName": "v1.0 VAE fix"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 135867,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Lady_Luminous",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 33576443,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/42244b90-6d09-481f-b112-86a07732b00c/width=1800/42244b90-6d09-481f-b112-86a07732b00c.jpeg",
            "hash": "U9E3bl^Q8^n#}ZwI4nRjU_R+J$ShQmj@.StS",
            "width": 2048,
            "height": 2048,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-09T00:45:17.481Z",
            "postId": 7679501,
            "stats": {
                "cryCount": 29,
                "laughCount": 55,
                "likeCount": 381,
                "dislikeCount": 0,
                "heartCount": 127,
                "commentCount": 0
            },
            "meta": {
                "seed": 186789830055524,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\clip_l.safetensors\", \"clip_name2\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux_dev.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"beta\", \"steps\": 40, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 186789830055524}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 4.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": 1024, \"height\": 1024, \"model\": [\"156\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.4, \"alpha\": 0.4, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.5, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.05, \"scale\": 100.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"156\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 1], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"71\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.4, \"alpha\": 0.4, \"image\": [\"69\", 0]}, \"class_type\": \"ImageSharpen\"}, \"73\": {\"inputs\": {\"intensity\": 0.1, \"scale\": 100.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"71\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.5, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"beta\", \"steps\": 15, \"denoise\": 0.2, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"photorealistic portrayal of a female warrior encased in a heavily armored mech suit. Her suit is a blend of futuristic technology and combat-ready functionality, featuring an array of weapons systems integrated into the massive arm attachments that extend from her shoulders. The suit\\u2019s armor is primarily white, with black and gray accents that add depth and dimension, while bright neon teal lights highlight various functional parts. These glowing teal lights can be seen on the chest, arms, and legs, giving the suit an otherworldly, cybernetic appearance. The armor is meticulously detailed with visible screws, hydraulic systems, and joint mechanisms, which suggest enhanced strength and agility. Her face, framed by soft, pink hair, is calm and determined, contrasting with the industrial and formidable design of her suit. The background is  brick wall with a small hole on the center, a utility pole with attached electrical panel right behind her,   allowing the intricate details of the suit to stand out, showcasing the character as a powerful blend of human and machine.\\n\\nWith one arm resting on her hip, the other extended behind her, her pink hair flowing over her shoulder.\\n\", \"clip\": [\"156\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"155\": {\"inputs\": {\"lora_name\": \"flux1\\\\aeshteticv3.safetensors\", \"strength_model\": 0.5, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"156\": {\"inputs\": {\"lora_name\": \"flux1\\\\realism_lora_comfy flux_converted.safetensors\", \"strength_model\": 0.7000000000000001, \"strength_clip\": 1.0, \"model\": [\"155\", 0], \"clip\": [\"155\", 1]}, \"class_type\": \"LoraLoader\"}}, \"workflow\": {\"last_node_id\": 178, \"last_link_id\": 395, \"nodes\": [{\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 450, \"1\": 1353}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 289}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 884, \"1\": 975}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 100, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 511, \"1\": -87}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 876, \"1\": 785}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 289], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 324, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 1024, 1024]}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1465, \"1\": 40}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -124}, \"size\": [75, 26], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 1, \"1\": 308}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1199, \"1\": 23}, \"size\": {\"0\": 245.11636352539062, \"1\": 82}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 283, \"1\": -178}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 356}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 893, \"1\": 37}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": [], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [186789830055524, \"randomize\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 516, \"1\": 895}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": 0, \"1\": 40}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux_dev.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 17, \"1\": 780}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {\"collapsed\": true}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 342, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [1024, 1024, 1]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -5, \"1\": 183}, \"size\": {\"0\": 302.84521484375, \"1\": 109.7906265258789}, \"flags\": {\"collapsed\": true}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [333], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\clip_l.safetensors\", \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"flux\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 877, \"1\": 1284}, \"size\": {\"0\": 324.046875, \"1\": 80.85858154296875}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1457, \"1\": 152}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 350}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [390], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 862, \"1\": 628}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.4, 0.4], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1210, \"1\": 848}, \"size\": {\"0\": 513.1029052734375, \"1\": 947.150634765625}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 1721, \"1\": 58}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 390}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [391], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.4, 0.4], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 1780, \"1\": 855}, \"size\": {\"0\": 510.7679443359375, \"1\": 941.9960327148438}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1594, \"1\": 248}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 58, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 391}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [392], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.75, 0.08, 0.98, 1, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 154, \"type\": \"LoraLoader\", \"pos\": {\"0\": -760, \"1\": 594}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 25, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 347}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 348}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [326], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [327], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Echi_Anime_Style_FLUX.safetensors\", 0.5, 1]}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1228, \"1\": 152}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [393], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 238, \"1\": -91}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [4], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 483, \"1\": 998}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"beta\", 40, 1]}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1611, \"1\": 476}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 392}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.1, 100, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1617, \"1\": 666}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [394], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"beta\", 15, 0.2], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 161, \"type\": \"LoraLoader\", \"pos\": {\"0\": -755, \"1\": 406}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 24, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 343}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 344}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [347], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [348], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\AniVerse_flux_lora_01.safetensors\", 1, 1]}, {\"id\": 160, \"type\": \"LoraLoader\", \"pos\": {\"0\": -381, \"1\": 424}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 22, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 346}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 345}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [343], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [344], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\DWchinese_doll_likeliness_Flux_v10.safetensors\", 1, 1]}, {\"id\": 153, \"type\": \"LoraLoader\", \"pos\": {\"0\": -10, \"1\": 421}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 26, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 326}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 327}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [324], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [356], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\XT404.BOOBS-Bastic.XXL.safetensors\", 0.45, 1]}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -50}, \"size\": [75, 26], \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 883, \"1\": 1143}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.5], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 833, \"1\": 31}, \"size\": [314.04484038830265, 531.5429675963896], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": [], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1218, \"1\": 254}, \"size\": {\"0\": 334.8955383300781, \"1\": 535.3447265625}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 393, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 394, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [350], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 615, \"1\": 643}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1024, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 387, \"1\": 647}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 342], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1024, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 156, \"type\": \"LoraLoader\", \"pos\": {\"0\": -409, \"1\": 606}, \"size\": {\"0\": 350.4808654785156, \"1\": 126}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 330}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 331}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [346], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [345], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\realism_lora_comfy flux_converted.safetensors\", 0.7000000000000001, 1]}, {\"id\": 155, \"type\": \"LoraLoader\", \"pos\": {\"0\": -21, \"1\": 600}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 332}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 333}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [330], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [331], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\aeshteticv3.safetensors\", 0.5, 1]}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 340, \"1\": 23}, \"size\": {\"0\": 413.48834228515625, \"1\": 487.7874450683594}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"photorealistic portrayal of a female warrior encased in a heavily armored mech suit. Her suit is a blend of futuristic technology and combat-ready functionality, featuring an array of weapons systems integrated into the massive arm attachments that extend from her shoulders. The suit\\u2019s armor is primarily white, with black and gray accents that add depth and dimension, while bright neon teal lights highlight various functional parts. These glowing teal lights can be seen on the chest, arms, and legs, giving the suit an otherworldly, cybernetic appearance. The armor is meticulously detailed with visible screws, hydraulic systems, and joint mechanisms, which suggest enhanced strength and agility. Her face, framed by soft, pink hair, is calm and determined, contrasting with the industrial and formidable design of her suit. The background is  brick wall with a small hole on the center, a utility pole with attached electrical panel right behind her,   allowing the intricate details of the suit to stand out, showcasing the character as a powerful blend of human and machine.\\n\\nWith one arm resting on her hip, the other extended behind her, her pink hair flowing over her shoulder.\\n\"]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [285, 75, 0, 59, 0, \"IMAGE\"], [288, 62, 0, 41, 0, \"IMAGE\"], [289, 61, 0, 77, 1, \"IMAGE\"], [324, 153, 0, 30, 0, \"MODEL\"], [326, 154, 0, 153, 0, \"MODEL\"], [327, 154, 1, 153, 1, \"CLIP\"], [330, 155, 0, 156, 0, \"MODEL\"], [331, 155, 1, 156, 1, \"CLIP\"], [332, 12, 0, 155, 0, \"MODEL\"], [333, 11, 0, 155, 1, \"CLIP\"], [342, 34, 0, 27, 0, \"INT\"], [343, 160, 0, 161, 0, \"MODEL\"], [344, 160, 1, 161, 1, \"CLIP\"], [345, 156, 1, 160, 1, \"CLIP\"], [346, 156, 0, 160, 0, \"MODEL\"], [347, 161, 0, 154, 0, \"MODEL\"], [348, 161, 1, 154, 1, \"CLIP\"], [350, 42, 1, 69, 0, \"LATENT\"], [356, 153, 1, 49, 0, \"*\"], [390, 69, 0, 71, 0, \"IMAGE\"], [391, 71, 0, 72, 0, \"IMAGE\"], [392, 72, 0, 73, 0, \"IMAGE\"], [393, 134, 0, 42, 2, \"SAMPLER\"], [394, 79, 0, 42, 3, \"SIGMAS\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 2.0092532782048504, \"offset\": [-214.7836659066827, -67.16328379844595]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}}}}",
                "steps": 40,
                "models": [],
                "prompt": "photorealistic portrayal of a female warrior encased in a heavily armored mech suit. Her suit is a blend of futuristic technology and combat-ready functionality, featuring an array of weapons systems integrated into the massive arm attachments that extend from her shoulders. The suit\u2019s armor is primarily white, with black and gray accents that add depth and dimension, while bright neon teal lights highlight various functional parts. These glowing teal lights can be seen on the chest, arms, and legs, giving the suit an otherworldly, cybernetic appearance. The armor is meticulously detailed with visible screws, hydraulic systems, and joint mechanisms, which suggest enhanced strength and agility. Her face, framed by soft, pink hair, is calm and determined, contrasting with the industrial and formidable design of her suit. The background is  brick wall with a small hole on the center, a utility pole with attached electrical panel right behind her,   allowing the intricate details of the suit to stand out, showcasing the character as a powerful blend of human and machine.\n\nWith one arm resting on her hip, the other extended behind her, her pink hair flowing over her shoulder.\n",
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 4,
                "modelIds": [],
                "scheduler": "beta",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux1\\aeshteticv3.safetensors",
                        "type": "lora",
                        "strength": 0.5,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux1\\realism_lora_comfy flux_converted.safetensors",
                        "type": "lora",
                        "strength": 0.7000000000000001,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "1stgenerationpme",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 32242813,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f1f3f6bd-6a86-4c8e-8152-30b8b9b77db5/width=832/f1f3f6bd-6a86-4c8e-8152-30b8b9b77db5.jpeg",
            "hash": "UEL:r_^iP.Rjt,kDsXog0KR%}@xu~C4.OsNG",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-10-01T10:38:29.884Z",
            "postId": 7378606,
            "stats": {
                "cryCount": 12,
                "laughCount": 39,
                "likeCount": 402,
                "dislikeCount": 0,
                "heartCount": 139,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3234326710,
                "steps": 14,
                "prompt": "score_4,score_5,score_6,score_7_up,score_8_up,score_9\n((masterpiece,best quality,ultra detailed,highres,HD,4k:1.2)),\n1girl, solo, girl forcus,solo forcus,\nshort hair,brown hair,arms behind back, camisole,black skirt,pleated skirt,mini skirt, \nroom,indoors,\nblush,smile,open mouth,",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-01T1106:03.5887701Z",
                "negativePrompt": "(Macho, muscular, old man, fat man,Nostrils,\n,text,yuri,roll one \u0019s eyes:1.5),(worst quality, low quality:1.4), (patreon username, patreon logo, signature, watermark:1.0),easynegative,negative_hand-neg, bad-hands-5,low quality,bad-hands-5,extra limbs,missing limb,extra digit,fewer digit,missing digit,missing fingers,mutated hands and fingers,fused limb,bad hands,long neck,long body,bad anatomy,disfigured,deformed,poorly drawn,mutation,extra nippless,extra breasts,disembodied penis,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 828380,
                        "modelVersionName": "v3"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 899254,
                        "modelVersionName": "V1"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "tousaku555913485",
            "baseModel": "Pony"
        },
        {
            "id": 32137558,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/71fd3b7f-687d-45b8-9520-524f01a333fd/width=832/71fd3b7f-687d-45b8-9520-524f01a333fd.jpeg",
            "hash": "UC5@F}Olw5Mzd5tjQ:oLUzkVizo{Rjs;W.n,",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-30T23:00:00.000Z",
            "postId": 7355109,
            "stats": {
                "cryCount": 16,
                "laughCount": 56,
                "likeCount": 390,
                "dislikeCount": 0,
                "heartCount": 130,
                "commentCount": 1
            },
            "meta": null,
            "username": "3mcg33",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 31979854,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/98fc53e1-7157-41ab-add3-816e4eaecf3d/width=832/98fc53e1-7157-41ab-add3-816e4eaecf3d.jpeg",
            "hash": "UIAdQCXn-:RjYR$gNHoKMxIoMxofD%RkROWX",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-29T21:16:07.419Z",
            "postId": 7301191,
            "stats": {
                "cryCount": 9,
                "laughCount": 45,
                "likeCount": 432,
                "dislikeCount": 0,
                "heartCount": 106,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3208469694,
                "steps": 39,
                "prompt": "An action scene shot captures a dark, menacing towering fluffy black cat knight in the heat of an intense, action-packed battle, reminiscent of gritty realism from an old analog camera. The knight\u2019s intricately designed, battle-worn helmet reflects the eerie magical, ethereal glow of its weapon\u2014a massive, twisted sword. The blade crackles with dark energy, gathering ominously at its tip, where a glowing orb of faded blue light pulses with immense, destructive power. This energy radiates along the blade, casting a ghostly blue glow that illuminates the knight\u2019s helmet and armor, creating stark contrasts between light and deep shadows. In its other paw, the cat wields a terrifying shield adorned with jagged, twisted patterns and a ghastly visage that seems to stare into the souls of its enemies. The shield emanates a sense of foreboding, as if cursed by dark magic, enhancing the overall terror of its presence. The glow from the sword accentuates the intricate details of the shield, casting long shadows that flicker across the lone desert battlefield amidst the dunes.",
                "sampler": "Undefined",
                "cfgScale": 4.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-09-29T1349:24.1744134Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.35,
                        "modelVersionId": 801005,
                        "modelVersionName": "Flux.1 D v2.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 781667,
                        "modelVersionName": "V1"
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 816800,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.5,
                        "modelVersionId": 903120,
                        "modelVersionName": "Flux"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 756311,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.25,
                        "modelVersionId": 748318,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Ajuro",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 31028436,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/84138e22-7703-45d9-a725-10763745d0f2/width=1248/84138e22-7703-45d9-a725-10763745d0f2.jpeg",
            "hash": "U46HDl-o0L0f%1xG9uIp0fI:~B={0LNG~B-o",
            "width": 1248,
            "height": 1608,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-24T01:35:13.551Z",
            "postId": 6936086,
            "stats": {
                "cryCount": 31,
                "laughCount": 56,
                "likeCount": 385,
                "dislikeCount": 0,
                "heartCount": 120,
                "commentCount": 0
            },
            "meta": {
                "seed": 387,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux_dev.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 35, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 387}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 3.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 896, \"height\": 1152, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": 896, \"height\": 1152, \"model\": [\"161\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.5, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.05, \"scale\": 100.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"161\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 1], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"69\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.35000000000000003, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 40, \"denoise\": 0.25, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"A photorealistic close-up of sabcarp, woman\\u2019s face,  partially illuminated by a single, soft light source. Her pale skin contrasts sharply with the deep shadows surrounding her. Her hair is wavy brown, with bangs, revealing perfectly arched eyebrows. Her eyes, wide and strikingly blue, are framed by long, dark lashes. Her lips are painted a bold red, adding a touch of glamour to the otherwise stark image. The background is a deep black, making her face the sole focal point. She is wearing an outfit with turtleneck\\n\\nAesthetics include Micro-Detail Skin Texturing, Reflective Eye Highlights,Smooth Transition of Light and Shadow, Refined Eye Makeup with Gradient Shadows.\\n\\nsubtle backlighting to highlight the edges of the hair and shoulders, giving the subject a glowing outline against the darker background. glimmering specular highlights on the lips and eyes, catching the light in precise spots to enhance their wet, glossy appearance. a few soft hair strands gently framing the face, with natural movement and flow, adding depth and dimension to the hairstyle.\\n\\nArms crossed over her chest, head tilted forward slightly, \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", \"clip\": [\"161\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"117\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"file_type\": \"JPEG\", \"remove_metadata\": true, \"images\": [\"69\", 0]}, \"class_type\": \"SaveImagePlus\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"141\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"144\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"147\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"149\": {\"inputs\": {\"scale_method\": \"nearest-exact\", \"scale_factor\": 1.5, \"use_tiled_vae\": false}, \"class_type\": \"LatentPixelScale\"}, \"155\": {\"inputs\": {\"lora_name\": \"flux1\\\\detailed_skin_portraits-000005.safetensors\", \"strength_model\": 0.4, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"160\": {\"inputs\": {\"lora_name\": \"flux1\\\\realism_lora_comfy flux_converted.safetensors\", \"strength_model\": 0.35000000000000003, \"strength_clip\": 1.0, \"model\": [\"155\", 0], \"clip\": [\"155\", 1]}, \"class_type\": \"LoraLoader\"}, \"161\": {\"inputs\": {\"lora_name\": \"flux1\\\\sabrina_carpenter.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"160\", 0], \"clip\": [\"160\", 1]}, \"class_type\": \"LoraLoader\"}, \"162\": {\"inputs\": {\"text_input\": \"\", \"task\": \"region_caption\", \"fill_mask\": true, \"keep_model_loaded\": false, \"max_new_tokens\": 1024, \"num_beams\": 3, \"do_sample\": true, \"output_mask_select\": \"\", \"seed\": 755685400146624, \"florence2_model\": [\"163\", 0]}, \"class_type\": \"Florence2Run\"}, \"163\": {\"inputs\": {\"precision\": \"fp32\", \"attention\": \"sdpa\"}, \"class_type\": \"Florence2ModelLoader\"}}, \"workflow\": {\"last_node_id\": 163, \"last_link_id\": 350, \"nodes\": [{\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1300, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 892, \"1\": 13}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 450, \"1\": 1353}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 289}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 141, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2036, \"1\": 41}, \"size\": {\"0\": 428.9556884765625, \"1\": 78}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": 2156, \"1\": 435}, \"size\": {\"0\": 504.7402648925781, \"1\": 472.86358642578125}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [294, 305], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [295, 306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [296, 307], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186, 297, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3079, \"1\": -575}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 311}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 148, \"type\": \"SaveImage\", \"pos\": {\"0\": 3061, \"1\": -483}, \"size\": {\"0\": 281.4468078613281, \"1\": 480.5931091308594}, \"flags\": {}, \"order\": 67, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 313}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 149, \"type\": \"LatentPixelScale\", \"pos\": {\"0\": 445.9807434082031, \"1\": 1519.1585693359375}, \"size\": {\"0\": 365.4000244140625, \"1\": 146}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model_opt\", \"type\": \"UPSCALE_MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentPixelScale\"}, \"widgets_values\": [\"nearest-exact\", 1.5, false]}, {\"id\": 146, \"type\": \"DZ_Face_Detailer\", \"pos\": {\"0\": 2658, \"1\": -843}, \"size\": {\"0\": 309.8262939453125, \"1\": 842.9425659179688}, \"flags\": {}, \"order\": 63, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 305}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 306}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 307}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DZ_Face_Detailer\"}, \"widgets_values\": [1, \"fixed\", 20, 4, \"euler\", \"sgm_uniform\", 0.25, 32, \"face\", \"dilate\", 3, 3]}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": 14, \"1\": 1284}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 301, \"1\": -171}, \"size\": [75, 26], \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 325}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -29, \"1\": 159}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [333], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1303, \"1\": 949}, \"size\": {\"0\": 848.655029296875, \"1\": 899.4495849609375}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1505, \"1\": 40}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1813, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 66, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [260, 299], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.75, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 883, \"1\": 758}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 289], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 142, \"type\": \"SaveImage\", \"pos\": {\"0\": 3181, \"1\": 87}, \"size\": {\"0\": 813.5270385742188, \"1\": 1236.560546875}, \"flags\": {}, \"order\": 71, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 300}], \"outputs\": [], \"title\": \"FinalPass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 140, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2769, \"1\": 86}, \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 69, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 294}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 295}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 296}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 297}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 298}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.25, 1, \"fixed\", 25, 3, \"euler\", \"sgm_uniform\", 0.2, \"Linear\", 832, 1216, 24, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 2233, \"1\": 955}, \"size\": {\"0\": 848.405029296875, \"1\": 898.4495849609375}, \"flags\": {}, \"order\": 72, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 117, \"type\": \"SaveImagePlus\", \"pos\": {\"0\": 4366, \"1\": 456}, \"size\": {\"0\": 832.2413940429688, \"1\": 1183.025634765625}, \"flags\": {}, \"order\": 73, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 282}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImagePlus\"}, \"widgets_values\": [\"ComfyUI\", \"JPEG\", true]}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 2061, \"1\": 273}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 260}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.3, 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1195, \"1\": 46}, \"size\": {\"0\": 245.11636352539062, \"1\": 82}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 258, \"1\": 793}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 342, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [896, 1152, 1]}, {\"id\": 156, \"type\": \"LoraLoader\", \"pos\": {\"0\": -399, \"1\": 593}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 24, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 330}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 331}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [346], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [345], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Flux__Semi-realistic_art_style-000004.safetensors\", 0.7000000000000001, 1]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -37, \"1\": 33}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux_dev.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1809, \"1\": 365}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 70, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168, 282], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.07, 100, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 324, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 896, 1152]}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 11, \"1\": 300}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": -460, \"1\": 790}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 884, \"1\": 975}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 100, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 154, \"type\": \"LoraLoader\", \"pos\": {\"0\": -401, \"1\": 405}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 32, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 347}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 348}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [326], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [327], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Flux__Semi-realistic_art_style-000004.safetensors\", 0.35000000000000003, 1]}, {\"id\": 153, \"type\": \"LoraLoader\", \"pos\": {\"0\": -36, \"1\": 410}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 33, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 326}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 327}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [324], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [325], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Fake_breasts_flux_v4-000027.safetensors\", 0.4, 1]}, {\"id\": 162, \"type\": \"Florence2Run\", \"pos\": {\"0\": -9, \"1\": -1313}, \"size\": {\"0\": 400, \"1\": 352}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"link\": 349}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"caption\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}, {\"name\": \"data\", \"type\": \"JSON\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Florence2Run\"}, \"widgets_values\": [\"\", \"region_caption\", true, false, 1024, 3, true, \"\", 755685400146624, \"randomize\"]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 511, \"1\": -87}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 493, \"1\": 12}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1214, \"1\": 174}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [287], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1801, \"1\": 21}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 350}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1454, \"1\": 131}, \"size\": {\"0\": 334.8955383300781, \"1\": 535.3447265625}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 287, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [308], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [350], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [387, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 617, \"1\": 645}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1152, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 386, \"1\": 647}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 342], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [896, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 869, \"1\": 622}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 474, \"1\": 893}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 163, \"type\": \"Florence2ModelLoader\", \"pos\": {\"0\": -430, \"1\": -1290}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"lora\", \"type\": \"PEFTLORA\", \"link\": null}], \"outputs\": [{\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"links\": [349], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"Florence2ModelLoader\"}, \"widgets_values\": [null, \"fp32\", \"sdpa\"]}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 883, \"1\": 1143}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 487, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 35, 1]}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1829, \"1\": 554}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 40, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 837, \"1\": 1291}, \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 155, \"type\": \"LoraLoader\", \"pos\": {\"0\": -23, \"1\": 601}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 332}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 333}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [330], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [331], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\detailed_skin_portraits-000005.safetensors\", 0.4, 1]}, {\"id\": 161, \"type\": \"LoraLoader\", \"pos\": {\"0\": -755, \"1\": 406}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 343}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 344}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [347], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [348], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\sabrina_carpenter.safetensors\", 1, 1]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 848, \"1\": -32}, \"size\": {\"0\": 318.1961975097656, \"1\": 569.048095703125}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 160, \"type\": \"LoraLoader\", \"pos\": {\"0\": -763, \"1\": 592}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 346}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 345}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [343], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [344], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\realism_lora_comfy flux_converted.safetensors\", 0.35000000000000003, 1]}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 332, \"1\": 116}, \"size\": {\"0\": 499.79559326171875, \"1\": 484.8913879394531}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"A photorealistic close-up of sabcarp, woman\\u2019s face,  partially illuminated by a single, soft light source. Her pale skin contrasts sharply with the deep shadows surrounding her. Her hair is wavy brown, with bangs, revealing perfectly arched eyebrows. Her eyes, wide and strikingly blue, are framed by long, dark lashes. Her lips are painted a bold red, adding a touch of glamour to the otherwise stark image. The background is a deep black, making her face the sole focal point. She is wearing an outfit with turtleneck\\n\\nAesthetics include Micro-Detail Skin Texturing, Reflective Eye Highlights,Smooth Transition of Light and Shadow, Refined Eye Makeup with Gradient Shadows.\\n\\nsubtle backlighting to highlight the edges of the hair and shoulders, giving the subject a glowing outline against the darker background. glimmering specular highlights on the lips and eyes, catching the light in precise spots to enhance their wet, glossy appearance. a few soft hair strands gently framing the face, with natural movement and flow, adding depth and dimension to the hairstyle.\\n\\nArms crossed over her chest, head tilted forward slightly, \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [260, 72, 0, 71, 0, \"IMAGE\"], [282, 73, 0, 117, 0, \"IMAGE\"], [285, 75, 0, 59, 0, \"IMAGE\"], [287, 134, 0, 42, 2, \"SAMPLER\"], [288, 62, 0, 41, 0, \"IMAGE\"], [289, 61, 0, 77, 1, \"IMAGE\"], [294, 96, 0, 140, 1, \"MODEL\"], [295, 64, 0, 140, 2, \"CONDITIONING\"], [296, 65, 0, 140, 3, \"CONDITIONING\"], [297, 70, 0, 140, 4, \"VAE\"], [298, 141, 0, 140, 5, \"UPSCALE_MODEL\"], [299, 72, 0, 140, 0, \"IMAGE\"], [300, 140, 0, 142, 0, \"IMAGE\"], [305, 96, 0, 146, 0, \"MODEL\"], [306, 64, 0, 146, 1, \"CONDITIONING\"], [307, 65, 0, 146, 2, \"CONDITIONING\"], [308, 42, 0, 146, 3, \"LATENT\"], [310, 70, 0, 146, 4, \"VAE\"], [311, 146, 0, 147, 0, \"LATENT\"], [312, 81, 0, 147, 1, \"VAE\"], [313, 147, 0, 148, 0, \"IMAGE\"], [324, 153, 0, 30, 0, \"MODEL\"], [325, 153, 1, 49, 0, \"*\"], [326, 154, 0, 153, 0, \"MODEL\"], [327, 154, 1, 153, 1, \"CLIP\"], [330, 155, 0, 156, 0, \"MODEL\"], [331, 155, 1, 156, 1, \"CLIP\"], [332, 12, 0, 155, 0, \"MODEL\"], [333, 11, 0, 155, 1, \"CLIP\"], [342, 34, 0, 27, 0, \"INT\"], [343, 160, 0, 161, 0, \"MODEL\"], [344, 160, 1, 161, 1, \"CLIP\"], [345, 156, 1, 160, 1, \"CLIP\"], [346, 156, 0, 160, 0, \"MODEL\"], [347, 161, 0, 154, 0, \"MODEL\"], [348, 161, 1, 154, 1, \"CLIP\"], [349, 163, 0, 162, 1, \"FL2MODEL\"], [350, 42, 1, 69, 0, \"LATENT\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.7715610000000013, \"offset\": [60.87361405402961, -4.187935739969274]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}, \"140\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"146\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"162\": {\"seed\": 8}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"140\": 1, \"146\": 0, \"162\": 8}}}",
                "steps": 35,
                "models": [],
                "prompt": "A photorealistic close-up of sabcarp, woman\u2019s face,  partially illuminated by a single, soft light source. Her pale skin contrasts sharply with the deep shadows surrounding her. Her hair is wavy brown, with bangs, revealing perfectly arched eyebrows. Her eyes, wide and strikingly blue, are framed by long, dark lashes. Her lips are painted a bold red, adding a touch of glamour to the otherwise stark image. The background is a deep black, making her face the sole focal point. She is wearing an outfit with turtleneck\n\nAesthetics include Micro-Detail Skin Texturing, Reflective Eye Highlights,Smooth Transition of Light and Shadow, Refined Eye Makeup with Gradient Shadows.\n\nsubtle backlighting to highlight the edges of the hair and shoulders, giving the subject a glowing outline against the darker background. glimmering specular highlights on the lips and eyes, catching the light in precise spots to enhance their wet, glossy appearance. a few soft hair strands gently framing the face, with natural movement and flow, adding depth and dimension to the hairstyle.\n\nArms crossed over her chest, head tilted forward slightly, \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 3,
                "modelIds": [],
                "scheduler": "sgm_uniform",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux1\\detailed_skin_portraits-000005.safetensors",
                        "type": "lora",
                        "strength": 0.4,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux1\\realism_lora_comfy flux_converted.safetensors",
                        "type": "lora",
                        "strength": 0.35,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux1\\sabrina_carpenter.safetensors",
                        "type": "lora",
                        "strength": 1,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "salammy",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 24533840,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9f35c00f-6df0-459c-afc8-422923cc560a/width=832/9f35c00f-6df0-459c-afc8-422923cc560a.jpeg",
            "hash": "UWIpb-^k%2J7}[NGrtWB$kV[RQxa-Us:NGxu",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-08-16T03:58:07.840Z",
            "postId": 5480981,
            "stats": {
                "cryCount": 20,
                "laughCount": 34,
                "likeCount": 372,
                "dislikeCount": 0,
                "heartCount": 166,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 866917975,
                "steps": 40,
                "prompt": "photorealistic photography of a serene scene of a  woman sitting on a tree branch surrounded by blooming cherry blossoms, wearing headphones, listening to music, soft sunlight filtering through the pink petals, gentle breeze, realistic details, high-definition, intricate fabric textures, flowing hair, serene expression, glowing soft light, dynamic lighting, vibrant colors, romantic atmosphere, delicate butterflies, ultra-detailed, cinematic composition, gentle shadows, ethereal and peaceful, warm pastel tones\nThe woman characteristic are, curvy body, beautiful large round eyes, large breasts,   black hair, long bangs,  brown eyes. She is wearing necklace, ring,  piercing, bracelet, wristwatch, fake nails,",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-16T0349:04.3201903Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 699332,
                        "modelVersionName": "Pro"
                    }
                ]
            },
            "username": "salammy",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 21083738,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a55908e8-f2ca-41fe-a64d-3d8fa94440f8/width=1664/a55908e8-f2ca-41fe-a64d-3d8fa94440f8.jpeg",
            "hash": "UFB4Br.9M{IA?^x]axM_R-t7bHR*-;X8RPRj",
            "width": 1664,
            "height": 2432,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-23T22:05:38.213Z",
            "postId": 4702233,
            "stats": {
                "cryCount": 7,
                "laughCount": 39,
                "likeCount": 439,
                "dislikeCount": 0,
                "heartCount": 107,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1045629314,
                "Model": "forrealxl_v05",
                "steps": 16,
                "hashes": {
                    "model": "6f228e128a",
                    "lora:MJ52": "000c96b6bd08",
                    "lora:EpicF4nta5yXL": "d9d6e8652da0"
                },
                "prompt": "An anthropomorphic mouse in medieval armor stands heroically beside a stoic big snail and perched on a branch, snail has a big shell, behind them is an ethereal forest with soft beams of light piercing through the blue-grey mist, the mouse's holding a flowing black banner-staff, serene and fantastical scene, <lora:MJ52:0.4>, <lora:EpicF4nta5yXL:0.7>",
                "Version": "f0.0.17v1.8.0rc-latest-278-gbfee03d8",
                "sampler": "DDPM",
                "cfgScale": 1.5,
                "resources": [
                    {
                        "hash": "000c96b6bd08",
                        "name": "MJ52",
                        "type": "lora",
                        "weight": 0.4
                    },
                    {
                        "hash": "d9d6e8652da0",
                        "name": "EpicF4nta5yXL",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "hash": "6f228e128a",
                        "name": "forrealxl_v05",
                        "type": "model"
                    }
                ],
                "Model hash": "6f228e128a",
                "Hires steps": "8",
                "ControlNet 0": {
                    "Model": "diffusers_xl_canny_full [2b69fca4]",
                    "Module": "canny",
                    "Weight": "0.7",
                    "Hr Option": "Both",
                    "Resize Mode": "Crop and Resize",
                    "Threshold A": "56",
                    "Threshold B": "112",
                    "Control Mode": "Balanced",
                    "Guidance End": "1",
                    "Pixel Perfect": "True",
                    "Processor Res": "512",
                    "Guidance Start": "0"
                },
                "Hires upscale": "2",
                "Hires upscaler": "4x_NMKD-Siax_200k",
                "negativePrompt": "blurry, low quality, deformed, disfigured, anime, drawing, painting, illustration, painting, sketch, cartoon, watermark, signature",
                "Denoising strength": "0.15"
            },
            "username": "DreamCk",
            "baseModel": "SDXL Lightning"
        },
        {
            "id": 11954268,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8c066a0d-0a85-4b3d-a035-7770a5db8bca/width=1224/8c066a0d-0a85-4b3d-a035-7770a5db8bca.jpeg",
            "hash": "ULIN]q0L0g~Uk;NHDjbapysmrX%2tRs:MxV@",
            "width": 1224,
            "height": 1920,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-05-09T09:10:05.007Z",
            "postId": 2637081,
            "stats": {
                "cryCount": 2,
                "laughCount": 57,
                "likeCount": 418,
                "dislikeCount": 0,
                "heartCount": 115,
                "commentCount": 3
            },
            "meta": {
                "VAE": "sdxl-fp16-fix.vae.safetensors",
                "Size": "768x1200",
                "seed": 1233373383,
                "Model": "zavychromaxl_v70",
                "steps": 20,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "3e0a3274d0",
                    "lora:Runway_Fashion_XL": "9c555746900b"
                },
                "prompt": "Minecraft style art of (Runway fashion:1.4), Gothic aesthetic, godzilla walking down the runway wearing an unexpected designer outfit, soft-hued colors, stunning background. warm and bright sunlight, a mesmerizing blend of light and shadow. masterpiece, absurdres, intricate details <lora:Runway_Fashion_XL:1.0>, Blocky, pixelated, vibrant colors, recognizable characters and objects, game assets, Minecraft style",
                "Version": "v1.9.3",
                "sampler": "DPM++ 2M",
                "cfgScale": 4.5,
                "resources": [
                    {
                        "hash": "9c555746900b",
                        "name": "Runway_Fashion_XL",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "3e0a3274d0",
                        "name": "zavychromaxl_v70",
                        "type": "model"
                    }
                ],
                "Model hash": "3e0a3274d0",
                "Hires steps": "10",
                "Hires prompt": {
                    "(Runway fashion": "1.4)",
                    "Runway_Fashion_XL": "1.0>"
                },
                "Hires upscale": "1.6",
                "Hypertile VAE": "True",
                "Schedule type": "Automatic",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "smooth, realistic, detailed, photorealistic, noise, blurry, deformed, dirty, messy, tattoo, face paint, calavera, (worst quality, low quality, thumbnail:1.4), signature, artist name, web address, cropped, jpeg artifacts, watermark, username, collage, grid",
                "Hypertile U-Net": "True",
                "Denoising strength": "0.31",
                "Hires schedule type": "Karras",
                "Style Selector Style": "Minecraft",
                "Hires negative prompt": {
                    "thumbnail": "1.4)"
                },
                "Style Selector Enabled": "True",
                "Downcast alphas_cumprod": "True",
                "Style Selector Randomize": "False"
            },
            "username": "jah",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 3598340,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6c6ccddc-bf56-4d6c-9b12-72c27072a6c7/width=1280/6c6ccddc-bf56-4d6c-9b12-72c27072a6c7.jpeg",
            "hash": "U5ExhO0g00wK01Rjs:-:00%1}sSgIo%1-pIV",
            "width": 1280,
            "height": 1920,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-11-13T18:36:28.981Z",
            "postId": 816792,
            "stats": {
                "cryCount": 20,
                "laughCount": 27,
                "likeCount": 299,
                "dislikeCount": 0,
                "heartCount": 246,
                "commentCount": 8
            },
            "meta": {
                "VAE": "vae-ft-mse-840000-ema-pruned.safetensors",
                "Size": "640x960",
                "seed": 2462773145,
                "Model": "epinikion",
                "steps": 20,
                "hashes": {
                    "model": "62bb78983a"
                },
                "prompt": "super cute blond woman in a dark theme",
                "Version": "v1.6.0-2-g4afaaf8a",
                "sampler": "DPM++ 2M Karras",
                "VAE hash": "1006afe4e2",
                "cfgScale": 5,
                "resources": [
                    {
                        "hash": "62bb78983a",
                        "name": "epinikion",
                        "type": "model"
                    }
                ],
                "Model hash": "62bb78983a",
                "Hires steps": "10",
                "Hires upscale": "2",
                "Hires upscaler": "4x_NMKD-Superscale-SP_178000_G",
                "negativePrompt": "render, cartoon, cgi, render, illustration, painting, drawing",
                "Denoising strength": "0.35"
            },
            "username": "epinikion",
            "baseModel": "SD 1.5"
        },
        {
            "id": 34096181,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/45c20b4d-bb8e-4d65-865f-ba0440663f0e/width=832/45c20b4d-bb8e-4d65-865f-ba0440663f0e.jpeg",
            "hash": "UHFEGx0f=_r@yD57KOR+}?IV-UoJ5-E2f,oy",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-12T00:23:30.377Z",
            "postId": 7793626,
            "stats": {
                "cryCount": 25,
                "laughCount": 15,
                "likeCount": 434,
                "dislikeCount": 0,
                "heartCount": 117,
                "commentCount": 0
            },
            "meta": {
                "seed": 3707318819,
                "vaes": [],
                "Model": "urn:air:sdxl:checkpoint:civitai:257749@290640",
                "extra": {
                    "remixOfId": 33754556
                },
                "steps": 30,
                "models": [
                    "urn:air:sdxl:checkpoint:civitai:257749@290640"
                ],
                "prompt": "safe_pos, score_9, score_8_up, score_8, 1 elf girl, solo, sexy witch girl, perfect face, thick eyeliner, small breasts, long pink hair, green eyes, witch outfit, indoors, library, cowboy shot, (casting magic spell), holding book, magic aura, glowing particles, dynamic pose, detailed background, dynamic angle, volumetric lighting, cinematic lighting, jack o lantern in background",
                "sampler": "Euler a",
                "cfgScale": 4,
                "modelIds": [],
                "workflow": "img2img-facefix",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "safe_neg, score_6, score_5, score_4, busty, (large breasts:0.3), ugly face, mutated hands, low res, blurry face, (hairy pussy:1.2), pumped body, athletic body, black and white, sepia, camera",
                "civitaiResources": [
                    {
                        "weight": 1,
                        "modelVersionId": 290640
                    },
                    {
                        "weight": 1,
                        "modelVersionId": 290640
                    },
                    {
                        "weight": 1,
                        "modelVersionId": 60938
                    },
                    {
                        "weight": 1,
                        "modelVersionId": 179964
                    },
                    {
                        "weight": 0.65,
                        "modelVersionId": 244808
                    },
                    {
                        "weight": 0.9,
                        "modelVersionId": 298238
                    },
                    {
                        "weight": 0.55,
                        "modelVersionId": 378950
                    },
                    {
                        "weight": 0.75,
                        "modelVersionId": 421754
                    },
                    {
                        "modelVersionId": 250708
                    },
                    {
                        "modelVersionId": 250712
                    },
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640
                    },
                    {
                        "type": "lora",
                        "weight": 0.65,
                        "modelVersionId": 244808
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 298238
                    },
                    {
                        "type": "lora",
                        "weight": 0.55,
                        "modelVersionId": 378950
                    },
                    {
                        "type": "lora",
                        "weight": 0.75,
                        "modelVersionId": 421754
                    }
                ],
                "additionalResources": [
                    {
                        "name": "urn:air:sdxl:lora:civitai:212532@244808",
                        "type": "lora",
                        "strength": 0.65,
                        "strengthClip": 1
                    },
                    {
                        "name": "urn:air:sdxl:lora:civitai:264290@298238",
                        "type": "lora",
                        "strength": 0.9,
                        "strengthClip": 1
                    },
                    {
                        "name": "urn:air:sdxl:lora:civitai:211726@378950",
                        "type": "lora",
                        "strength": 0.55,
                        "strengthClip": 1
                    },
                    {
                        "name": "urn:air:sdxl:lora:civitai:377690@421754",
                        "type": "lora",
                        "strength": 0.75,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "ElvishDreams",
            "baseModel": "PonyPonyPony"
        },
        {
            "id": 33506936,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5dfd84af-cd30-4ecb-9814-e5b7710cee2f/width=768/5dfd84af-cd30-4ecb-9814-e5b7710cee2f.jpeg",
            "hash": "UF6b.FWYIUt6p{V?R4t7t,nOQ,bcOtbcrqkD",
            "width": 768,
            "height": 1368,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-08T15:21:18.973Z",
            "postId": 7664189,
            "stats": {
                "cryCount": 30,
                "laughCount": 16,
                "likeCount": 423,
                "dislikeCount": 0,
                "heartCount": 122,
                "commentCount": 1
            },
            "meta": {
                "Size": "768x1368",
                "seed": 455963334,
                "Model": "flux1-dev-Q8_0",
                "steps": 30,
                "hashes": {
                    "model": "52cfce60d7",
                    "lora:detailed": "E5F80A108CDC",
                    "lora:FLUX-daubrez-DB4RZ-v2": "9A6DFC274BBD",
                    "lora:flux_detailed_v2_flux_ntc": "60109e97793e"
                },
                "prompt": "A highly detailed, mid-close-up fantasy scene of a battle-worn knight standing in a dark, enchanted forest. His weathered armor is adorned with glowing, mystical symbols, faintly pulsing with ancient magic. In one hand, he grips a massive, enchanted sword with a glowing blue edge, while the other hand rests on a battered shield etched with deep scratches. His face, partially obscured by a tattered hood, reveals a determined gaze. Behind him, faint ethereal spirits hover between the twisted, gnarled trees, their pale blue light contrasting with the knight's stern, grounded presence.\n <lora:flux_detailed_v2_flux_ntc:0.7> <lora:FLUX-daubrez-DB4RZ-v2:0.7> <lora:detailed:0.7>",
                "Version": "f2.0.1v1.10.1-previous-556-gcc378589",
                "sampler": "Euler",
                "Module 1": "ae",
                "Module 2": "clip_l",
                "Module 3": "t5xxl_fp16",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "60109e97793e",
                        "name": "flux_detailed_v2_flux_ntc",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "hash": "9A6DFC274BBD",
                        "name": "FLUX-daubrez-DB4RZ-v2",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "hash": "E5F80A108CDC",
                        "name": "detailed",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "hash": "52cfce60d7",
                        "name": "flux1-dev-Q8_0",
                        "type": "model"
                    }
                ],
                "Model hash": "52cfce60d7",
                "Schedule type": "Beta",
                "Beta schedule beta": "0.6",
                "Beta schedule alpha": "0.6",
                "Distilled CFG Scale": "3.1",
                "Diffusion in Low Bits": "Automatic (fp16 LoRA)"
            },
            "username": "Van978",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 33032371,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bf8a4f55-a4d0-4606-b166-8119465d9df8/width=1344/bf8a4f55-a4d0-4606-b166-8119465d9df8.jpeg",
            "hash": "UIBX4k?wkX%hMxRjWEM{8wRQWXIT?wx]Rjof",
            "width": 1344,
            "height": 1728,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-06T00:05:18.387Z",
            "postId": 7559082,
            "stats": {
                "cryCount": 4,
                "laughCount": 25,
                "likeCount": 427,
                "dislikeCount": 0,
                "heartCount": 135,
                "commentCount": 1
            },
            "meta": {
                "Size": "896x1152",
                "seed": 3494027905,
                "Model": "flux1-dev-bnb-nf4-v2",
                "steps": 25,
                "hashes": {
                    "model": "bea01d51bd",
                    "lora:dark_fantasy_flux": "6E5F580C0E",
                    "lora:FluxMythP0rtr4itStyle": "8ea428b224a8",
                    "lora:FredFraiStyle-FLUX-Share": "63BFAA1CF9"
                },
                "Version": "f2.0.1v1.10.1-previous-450-gdb6448df",
                "sampler": "Euler",
                "cfgScale": 1.1,
                "resources": [
                    {
                        "hash": "63BFAA1CF9",
                        "name": "FredFraiStyle-FLUX-Share",
                        "type": "lora"
                    },
                    {
                        "hash": "8ea428b224a8",
                        "name": "FluxMythP0rtr4itStyle",
                        "type": "lora"
                    },
                    {
                        "hash": "6E5F580C0E",
                        "name": "dark_fantasy_flux",
                        "type": "lora"
                    },
                    {
                        "hash": "bea01d51bd",
                        "name": "flux1-dev-bnb-nf4-v2",
                        "type": "model"
                    }
                ],
                "Model hash": "bea01d51bd",
                "Hires steps": "20",
                "Hires upscale": "1.5",
                "Schedule type": "Normal",
                "Hires upscaler": "4x-UltraSharp",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.8.0",
                "Denoising strength": "0.25",
                "ADetailer mask blur": "10",
                "Distilled CFG Scale": "3.3",
                "ADetailer confidence": "0.3",
                "Diffusion in Low Bits": "Automatic (fp16 LoRA)",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint width": "768",
                "ADetailer inpaint height": "1024",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.2",
                "ADetailer inpaint only masked": "True",
                "ADetailer use inpaint width height": "True"
            },
            "username": "ArtifyAI",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 31519455,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e1c85e31-38ad-47b9-987e-08ec87efba24/width=1160/e1c85e31-38ad-47b9-987e-08ec87efba24.jpeg",
            "hash": "UE5$VqpdtRMx*0x^RjVYk?tRRjV?o}kCV@WB",
            "width": 1160,
            "height": 1696,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-27T01:11:03.869Z",
            "postId": 7047880,
            "stats": {
                "cryCount": 22,
                "laughCount": 51,
                "likeCount": 406,
                "dislikeCount": 0,
                "heartCount": 112,
                "commentCount": 0
            },
            "meta": {
                "seed": 1665,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux_dev.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 25, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 1665}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 0.5, \"base_shift\": 0.3, \"width\": 832, \"height\": 1216, \"model\": [\"12\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.5, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.05, \"scale\": 100.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 1], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"71\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.3, \"alpha\": 0.3, \"image\": [\"69\", 0]}, \"class_type\": \"ImageSharpen\"}, \"73\": {\"inputs\": {\"intensity\": 0.08, \"scale\": 100.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"71\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.35000000000000003, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 20, \"denoise\": 0.3, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"a photorealistic photography of a woman in a black suit with intricate tattoos glowing with digital patterns. Her form shifts between a solid, authoritative presence and a fragmented digital entity, the background a blend of high-tech cityscape and a data-infused matrix.\", \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"141\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"144\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"147\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"149\": {\"inputs\": {\"scale_method\": \"nearest-exact\", \"scale_factor\": 1.5, \"use_tiled_vae\": false}, \"class_type\": \"LatentPixelScale\"}, \"162\": {\"inputs\": {\"text_input\": \"\", \"task\": \"region_caption\", \"fill_mask\": true, \"keep_model_loaded\": false, \"max_new_tokens\": 1024, \"num_beams\": 3, \"do_sample\": true, \"output_mask_select\": \"\", \"seed\": 247479212532974, \"florence2_model\": [\"163\", 0]}, \"class_type\": \"Florence2Run\"}, \"163\": {\"inputs\": {\"model\": null, \"precision\": \"fp32\", \"attention\": \"sdpa\"}, \"class_type\": \"Florence2ModelLoader\"}, \"164\": {\"inputs\": {\"control_net_name\": \"Flux1\\\\flux-canny-controlnet.safetensors\"}, \"class_type\": \"ControlNetLoader\"}, \"165\": {\"inputs\": {\"strength\": 1}, \"class_type\": \"ControlNetApply\"}}, \"workflow\": {\"last_node_id\": 165, \"last_link_id\": 350, \"nodes\": [{\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1300, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 892, \"1\": 13}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 450, \"1\": 1353}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 289}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 141, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2036, \"1\": 41}, \"size\": {\"0\": 428.9556884765625, \"1\": 78}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": 2156, \"1\": 435}, \"size\": {\"0\": 504.7402648925781, \"1\": 472.86358642578125}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [294, 305], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [295, 306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [296, 307], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186, 297, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3079, \"1\": -575}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 311}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 148, \"type\": \"SaveImage\", \"pos\": {\"0\": 3061, \"1\": -483}, \"size\": {\"0\": 281.4468078613281, \"1\": 480.5931091308594}, \"flags\": {}, \"order\": 69, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 313}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 149, \"type\": \"LatentPixelScale\", \"pos\": {\"0\": 445.9807434082031, \"1\": 1519.1585693359375}, \"size\": {\"0\": 365.4000244140625, \"1\": 146}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model_opt\", \"type\": \"UPSCALE_MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentPixelScale\"}, \"widgets_values\": [\"nearest-exact\", 1.5, false]}, {\"id\": 146, \"type\": \"DZ_Face_Detailer\", \"pos\": {\"0\": 2658, \"1\": -843}, \"size\": {\"0\": 309.8262939453125, \"1\": 842.9425659179688}, \"flags\": {}, \"order\": 65, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 305}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 306}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 307}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DZ_Face_Detailer\"}, \"widgets_values\": [1, \"fixed\", 20, 4, \"euler\", \"sgm_uniform\", 0.25, 32, \"face\", \"dilate\", 3, 3]}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": 14, \"1\": 1284}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 301, \"1\": -171}, \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 325}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1813, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [260, 299], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.75, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 142, \"type\": \"SaveImage\", \"pos\": {\"0\": 3181, \"1\": 87}, \"size\": {\"0\": 813.5270385742188, \"1\": 1236.560546875}, \"flags\": {}, \"order\": 73, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 300}], \"outputs\": [], \"title\": \"FinalPass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 140, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2769, \"1\": 86}, \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 71, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 294}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 295}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 296}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 297}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 298}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.25, 1, \"fixed\", 25, 3, \"euler\", \"sgm_uniform\", 0.2, \"Linear\", 832, 1216, 24, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 2233, \"1\": 955}, \"size\": {\"0\": 848.405029296875, \"1\": 898.4495849609375}, \"flags\": {}, \"order\": 74, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 117, \"type\": \"SaveImagePlus\", \"pos\": {\"0\": 4366, \"1\": 456}, \"size\": {\"0\": 832.2413940429688, \"1\": 1183.025634765625}, \"flags\": {}, \"order\": 75, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 282}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImagePlus\"}, \"widgets_values\": [\"ComfyUI\", \"JPEG\", true]}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 258, \"1\": 793}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 342, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 884, \"1\": 975}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 100, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 162, \"type\": \"Florence2Run\", \"pos\": {\"0\": -9, \"1\": -1313}, \"size\": {\"0\": 400, \"1\": 352}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"link\": 349}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"caption\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}, {\"name\": \"data\", \"type\": \"JSON\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Florence2Run\"}, \"widgets_values\": [\"\", \"region_caption\", true, false, 1024, 3, true, \"\", 247479212532974, \"randomize\"]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 511, \"1\": -87}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1801, \"1\": 21}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 66, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 350}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 869, \"1\": 622}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 163, \"type\": \"Florence2ModelLoader\", \"pos\": {\"0\": -430, \"1\": -1290}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"lora\", \"type\": \"PEFTLORA\", \"link\": null}], \"outputs\": [{\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"links\": [349], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Florence2ModelLoader\"}, \"widgets_values\": [null, \"fp32\", \"sdpa\"]}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 876, \"1\": 785}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 289], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 165, \"type\": \"ControlNetApply\", \"pos\": {\"0\": -407, \"1\": 189}, \"size\": {\"0\": 317.4000244140625, \"1\": 98}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": null}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetApply\"}, \"widgets_values\": [1]}, {\"id\": 164, \"type\": \"ControlNetLoader\", \"pos\": {\"0\": -408, \"1\": 84}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"Flux1\\\\flux-canny-controlnet.safetensors\"]}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1197, \"1\": 34}, \"size\": {\"0\": 245.11636352539062, \"1\": 82}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1513, \"1\": 38}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 63, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1215, \"1\": 172}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [287], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 19, \"1\": 308}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 154, \"type\": \"LoraLoader\", \"pos\": {\"0\": -390, \"1\": 408}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 34, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 347}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 348}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [326], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [327], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Flux__Semi-realistic_art_style-000004.safetensors\", 0.35000000000000003, 1]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -29, \"1\": 159}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [333], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 324, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [0.5, 0.3, 832, 1216]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -37, \"1\": 33}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux_dev.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 493, \"1\": 12}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1326, \"1\": 965}, \"size\": {\"0\": 848.655029296875, \"1\": 899.4495849609375}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": -404, \"1\": 781}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 155, \"type\": \"LoraLoader\", \"pos\": {\"0\": -22, \"1\": 601}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 23, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 332}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 333}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [330], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [331], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\detailed_skin_portraits-000005.safetensors\", 0.25, 1]}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 837, \"1\": 1291}, \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1809, \"1\": 365}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 72, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168, 282], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.08, 100, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 2061, \"1\": 273}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 70, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 260}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.3, 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1829, \"1\": 554}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 20, 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [1665, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1454, \"1\": 131}, \"size\": {\"0\": 334.8955383300781, \"1\": 535.3447265625}, \"flags\": {}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 287, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [308], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [350], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 153, \"type\": \"LoraLoader\", \"pos\": {\"0\": -36, \"1\": 410}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 35, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 326}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 327}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [324], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [325], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\XT404.BOOBS-Bastic.XXL.safetensors\", 0.3, 1]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 474, \"1\": 893}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 617, \"1\": 645}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1216, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 386, \"1\": 647}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 342], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [832, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 883, \"1\": 1143}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 160, \"type\": \"LoraLoader\", \"pos\": {\"0\": -768, \"1\": 597}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 30, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 346}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 345}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [343], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [344], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\realism_lora_comfy flux_converted.safetensors\", 0.35000000000000003, 1]}, {\"id\": 156, \"type\": \"LoraLoader\", \"pos\": {\"0\": -399, \"1\": 593}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 27, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 330}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 331}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [346], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [345], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Flux__Semi-realistic_art_style-000004.safetensors\", 0.25, 1]}, {\"id\": 161, \"type\": \"LoraLoader\", \"pos\": {\"0\": -755, \"1\": 406}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 33, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 343}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 344}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [347], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [348], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\sabrina_carpenter.safetensors\", 1, 1]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 487, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 25, 1]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 883, \"1\": 0}, \"size\": {\"0\": 318.1961975097656, \"1\": 569.048095703125}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 310, \"1\": 77}, \"size\": {\"0\": 499.79559326171875, \"1\": 484.8913879394531}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"a photorealistic photography of a woman in a black suit with intricate tattoos glowing with digital patterns. Her form shifts between a solid, authoritative presence and a fragmented digital entity, the background a blend of high-tech cityscape and a data-infused matrix.\"]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [260, 72, 0, 71, 0, \"IMAGE\"], [282, 73, 0, 117, 0, \"IMAGE\"], [285, 75, 0, 59, 0, \"IMAGE\"], [287, 134, 0, 42, 2, \"SAMPLER\"], [288, 62, 0, 41, 0, \"IMAGE\"], [289, 61, 0, 77, 1, \"IMAGE\"], [294, 96, 0, 140, 1, \"MODEL\"], [295, 64, 0, 140, 2, \"CONDITIONING\"], [296, 65, 0, 140, 3, \"CONDITIONING\"], [297, 70, 0, 140, 4, \"VAE\"], [298, 141, 0, 140, 5, \"UPSCALE_MODEL\"], [299, 72, 0, 140, 0, \"IMAGE\"], [300, 140, 0, 142, 0, \"IMAGE\"], [305, 96, 0, 146, 0, \"MODEL\"], [306, 64, 0, 146, 1, \"CONDITIONING\"], [307, 65, 0, 146, 2, \"CONDITIONING\"], [308, 42, 0, 146, 3, \"LATENT\"], [310, 70, 0, 146, 4, \"VAE\"], [311, 146, 0, 147, 0, \"LATENT\"], [312, 81, 0, 147, 1, \"VAE\"], [313, 147, 0, 148, 0, \"IMAGE\"], [324, 153, 0, 30, 0, \"MODEL\"], [325, 153, 1, 49, 0, \"*\"], [326, 154, 0, 153, 0, \"MODEL\"], [327, 154, 1, 153, 1, \"CLIP\"], [330, 155, 0, 156, 0, \"MODEL\"], [331, 155, 1, 156, 1, \"CLIP\"], [332, 12, 0, 155, 0, \"MODEL\"], [333, 11, 0, 155, 1, \"CLIP\"], [342, 34, 0, 27, 0, \"INT\"], [343, 160, 0, 161, 0, \"MODEL\"], [344, 160, 1, 161, 1, \"CLIP\"], [345, 156, 1, 160, 1, \"CLIP\"], [346, 156, 0, 160, 0, \"MODEL\"], [347, 161, 0, 154, 0, \"MODEL\"], [348, 161, 1, 154, 1, \"CLIP\"], [349, 163, 0, 162, 1, \"FL2MODEL\"], [350, 42, 1, 69, 0, \"LATENT\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.9487171000000014, \"offset\": [-324.77480687394194, -85.0237105659956]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}, \"140\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"146\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"162\": {\"seed\": 8}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"140\": 1, \"146\": 0, \"162\": 8}}}",
                "steps": 25,
                "models": [],
                "prompt": "a photorealistic photography of a woman in a black suit with intricate tattoos glowing with digital patterns. Her form shifts between a solid, authoritative presence and a fragmented digital entity, the background a blend of high-tech cityscape and a data-infused matrix.",
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 3.5,
                "modelIds": [],
                "scheduler": "simple",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [
                    "Flux1\\flux-canny-controlnet.safetensors"
                ],
                "additionalResources": []
            },
            "username": "salammy",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 25365062,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5e491518-287a-4749-a56d-00fabc0d583d/width=832/5e491518-287a-4749-a56d-00fabc0d583d.jpeg",
            "hash": "UcCGlRRjR*kC_MV@ayj[.8Rjn%j[%fWBoLa}",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-21T03:04:25.703Z",
            "postId": 5668284,
            "stats": {
                "cryCount": 3,
                "laughCount": 49,
                "likeCount": 429,
                "dislikeCount": 0,
                "heartCount": 110,
                "commentCount": 3
            },
            "meta": null,
            "username": "DreamCk",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 24807423,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b6c338f4-5aa7-48e9-b23e-e360db0160f8/width=864/b6c338f4-5aa7-48e9-b23e-e360db0160f8.jpeg",
            "hash": "U17BAm~qM|t7RiIU_3~pIU9GIUxuofD%ofj[",
            "width": 864,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-17T20:52:28.073Z",
            "postId": 5543600,
            "stats": {
                "cryCount": 14,
                "laughCount": 40,
                "likeCount": 394,
                "dislikeCount": 0,
                "heartCount": 143,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "sdxl_vae.safetensors",
                "Size": "864x1152",
                "seed": 4050989933,
                "Model": "autismmixSDXL_autismmixPony",
                "steps": 30,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "821aa5537f",
                    "lora:th3d4rkXLP": "e608341952fa"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up,  <lora:th3d4rkXLP:1> th3d4rk, darkness, shadow, 1girl, monochrome, hug",
                "Version": "v1.10.1",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "e608341952fa",
                        "name": "th3d4rkXLP",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "821aa5537f",
                        "name": "autismmixSDXL_autismmixPony",
                        "type": "model"
                    }
                ],
                "Model hash": "821aa5537f",
                "Schedule type": "Automatic",
                "negativePrompt": "watermark, signature, artist name, twitter username,",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.6.0",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "freckledvixon",
            "baseModel": "Pony"
        },
        {
            "id": 23557456,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b54e9fd6-3577-4ca1-977b-a1b96ed37d7e/width=1248/b54e9fd6-3577-4ca1-977b-a1b96ed37d7e.jpeg",
            "hash": "U8BpCM,-020f0%Mw-o={E3jtobNG0jX9~WW9",
            "width": 1248,
            "height": 1872,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-08-10T01:28:10.496Z",
            "postId": 5253945,
            "stats": {
                "cryCount": 15,
                "laughCount": 34,
                "likeCount": 341,
                "dislikeCount": 0,
                "heartCount": 201,
                "commentCount": 0
            },
            "meta": {
                "RNG": "CPU",
                "VAE": "sdxl_vae.safetensors",
                "Size": "832x1248",
                "seed": 1015058246,
                "Model": "snowpony_v10",
                "steps": 28,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "d6f941b46b",
                    "lora:dcsorceress-pdxl-nvwls-v1-000004": "75bb6bab4db7"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime, 1girl, solo,  <lora:dcsorceress-pdxl-nvwls-v1-000004:1> dcSorc, brown hair, brown eyes, long hair, witch hat, strapless dress, detached sleeves, cleavage, sash, purple skirt, side slit, huge breasts, looking at you, forest, night sky, night, upper body, seductive, wide hips",
                "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
                "sampler": "Euler a",
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "75bb6bab4db7",
                        "name": "dcsorceress-pdxl-nvwls-v1-000004",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "d6f941b46b",
                        "name": "snowpony_v10",
                        "type": "model"
                    }
                ],
                "Model hash": "d6f941b46b",
                "Hires steps": "10",
                "Hires upscale": "1.5",
                "Schedule type": "Automatic",
                "Hires upscaler": "4x-AnimeSharp",
                "negativePrompt": "monochrome",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.4.2",
                "Denoising strength": "0.5",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "novowels",
            "baseModel": "Pony"
        },
        {
            "id": 22547361,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9468c65e-a80a-448c-a1e8-4290ac9c8a7c/width=832/9468c65e-a80a-448c-a1e8-4290ac9c8a7c.jpeg",
            "hash": "UQHw_.-p.TWAkts:bbs.E+o}nho0I=tRkB%2",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-03T09:59:19.448Z",
            "postId": 5024476,
            "stats": {
                "cryCount": 11,
                "laughCount": 27,
                "likeCount": 450,
                "dislikeCount": 0,
                "heartCount": 103,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3366948201,
                "steps": 48,
                "prompt": "score_9, score_8_up, score_7_up, Extradimensional sex, Hypersexualized, gravity-defying breasts, petite, prominent nipples, jiggle, unnatural, unprecedentedly, spread buttocks, stretched, (weird:0.1), (implied dynamism:0.25), lascivious, extraordinary, rating_explicit,   s0ftp1nk, (incredibly detailed:1.2), masterpiece, porn, clean colors, (comicsy outline:0.4), (ultra wide angle shot:0.65), aesthetic, artstation, concept art, smooth, sharp focus, <lora:add-detail-xl:0.25>, semirealistic, style of Yuko Shimizu, alchilia01f1",
                "sampler": "Euler a",
                "cfgScale": 8,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "add-detail-xl",
                        "type": "lora",
                        "weight": 0.25
                    }
                ],
                "Created Date": "2024-08-03T0954:07.7192462Z",
                "negativePrompt": "plain angle, ugly, (render:1.5), scribble, fused, muscular female, finger mess, draft, censored, doodles, flickering, , sketch, unclear, score_6, score_5, score_4, (worst quality:1.1), (low quality:1.1), CG, fat, elongated neck, source_pony, source_furry, rating_safe, (milf:0.45), kid, infant, chibi, lying, futa, sad, angry, motherly",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640,
                        "modelVersionName": "V6 (start with this one)"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 135867,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": -0.5,
                        "modelVersionId": 342953,
                        "modelVersionName": "SDXL"
                    },
                    {
                        "type": "lora",
                        "weight": 0.35,
                        "modelVersionId": 411310,
                        "modelVersionName": "v3.0 Type A [AutismMix]"
                    },
                    {
                        "type": "lora",
                        "weight": 0.2,
                        "modelVersionId": 531890,
                        "modelVersionName": "Soft Pink Trad"
                    },
                    {
                        "type": "lora",
                        "weight": 0.65,
                        "modelVersionId": 558777,
                        "modelVersionName": "Vivid Neon Mess Style [PONY]"
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 559258,
                        "modelVersionName": "HMAS Canberra\uff08D33\uff09 pony"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 561360,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.5,
                        "modelVersionId": 688549,
                        "modelVersionName": "AlchiliaStyle_v1.2"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250708,
                        "modelVersionName": "safe_pos"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250712,
                        "modelVersionName": "safe_neg"
                    }
                ]
            },
            "username": "DOK",
            "baseModel": "Pony"
        },
        {
            "id": 15548208,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c24f228d-14f3-4c0a-85ac-c2c49f80d02c/width=1024/c24f228d-14f3-4c0a-85ac-c2c49f80d02c.jpeg",
            "hash": "UVKKm6wa9aNz00%hx]%14:oL-p%M~qIUxaRk",
            "width": 1024,
            "height": 1024,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-12T17:02:51.545Z",
            "postId": 3462074,
            "stats": {
                "cryCount": 39,
                "laughCount": 217,
                "likeCount": 256,
                "dislikeCount": 0,
                "heartCount": 79,
                "commentCount": 4
            },
            "meta": {
                "seed": 988071912034475,
                "vaes": [],
                "Model": "stableDiffusion3SD3_sd3Medium",
                "comfy": "{\"prompt\": {\"3\": {\"inputs\": {\"seed\": 988071912034475, \"steps\": 30, \"cfg\": 5.0, \"sampler_name\": \"euler\", \"scheduler\": \"sgm_uniform\", \"denoise\": 1.0, \"model\": [\"4\", 0], \"positive\": [\"16\", 0], \"negative\": [\"40\", 0], \"latent_image\": [\"53\", 0]}, \"class_type\": \"KSampler\"}, \"4\": {\"inputs\": {\"ckpt_name\": \"stableDiffusion3SD3_sd3Medium.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"8\": {\"inputs\": {\"samples\": [\"3\", 0], \"vae\": [\"4\", 2]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"16\": {\"inputs\": {\"text\": \"japanese woman laughing covering her mouth looking at a computer screen, text on computer display says \\\"2b is all you need\\\"\", \"clip\": [\"43\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"40\": {\"inputs\": {\"text\": \"3d, render, cgi, unreal engine\", \"clip\": [\"43\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"41\": {\"inputs\": {\"clip_name\": \"t5xxl_fp8_e4m3fn.safetensors\", \"type\": \"sd3\"}, \"class_type\": \"CLIPLoader\"}, \"42\": {\"inputs\": {\"clip_name1\": \"clip_g.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"sd3\"}, \"class_type\": \"DualCLIPLoader\"}, \"43\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"clip_name3\": \"clip_g.safetensors\"}, \"class_type\": \"TripleCLIPLoader\"}, \"53\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}}, \"workflow\": {\"last_node_id\": 53, \"last_link_id\": 109, \"nodes\": [{\"id\": 8, \"type\": \"VAEDecode\", \"pos\": [1200, 96], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 7}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 53, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [51], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": [1440, 96], \"size\": {\"0\": 952.5112915039062, \"1\": 1007.9328002929688}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 51, \"slot_index\": 0}], \"properties\": {}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 53, \"type\": \"EmptySD3LatentImage\", \"pos\": [480, 576], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [100], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [1024, 1024, 1]}, {\"id\": 50, \"type\": \"Note\", \"pos\": [-384, 144], \"size\": {\"0\": 223.34756469726562, \"1\": 254.37765502929688}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"SD3 supports different text encoder configurations, you can see how to load them here.\\n\\n\\nMake sure to put these files:\\nclip_g.safetensors\\nclip_l.safetensors\\nt5xxl_fp16.safetensors\\n\\n\\nIn the ComfyUI/models/clip directory\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 51, \"type\": \"Note\", \"pos\": [-96, 624], \"size\": {\"0\": 384, \"1\": 192}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"sd3_medium.safetensors is the file that does not contain any CLIP/text encoder weights so you need to load them separately.\\n\\nThis file goes in the ComfyUI/models/checkpoints directory.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 41, \"type\": \"CLIPLoader\", \"pos\": [-96, 0], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp8_e4m3fn.safetensors\", \"sd3\"]}, {\"id\": 4, \"type\": \"CheckpointLoaderSimple\", \"pos\": [-96, 480], \"size\": {\"0\": 384.75592041015625, \"1\": 98}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [99], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [], \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [53], \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"stableDiffusion3SD3_sd3Medium.safetensors\"]}, {\"id\": 3, \"type\": \"KSampler\", \"pos\": [864, 96], \"size\": {\"0\": 315, \"1\": 262}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 99, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 21}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 80}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 100}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [7], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [988071912034475, \"randomize\", 30, 5, \"euler\", \"sgm_uniform\", 1]}, {\"id\": 42, \"type\": \"DualCLIPLoader\", \"pos\": [-99, 135], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"clip_g.safetensors\", \"clip_l.safetensors\", \"sd3\"]}, {\"id\": 16, \"type\": \"CLIPTextEncode\", \"pos\": [384, 96], \"size\": {\"0\": 432, \"1\": 192}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 108}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [21], \"slot_index\": 0}], \"title\": \"Positive Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"japanese woman laughing covering her mouth looking at a computer screen, text on computer display says \\\"2b is all you need\\\"\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 40, \"type\": \"CLIPTextEncode\", \"pos\": [384, 336], \"size\": {\"0\": 432, \"1\": 192}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 109}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [80], \"shape\": 3, \"slot_index\": 0}], \"title\": \"Negative Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"3d, render, cgi, unreal engine\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 43, \"type\": \"TripleCLIPLoader\", \"pos\": [-96, 288], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [108, 109], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"TripleCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"clip_g.safetensors\"]}], \"links\": [[7, 3, 0, 8, 0, \"LATENT\"], [21, 16, 0, 3, 1, \"CONDITIONING\"], [51, 8, 0, 9, 0, \"IMAGE\"], [53, 4, 2, 8, 1, \"VAE\"], [80, 40, 0, 3, 2, \"CONDITIONING\"], [99, 4, 0, 3, 0, \"MODEL\"], [100, 53, 0, 3, 3, \"LATENT\"], [108, 43, 0, 16, 0, \"CLIP\"], [109, 43, 0, 40, 0, \"CLIP\"]], \"groups\": [{\"title\": \"Different Text Encoder Configurations\", \"bounding\": [-144, -96, 480, 528], \"color\": \"#3f789e\", \"font_size\": 24}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.7513148009015777, \"offset\": [-445.1320638617596, -14.83327340591149]}}, \"version\": 0.4}}",
                "steps": 30,
                "width": 1024,
                "height": 1024,
                "models": [
                    "stableDiffusion3SD3_sd3Medium.safetensors"
                ],
                "prompt": "japanese woman laughing covering her mouth looking at a computer screen, text on computer display says \"2b is all you need\"",
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 5,
                "modelIds": [],
                "scheduler": "sgm_uniform",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "3d, render, cgi, unreal engine",
                "additionalResources": []
            },
            "username": "Capybaka",
            "baseModel": "SD 3"
        },
        {
            "id": 14839459,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/34ac37f3-10b9-4739-a332-c426fa13f2aa/width=1248/34ac37f3-10b9-4739-a332-c426fa13f2aa.jpeg",
            "hash": "UGC%?O_2?voz_N.8%goytRM{IUR*%htRMxMy",
            "width": 1248,
            "height": 1824,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-06T16:09:22.908Z",
            "postId": 3292204,
            "stats": {
                "cryCount": 36,
                "laughCount": 60,
                "likeCount": 367,
                "dislikeCount": 0,
                "heartCount": 128,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3731154722,
                "Model": "forrealxl_v05",
                "steps": 10,
                "hashes": {
                    "model": "6f228e128a",
                    "lora:MJ52": "000c96b6bd08",
                    "lora:add-detail-xl": "9c783c8ce46c",
                    "lora:[XL]\u00e5\u00b7\u00a8\u00e5\u0085\u00bd\u00e6\u0094\u00bb\u00e5\u009f\u008e": "4cf09f75803c"
                },
                "prompt": "Book Cover: \"Pacific Ocean Monsters\"Featuring an illustration of terrifying sea monsters and towering waves, creating a tense atmosphere amidst the vast ocean.(Anime,cartoon,light effect,lighting is smooth,in 3d animattion).Sub Oceanum  <lora:add-detail-xl:1> <lora:MJ52:0.5> <lora:[XL]\u00e5\u00b7\u00a8\u00e5\u0085\u00bd\u00e6\u0094\u00bb\u00e5\u009f\u008e:0.6> giant monster",
                "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
                "sampler": "DDPM",
                "cfgScale": 2,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "9c783c8ce46c",
                        "name": "add-detail-xl",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "000c96b6bd08",
                        "name": "MJ52",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "hash": "4cf09f75803c",
                        "name": "[XL]\u00e5\u00b7\u00a8\u00e5\u0085\u00bd\u00e6\u0094\u00bb\u00e5\u009f\u008e",
                        "type": "lora"
                    },
                    {
                        "hash": "6f228e128a",
                        "name": "forrealxl_v05",
                        "type": "model"
                    }
                ],
                "Model hash": "6f228e128a",
                "Hires steps": "15",
                "Hires upscale": "1.5",
                "Hires upscaler": "4x_NMKD-Siax_200k",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.3.2",
                "Denoising strength": "0.4",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "popyay",
            "baseModel": "SDXL Lightning"
        },
        {
            "id": 14347073,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b38bb602-6fa3-4b89-9854-eb533274bbcb/width=1800/b38bb602-6fa3-4b89-9854-eb533274bbcb.jpeg",
            "hash": "U8D,ck?^F}IVitm*8w9aI;D%8^kDM|t-IU-=",
            "width": 2112,
            "height": 3096,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-06-02T11:00:38.291Z",
            "postId": 3185278,
            "stats": {
                "cryCount": 34,
                "laughCount": 56,
                "likeCount": 349,
                "dislikeCount": 0,
                "heartCount": 152,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 4080959001,
                "steps": 30,
                "hashes": {
                    "model": "67ab2fd8ec",
                    "LORA:Fant5yP0ny": "361505e210",
                    "embed:negativeXL_D": "fff5d51ab6",
                    "LORA:Pony_Fantasy_Wizard__Witches_-_By_HailoKnight": "29a4de2f29"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up,  sorceress, casting water magic spells, blue hood, medium breasts, colorful eyes, freckles, white hair, magic circle, thigh strap, petite, 1girl, delicate and smooth skin, blush, perfect body, thighs, large breasts, highly detailed, glossy lips, looking at viewer, waves in background, magic, ritual, swirling water, water splash, wet, Hydromancy,  <lora:Fant5yP0ny:0.8>,  <lora:Pony_Fantasy_Wizard__Witches_-_By_HailoKnight:0.8> hkmagic",
                "sampler": "Euler a Karras",
                "cfgScale": 7,
                "resources": [
                    {
                        "name": "Fant5yP0ny",
                        "type": "lora",
                        "weight": 0.8
                    },
                    {
                        "name": "Pony_Fantasy_Wizard__Witches_-_By_HailoKnight",
                        "type": "lora",
                        "weight": 0.8
                    }
                ],
                "Model hash": "67ab2fd8ec",
                "negativePrompt": "embedding:negativeXL_D, furry,",
                "ponyDiffusionV6XL_v6StartWithThisOne Version": "ComfyUI"
            },
            "username": "popyay",
            "baseModel": "Pony"
        },
        {
            "id": 4031192,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/553a1821-ef04-4bcd-9677-b803482bb04f/width=1024/553a1821-ef04-4bcd-9677-b803482bb04f.jpeg",
            "hash": "U45r*~kC00jZDNadx^o#Hqjsb0V@*0ayHqV?",
            "width": 1024,
            "height": 1536,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-11-29T19:44:12.215Z",
            "postId": 904716,
            "stats": {
                "cryCount": 9,
                "laughCount": 27,
                "likeCount": 329,
                "dislikeCount": 0,
                "heartCount": 226,
                "commentCount": 3
            },
            "meta": {
                "VAE": "vae-ft-mse-840000-ema-pruned.safetensors",
                "Size": "512x768",
                "seed": 1869144976,
                "Model": "anrealspicemix_v10",
                "steps": 25,
                "hashes": {
                    "vae": "735e4c3a44",
                    "model": "e61db9dc3d",
                    "lora:GoodHands-beta2": "ba43b0efee",
                    "lora:kVoidEnergy-000001": "2dbcfb380b",
                    "lora:add_detail_realistic": "098bfc73f8"
                },
                "prompt": "realistic shadows, depth of field, bokeh, <lora:add_detail_realistic:1>,\n1 girl, adult (elven:0.7) woman,  amber eyes, dark brown wedge cut hair,  \n<lora:GoodHands-beta2:0.8>,\n  solo, from front, front view, (full body:0.6), (closed eyes:1.1),   detailed background, detailed face, (<lora:kVoidEnergy-000001:0.5>, V0id3nergy, void theme:1.1)  glowing magical third eye  on forehead, eye tattoo, illusionist, psychic powers, awareness,   mind control, hypnosis,  enchantment, psychomancy,   clairvoyance, mesmerizing, aura,   mind portal, mind energy, magical blue psychic energy emanating, updraft,  magic in background, ethereal atmosphere,",
                "sampler": "DPM++ 2M Karras",
                "VAE hash": "df3c506e51",
                "cfgScale": 20,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "add_detail_realistic",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "e61db9dc3d",
                        "name": "anrealspicemix_v10",
                        "type": "model"
                    }
                ],
                "Model hash": "e61db9dc3d",
                "Hires steps": "10",
                "Hires upscale": "2",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "cartoon, painting, illustration, (worst quality, low quality, normal quality:2), watermark, logo,(male, man, boy, masculine:1.2), (open eyes, eyes open, wink:1.2),",
                "ADetailer model": "face_yolov8n.pt",
                "GoodHands-beta2": "0.8>,\\n__full-prompt-fantasy__\"",
                "Wildcard prompt": "\"{soft lighting,|} {realistic shadows,|} {depth of field, bokeh",
                "ADetailer version": "23.11.1",
                "Denoising strength": "0.5",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "add_detail_realistic": "1>",
                "\"add_detail_realistic": "802eec3d9cbc",
                "ADetailer dilate erode": "32",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "TxcTrtl",
            "baseModel": "SD 1.5"
        },
        {
            "id": 39128589,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2a94802b-2c2d-43b7-bdc3-87b07ae84d51/width=832/2a94802b-2c2d-43b7-bdc3-87b07ae84d51.jpeg",
            "hash": "U3BV*53C00#81iV[n3tQ00#8~q-U]*XlE2IC",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-09T04:30:00.000Z",
            "postId": 8928790,
            "stats": {
                "cryCount": 27,
                "laughCount": 59,
                "likeCount": 374,
                "dislikeCount": 0,
                "heartCount": 130,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2058345023,
                "steps": 20,
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, solo, 1girl, looking at viewer, lips, close-up, realistic, freckles, portrait, slight smile, makeup, black hair, tattoo on face, emo girl, egirl",
                "sampler": "Euler a",
                "cfgScale": 6,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-11-09T0331:35.4599612Z",
                "negativePrompt": "score_6, score_5, score_4, source_pony, source_anime, source_furry, source_cartoon, worst quality, low quality",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640,
                        "modelVersionName": "V6 (start with this one)"
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 1007569,
                        "modelVersionName": "V1"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Zoropaton",
            "baseModel": "Pony"
        },
        {
            "id": 37787751,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6933e316-67af-4ce0-acb9-3105da50649c/width=832/6933e316-67af-4ce0-acb9-3105da50649c.jpeg",
            "hash": "UEC?1C^j0Lj?57Ip-U-B02M|%fjY~A%LE3Vt",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-04T05:01:00.000Z",
            "postId": 8629732,
            "stats": {
                "cryCount": 28,
                "laughCount": 39,
                "likeCount": 421,
                "dislikeCount": 0,
                "heartCount": 102,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2553701074,
                "extra": {
                    "remixOfId": 34419985
                },
                "steps": 38,
                "prompt": "linquivera,  Ink illustration, (anime:0.5), brown tones, aged black red paper, inkpunk, moonlight,surreal, a cat on a castle balcony in the forest, (at a distance), Will-o'-the-wisp, moonlit, lonely, solitude, windy, tall trees, willows, willowy,  OverallDetail, extremely detailed, UHD,(long exposure , dystopian but extremely beautiful:1.4),",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-22T0904:28.6781193Z",
                "negativePrompt": "(worst quality, low quality, illustration, 3d, 2d, painting, cartoons, sketch), open mouth",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 916744,
                        "modelVersionName": "v10.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 135867,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.75,
                        "modelVersionId": 283697,
                        "modelVersionName": "v1.2"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Genzo93",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 34993669,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f7190c19-b10a-4ffd-bd30-6fe66dbc8cf4/width=1800/f7190c19-b10a-4ffd-bd30-6fe66dbc8cf4.jpeg",
            "hash": "UIJ%LT-pFsJ7EO?bxvOYo|-;-p?H}]f,tkNI",
            "width": 2560,
            "height": 3712,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-17T01:21:00.000Z",
            "postId": 7998142,
            "stats": {
                "cryCount": 38,
                "laughCount": 77,
                "likeCount": 331,
                "dislikeCount": 0,
                "heartCount": 144,
                "commentCount": 6
            },
            "meta": {
                "seed": 2032532519,
                "vaes": [],
                "extra": {},
                "steps": 19,
                "models": [],
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, [][][][][] m0use_goldie, (light beige fur, brown eyes), (((rabbit))), (feral:1.1), indoors, cottage, bed, sitting, (leaning back:1.2), (rabbit onesie), (rabbit costume:1.5), (pink rabbit ears), (drooping ears:1.5), (hood up:2), ((glasses)), barefoot, animal costume, pink pajamas, solo, (embarrassed expression:1.5), high angle view, (look at viewer:1.5), books, ((rabbit tail))",
                "sampler": "Euler a",
                "cfgScale": 3,
                "modelIds": [],
                "workflow": "img2img-upscale",
                "upscalers": [
                    "urn:air:multi:upscaler:civitai:147759@164821"
                ],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "score_6, score_5, score_4, (cute, cub, young, child, chibi:1.5), busty, ugly face, low res, blurry face, ugly hands, pumped body, breasts, big ears, ((hair)), green fur, belly, extra ears, human, blue fur, (mouse ears:3)",
                "civitaiResources": [
                    {
                        "weight": 1,
                        "modelVersionId": 494387
                    },
                    {
                        "weight": 1,
                        "modelVersionId": 494387
                    },
                    {
                        "weight": 1,
                        "modelVersionId": 954518
                    },
                    {
                        "weight": 0.6,
                        "modelVersionId": 883013
                    },
                    {
                        "weight": 1,
                        "modelVersionId": 730271
                    },
                    {
                        "type": "upscaler",
                        "modelVersionId": 164821
                    }
                ],
                "additionalResources": []
            },
            "username": "JustAMouse",
            "baseModel": "PonyPony"
        }
    ],
    "metadata": {
        "nextCursor": "8400|1727677502809",
        "nextPage": "https://civitai.com/api/v1/images?sort=Most%20Reactions&nsfw=Soft&cursor=8400%7C1727677502809"
    }
}