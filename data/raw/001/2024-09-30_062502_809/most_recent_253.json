{
    "items": [
        {
            "id": 9390329,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8d5ef158-fdde-4733-9d82-0e55e9306628/width=832/8d5ef158-fdde-4733-9d82-0e55e9306628.jpeg",
            "hash": "UFGP%p-Wrr9sXn-V0_9@5jEeI.}uJ69@-C-V",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-04-07T23:23:43.519Z",
            "postId": 2031963,
            "stats": {
                "cryCount": 15,
                "laughCount": 31,
                "likeCount": 221,
                "dislikeCount": 0,
                "heartCount": 125,
                "commentCount": 0
            },
            "meta": null,
            "username": "Bapho90",
            "baseModel": "Pony"
        },
        {
            "id": 6694474,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0432a065-e575-496f-bbd0-cd1f0cb341a5/width=832/0432a065-e575-496f-bbd0-cd1f0cb341a5.jpeg",
            "hash": "UIDSK=$*0gNF~Aj@E3t6IoV@xa%2Rjf*xYni",
            "width": 832,
            "height": 1248,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-16T05:16:03.890Z",
            "postId": 1445608,
            "stats": {
                "cryCount": 0,
                "laughCount": 57,
                "likeCount": 213,
                "dislikeCount": 0,
                "heartCount": 122,
                "commentCount": 2
            },
            "meta": {
                "RNG": "CPU",
                "VAE": "sdxl_vae.safetensors",
                "Size": "832x1248",
                "seed": 3664132017,
                "Model": "SDXLFaetastic_v24",
                "steps": 28,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "07b985d12f"
                },
                "prompt": "extremely detailed fantasy illustration of a fairy riding on the back of a pembroke welsh corgi, forest, dense foliage, night sky, fireflies",
                "Version": "v1.6.0-2-g4afaaf8a",
                "sampler": "Euler a",
                "VAE hash": "63aeecb90f",
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "07b985d12f",
                        "name": "SDXLFaetastic_v24",
                        "type": "model"
                    }
                ],
                "Model hash": "07b985d12f",
                "negativePrompt": "monochrome",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "23.11.1",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "32",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "novowels",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 6405287,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/96e9eb07-7850-4482-b45b-0d167c997314/width=1024/96e9eb07-7850-4482-b45b-0d167c997314.jpeg",
            "hash": "U7EKZRExO^0:1m5Q}tsA0JRjv{,,[7Av5Q=s",
            "width": 1024,
            "height": 1536,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-08T15:38:30.419Z",
            "postId": 1383207,
            "stats": {
                "cryCount": 52,
                "laughCount": 60,
                "likeCount": 159,
                "dislikeCount": 0,
                "heartCount": 121,
                "commentCount": 0
            },
            "meta": {
                "Size": "640x896",
                "seed": 3769047049,
                "Model": "EMS-14040-EMS",
                "steps": 25,
                "TaskID": "692059964583276764",
                "prompt": "new year celebration,  art work,  red and yellow dragon,  16k,  best quality,  HDR,  night,  show people,  Fireworks 2024 on sky,  16k,  HDR,<lora:EMS-255229-EMS:0.600000>,<lora:EMS-88628-EMS:0.800000>",
                "Version": "v1.6.0.127-beta-3-1-g46a8f36",
                "sampler": "DPM++ SDE Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Hires steps": "25",
                "Hires resize": "1024x1536",
                "EMS-88628-EMS": "6fee08cd7ceb\"",
                "Hires upscaler": "4x_NMKD-Superscale-SP_178000_G",
                "negativePrompt": "low quality,  worst quality:1.4),  (bad anatomy),  (inaccurate limb:1.2), bad composition,  inaccurate eyes,  extra digit, fewer digits, (extra arms:1.2),  extra legs,  inaccurate eyes,  inaccurate mouth,  inaccurate face,  strange things",
                "\"EMS-255229-EMS": "f2a8b540f77d",
                "ADetailer model": "face_yolov8s.pt",
                "ADetailer version": "23.9.1",
                "Denoising strength": "0.3",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.5",
                "Style Selector Style": "base",
                "ADetailer dilate/erode": "4",
                "Style Selector Enabled": "True",
                "Style Selector Randomize": "False",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.5",
                "ADetailer inpaint only masked": "True"
            },
            "username": "FUNIP",
            "baseModel": ""
        },
        {
            "id": 5324782,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9c1222c8-6ce9-45a6-bb25-4ce19ca7ea4a/width=1536/9c1222c8-6ce9-45a6-bb25-4ce19ca7ea4a.jpeg",
            "hash": "UIJ*6J~A4p9Z?w%KDiD*Y7xYIAD*WAIqOFxW",
            "width": 1536,
            "height": 2688,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-01-09T17:11:13.619Z",
            "postId": 1161693,
            "stats": {
                "cryCount": 0,
                "laughCount": 23,
                "likeCount": 247,
                "dislikeCount": 0,
                "heartCount": 122,
                "commentCount": 0
            },
            "meta": {
                "steps": 50,
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 5
            },
            "username": "BIG_A",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 37305663,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/294f6690-7fb7-4016-9b2e-7eae520494bd/width=832/294f6690-7fb7-4016-9b2e-7eae520494bd.jpeg",
            "hash": "U4Dl.%Fgl:=ZpLof00Rj00rW~qTK00Io~X%L",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-30T01:58:42.847Z",
            "postId": 8520192,
            "stats": {
                "cryCount": 9,
                "laughCount": 33,
                "likeCount": 256,
                "dislikeCount": 0,
                "heartCount": 93,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 702791431,
                "steps": 25,
                "prompt": "score_9, score_8_up, score_7_up, beautyfull color, aesthetic, 1girl, solo, twisted ram's horns, freckles, white hair, long bangs, golden eyes, vertical pupils, pale skin, green dress, BREAK medium shot, detailed background",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-30T0140:30.3190732Z",
                "negativePrompt": "score_6, score_5, score_4, text, watermark, strabismus, pointy ears",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640,
                        "modelVersionName": "V6 (start with this one)"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 543340,
                        "modelVersionName": "Dizi Style"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "ananasic",
            "baseModel": "Pony"
        },
        {
            "id": 36740795,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a90a002e-8644-4351-8d12-3f32b9b0163c/width=832/a90a002e-8644-4351-8d12-3f32b9b0163c.jpeg",
            "hash": "U35OjFRPRPRP_NozIAkBtSofI9RPozt7DiV@",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-26T23:50:43.491Z",
            "postId": 8392355,
            "stats": {
                "cryCount": 12,
                "laughCount": 14,
                "likeCount": 296,
                "dislikeCount": 0,
                "heartCount": 69,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3729437318,
                "Model": "flux_dev",
                "steps": 30,
                "hashes": {
                    "model": "06f96f89f6",
                    "lora:dark_fantasy_flux": "e3b0c44298fc",
                    "lora:FluxMythP0rtr4itStyle": "8ea428b224a8",
                    "lora:FredFraiStyle-FLUX-Share": "de92428f6411"
                },
                "prompt": "A mysterious, hooded figure. The figure is clad in intricately detailed black armor, adorned with ornate patterns and textures that suggest a gothic or medieval style. The hood obscures the face, casting deep shadows that enhance the enigmatic presence. The figure's hands, covered in armored gauntlets, grip the hilt of a large, menacing sword. The sword's blade is partially visible, reflecting a cold, metallic sheen. The background is blurred, emphasizing the central figure and adding to the atmospheric, moody tone of the composition. Water droplets are visible on the armor, suggesting a recent rain or mist, adding a dynamic element to the scene.   <lora:dark_fantasy_flux:0.83> <lora:FredFraiStyle-FLUX-Share:0.63>, <lora:FluxMythP0rtr4itStyle:0.33> mythp0rt",
                "Version": "f2.0.1v1.10.1-previous-519-g44eb4ea8",
                "sampler": "Euler",
                "Module 1": "ae",
                "Module 2": "t5xxl_fp16",
                "Module 3": "ViT-L-14-BEST-smooth-GmP-TE-only-HF-format",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "e3b0c44298fc",
                        "name": "dark_fantasy_flux",
                        "type": "lora",
                        "weight": 0.83
                    },
                    {
                        "hash": "de92428f6411",
                        "name": "FredFraiStyle-FLUX-Share",
                        "type": "lora",
                        "weight": 0.63
                    },
                    {
                        "hash": "8ea428b224a8",
                        "name": "FluxMythP0rtr4itStyle",
                        "type": "lora",
                        "weight": 0.33
                    },
                    {
                        "hash": "06f96f89f6",
                        "name": "flux_dev",
                        "type": "model"
                    }
                ],
                "Model hash": "06f96f89f6",
                "Schedule type": "Simple",
                "Distilled CFG Scale": "3.5",
                "Diffusion in Low Bits": "Automatic (fp16 LoRA)"
            },
            "username": "VelvetS",
            "baseModel": null
        },
        {
            "id": 36008680,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f7d20f23-c46b-4bf7-9d70-c86c5f0b27b4/width=896/f7d20f23-c46b-4bf7-9d70-c86c5f0b27b4.jpeg",
            "hash": "U5I4te0M00-.^*xVs,SO00xtI@Rj~9tRE2R*",
            "width": 896,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-23T11:00:00.000Z",
            "postId": 8226919,
            "stats": {
                "cryCount": 3,
                "laughCount": 13,
                "likeCount": 310,
                "dislikeCount": 0,
                "heartCount": 64,
                "commentCount": 5
            },
            "meta": {
                "Size": "896x1152",
                "seed": 655577674,
                "Model": "flux1-dev-fp8",
                "steps": 20,
                "hashes": {
                    "model": "275ef623d3",
                    "lora:the_forbidden_book_v10_1500": "4b44779fae8c"
                },
                "prompt": "<lora:the_forbidden_book_v10_1500:1>, ncrnmcn, An ancient manuscript displays a giant spider with a body covered in rune-like patterns. Its legs extend outward, reaching the edges of the page as if trapping the scene within its web. At the top and center of the page \"The Forbidden Book\" in a large runic font. Below the spider, a figure draped in a robe holds a candle, casting shadows across the page. The border is filled with interwoven web designs and symbols associated with darkness and mystery. The aged paper has small tears and spots, giving it the appearance of an artifact that has endured centuries.  \"Version 1.0\" and \"by Dark Infinity\" appear in smaller font at the bottom of the image.",
                "Version": "f2.0.1v1.10.1-previous-576-g534405e5",
                "sampler": "Euler",
                "Module 1": "t5xxl_fp8_e4m3fn",
                "Module 2": "clip_l",
                "Module 3": "ae",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "4b44779fae8c",
                        "name": "the_forbidden_book_v10_1500",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "275ef623d3",
                        "name": "flux1-dev-fp8",
                        "type": "model"
                    }
                ],
                "Model hash": "275ef623d3",
                "Schedule type": "Simple",
                "negativePrompt": "watermark, text, kids, loli, teenager, children, SFW",
                "Distilled CFG Scale": "3.5"
            },
            "username": "Dark_infinity",
            "baseModel": null
        },
        {
            "id": 35124508,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4d8ef45d-fd5b-478e-a339-e1ab2255d19a/width=1800/4d8ef45d-fd5b-478e-a339-e1ab2255d19a.jpeg",
            "hash": "U78#Tqi^L#V]mRXTTdnN8wt7X*XSysozvfog",
            "width": 2048,
            "height": 2048,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-17T19:57:48.500Z",
            "postId": 8027689,
            "stats": {
                "cryCount": 9,
                "laughCount": 72,
                "likeCount": 239,
                "dislikeCount": 0,
                "heartCount": 71,
                "commentCount": 9
            },
            "meta": {
                "RNG": "NV",
                "VAE": "fixFP16ErrorsSDXLLowerMemoryUse_v10.safetensors",
                "Size": "1024x1024",
                "seed": 1353089694,
                "Model": "incursiosMemeDiffusion_v27",
                "steps": 24,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "5e37c6849c",
                    "lora:JetstreamSam_XLPD": "37057fd32082",
                    "lora:AmongUs_pdxl_Incrs_v1": "9c18eedb825f",
                    "lora:PonderingMyOrbMeme_pdxl_Incrs_v1": "0d3a774cdfcc"
                },
                "prompt": "score_9, score_8_up, score_7_up, sitting, orb, throne, crystal ball, chair, hooded cloak, robe, hood up, <lora:PonderingMyOrbMeme_pdxl_Incrs_v1:1.2>, solo, upper body, <lora:JetstreamSam_XLPD:0.8> JetstreamSam, headgear, beard, <lora:AmongUs_pdxl_Incrs_v1:1> crewmate (among us), spacesuit, no humans, space helmet, full body, solo, wide shot, red theme, red suit,",
                "Version": "f0.0.17v1.8.0rc-latest-287-g77bdb920",
                "sampler": "Euler a",
                "Emphasis": "No norm",
                "cfgScale": 6,
                "Mask blur": "4",
                "resources": [
                    {
                        "hash": "0d3a774cdfcc",
                        "name": "PonderingMyOrbMeme_pdxl_Incrs_v1",
                        "type": "lora",
                        "weight": 1.2
                    },
                    {
                        "hash": "37057fd32082",
                        "name": "JetstreamSam_XLPD",
                        "type": "lora",
                        "weight": 0.8
                    },
                    {
                        "hash": "9c18eedb825f",
                        "name": "AmongUs_pdxl_Incrs_v1",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "5e37c6849c",
                        "name": "incursiosMemeDiffusion_v27",
                        "type": "model"
                    }
                ],
                "Model hash": "5e37c6849c",
                "Inpaint area": "Only masked",
                "negativePrompt": "monochrome",
                "Denoising strength": "0.1",
                "Masked area padding": "32"
            },
            "username": "FallenIncursio",
            "baseModel": "Pony"
        },
        {
            "id": 34767452,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5d7efff3-6058-4ec9-82fa-618ee2c9e64b/width=832/5d7efff3-6058-4ec9-82fa-618ee2c9e64b.jpeg",
            "hash": "UwGR^tIU-.%L~oRj%1t7%KofoeWBs,ogRkWB",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-15T17:39:37.700Z",
            "postId": 7944897,
            "stats": {
                "cryCount": 3,
                "laughCount": 10,
                "likeCount": 290,
                "dislikeCount": 0,
                "heartCount": 88,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 4025446527,
                "extra": {
                    "remixOfId": 33965071
                },
                "steps": 25,
                "prompt": "silhouette art, japanese female assassin, long hair, black robes, hood, a katana slung over her back, viewed from the side, silhouetted, chiascuro, light hitting one side of her face, edu-era traditional japanese castle in the background",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-14T2049:06.2530589Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 747357,
                        "modelVersionName": "V1"
                    }
                ]
            },
            "username": "Stu42",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 31815791,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0ca83a48-675b-454d-a445-ba68b81f8c29/width=904/0ca83a48-675b-454d-a445-ba68b81f8c29.jpeg",
            "hash": "UDA,g$01tlxa_M9Gt7t7-;D*jZoz-:IVR+t7",
            "width": 904,
            "height": 1184,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-28T22:40:59.258Z",
            "postId": 7237763,
            "stats": {
                "cryCount": 4,
                "laughCount": 31,
                "likeCount": 285,
                "dislikeCount": 0,
                "heartCount": 71,
                "commentCount": 2
            },
            "meta": null,
            "username": "spatio",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 29735895,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/26de5c63-c175-488e-a583-b33858e24735/width=1620/26de5c63-c175-488e-a583-b33858e24735.jpeg",
            "hash": "U9Ci]$0LuP=ym6%#9EM_DO-pE1njPoVZ%MI:",
            "width": 1620,
            "height": 2430,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-16T16:07:34.884Z",
            "postId": 6653533,
            "stats": {
                "cryCount": 3,
                "laughCount": 10,
                "likeCount": 309,
                "dislikeCount": 0,
                "heartCount": 70,
                "commentCount": 2
            },
            "meta": {
                "prompt": "Highly detailed, futuristic digital artwork featuring a humanoid robot. The robot is adorned in a sleek, black exoskeleton suit with various mechanical components and illuminated accents. The head is a spherical, white helmet with a prominent red glowing eye and multiple antennae-like wires extending from the back, emitting a bright red light. The suit has intricate details, including a red and white emblem on the chest and a digital display on the left arm. The background is a dynamic, blurred scene with floating debris and a bright, glowing light source, enhancing the high-tech, sci-fi atmosphere."
            },
            "username": "eduardo_saffe",
            "baseModel": ""
        },
        {
            "id": 27745751,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/054c95b5-d006-4eb3-a5dc-32d002163641/width=832/054c95b5-d006-4eb3-a5dc-32d002163641.jpeg",
            "hash": "UFBxD~63S#=e}tNaSgbbK5$NJ7JRFdwvJRsU",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-04T16:45:00.527Z",
            "postId": 6205454,
            "stats": {
                "cryCount": 11,
                "laughCount": 30,
                "likeCount": 277,
                "dislikeCount": 0,
                "heartCount": 73,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 4294967295,
                "extra": {
                    "remixOfId": 27741918
                },
                "steps": 15,
                "prompt": "Vibrant Colorful Realistic analog photo, very detailed, hyper detailed, photorealistic, hyperdetailed, uhd, 4k, the focus of the image is on the witch, extreme closeup Face Portrait, extreme face closeup, head focus, Realistic analog photo, awesome, high Quality, photorealistic, atmospheric lighting, volumetric lighting, cinematic, Epic Film Quality, A muscular old magician stands in the midst of a ferocious DARK sandstormamidst a Desert night, His billowing Bioluminescent Aura and tattered robe barely clinging to his body, revealing glimpses of His scars and sweat-slicked skin. With one hand raised, he conjures a colossal, ancient vibrant black negativ luminous light spell from the swirling dust, its ethereal ghostly form towering above, terrifying and awe-inspiring. The hkmagic witch\u2019s face is shrouded in the shadows of her hood, adding an air of dark mystery. The colorful Flower meadow landscape around her is cloaked in a dusty, dystopian atmosphere, with the sun obscured by the storm. The only light breaking through the chaos is the glowing dark-red aura of her powerful spell, casting an eerie illumination over the scene.",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-09-04T1629:51.2782303Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.2,
                        "modelVersionId": 785638,
                        "modelVersionName": "V1"
                    }
                ]
            },
            "username": "Cosmic_Crafter",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 27234931,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7f29e105-7c96-4a13-9ba4-2b3ae1d81708/width=1040/7f29e105-7c96-4a13-9ba4-2b3ae1d81708.jpeg",
            "hash": "U89@bHBY01[SM0IUyC-p~8K6ES=r=Y9}s+=q",
            "width": 1040,
            "height": 1520,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-01T17:41:53.100Z",
            "postId": 6088089,
            "stats": {
                "cryCount": 7,
                "laughCount": 32,
                "likeCount": 288,
                "dislikeCount": 0,
                "heartCount": 64,
                "commentCount": 3
            },
            "meta": {
                "VAE": "xlVAEC_c1.safetensors",
                "Size": "832x1216",
                "seed": 4099791981,
                "Model": "_Cheyenne_1.8_VAE_Baked.fp16",
                "steps": 25,
                "hashes": {
                    "vae": "11ef3656b6",
                    "model": "c5d7e4579c"
                },
                "prompt": "fantasy illustration by John Howe, James C. Christensen, Richard Hescox, Hayao Miyazaki, Lois van Baarle Jason A. Engle Gerald Brom Yoshitaka Amano Moebius, Victo Ngai Katsuya Terada, hyperdetailed, hyper quality, artstation winning award, bright highlights, deep shadows",
                "Version": "v1.10.1",
                "sampler": "DPM++ 2M",
                "cfgScale": 3.12,
                "resources": [
                    {
                        "hash": "c5d7e4579c",
                        "name": "_Cheyenne_1.8_VAE_Baked.fp16",
                        "type": "model"
                    }
                ],
                "Model hash": "c5d7e4579c",
                "Hires steps": "4",
                "Hires upscale": "1.25",
                "Schedule type": "Karras",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, blurry, bad anatomy, blurred, watermark, grainy, signature, cut off, draft",
                "Denoising strength": "0.5",
                "Token merging ratio": "0.5",
                "Token merging ratio hr": "0.5"
            },
            "username": "Aurety",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 26915839,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5b9bab89-66e4-4ab7-b879-76a1c9f64b2b/width=512/5b9bab89-66e4-4ab7-b879-76a1c9f64b2b.jpeg",
            "hash": "U28z+7I:00?b8_IU?Hxu00_3?v00_NnO00%M",
            "width": 512,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-31T08:10:00.000Z",
            "postId": 6020133,
            "stats": {
                "cryCount": 6,
                "laughCount": 10,
                "likeCount": 323,
                "dislikeCount": 0,
                "heartCount": 52,
                "commentCount": 0
            },
            "meta": {
                "Size": "512x768",
                "seed": 2859470381,
                "extra": {
                    "remixOfId": 16636325
                },
                "steps": 25,
                "prompt": "A stunningly realistic and brutal photo of a demonic sword, featuring a long, sleek black metal blade that reflects light.\nThe double-edged, full tang blade is sharp and deadly.\nThe handle, made of black material, showcases intricate demonic patterns and stripes.\nA ruby adorns the center, adding a pop of red to the sinister design.\nThe dagger is depicted alone, with no humans or other objects in the image, allowing the viewer to fully appreciate its menacing beauty.\nphoto, product",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 2,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-30T1913:09.8946239Z",
                "negativePrompt": "(blue, pink, violet, orange, yellow, green, purple, magenta, cyan), ziprealism",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 128713,
                        "modelVersionName": "8"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Azerlund",
            "baseModel": "SD 1.5"
        },
        {
            "id": 26488506,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/53e47f82-30ed-4d11-9d37-4f2f8b81b6cb/width=1248/53e47f82-30ed-4d11-9d37-4f2f8b81b6cb.jpeg",
            "hash": "UGEVpaZzm*_N%%$xrVTK01WqogRQ02R.tSMy",
            "width": 1248,
            "height": 1872,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-28T00:55:53.441Z",
            "postId": 5920684,
            "stats": {
                "cryCount": 6,
                "laughCount": 14,
                "likeCount": 271,
                "dislikeCount": 0,
                "heartCount": 100,
                "commentCount": 0
            },
            "meta": {
                "RNG": "CPU",
                "VAE": "sdxl_vae.safetensors",
                "Size": "832x1248",
                "seed": 2570086385,
                "Model": "clampdxl_v30",
                "steps": 28,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "d4bbd81581",
                    "lora:pkmnevelyn-pdxl-nvwls-v1-000006": "cef5d4921074"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime, 1girl, solo <lora:pkmnevelyn-pdxl-nvwls-v1-000006:1> pmEvelyn, dark blue hair, bob cut, parted bangs, short hair, blue eyes, large breasts, black shirt, collared shirt, red necktie, black skirt, belt, looking at you, smile, night, city, alleyway",
                "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
                "sampler": "Euler a",
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "cef5d4921074",
                        "name": "pkmnevelyn-pdxl-nvwls-v1-000006",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "d4bbd81581",
                        "name": "clampdxl_v30",
                        "type": "model"
                    }
                ],
                "Model hash": "d4bbd81581",
                "Hires steps": "10",
                "Hires upscale": "1.5",
                "Schedule type": "Automatic",
                "Hires upscaler": "4x-AnimeSharp",
                "negativePrompt": "3d, monochrome, greyscale",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.4.2",
                "Denoising strength": "0.5",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "novowels",
            "baseModel": "Pony"
        },
        {
            "id": 26099269,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/423f8075-b2c6-4c8d-9274-00f2ef478c9d/width=832/423f8075-b2c6-4c8d-9274-00f2ef478c9d.jpeg",
            "hash": "UKC4*4ww|{xGbwjFI.W;BnjuI:X8$*oL#mso",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-08-25T16:19:13.868Z",
            "postId": 5833896,
            "stats": {
                "cryCount": 12,
                "laughCount": 31,
                "likeCount": 246,
                "dislikeCount": 0,
                "heartCount": 102,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1905366993,
                "steps": 40,
                "prompt": "A beautiful woman with red eyes and long black hair, wearing a black fullbody latex suite, shiny latex, casting electric thunder spells from her hands in an attacking pose. The art is in the style of a fantasy style, concept design with a full body shot. hkmagic, masterpiece, best quality, highly detailed, sharp focus, dynamic lighting, mythp0rt",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-25T1614:19.5204018Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 767132,
                        "modelVersionName": "Flux"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 753053,
                        "modelVersionName": "Flux"
                    }
                ]
            },
            "username": "HailoKnight",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 25366154,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/caea454f-8091-4af6-ade3-43645de30706/width=1024/caea454f-8091-4af6-ade3-43645de30706.jpeg",
            "hash": "UOE-dV~B%zk=KixGS~AaF{KPkW%1yC%f%L-.",
            "width": 1024,
            "height": 1024,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-21T03:15:00.099Z",
            "postId": 5668529,
            "stats": {
                "cryCount": 10,
                "laughCount": 26,
                "likeCount": 265,
                "dislikeCount": 0,
                "heartCount": 90,
                "commentCount": 0
            },
            "meta": {
                "seed": 3478,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"6\": {\"inputs\": {\"text\": \"Photorealistic photography of a stunning beauty, close-up, mouth focus, extremely high detail, intricate textures, extremely dark surrounding, extremely low light, nighttime setting, ultra realistic shadows, ethereal, flowing hair illuminated by glowing butterflies, seductive smile, looking at viewer while playing with her hair,  vibrant colors, dreamlike atmosphere, captivating expression, magical forest background, fiery glow, enchanted lighting, expressive eyes reflecting the glowing light, soft, ethereal glow around the figure, delicate and detailed facial features, golden light, intricate patterns in the background\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", \"clip\": [\"86\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp16.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"default\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"dpm_2\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 40, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 3478}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 3.0, \"conditioning\": [\"6\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5, \"width\": 1024, \"height\": 1024, \"model\": [\"86\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"42\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.4, \"alpha\": 0.4, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"43\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"72\", 0]}, \"class_type\": \"SaveImage\"}, \"70\": {\"inputs\": {\"lora_name\": \"flux1\\\\Madison_Beer_For_Flux.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"72\": {\"inputs\": {\"intensity\": 0.03, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"127\", 0]}, \"class_type\": \"FilmGrain\"}, \"86\": {\"inputs\": {\"lora_name\": \"flux1\\\\flux_realism_lora.safetensors\", \"strength_model\": 0.75, \"strength_clip\": 1.0, \"model\": [\"70\", 0], \"clip\": [\"70\", 1]}, \"class_type\": \"LoraLoader\"}, \"104\": {\"inputs\": {\"text\": \"\", \"clip\": [\"86\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"111\": {\"inputs\": {\"upscale_by\": 2.0, \"seed\": 317, \"steps\": 15, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 0.25, \"mode_type\": \"Linear\", \"tile_width\": 1024, \"tile_height\": 1024, \"mask_blur\": 20, \"tile_padding\": 56, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 16, \"seam_fix_padding\": 32, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"72\", 0], \"model\": [\"30\", 0], \"positive\": [\"6\", 0], \"negative\": [\"104\", 0], \"vae\": [\"10\", 0], \"upscale_model\": [\"112\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"112\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"119\": {\"inputs\": {\"sharpen_radius\": 2, \"sigma\": 0.25, \"alpha\": 0.25, \"image\": [\"111\", 0]}, \"class_type\": \"ImageSharpen\"}, \"120\": {\"inputs\": {\"scale\": 0.25, \"strength\": 0.05, \"saturation\": 0.7, \"toe\": 0.0, \"seed\": 585551037753486, \"image\": [\"125\", 0]}, \"class_type\": \"BetterFilmGrain\"}, \"125\": {\"inputs\": {\"hdr_intensity\": 0.8, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"119\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"127\": {\"inputs\": {\"hdr_intensity\": 0.85, \"shadow_intensity\": 0.45, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.35000000000000003, \"image\": [\"42\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"173\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"120\", 0]}, \"class_type\": \"SaveImage\"}, \"176\": {\"inputs\": {\"guide_size\": 512, \"guide_size_for\": true, \"max_size\": 1024, \"seed\": 1014061238560136, \"steps\": 20, \"cfg\": 8, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.5, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.5, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"bbox_detector\": [\"179\", 0], \"sam_model_opt\": [\"178\", 0], \"segm_detector_opt\": [\"181\", 1]}, \"class_type\": \"FaceDetailer\"}, \"177\": {\"inputs\": {\"threshold\": 0.5, \"dilation\": 10, \"crop_factor\": 3, \"drop_size\": 10, \"labels\": \"all\"}, \"class_type\": \"BboxDetectorSEGS\"}, \"178\": {\"inputs\": {\"model_name\": \"mobile_sam.pt\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\"}, \"179\": {\"inputs\": {\"model_name\": null}, \"class_type\": \"ONNXDetectorProvider\"}, \"181\": {\"inputs\": {\"model_name\": \"bbox/face_yolov8m.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"196\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"default\", \"double_blocks_cuda_size\": 7, \"single_blocks_cuda_size\": 7}, \"class_type\": \"MZ_Flux1UnetLoader_cpuDynOffload\"}, \"197\": {\"inputs\": {\"ckpt_name\": \"AuraFlow\\\\aura_flow_0.3.safetensors\", \"double_blocks_cuda_size\": 7, \"single_blocks_cuda_size\": 7}, \"class_type\": \"MZ_Flux1CheckpointLoaderNF4_cpuDynOffload\"}, \"198\": {\"inputs\": {\"anything\": [\"120\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}, \"199\": {\"inputs\": {\"anything\": [\"72\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}, \"201\": {\"inputs\": {\"anything\": [\"27\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}}, \"workflow\": {\"last_node_id\": 203, \"last_link_id\": 337, \"nodes\": [{\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": [359, 149], \"size\": [644.2343679302923, 423.40483577107705], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 162, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [272, 275], \"slot_index\": 0}], \"title\": \"CLIP Text Encode (Positive Prompt)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"Photorealistic photography of a stunning beauty, close-up, mouth focus, extremely high detail, intricate textures, extremely dark surrounding, extremely low light, nighttime setting, ultra realistic shadows, ethereal, flowing hair illuminated by glowing butterflies, seductive smile, looking at viewer while playing with her hair,  vibrant colors, dreamlike atmosphere, captivating expression, magical forest background, fiery glow, enchanted lighting, expressive eyes reflecting the glowing light, soft, ethereal glow around the figure, delicate and detailed facial features, golden light, intricate patterns in the background\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": [825, 48], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 180}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [296], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": [27, 330], \"size\": {\"0\": 311.81634521484375, \"1\": 60.429901123046875}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12, 199], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": [9, 171], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [146], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp16.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": [6, 41], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"default\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": [788, 615], \"size\": {\"0\": 308.62738037109375, \"1\": 567.866943359375}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 30, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 327, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [180], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": [408, 1017], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpm_2\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": [409, 1117], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 55, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 40, 1]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": [349, 39], \"size\": {\"0\": 222.3482666015625, \"1\": 46}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 265, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [30], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": [411, 893], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [3478, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": [591, 42], \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 272}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [265], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": [406, 745], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 140, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [326, 327], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [1024, 1024, 1]}, {\"id\": 28, \"type\": \"Note\", \"pos\": [27, 779], \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": [468, 1286], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 161, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 55, 325], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 1024, 1024]}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": [346, 622], \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 140], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1024, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": [572, 625], \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1024, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 37, \"type\": \"Note\", \"pos\": [35, 1111], \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": [1507, -884], \"size\": {\"0\": 393.98309326171875, \"1\": 1198.8323974609375}, \"flags\": {}, \"order\": 5, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": null}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 42, \"type\": \"ImageSharpen\", \"pos\": [732, -113], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 296, \"slot_index\": 0}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [286], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.4, 0.4]}, {\"id\": 43, \"type\": \"SaveImage\", \"pos\": [1082, -882], \"size\": {\"0\": 396.35198974609375, \"1\": 1194.08154296875}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 318}], \"title\": \"Save Image (sharp and enhance)\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 70, \"type\": \"LoraLoader\", \"pos\": [18, 435], \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 145, \"slot_index\": 0}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 146, \"slot_index\": 1}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [159], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [160], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Madison_Beer_For_Flux.safetensors\", 1, 1]}, {\"id\": 72, \"type\": \"FilmGrain\", \"pos\": [387, -565], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 302, \"slot_index\": 0}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [317, 323, 324], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.03, 10, 0, 0]}, {\"id\": 86, \"type\": \"LoraLoader\", \"pos\": [20, 609], \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 159, \"slot_index\": 0}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 160, \"slot_index\": 1}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [161], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [162, 172], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\flux_realism_lora.safetensors\", 0.75, 1]}, {\"id\": 104, \"type\": \"CLIPTextEncode\", \"pos\": [864, 1096], \"size\": {\"0\": 409.1979064941406, \"1\": 75.99993896484375}, \"flags\": {\"collapsed\": true}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 172, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [191], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 111, \"type\": \"UltimateSDUpscale\", \"pos\": [1116, 550], \"size\": [264.3000183105469, 980.3591918945312], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 324}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 325, \"slot_index\": 1}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 275, \"slot_index\": 2}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 191, \"slot_index\": 3}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 199, \"slot_index\": 4}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 194}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [276], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 317, \"increment\", 15, 1, \"euler\", \"simple\", 0.25, \"Linear\", 1024, 1024, 20, 56, \"None\", 1, 64, 16, 32, true, false], \"locked\": true}, {\"id\": 112, \"type\": \"UpscaleModelLoader\", \"pos\": [1668, 432], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [194], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"]}, {\"id\": 119, \"type\": \"ImageSharpen\", \"pos\": [2512, 894], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 276, \"slot_index\": 0}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [329], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [2, 0.25, 0.25]}, {\"id\": 120, \"type\": \"BetterFilmGrain\", \"pos\": [2518, 1260], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 332}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [309, 335], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BetterFilmGrain\"}, \"widgets_values\": [0.25, 0.05, 0.7, 0, 585551037753486, \"randomize\"]}, {\"id\": 125, \"type\": \"LayerFilter: HDREffects\", \"pos\": [2519, 1042], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 329}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.8, 0.25, 0.75, 0.25, 0.1, 0.25]}, {\"id\": 127, \"type\": \"LayerFilter: HDREffects\", \"pos\": [730, -607], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {\"collapsed\": false}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 298}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [302], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.85, 0.45, 0.75, 0.25, 0.1, 0.35000000000000003]}, {\"id\": 139, \"type\": \"LayerFilter: HDREffects\", \"pos\": [-114, -409], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {\"collapsed\": false}, \"order\": 6, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25]}, {\"id\": 173, \"type\": \"SaveImage\", \"pos\": [1404, 551], \"size\": [557.3127827102903, 897.0792923661102], \"flags\": {\"collapsed\": false}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 337, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"locked\": true}, {\"id\": 174, \"type\": \"CR Aspect Ratio SDXL\", \"pos\": [-415, 850], \"size\": {\"0\": 315, \"1\": 302}, \"flags\": {}, \"order\": 7, \"mode\": 4, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"INT\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"slot_index\": 2, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}, {\"name\": \"INT\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR Aspect Ratio SDXL\"}, \"widgets_values\": [1024, 1024, \"custom\", \"Off\", 1, 1, 1]}, {\"id\": 176, \"type\": \"FaceDetailer\", \"pos\": [3062, -191], \"size\": {\"0\": 519, \"1\": 900}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 282}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 281}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 284}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": null, \"slot_index\": 1, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [512, true, 1024, 1014061238560136, \"randomize\", 20, 8, \"euler\", \"normal\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 177, \"type\": \"BboxDetectorSEGS\", \"pos\": [2632, -185], \"size\": {\"0\": 400, \"1\": 212}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": null}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}], \"outputs\": [{\"name\": \"SEGS\", \"type\": \"SEGS\", \"links\": null, \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BboxDetectorSEGS\"}, \"widgets_values\": [0.5, 10, 3, 10, \"all\"]}, {\"id\": 178, \"type\": \"SAMLoader\", \"pos\": [2709, 74], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [281], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"mobile_sam.pt\", \"AUTO\"]}, {\"id\": 179, \"type\": \"ONNXDetectorProvider\", \"pos\": [2705, 218], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [282], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ONNXDetectorProvider\"}, \"widgets_values\": [null]}, {\"id\": 181, \"type\": \"UltralyticsDetectorProvider\", \"pos\": [2281, -122], \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [284], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 182, \"type\": \"EnhanceDetail\", \"pos\": [420, -369], \"size\": {\"0\": 253.6738739013672, \"1\": 130}, \"flags\": {}, \"order\": 33, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 286}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [297], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EnhanceDetail\"}, \"widgets_values\": [2, 0.1, 0.1, 1.5]}, {\"id\": 192, \"type\": \"Image Filter Adjustments\", \"pos\": [721, -382], \"size\": {\"0\": 315, \"1\": 226}, \"flags\": {}, \"order\": 34, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 297}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Filter Adjustments\"}, \"widgets_values\": [0, 1, 1, 1, 0, 0, 0, \"true\"]}, {\"id\": 196, \"type\": \"MZ_Flux1UnetLoader_cpuDynOffload\", \"pos\": [2874, 1406], \"size\": {\"0\": 344.3999938964844, \"1\": 130}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"MZ_Flux1UnetLoader_cpuDynOffload\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"default\", 7, 7]}, {\"id\": 197, \"type\": \"MZ_Flux1CheckpointLoaderNF4_cpuDynOffload\", \"pos\": [3199.2669388355403, 1397.6350680173095], \"size\": {\"0\": 420, \"1\": 146}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": null, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": null, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"MZ_Flux1CheckpointLoaderNF4_cpuDynOffload\"}, \"widgets_values\": [\"AuraFlow\\\\aura_flow_0.3.safetensors\", 7, 7]}, {\"id\": 198, \"type\": \"easy cleanGpuUsed\", \"pos\": [2598, 856], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"collapsed\": true}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 309}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 199, \"type\": \"easy cleanGpuUsed\", \"pos\": [1181, 511], \"size\": [140, 26], \"flags\": {\"collapsed\": true}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 323}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 200, \"type\": \"Reroute\", \"pos\": [785, -778], \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 317}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [318], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 201, \"type\": \"easy cleanGpuUsed\", \"pos\": [876, 1227], \"size\": {\"0\": 140, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 326}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 202, \"type\": \"Reroute\", \"pos\": [2735, 1457], \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 335}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [336], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 203, \"type\": \"Reroute\", \"pos\": [1424, 1457], \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 336}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [337], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}], \"links\": [[12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [30, 22, 0, 13, 1, \"GUIDER\"], [37, 25, 0, 13, 0, \"NOISE\"], [54, 30, 0, 22, 0, \"MODEL\"], [55, 30, 0, 17, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [140, 34, 0, 27, 0, \"INT\"], [145, 12, 0, 70, 0, \"MODEL\"], [146, 11, 0, 70, 1, \"CLIP\"], [159, 70, 0, 86, 0, \"MODEL\"], [160, 70, 1, 86, 1, \"CLIP\"], [161, 86, 0, 30, 0, \"MODEL\"], [162, 86, 1, 6, 0, \"CLIP\"], [172, 86, 1, 104, 0, \"CLIP\"], [180, 13, 0, 8, 0, \"LATENT\"], [191, 104, 0, 111, 3, \"CONDITIONING\"], [194, 112, 0, 111, 5, \"UPSCALE_MODEL\"], [199, 10, 0, 111, 4, \"VAE\"], [265, 26, 0, 22, 1, \"CONDITIONING\"], [272, 6, 0, 26, 0, \"CONDITIONING\"], [275, 6, 0, 111, 2, \"CONDITIONING\"], [276, 111, 0, 119, 0, \"IMAGE\"], [281, 178, 0, 176, 7, \"SAM_MODEL\"], [282, 179, 0, 176, 6, \"BBOX_DETECTOR\"], [284, 181, 1, 176, 8, \"SEGM_DETECTOR\"], [286, 42, 0, 182, 0, \"IMAGE\"], [296, 8, 0, 42, 0, \"IMAGE\"], [297, 182, 0, 192, 0, \"IMAGE\"], [298, 192, 0, 127, 0, \"IMAGE\"], [302, 127, 0, 72, 0, \"IMAGE\"], [309, 120, 0, 198, 0, \"*\"], [317, 72, 0, 200, 0, \"*\"], [318, 200, 0, 43, 0, \"IMAGE\"], [323, 72, 0, 199, 0, \"*\"], [324, 72, 0, 111, 0, \"IMAGE\"], [325, 30, 0, 111, 1, \"MODEL\"], [326, 27, 0, 201, 0, \"*\"], [327, 27, 0, 13, 4, \"LATENT\"], [329, 119, 0, 125, 0, \"IMAGE\"], [332, 125, 0, 120, 0, \"IMAGE\"], [335, 120, 0, 202, 0, \"*\"], [336, 202, 0, 203, 0, \"*\"], [337, 203, 0, 173, 0, \"IMAGE\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.9090909090909091, \"offset\": [-136.51861823690257, 479.4469318606546]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"111\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"120\": {\"seed\": 4}, \"176\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}}, \"seed_widgets\": {\"25\": 0, \"111\": 1, \"120\": 4, \"176\": 3}}}",
                "steps": 40,
                "models": [],
                "prompt": "Photorealistic photography of a stunning beauty, close-up, mouth focus, extremely high detail, intricate textures, extremely dark surrounding, extremely low light, nighttime setting, ultra realistic shadows, ethereal, flowing hair illuminated by glowing butterflies, seductive smile, looking at viewer while playing with her hair,  vibrant colors, dreamlike atmosphere, captivating expression, magical forest background, fiery glow, enchanted lighting, expressive eyes reflecting the glowing light, soft, ethereal glow around the figure, delicate and detailed facial features, golden light, intricate patterns in the background\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
                "denoise": 1,
                "sampler": "DPM2",
                "cfgScale": 3,
                "modelIds": [],
                "scheduler": "simple",
                "upscalers": [
                    "4x-UltraSharp.pth"
                ],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux1\\Madison_Beer_For_Flux.safetensors",
                        "type": "lora",
                        "strength": 1,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux1\\flux_realism_lora.safetensors",
                        "type": "lora",
                        "strength": 0.75,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "salammy",
            "baseModel": null
        },
        {
            "id": 25175086,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/513b0499-49ce-4ef2-82f1-9fcae8f9a9fb/width=832/513b0499-49ce-4ef2-82f1-9fcae8f9a9fb.jpeg",
            "hash": "UGGuRB_N9GM{00E3?H-;-oNG%2xuRPt7ofM{",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-20T00:11:32.647Z",
            "postId": 5626172,
            "stats": {
                "cryCount": 17,
                "laughCount": 74,
                "likeCount": 228,
                "dislikeCount": 0,
                "heartCount": 72,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3154413554,
                "extra": {
                    "remixOfId": 24996677
                },
                "steps": 30,
                "prompt": "realistic photo of crying cat looking at a jar of milk that is on its side, the jar of milk is spilling onto the floor, the cat is sitting on the floor, shallow depth of field, kitchen in background, incredibly detailed, hyperrealistic digital photo, crying, tears, the jar of milk is labled \"milk\"",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-19T2004:52.5379838Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 739589,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "LordTerror",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 24714116,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3e1ea49e-85dd-4084-b7f5-7f76ad787e99/width=1800/3e1ea49e-85dd-4084-b7f5-7f76ad787e99.jpeg",
            "hash": "ULCiw8t700jZ_Noz9FRj-;t7M{WB%MofRjWB",
            "width": 3056,
            "height": 4496,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-17T06:23:26.662Z",
            "postId": 5521632,
            "stats": {
                "cryCount": 13,
                "laughCount": 15,
                "likeCount": 290,
                "dislikeCount": 0,
                "heartCount": 73,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 487472808331372,
                "Model": "FLUX",
                "steps": 30,
                "hashes": {
                    "model": "",
                    "embed:EZNegPONYXL": "4dbf83ac7c"
                },
                "prompt": "rbcharc0al, ultra detailed cityscape scene of a futuristic metropolis in the style of blade runner",
                "Version": "ComfyUI",
                "sampler": "Euler",
                "cfgScale": 2.5,
                "resources": [],
                "Model hash": "",
                "negativePrompt": "embedding:EZNegPONYXL,"
            },
            "username": "pAInCREAT0R",
            "baseModel": null
        },
        {
            "id": 22171331,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fd4fe027-69ec-46ba-bbfe-c42cb7773503/width=832/fd4fe027-69ec-46ba-bbfe-c42cb7773503.jpeg",
            "hash": "U8Ad13Q-4qtk_MD*My%LPCIof4xutSRQayxt",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-31T15:59:37.238Z",
            "postId": 4942087,
            "stats": {
                "cryCount": 5,
                "laughCount": 19,
                "likeCount": 270,
                "dislikeCount": 0,
                "heartCount": 97,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 985175134,
                "steps": 10,
                "prompt": "Vegetables houses, Designed houses made from various vegetables. Picture a vibrant scene with carrot cottages, tomato towers, and leafy greens forming the village landscape. The atmosphere is mystic and dreamy, with soft, glowing lights illuminating the vegetable homes. Delicate details like tiny elf gardens, miniature bridges made of twigs, enhancing the enchanting feel of this vegetable wonderland.\n[style of greg rutkowski,janek sedlar,jenny saville:0]  <lora:vivid_everclear:0.35>  <lora:Sinozick:0.35>  <lora:MJ52:0.35>",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 2.5,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "vivid_everclear",
                        "type": "lora",
                        "weight": 0.35
                    },
                    {
                        "name": "Sinozick",
                        "type": "lora",
                        "weight": 0.35
                    },
                    {
                        "name": "MJ52",
                        "type": "lora",
                        "weight": 0.35
                    }
                ],
                "Created Date": "2024-07-31T1555:48.8056709Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 345685,
                        "modelVersionName": "FUSION OG"
                    },
                    {
                        "type": "lora",
                        "weight": 0.35,
                        "modelVersionId": 283697,
                        "modelVersionName": "v1.2"
                    },
                    {
                        "type": "lora",
                        "weight": 0.35,
                        "modelVersionId": 403123,
                        "modelVersionName": "V1"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Disto",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 20595772,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/10450daf-ef04-4dca-aa82-c1c03344f1db/width=832/10450daf-ef04-4dca-aa82-c1c03344f1db.jpeg",
            "hash": "U7E{In+tc=I:1TU]0dJ-0J00ogIU_1?G~Xix",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-20T04:58:01.720Z",
            "postId": 4592828,
            "stats": {
                "cryCount": 24,
                "laughCount": 46,
                "likeCount": 237,
                "dislikeCount": 0,
                "heartCount": 84,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 878181556,
                "steps": 40,
                "prompt": "white desert oasis, salty earth, hyper detailed,  rusty, striking, animalistic, bite-sized, by Floris van Schooten  and by richard avedon, famous artwork inspired by (beeple:1.3) and (cliff nielsen:1.4), crystalline, fractal art, fantasy style, this peculiar life form, the \"inquisitive plerkblortz\" hides in the gnarling dense crystal jungles of the puffalorpled exoplanet \"gazorpazorp secundus\", covered in a metallic exoskeleton it ambushes its prey with (long crystalline appendages:1.4), dark, shadows, black, shadow hues, highly artistic, highly painterly, harmonic colors, expressive, ultimate aesthetic level, visible brushstrokes, masterclass artistry, vibrant energy, apocalyptic mood, atmospheric haze and dense fog, strong winds,  highly aesthetic, otherworldly, limited palette,  faded colors, washed out colors, extremely dark, extremely low key lighting, dark shadows, perfect composition, full panoramic shot translucent, transparent, glowneon, glowing, sparks, lightning",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-07-20T0047:27.9703734Z",
                "negativePrompt": "(worst quality, greyscale, jpeg artifacts:1.2)",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 329420,
                        "modelVersionName": "v2.1"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 135867,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 348189,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 177888,
                        "modelVersionName": "SDXL VERSION"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "HyperActive84",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 19410855,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ffde565e-618c-4e0f-8346-4dcd949c17a6/width=1536/ffde565e-618c-4e0f-8346-4dcd949c17a6.jpeg",
            "hash": "UKH1GG-:B-~VK3%2wJRjELIVRPW;9GxttQn%",
            "width": 1536,
            "height": 2304,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-07-11T19:08:00.474Z",
            "postId": 4336131,
            "stats": {
                "cryCount": 14,
                "laughCount": 43,
                "likeCount": 248,
                "dislikeCount": 0,
                "heartCount": 86,
                "commentCount": 0
            },
            "meta": {
                "Size": "512x512",
                "Model": "majicmixRealistic_v7",
                "hashes": {
                    "model": "7c819b6d13",
                    "lora:Lavadress": "cb399d9d046f"
                },
                "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
                "sampler": "DPM++ 2M Karras",
                "clipSkip": 2,
                "Mask blur": "4",
                "resources": [
                    {
                        "hash": "cb399d9d046f",
                        "name": "Lavadress",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "hash": "7c819b6d13",
                        "name": "majicmixRealistic_v7",
                        "type": "model"
                    }
                ],
                "Model hash": "7c819b6d13",
                "Inpaint area": "Only masked",
                "Denoising strength": "0.35",
                "Masked area padding": "32"
            },
            "username": "Vivi_AI",
            "baseModel": "SD 1.5"
        },
        {
            "id": 16877663,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cab4560f-6e60-4f7c-a8dc-bfd518ea7459/width=1024/cab4560f-6e60-4f7c-a8dc-bfd518ea7459.jpeg",
            "hash": "UBD]Cy~V4:S4EKE1D+Rk.7xaD*t6.Ss;RPt6",
            "width": 1024,
            "height": 1024,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-23T14:18:15.131Z",
            "postId": 3786079,
            "stats": {
                "cryCount": 43,
                "laughCount": 157,
                "likeCount": 134,
                "dislikeCount": 0,
                "heartCount": 57,
                "commentCount": 2
            },
            "meta": {
                "Size": "1024x1024",
                "seed": 1861874159,
                "steps": 40,
                "prompt": "score_9, score_8_up, score_7_up, uncensored, 5_fingers, fantasy,village, outdoors,\nADDCOMM\n(shrek, green skin), torn clothes,  (pillorypose,public indecency), dirty, filthy, muddy, grinning\n<lora:pillorypose:1>",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "pillorypose",
                        "type": "lora",
                        "weight": 1
                    }
                ],
                "Created Date": "2024-06-23T1413:05.6087716Z",
                "negativePrompt": "source_pony, source_furry, score 5, score 4, greyscale, monochrome, simple background, white background, censored, mole, muscular female, futanari, lipstick, text, patreon username, signature, watermark, (dark-skinned male), sheep ears,, dark-skinned female,extra digits, bad anatomy,bad_feet,blue_skin,cat boy, black tail,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 534642,
                        "modelVersionName": "v2.1 Main + VAE"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 395911,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 592762,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "kftiger",
            "baseModel": "Pony"
        },
        {
            "id": 7931092,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7e82aed7-9fc8-4888-9aab-7f75fc913080/width=1800/7e82aed7-9fc8-4888-9aab-7f75fc913080.jpeg",
            "hash": "UAC%1?~pxZ%158S5R+g3xat8-:xZ%1bcNeRj",
            "width": 2048,
            "height": 3072,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-03-14T10:16:27.157Z",
            "postId": 1718924,
            "stats": {
                "cryCount": 7,
                "laughCount": 11,
                "likeCount": 240,
                "dislikeCount": 0,
                "heartCount": 133,
                "commentCount": 2
            },
            "meta": {
                "Size": "1024x1536",
                "seed": 3361558687,
                "Model": "GhostXL_V1.0-Baked VAE",
                "steps": 20,
                "hashes": {
                    "model": "ee1fdc86f7"
                },
                "prompt": "abstract art,(style of Yuko Shimizu:1.3),gold theme,dark sky,dark stars,<lora:20240222-1708571578268:1>,",
                "Version": "v1.6.0",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "ee1fdc86f7",
                        "name": "GhostXL_V1.0-Baked VAE",
                        "type": "model"
                    }
                ],
                "Model hash": "ee1fdc86f7",
                "negativePrompt": "ng_deepnegative_v1_75t,badhandv4 (worst quality:2),(low quality:2),(normal quality:2),lowres,bad anatomy,bad hands,normal quality,((monochrome)),((grayscale)),nsfw,",
                "Denoising strength": "0.4",
                "SD upscale overlap": "64",
                "SD upscale upscaler": "4x-UltraSharp",
                "\"20240222-1708571578268": "603c348161a7\""
            },
            "username": "RichWalsh",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 6194937,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7213dd53-df3c-4015-856e-efe7205ae237/width=1072/7213dd53-df3c-4015-856e-efe7205ae237.jpeg",
            "hash": "U8DR{C}@0BWtcFNGrZso0W9u-Qoe0VxG^cSO",
            "width": 1072,
            "height": 1608,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-03T00:30:12.302Z",
            "postId": 1340234,
            "stats": {
                "cryCount": 1,
                "laughCount": 32,
                "likeCount": 230,
                "dislikeCount": 0,
                "heartCount": 128,
                "commentCount": 0
            },
            "meta": {
                "VAE": "sdxl_vae.safetensors",
                "Size": "768x1152",
                "seed": 1996009998,
                "Model": "zavychromaxl_v40",
                "steps": 24,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "63a3752da1",
                    "lora:dreamyvibes_artstyle": "1a25fddf84"
                },
                "prompt": "by Natalia Rak and Robert Haganin the style of John Atkinson Grimshaw, dreamyvibes artstyle <lora:dreamyvibes_artstyle:0.60>",
                "Version": "v1.7.0",
                "sampler": "DPM++ 2M Karras",
                "Template": "\"by Natalia Rak and Robert Haganin the style of John Atkinson Grimshaw",
                "VAE hash": "235745af8d",
                "cfgScale": 7,
                "Pad conds": "True",
                "resources": [
                    {
                        "name": "dreamyvibes_artstyle",
                        "type": "lora",
                        "weight": 0.6
                    },
                    {
                        "hash": "63a3752da1",
                        "name": "zavychromaxl_v40",
                        "type": "model"
                    }
                ],
                "(tan lines": "1.6), (Unspeakable-Horrors-Composition-4v, deepnegative_v1_75t, BadDream",
                "Model hash": "63a3752da1",
                "Hires steps": "10",
                "Hires upscale": "1.4",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "deviantart, deviant, art, amateur, poorly drawn, messy, mess, low quality, doll, doll eyes, deformed, mutant, multicolored hair, painted face, multiple heads, extra limbs, gross, poorly drawn hands, poorly drawn face, cloned, duplicated, deformed fingers, comic, illustration, painting, drawing, surreal, weird clothing, weird art, ugly eyes, closed eyes",
                "normal quality": "2.0)",
                "ADetailer model": "face_yolov8n.pt",
                "UnrealisticDream": "1.2)\"",
                "ADetailer VAE 3rd": "vae-ft-mse-840000-ema-pruned.ckpt",
                "ADetailer version": "24.1.2",
                "Negative Template": "\"deviantart, deviant, art, amateur, poorly drawn, messy, mess, low quality, doll, doll eyes, deformed, mutant, multicolored hair, painted face, multiple heads, extra limbs, gross, poorly drawn hands, poorly drawn face, cloned, duplicated, deformed fingers, comic, illustration, painting, drawing, surreal, weird clothing, weird art, ugly eyes, closed eyes\"",
                "Denoising strength": "0.4",
                "ADetailer mask blur": "12",
                "ADetailer model 2nd": "hand_yolov8n.pt",
                "ADetailer model 3rd": "female_breast_v3.2.pt",
                "ADetailer steps 3rd": "20",
                "ADetailer confidence": "0.5",
                "ADetailer prompt 3rd": "[[ __prompt__ ]] __detailer/breasts__",
                "dreamyvibes_artstyle": "0.60>\"",
                "\"dreamyvibes_artstyle": "878e2d40fdc5\"",
                "ADetailer sampler 3rd": "DPM++ 2M Karras",
                "ADetailer dilate erode": "12",
                "ADetailer CFG scale 3rd": "7.0",
                "ADetailer inpaint width": "1024",
                "ADetailer mask blur 2nd": "12",
                "ADetailer mask blur 3rd": "12",
                "ADetailer checkpoint 3rd": "SD1.5\\wafflemix7.safetensors [4844f773bb]",
                "ADetailer confidence 2nd": "0.5",
                "ADetailer confidence 3rd": "0.5",
                "ADetailer inpaint height": "1024",
                "ADetailer mask min ratio": "0.001",
                "ADetailer inpaint padding": "256",
                "ADetailer dilate erode 2nd": "12",
                "ADetailer dilate erode 3rd": "12",
                "ADetailer inpaint width 2nd": "896",
                "ADetailer inpaint width 3rd": "1024",
                "ADetailer denoising strength": "0.45",
                "ADetailer inpaint height 2nd": "896",
                "ADetailer inpaint height 3rd": "1024",
                "ADetailer mask min ratio 2nd": "0.001",
                "ADetailer mask min ratio 3rd": "0.001",
                "ADetailer inpaint only masked": "True",
                "ADetailer inpaint padding 2nd": "256",
                "ADetailer inpaint padding 3rd": "256",
                "ADetailer negative prompt 3rd": "\"cartoon, painting, illustration, (worst quality, low quality",
                "ADetailer use separate VAE 3rd": "True",
                "ADetailer denoising strength 2nd": "0.35",
                "ADetailer denoising strength 3rd": "0.45",
                "ADetailer use separate steps 3rd": "True",
                "ADetailer inpaint only masked 2nd": "True",
                "ADetailer inpaint only masked 3rd": "True",
                "ADetailer mask only top k largest": "5",
                "ADetailer use inpaint width height": "True",
                "ADetailer use separate sampler 3rd": "True",
                "ADetailer use separate CFG scale 3rd": "True",
                "ADetailer mask only top k largest 2nd": "6",
                "ADetailer mask only top k largest 3rd": "4",
                "ADetailer use separate checkpoint 3rd": "True",
                "ADetailer use inpaint width height 2nd": "True",
                "ADetailer use inpaint width height 3rd": "True"
            },
            "username": "LordTerror",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 5233301,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ab91c97d-1baa-472d-a846-382783bdb373/width=1152/ab91c97d-1baa-472d-a846-382783bdb373.jpeg",
            "hash": "U78|@VxZIU?G~pRjIUxtR6kCIVRjaK-:%LRP",
            "width": 1152,
            "height": 1800,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-01-06T22:05:24.136Z",
            "postId": 1143367,
            "stats": {
                "cryCount": 8,
                "laughCount": 26,
                "likeCount": 227,
                "dislikeCount": 0,
                "heartCount": 130,
                "commentCount": 5
            },
            "meta": {
                "Size": "768x1200",
                "seed": 1259215713,
                "Model": "sdxlUnstableDiffusers_v11",
                "steps": 25,
                "hashes": {
                    "model": "096eb037fc"
                },
                "prompt": "photography in the style of detailed hyperrealism ,creature ,fantasy,James Christensen,bold lines,hyper detailed",
                "\"Module": "lineart_anime",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "096eb037fc",
                        "name": "sdxlUnstableDiffusers_v11",
                        "type": "model"
                    }
                ],
                "Model hash": "096eb037fc",
                "negativePrompt": "negativeXL_D,nude, asian",
                "Denoising strength": "0.2"
            },
            "username": "Jogging",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 2148925,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9f71ed4a-3858-4626-834c-e61845deda50/width=1792/9f71ed4a-3858-4626-834c-e61845deda50.jpeg",
            "hash": "ULL;a9~WIU9Z_3?bIU%gDispIU_3sARj%Mo}",
            "width": 1792,
            "height": 2304,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-09-02T04:48:35.443Z",
            "postId": 525454,
            "stats": {
                "cryCount": 30,
                "laughCount": 15,
                "likeCount": 215,
                "dislikeCount": 0,
                "heartCount": 131,
                "commentCount": 4
            },
            "meta": {
                "Size": "896x1152",
                "seed": 4289357550,
                "Model": "dreamshaperSDXL10_alpha2Xl10",
                "steps": 50,
                "hashes": {
                    "model": "0f1b80cfe8"
                },
                "prompt": "a black and white painting of a little girl red dress, side view, giving a red balloon to an adult army soldier holding a rifle,  with red paint splatters, , with a black and white background, Carne Griffiths, incredible art, graffiti art, modern european ink painting",
                "Version": "v1.5.1",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 25,
                "resources": [
                    {
                        "hash": "0f1b80cfe8",
                        "name": "dreamshaperSDXL10_alpha2Xl10",
                        "type": "model"
                    }
                ],
                "Model hash": "0f1b80cfe8",
                "negativePrompt": "Bad Quality, Deformed, Extra Fingers, watermark, text, blurry, rough draft",
                "Denoising strength": "0.2",
                "SD upscale overlap": "64",
                "SD upscale upscaler": "4x-UltraMix_Restore"
            },
            "username": "StatikFlux",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 2000904,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b0a4619e-b98f-428b-a19b-e8656af65510/width=768/b0a4619e-b98f-428b-a19b-e8656af65510.jpeg",
            "hash": "UIKBBxu4_M#7P7%3Mxtm~q?c-;o|9cxu$*sk",
            "width": 768,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-08-12T23:15:20.635Z",
            "postId": 492267,
            "stats": {
                "cryCount": 19,
                "laughCount": 38,
                "likeCount": 233,
                "dislikeCount": 0,
                "heartCount": 101,
                "commentCount": 0
            },
            "meta": {
                "Size": "512x512",
                "seed": 3025135048,
                "try2": "91184b428ad3\"",
                "Model": "AnythingV5Ink_ink",
                "steps": 30,
                "hashes": {
                    "model": "a1535d0a42"
                },
                "prompt": "<lora:HarukaKamijo-08:0.9>, (extremely detailed:1.2),(highly detailed:1.1),(best quality:1.1),(masterpiece:1.1), 1girl, solo, HarukaKamijo, v-shaped eyebrows, long hair, very long hair, blue hair, purple hair, purple eyes, swept bangs, thighhighs, Chinese clothes, China dress, red dress, long dress, single hair bun necklace, jewelry, dynamic poses, outdoors, cherry blossom trees, <lyco:GoodHands-beta2 (1):1.0>, nice hands, perfect hands, <lora:try2:0.8>",
                "Version": "## 1.4.0",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 6,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "try2",
                        "type": "lora",
                        "weight": 0.8
                    },
                    {
                        "hash": "a1535d0a42",
                        "name": "AnythingV5Ink_ink",
                        "type": "model"
                    }
                ],
                "Model hash": "a1535d0a42",
                "Hires upscale": "1.5",
                "Hires upscaler": "R-ESRGAN 4x+ Anime6B",
                "negativePrompt": "(negative_hand-neg:1.1), (EasyNegative:1.1), jpeg artifacts, (signature:1.4), (watermark:1.4), (username:1.4), blurry, (artist name:1.4), extra arms, (extra fingers, deformed hands, polydactyl:1.5)",
                "\"HarukaKamijo-08": "fab7ec121c41",
                "Denoising strength": "0.5"
            },
            "username": "Zephyrous",
            "baseModel": "SD 1.5"
        },
        {
            "id": 1777436,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8f9573d7-5616-4260-a967-53343afd5e33/width=896/8f9573d7-5616-4260-a967-53343afd5e33.jpeg",
            "hash": "U8F580W;01IT-,4;Nz%10eD*?Ho#~paxv}M{",
            "width": 896,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-14T00:24:12.321Z",
            "postId": 439417,
            "stats": {
                "cryCount": 7,
                "laughCount": 35,
                "likeCount": 196,
                "dislikeCount": 0,
                "heartCount": 153,
                "commentCount": 0
            },
            "meta": {
                "vaes": [
                    "sdXLVAE_09.safetensors"
                ],
                "Model": "sd_xl_base_1.0_0.9vae",
                "comfy": {
                    "prompt": {
                        "4": {
                            "inputs": {
                                "ckpt_name": "sd_xl_base_1.0_0.9vae.safetensors"
                            },
                            "class_type": "CheckpointLoaderSimple"
                        },
                        "5": {
                            "inputs": {
                                "width": 896,
                                "height": 1152,
                                "batch_size": 1
                            },
                            "class_type": "EmptyLatentImage"
                        },
                        "6": {
                            "inputs": {
                                "clip": [
                                    "4",
                                    1
                                ],
                                "text": "masterpiece, best quality, gorgeous pale american cute girl, smiling, (crop top), red hair loose braided hair, short polca skirt, lean against a tree, field, flowers smiling, perfectly symmetrical face, detailed skin, elegant, alluring, attractive, amazing photograph, masterpiece, best quality, 8K, high quality, photorealistic, realism, art photography, Nikon D850, 16k, sharp focus, masterpiece, breathtaking, atmospheric perspective, diffusion, pore correlation, skin imperfections, DSLR, 80mm Sigma f2, depth of field, intricate natural lighting, looking at camara"
                            },
                            "class_type": "CLIPTextEncode"
                        },
                        "7": {
                            "inputs": {
                                "clip": [
                                    "4",
                                    1
                                ],
                                "text": "(deformed iris, deformed pupils), text, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, (extra fingers), (mutated hands), poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, (fused fingers), (too many fingers), long neck, camera"
                            },
                            "class_type": "CLIPTextEncode"
                        },
                        "10": {
                            "inputs": {
                                "cfg": 8,
                                "model": [
                                    "4",
                                    0
                                ],
                                "steps": 50,
                                "negative": [
                                    "7",
                                    0
                                ],
                                "positive": [
                                    "6",
                                    0
                                ],
                                "add_noise": "enable",
                                "scheduler": "normal",
                                "noise_seed": 968671136649137,
                                "end_at_step": 25,
                                "latent_image": [
                                    "5",
                                    0
                                ],
                                "sampler_name": "euler",
                                "start_at_step": 0,
                                "return_with_leftover_noise": "enable"
                            },
                            "class_type": "KSamplerAdvanced"
                        },
                        "11": {
                            "inputs": {
                                "cfg": 8,
                                "model": [
                                    "12",
                                    0
                                ],
                                "steps": 50,
                                "negative": [
                                    "16",
                                    0
                                ],
                                "positive": [
                                    "15",
                                    0
                                ],
                                "add_noise": "disable",
                                "scheduler": "normal",
                                "noise_seed": 0,
                                "end_at_step": 10000,
                                "latent_image": [
                                    "10",
                                    0
                                ],
                                "sampler_name": "euler",
                                "start_at_step": 25,
                                "return_with_leftover_noise": "disable"
                            },
                            "class_type": "KSamplerAdvanced"
                        },
                        "12": {
                            "inputs": {
                                "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                            },
                            "class_type": "CheckpointLoaderSimple"
                        },
                        "15": {
                            "inputs": {
                                "clip": [
                                    "12",
                                    1
                                ],
                                "text": "masterpiece, best quality, gorgeous pale american cute girl, smiling, (crop top), red hair loose braided hair, short polca skirt, lean against a tree, field, flowers smiling, perfectly symmetrical face, detailed skin, elegant, alluring, attractive, amazing photograph, masterpiece, best quality, 8K, high quality, photorealistic, realism, art photography, Nikon D850, 16k, sharp focus, masterpiece, breathtaking, atmospheric perspective, diffusion, pore correlation, skin imperfections, DSLR, 80mm Sigma f2, depth of field, intricate natural lighting, looking at camara"
                            },
                            "class_type": "CLIPTextEncode"
                        },
                        "16": {
                            "inputs": {
                                "clip": [
                                    "12",
                                    1
                                ],
                                "text": "(deformed iris, deformed pupils), text, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, (extra fingers), (mutated hands), poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, (fused fingers), (too many fingers), long neck, camera"
                            },
                            "class_type": "CLIPTextEncode"
                        },
                        "17": {
                            "inputs": {
                                "vae": [
                                    "4",
                                    2
                                ],
                                "samples": [
                                    "11",
                                    0
                                ]
                            },
                            "class_type": "VAEDecode"
                        },
                        "19": {
                            "inputs": {
                                "images": [
                                    "17",
                                    0
                                ],
                                "filename_prefix": "ComfyUI"
                            },
                            "class_type": "SaveImage"
                        },
                        "48": {
                            "inputs": {
                                "vae_name": "sdXLVAE_09.safetensors"
                            },
                            "class_type": "VAELoader"
                        }
                    },
                    "workflow": {
                        "extra": {},
                        "links": [
                            [
                                3,
                                4,
                                1,
                                6,
                                0,
                                "CLIP"
                            ],
                            [
                                5,
                                4,
                                1,
                                7,
                                0,
                                "CLIP"
                            ],
                            [
                                10,
                                4,
                                0,
                                10,
                                0,
                                "MODEL"
                            ],
                            [
                                11,
                                6,
                                0,
                                10,
                                1,
                                "CONDITIONING"
                            ],
                            [
                                12,
                                7,
                                0,
                                10,
                                2,
                                "CONDITIONING"
                            ],
                            [
                                13,
                                10,
                                0,
                                11,
                                3,
                                "LATENT"
                            ],
                            [
                                14,
                                12,
                                0,
                                11,
                                0,
                                "MODEL"
                            ],
                            [
                                16,
                                13,
                                0,
                                6,
                                1,
                                "STRING"
                            ],
                            [
                                18,
                                14,
                                0,
                                7,
                                1,
                                "STRING"
                            ],
                            [
                                19,
                                12,
                                1,
                                15,
                                0,
                                "CLIP"
                            ],
                            [
                                20,
                                12,
                                1,
                                16,
                                0,
                                "CLIP"
                            ],
                            [
                                21,
                                13,
                                0,
                                15,
                                1,
                                "STRING"
                            ],
                            [
                                22,
                                14,
                                0,
                                16,
                                1,
                                "STRING"
                            ],
                            [
                                23,
                                15,
                                0,
                                11,
                                1,
                                "CONDITIONING"
                            ],
                            [
                                24,
                                16,
                                0,
                                11,
                                2,
                                "CONDITIONING"
                            ],
                            [
                                25,
                                11,
                                0,
                                17,
                                0,
                                "LATENT"
                            ],
                            [
                                27,
                                5,
                                0,
                                10,
                                3,
                                "LATENT"
                            ],
                            [
                                28,
                                17,
                                0,
                                19,
                                0,
                                "IMAGE"
                            ],
                            [
                                38,
                                45,
                                0,
                                11,
                                4,
                                "INT"
                            ],
                            [
                                41,
                                45,
                                0,
                                10,
                                4,
                                "INT"
                            ],
                            [
                                43,
                                47,
                                0,
                                10,
                                5,
                                "INT"
                            ],
                            [
                                44,
                                47,
                                0,
                                11,
                                5,
                                "INT"
                            ],
                            [
                                46,
                                4,
                                2,
                                17,
                                1,
                                "VAE"
                            ]
                        ],
                        "nodes": [
                            {
                                "id": 15,
                                "pos": [
                                    275.7593716647332,
                                    667.5821631843008
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 54
                                },
                                "type": "CLIPTextEncode",
                                "color": "#232",
                                "flags": {},
                                "order": 16,
                                "inputs": [
                                    {
                                        "link": 19,
                                        "name": "clip",
                                        "type": "CLIP"
                                    },
                                    {
                                        "link": 21,
                                        "name": "text",
                                        "type": "STRING",
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 1
                                    }
                                ],
                                "bgcolor": "#353",
                                "outputs": [
                                    {
                                        "name": "CONDITIONING",
                                        "type": "CONDITIONING",
                                        "links": [
                                            23
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CLIPTextEncode"
                                },
                                "widgets_values": [
                                    "photo realistic, ultra details, natural light ultra detailed portrait of a female necromancer, skeleton face volumetric fog, Hyperrealism, breathtaking, ultra realistic, ultra detailed, cyber background, cinematic lighting, highly detailed, breathtaking, photography, stunning environment, wide-angle\", \"text_l\": \"photo realistic, ultra details, natural light ultra detailed portrait of a female necromancer, skeleton face volumetric fog, Hyperrealism, breathtaking, ultra realistic, ultra detailed, cyber background, cinematic lighting, highly detailed, breathtaking, photography, stunning environment, wide-angle"
                                ]
                            },
                            {
                                "id": 16,
                                "pos": [
                                    275.7593716647332,
                                    757.5821631843007
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 54
                                },
                                "type": "CLIPTextEncode",
                                "color": "#322",
                                "flags": {},
                                "order": 17,
                                "inputs": [
                                    {
                                        "link": 20,
                                        "name": "clip",
                                        "type": "CLIP"
                                    },
                                    {
                                        "link": 22,
                                        "name": "text",
                                        "type": "STRING",
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 1
                                    }
                                ],
                                "bgcolor": "#533",
                                "outputs": [
                                    {
                                        "name": "CONDITIONING",
                                        "type": "CONDITIONING",
                                        "links": [
                                            24
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CLIPTextEncode"
                                },
                                "widgets_values": [
                                    "(deformed iris, deformed pupils), text, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, (extra fingers), (mutated hands), poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, (fused fingers), (too many fingers), long neck, camera"
                                ]
                            },
                            {
                                "id": 14,
                                "pos": [
                                    0,
                                    230
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 160
                                },
                                "type": "PrimitiveNode",
                                "color": "#322",
                                "flags": {},
                                "order": 0,
                                "title": "Negative Prompt (Text)",
                                "bgcolor": "#533",
                                "outputs": [
                                    {
                                        "name": "STRING",
                                        "type": "STRING",
                                        "links": [
                                            18,
                                            22
                                        ],
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    "(deformed iris, deformed pupils), text, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, (extra fingers), (mutated hands), poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, (fused fingers), (too many fingers), long neck, camera"
                                ]
                            },
                            {
                                "id": 37,
                                "pos": [
                                    390.7699487304686,
                                    -222.63156538085923
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 330,
                                    "1": 140
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 1,
                                "title": "Note - Load Checkpoint REFINER",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "This is a checkpoint model loader. \n - This is set up automatically with the optimal settings for whatever SD model version you choose to use.\n - In this example, it is for the Refiner SDXL model\n\nNOTE: When loading in another person's workflow, be sure to manually choose your own *local* model. This also applies to LoRas and all their deviations."
                                ]
                            },
                            {
                                "id": 38,
                                "pos": [
                                    9,
                                    429
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 284.3257141113281,
                                    "1": 123.88604736328125
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 2,
                                "title": "Note - Text Prompts",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "These nodes are where you include the text for:\n - what you want in the picture (Positive Prompt, Green)\n - or what you don't want in the picture (Negative Prompt, Red)\n\nThis node type is called a \"PrimitiveNode\" if you are searching for the node type."
                                ]
                            },
                            {
                                "id": 17,
                                "pos": [
                                    854.9474981722423,
                                    130.28335640899812
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 200,
                                    "1": 50
                                },
                                "type": "VAEDecode",
                                "color": "#332922",
                                "flags": {},
                                "order": 22,
                                "inputs": [
                                    {
                                        "link": 25,
                                        "name": "samples",
                                        "type": "LATENT"
                                    },
                                    {
                                        "link": 46,
                                        "name": "vae",
                                        "type": "VAE"
                                    }
                                ],
                                "bgcolor": "#593930",
                                "outputs": [
                                    {
                                        "name": "IMAGE",
                                        "type": "IMAGE",
                                        "links": [
                                            28
                                        ],
                                        "shape": 3,
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "VAEDecode"
                                }
                            },
                            {
                                "id": 41,
                                "pos": [
                                    794.9474981722423,
                                    230.28335640899817
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 320,
                                    "1": 120
                                },
                                "type": "Note",
                                "color": "#332922",
                                "flags": {},
                                "order": 3,
                                "title": "Note - VAE Decoder",
                                "bgcolor": "#593930",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "This node will take the latent data from the KSampler and, using the VAE, it will decode it into visible data\n\nVAE = Latent --> Visible\n\nThis can then be sent to the Save Image node to be saved as a PNG."
                                ]
                            },
                            {
                                "id": 42,
                                "pos": [
                                    370.9816719852805,
                                    174.85043653634958
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 260,
                                    "1": 210
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 4,
                                "title": "Note - Empty Latent Image",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "This node sets the image's resolution in Width and Height.\n\nNOTE: For SDXL, it is recommended to use trained values listed below:\n - 1024 x 1024\n - 1152 x 896\n - 896  x 1152\n - 1216 x 832\n - 832  x 1216\n - 1344 x 768\n - 768  x 1344\n - 1536 x 640\n - 640  x 1536"
                                ]
                            },
                            {
                                "id": 43,
                                "pos": [
                                    261.64906289062463,
                                    859.3716520507812
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 240,
                                    "1": 80
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 5,
                                "title": "Note - CLIP Encode (REFINER)",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "These nodes receive the text from the prompt and use the optimal CLIP settings for the specified checkpoint model (in this case: SDXL Refiner)"
                                ]
                            },
                            {
                                "id": 6,
                                "pos": [
                                    -6.777983882626609,
                                    667.9484536162162
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 54
                                },
                                "type": "CLIPTextEncode",
                                "color": "#232",
                                "flags": {},
                                "order": 18,
                                "inputs": [
                                    {
                                        "link": 3,
                                        "name": "clip",
                                        "type": "CLIP"
                                    },
                                    {
                                        "link": 16,
                                        "name": "text",
                                        "type": "STRING",
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 1
                                    }
                                ],
                                "bgcolor": "#353",
                                "outputs": [
                                    {
                                        "name": "CONDITIONING",
                                        "type": "CONDITIONING",
                                        "links": [
                                            11
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CLIPTextEncode"
                                },
                                "widgets_values": [
                                    "photo realistic, ultra details, natural light ultra detailed portrait of a female necromancer, skeleton face volumetric fog, Hyperrealism, breathtaking, ultra realistic, ultra detailed, cyber background, cinematic lighting, highly detailed, breathtaking, photography, stunning environment, wide-angle\", \"text_l\": \"photo realistic, ultra details, natural light ultra detailed portrait of a female necromancer, skeleton face volumetric fog, Hyperrealism, breathtaking, ultra realistic, ultra detailed, cyber background, cinematic lighting, highly detailed, breathtaking, photography, stunning environment, wide-angle"
                                ]
                            },
                            {
                                "id": 7,
                                "pos": [
                                    -6.777983882626609,
                                    757.9484536162164
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 54
                                },
                                "type": "CLIPTextEncode",
                                "color": "#322",
                                "flags": {},
                                "order": 19,
                                "inputs": [
                                    {
                                        "link": 5,
                                        "name": "clip",
                                        "type": "CLIP"
                                    },
                                    {
                                        "link": 18,
                                        "name": "text",
                                        "type": "STRING",
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 1
                                    }
                                ],
                                "bgcolor": "#533",
                                "outputs": [
                                    {
                                        "name": "CONDITIONING",
                                        "type": "CONDITIONING",
                                        "links": [
                                            12
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CLIPTextEncode"
                                },
                                "widgets_values": [
                                    "(deformed iris, deformed pupils), text, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, (extra fingers), (mutated hands), poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, (fused fingers), (too many fingers), long neck, camera"
                                ]
                            },
                            {
                                "id": 39,
                                "pos": [
                                    -6.777983882626609,
                                    847.9484536162164
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 80
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 6,
                                "title": "Note - CLIP Encode (BASE)",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "These nodes receive the text from the prompt and use the optimal CLIP settings for the specified checkpoint model (in this case: SDXL Base)"
                                ]
                            },
                            {
                                "id": 40,
                                "pos": [
                                    777,
                                    -434
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 451.5049743652344,
                                    "1": 424.4164123535156
                                },
                                "type": "Note",
                                "color": "#432",
                                "flags": {},
                                "order": 7,
                                "title": "Note - KSampler  ADVANCED General Information",
                                "bgcolor": "#653",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "Here are the settings that SHOULD stay in place if you want this workflow to work correctly:\n - add_noise: enable = This adds random noise into the picture so the model can denoise it\n\n - return_with_leftover_noise: enable = This sends the latent image data and all it's leftover noise to the next KSampler node.\n\nThe settings to pay attention to:\n - control_after_generate = generates a new random seed after each workflow job completed.\n - steps = This is the amount of iterations you would like to run the positive and negative CLIP prompts through. Each Step will add (positive) or remove (negative) pixels based on what stable diffusion \"thinks\" should be there according to the model's training\n - cfg = This is how much you want SDXL to adhere to the prompt. Lower CFG gives you more creative but often blurrier results. Higher CFG (recommended max 10) gives you stricter results according to the CLIP prompt. If the CFG value is too high, it can also result in \"burn-in\" where the edges of the picture become even stronger, often highlighting details in unnatural ways.\n - sampler_name = This is the sampler type, and unfortunately different samplers and schedulers have better results with fewer steps, while others have better success with higher steps. This will require experimentation on your part!\n - scheduler = The algorithm/method used to choose the timesteps to denoise the picture.\n - start_at_step = This is the step number the KSampler will start out it's process of de-noising the picture or \"removing the random noise to reveal the picture within\". The first KSampler usually starts with Step 0. Starting at step 0 is the same as setting denoise to 1.0 in the regular Sampler node.\n - end_at_step = This is the step number the KSampler will stop it's process of de-noising the picture. If there is any remaining leftover noise and return_with_leftover_noise is enabled, then it will pass on the left over noise to the next KSampler (assuming there is another one)."
                                ]
                            },
                            {
                                "id": 10,
                                "pos": [
                                    827,
                                    561
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 334
                                },
                                "type": "KSamplerAdvanced",
                                "color": "#223",
                                "flags": {},
                                "order": 20,
                                "title": "KSampler (Advanced) - BASE",
                                "inputs": [
                                    {
                                        "link": 10,
                                        "name": "model",
                                        "type": "MODEL"
                                    },
                                    {
                                        "link": 11,
                                        "name": "positive",
                                        "type": "CONDITIONING"
                                    },
                                    {
                                        "link": 12,
                                        "name": "negative",
                                        "type": "CONDITIONING"
                                    },
                                    {
                                        "link": 27,
                                        "name": "latent_image",
                                        "type": "LATENT"
                                    },
                                    {
                                        "link": 41,
                                        "name": "steps",
                                        "type": "INT",
                                        "widget": {
                                            "name": "steps",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 1,
                                                    "default": 20
                                                }
                                            ]
                                        },
                                        "slot_index": 4
                                    },
                                    {
                                        "link": 43,
                                        "name": "end_at_step",
                                        "type": "INT",
                                        "widget": {
                                            "name": "end_at_step",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 0,
                                                    "default": 10000
                                                }
                                            ]
                                        },
                                        "slot_index": 5
                                    }
                                ],
                                "bgcolor": "#335",
                                "outputs": [
                                    {
                                        "name": "LATENT",
                                        "type": "LATENT",
                                        "links": [
                                            13
                                        ],
                                        "shape": 3,
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "KSamplerAdvanced"
                                },
                                "widgets_values": [
                                    "enable",
                                    968671136649137,
                                    "randomize",
                                    50,
                                    8,
                                    "euler",
                                    "normal",
                                    0,
                                    25,
                                    "enable"
                                ]
                            },
                            {
                                "id": 11,
                                "pos": [
                                    1136,
                                    563
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 340
                                },
                                "type": "KSamplerAdvanced",
                                "color": "#223",
                                "flags": {},
                                "order": 21,
                                "title": "KSampler (Advanced) - REFINER",
                                "inputs": [
                                    {
                                        "link": 14,
                                        "name": "model",
                                        "type": "MODEL",
                                        "slot_index": 0
                                    },
                                    {
                                        "link": 23,
                                        "name": "positive",
                                        "type": "CONDITIONING"
                                    },
                                    {
                                        "link": 24,
                                        "name": "negative",
                                        "type": "CONDITIONING"
                                    },
                                    {
                                        "link": 13,
                                        "name": "latent_image",
                                        "type": "LATENT"
                                    },
                                    {
                                        "link": 38,
                                        "name": "steps",
                                        "type": "INT",
                                        "widget": {
                                            "name": "steps",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 1,
                                                    "default": 20
                                                }
                                            ]
                                        },
                                        "slot_index": 4
                                    },
                                    {
                                        "link": 44,
                                        "name": "start_at_step",
                                        "type": "INT",
                                        "widget": {
                                            "name": "start_at_step",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 0,
                                                    "default": 0
                                                }
                                            ]
                                        }
                                    }
                                ],
                                "bgcolor": "#335",
                                "outputs": [
                                    {
                                        "name": "LATENT",
                                        "type": "LATENT",
                                        "links": [
                                            25
                                        ],
                                        "shape": 3,
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "KSamplerAdvanced"
                                },
                                "widgets_values": [
                                    "disable",
                                    0,
                                    "fixed",
                                    50,
                                    8,
                                    "euler",
                                    "normal",
                                    25,
                                    10000,
                                    "disable"
                                ]
                            },
                            {
                                "id": 47,
                                "pos": [
                                    581,
                                    686
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 82
                                },
                                "type": "PrimitiveNode",
                                "color": "#432",
                                "flags": {},
                                "order": 8,
                                "title": "end_at_step",
                                "bgcolor": "#653",
                                "outputs": [
                                    {
                                        "name": "INT",
                                        "type": "INT",
                                        "links": [
                                            43,
                                            44
                                        ],
                                        "widget": {
                                            "name": "end_at_step",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 0,
                                                    "default": 10000
                                                }
                                            ]
                                        },
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    25,
                                    "fixed"
                                ]
                            },
                            {
                                "id": 36,
                                "pos": [
                                    2,
                                    -233
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 315.70074462890625,
                                    "1": 147.9551239013672
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 9,
                                "title": "Note - Load Checkpoint BASE",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "This is a checkpoint model loader. \n - This is set up automatically with the optimal settings for whatever SD model version you choose to use.\n - In this example, it is for the Base SDXL model\n - This node is also used for SD1.5 and SD2.x models\n \nNOTE: When loading in another person's workflow, be sure to manually choose your own *local* model. This also applies to LoRas and all their deviations"
                                ]
                            },
                            {
                                "id": 45,
                                "pos": [
                                    579,
                                    565
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 82
                                },
                                "type": "PrimitiveNode",
                                "color": "#432",
                                "flags": {},
                                "order": 10,
                                "title": "steps",
                                "bgcolor": "#653",
                                "outputs": [
                                    {
                                        "name": "INT",
                                        "type": "INT",
                                        "links": [
                                            38,
                                            41
                                        ],
                                        "widget": {
                                            "name": "steps",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 1,
                                                    "default": 20
                                                }
                                            ]
                                        }
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    50,
                                    "fixed"
                                ]
                            },
                            {
                                "id": 13,
                                "pos": [
                                    0,
                                    30
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 160
                                },
                                "type": "PrimitiveNode",
                                "color": "#232",
                                "flags": {},
                                "order": 11,
                                "title": "Positive Prompt (Text)",
                                "bgcolor": "#353",
                                "outputs": [
                                    {
                                        "name": "STRING",
                                        "type": "STRING",
                                        "links": [
                                            16,
                                            21
                                        ],
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    "masterpiece, best quality, gorgeous pale american cute girl, smiling, (crop top), red hair loose braided hair, short polca skirt, lean against a tree, field, flowers smiling, perfectly symmetrical face, detailed skin, elegant, alluring, attractive, amazing photograph, masterpiece, best quality, 8K, high quality, photorealistic, realism, art photography, Nikon D850, 16k, sharp focus, masterpiece, breathtaking, atmospheric perspective, diffusion, pore correlation, skin imperfections, DSLR, 80mm Sigma f2, depth of field, intricate natural lighting, looking at camara"
                                ]
                            },
                            {
                                "id": 12,
                                "pos": [
                                    380.7699487304686,
                                    -373.6315653808593
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 350,
                                    "1": 100
                                },
                                "type": "CheckpointLoaderSimple",
                                "color": "#323",
                                "flags": {},
                                "order": 12,
                                "title": "Load Checkpoint - REFINER",
                                "bgcolor": "#535",
                                "outputs": [
                                    {
                                        "name": "MODEL",
                                        "type": "MODEL",
                                        "links": [
                                            14
                                        ],
                                        "shape": 3,
                                        "slot_index": 0
                                    },
                                    {
                                        "name": "CLIP",
                                        "type": "CLIP",
                                        "links": [
                                            19,
                                            20
                                        ],
                                        "shape": 3,
                                        "slot_index": 1
                                    },
                                    {
                                        "name": "VAE",
                                        "type": "VAE",
                                        "links": [],
                                        "shape": 3,
                                        "slot_index": 2
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CheckpointLoaderSimple"
                                },
                                "widgets_values": [
                                    "sd_xl_refiner_1.0_0.9vae.safetensors"
                                ]
                            },
                            {
                                "id": 48,
                                "pos": [
                                    -17,
                                    -554
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 315,
                                    "1": 58
                                },
                                "type": "VAELoader",
                                "flags": {},
                                "order": 13,
                                "outputs": [
                                    {
                                        "name": "VAE",
                                        "type": "VAE",
                                        "links": [],
                                        "shape": 3,
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "VAELoader"
                                },
                                "widgets_values": [
                                    "sdXLVAE_09.safetensors"
                                ]
                            },
                            {
                                "id": 4,
                                "pos": [
                                    -8.020796957397433,
                                    -382.63156538085923
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 350,
                                    "1": 100
                                },
                                "type": "CheckpointLoaderSimple",
                                "color": "#323",
                                "flags": {},
                                "order": 14,
                                "title": "Load Checkpoint - BASE",
                                "bgcolor": "#535",
                                "outputs": [
                                    {
                                        "name": "MODEL",
                                        "type": "MODEL",
                                        "links": [
                                            10
                                        ],
                                        "slot_index": 0
                                    },
                                    {
                                        "name": "CLIP",
                                        "type": "CLIP",
                                        "links": [
                                            3,
                                            5
                                        ],
                                        "slot_index": 1
                                    },
                                    {
                                        "name": "VAE",
                                        "type": "VAE",
                                        "links": [
                                            46
                                        ],
                                        "slot_index": 2
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CheckpointLoaderSimple"
                                },
                                "widgets_values": [
                                    "sd_xl_base_1.0_0.9vae.safetensors"
                                ]
                            },
                            {
                                "id": 5,
                                "pos": [
                                    350.98167198528,
                                    24.85043653634971
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 110
                                },
                                "type": "EmptyLatentImage",
                                "color": "#323",
                                "flags": {},
                                "order": 15,
                                "bgcolor": "#535",
                                "outputs": [
                                    {
                                        "name": "LATENT",
                                        "type": "LATENT",
                                        "links": [
                                            27
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "EmptyLatentImage"
                                },
                                "widgets_values": [
                                    896,
                                    1152,
                                    1
                                ]
                            },
                            {
                                "id": 19,
                                "pos": [
                                    1253,
                                    -433
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 867.0028076171875,
                                    "1": 913.7769775390625
                                },
                                "type": "SaveImage",
                                "flags": {},
                                "order": 23,
                                "inputs": [
                                    {
                                        "link": 28,
                                        "name": "images",
                                        "type": "IMAGE"
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    "ComfyUI"
                                ]
                            }
                        ],
                        "config": {},
                        "groups": [
                            {
                                "color": "#3f789e",
                                "title": "Base Prompt",
                                "bounding": [
                                    -27,
                                    587,
                                    252,
                                    361
                                ]
                            },
                            {
                                "color": "#3f789e",
                                "title": "Refiner Prompt",
                                "bounding": [
                                    239,
                                    588,
                                    279,
                                    362
                                ]
                            },
                            {
                                "color": "#3f789e",
                                "title": "Text Prompts",
                                "bounding": [
                                    -20,
                                    -53,
                                    339,
                                    622
                                ]
                            },
                            {
                                "color": "#a1309b",
                                "title": "Load in BASE SDXL Model",
                                "bounding": [
                                    -18,
                                    -463,
                                    369,
                                    399
                                ]
                            },
                            {
                                "color": "#a1309b",
                                "title": "Load in REFINER SDXL Model",
                                "bounding": [
                                    362,
                                    -463,
                                    391,
                                    400
                                ]
                            },
                            {
                                "color": "#a1309b",
                                "title": "Empty Latent Image",
                                "bounding": [
                                    330,
                                    -49,
                                    339,
                                    443
                                ]
                            },
                            {
                                "color": "#b06634",
                                "title": "VAE Decoder",
                                "bounding": [
                                    777,
                                    51,
                                    360,
                                    350
                                ]
                            }
                        ],
                        "version": 0.4,
                        "last_link_id": 46,
                        "last_node_id": 48
                    }
                },
                "steps": 50,
                "width": 896,
                "height": 1152,
                "models": [
                    "sd_xl_base_1.0_0.9vae.safetensors",
                    "sd_xl_refiner_1.0_0.9vae.safetensors"
                ],
                "prompt": "masterpiece, best quality, gorgeous pale american cute girl, smiling, (crop top), red hair loose braided hair, short polca skirt, lean against a tree, field, flowers smiling, perfectly symmetrical face, detailed skin, elegant, alluring, attractive, amazing photograph, masterpiece, best quality, 8K, high quality, photorealistic, realism, art photography, Nikon D850, 16k, sharp focus, masterpiece, breathtaking, atmospheric perspective, diffusion, pore correlation, skin imperfections, DSLR, 80mm Sigma f2, depth of field, intricate natural lighting, looking at camara",
                "sampler": "Euler",
                "cfgScale": 8,
                "scheduler": "normal",
                "upscalers": [],
                "controlNets": [],
                "negativePrompt": "(deformed iris, deformed pupils), text, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, (extra fingers), (mutated hands), poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, (fused fingers), (too many fingers), long neck, camera",
                "additionalResources": []
            },
            "username": "civitai",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 41323531,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c1bd1d39-1609-4f9a-a9f3-4067cc025fbc/width=832/c1bd1d39-1609-4f9a-a9f3-4067cc025fbc.jpeg",
            "hash": "URJI*0~Vx]o~%eV@IpNbEhtRDjslx]oeofV@",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-21T16:30:00.000Z",
            "postId": 9410898,
            "stats": {
                "cryCount": 10,
                "laughCount": 37,
                "likeCount": 237,
                "dislikeCount": 0,
                "heartCount": 106,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1568196569,
                "steps": 30,
                "prompt": "two joyful maltese and a dolphin, swimming in the sea, waves, foam, summer!!!, expressive, colorful, vivid colors",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-11-21T1414:55.5580327Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 922358,
                        "modelVersionName": "Pro 1.1"
                    }
                ]
            },
            "username": "White_Rabbit_A",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 40215596,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e6e52af6-c4c0-42bf-95c3-db362e31bb93/width=832/e6e52af6-c4c0-42bf-95c3-db362e31bb93.jpeg",
            "hash": "UIH27Z4:01_2~VV[WXIV_MMyWBxu.7M|NGxu",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-15T06:52:11.620Z",
            "postId": 9165980,
            "stats": {
                "cryCount": 27,
                "laughCount": 35,
                "likeCount": 253,
                "dislikeCount": 0,
                "heartCount": 75,
                "commentCount": 0
            },
            "meta": null,
            "username": "Lady_Luminous",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 40060293,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3ba79148-8b66-4296-8fc5-c4990126e6fd/width=1624/3ba79148-8b66-4296-8fc5-c4990126e6fd.jpeg",
            "hash": "UCGI[k%2~Axu00IU%Lt8#6NIE,4n~Voc$e%L",
            "width": 1624,
            "height": 2368,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-14T11:14:57.005Z",
            "postId": 9132037,
            "stats": {
                "cryCount": 26,
                "laughCount": 26,
                "likeCount": 272,
                "dislikeCount": 0,
                "heartCount": 66,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1035780843808238,
                "Model": "flux_dev",
                "steps": 20,
                "hashes": {
                    "model": "2eda627c8a",
                    "LORA:FLUX\\Anime v1.3": "0d061b16de",
                    "LORA:FLUX\\VividlyReal": "bd3bf33631",
                    "LORA:FLUX\\FLUX-daubrez-DB4RZ": "82acd43214"
                },
                "prompt": "(in Otomo Katsuhiro style:1.2), masterpiece, high-quality, A ghostly painter dressed in flowing ink-stained garments, wielding an oversized brush as though its a weapon, Each stroke she paints on thin air brings to life fragments of a surreal landscape a floating palace a river of stars, mountains growing like crystals\u00e2\u0080\u0094hovering around her in a swirling vortex of imagination, creation in motion, surreal fragments, floating art, Stylized anime with painterly abstract effects and a sense of fluidity, (elaborate fine details:1.1), (hyperdetailed:1.1), (intricate details:1.0), (Refined details:1.1), (best quality:1.1), (high resolution:1.2), <lora:FLUX\\Anime v1.3:0.6> <lora:FLUX\\VividlyReal:0.6> <lora:FLUX\\FLUX-daubrez-DB4RZ:0.4>",
                "Version": "ComfyUI",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 3.5,
                "resources": [
                    {
                        "hash": "2eda627c8a",
                        "name": "flux_dev",
                        "type": "model"
                    }
                ],
                "Model hash": "2eda627c8a"
            },
            "username": "RIDD",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 39412529,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/55cd1212-c8cd-4cd1-8c14-62b655451ff1/width=832/55cd1212-c8cd-4cd1-8c14-62b655451ff1.jpeg",
            "hash": "UdD+02%I},obIuNKNIbF9we:Iua#$|s.xYWD",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-10T18:50:00.081Z",
            "postId": 8991083,
            "stats": {
                "cryCount": 11,
                "laughCount": 17,
                "likeCount": 283,
                "dislikeCount": 0,
                "heartCount": 79,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2251831851,
                "steps": 24,
                "prompt": "1girl, solo, Balenciaga sunglasses , Portrait of young an Asian woman with white skin and orange eye makeup, the eyes have black eyeliner, she has blue lipstick on her lips, there is gold dots around one winged eye, soft light framing, high facial contrast, large fat breasts, hanging breasts, uncensored, black hair, short wavy hair, color gel lighting, smooth blurred background, ample copy space, A powerful earth goddess with three sets of eyes and ram-like horns adorns her head , Hyper-realistic digital illustration , His face is obscured by a dark chrome mask, with narrow slits revealing glowing red eyes. green color leaks streak across the floor as if marking his path. The background is a single, deep yellow hue, with surreal chrome reflecting jagged light, capturing the mysterious, cultish aura with high-contrast chrome detailing.",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-11-10T1847:09.7095799Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 863655,
                        "modelVersionName": "Balance_v2.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.2,
                        "modelVersionId": 981456,
                        "modelVersionName": "FLUX v0.4"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 774588,
                        "modelVersionName": "Flux"
                    }
                ]
            },
            "username": "WANEI",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 36715649,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5abb6410-8c81-4cdd-8b0d-992a20620b88/width=832/5abb6410-8c81-4cdd-8b0d-992a20620b88.jpeg",
            "hash": "UGBCZojZzpfS^ms;veoJ$,n*#kn%][oM=Log",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-26T20:07:37.538Z",
            "postId": 8386406,
            "stats": {
                "cryCount": 15,
                "laughCount": 31,
                "likeCount": 261,
                "dislikeCount": 0,
                "heartCount": 83,
                "commentCount": 1
            },
            "meta": {
                "2": "3",
                "vae": "ae",
                "Size": "832x1216",
                "seed": 1072869194,
                "Model": "flux_dev.safetensors",
                "steps": 20,
                "hashes": {
                    "model": "2f3c5caac046",
                    "lora:Portrait_Artifacts_-_V1": "c02663318336",
                    "lora:Epic_gorgeous_Details_-_Balance_v2-0": "2dbb61ac85e1",
                    "lora:Daubrez_FLUX_-_Henry_Daubrez_FLUX_v1-0": "9a6dfc274bbd"
                },
                "images": "15",
                "prompt": ", breathtaking Audrey Kawasaki style of a beautiful but evil female corrupted by tzeentch, ((cultist of tzeentch)), bird like mutations, feathers, she has (6 different eyes), (chaotic)  she is holding a wizard staff decorated with feathers and living eyes which are glowing with blue fire, ,dark allure, ,light pink and blue and purple white themes, beak gold face mask, runic, sharp demonic teeth, highly detailed dreamy background detailed skin texture, subsurface scattering award-winning, professional, highly detailed . dreamlike, mysterious, provocative, symbolic, intricate, detailed, switling maelstorm of chaos and cosmos in background",
                "sampler": "euler",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "9a6dfc274bbd",
                        "name": "Daubrez_FLUX_-_Henry_Daubrez_FLUX_v1-0",
                        "type": "lora"
                    },
                    {
                        "hash": "2dbb61ac85e1",
                        "name": "Epic_gorgeous_Details_-_Balance_v2-0",
                        "type": "lora"
                    },
                    {
                        "hash": "c02663318336",
                        "name": "Portrait_Artifacts_-_V1",
                        "type": "lora"
                    },
                    {
                        "hash": "2f3c5caac046",
                        "name": "flux_dev.safetensors",
                        "type": "model"
                    }
                ],
                "Model hash": "2f3c5caac046",
                "loraweights": {},
                "Schedule type": "beta",
                "fluxguidancescale": "3.5"
            },
            "username": "Sutech",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 35744124,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/29531921-a4d4-4217-b2c9-7e076832def7/width=864/29531921-a4d4-4217-b2c9-7e076832def7.jpeg",
            "hash": "UTHxQgxu_NV@^+t7NHM|EijFRPbGo#Rjs.t6",
            "width": 864,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-21T08:21:41.353Z",
            "postId": 8167834,
            "stats": {
                "cryCount": 1,
                "laughCount": 12,
                "likeCount": 274,
                "dislikeCount": 0,
                "heartCount": 103,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "sdxl_vae.safetensors",
                "Size": "864x1152",
                "seed": 1100190281,
                "Model": "autismmixSDXL_autismmixPony",
                "steps": 30,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "821aa5537f",
                    "lora:DemizuPosukaXLP": "a3a32e3b1c11"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up,  <lora:DemizuPosukaXLP:0.7> demizuposuka, 1girl, curvy, dress, cute, solo, portrait, witch",
                "Version": "v1.10.1",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "a3a32e3b1c11",
                        "name": "DemizuPosukaXLP",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "hash": "821aa5537f",
                        "name": "autismmixSDXL_autismmixPony",
                        "type": "model"
                    }
                ],
                "Model hash": "821aa5537f",
                "Schedule type": "Automatic",
                "negativePrompt": "watermark, signature, artist name, twitter username, censored, child, kid, loli, 3d, realistic,",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.9.0",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "freckledvixon",
            "baseModel": "Pony"
        },
        {
            "id": 34980466,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/288245cc-2d43-405f-8e2c-c2bbc371486d/width=1664/288245cc-2d43-405f-8e2c-c2bbc371486d.jpeg",
            "hash": "USDHj]-tFzOFxvtST1bx5+OTxVt8W-NYxBoe",
            "width": 1664,
            "height": 2432,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-16T23:44:10.401Z",
            "postId": 7995287,
            "stats": {
                "cryCount": 15,
                "laughCount": 45,
                "likeCount": 254,
                "dislikeCount": 0,
                "heartCount": 76,
                "commentCount": 3
            },
            "meta": {
                "Size": "832x1216",
                "seed": 789361173408153,
                "Model": "FLUX\\flux1-dev-fp8",
                "steps": 20,
                "hashes": {
                    "model": "8e91b68084"
                },
                "Version": "ComfyUI",
                "sampler": "euler_beta",
                "CFG Scale": "1.0",
                "resources": [
                    {
                        "hash": "8e91b68084",
                        "name": "FLUX\\flux1-dev-fp8",
                        "type": "model"
                    }
                ],
                "Model hash": "8e91b68084"
            },
            "username": "shadowfaxPC",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 34927647,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c96de979-3b1e-45b0-9b2e-f26274939bf9/width=896/c96de979-3b1e-45b0-9b2e-f26274939bf9.jpeg",
            "hash": "UhC%]DMytQWX_MRkWVWC%ftRRjafx[oyWCj[",
            "width": 896,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-16T16:06:22.527Z",
            "postId": 7982759,
            "stats": {
                "cryCount": 22,
                "laughCount": 46,
                "likeCount": 233,
                "dislikeCount": 0,
                "heartCount": 89,
                "commentCount": 8
            },
            "meta": {
                "Size": "896x1152",
                "seed": 630528799,
                "Model": "flux1-dev-bnb-nf4-v2",
                "steps": 25,
                "hashes": {
                    "model": "bea01d51bd"
                },
                "prompt": "beautiful woman with messy hair and melancholic appearance sitting on the ground in a voluminous dress made of dull green seaweed in a rocky beach setting at dawn, muted tones, nostalgia, melancholy, hyper-detailed",
                "Version": "f2.0.1v1.10.1-previous-414-gdf598c4d",
                "sampler": "Euler",
                "Module 1": "t5xxl_fp16",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "bea01d51bd",
                        "name": "flux1-dev-bnb-nf4-v2",
                        "type": "model"
                    }
                ],
                "Model hash": "bea01d51bd",
                "Schedule type": "Simple",
                "Distilled CFG Scale": "3.5"
            },
            "username": "JPP01",
            "baseModel": ""
        },
        {
            "id": 33195452,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8e62b513-c0b4-4b4e-878b-dbe2b2ec6fe8/width=832/8e62b513-c0b4-4b4e-878b-dbe2b2ec6fe8.jpeg",
            "hash": "UB8p[TRkRjt7~UWCM|s:-.ayIpoe%LayIpoe",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-06T21:39:56.827Z",
            "postId": 7595889,
            "stats": {
                "cryCount": 34,
                "laughCount": 14,
                "likeCount": 269,
                "dislikeCount": 0,
                "heartCount": 73,
                "commentCount": 1
            },
            "meta": null,
            "username": "Carcamagnu",
            "baseModel": null
        },
        {
            "id": 33021031,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cb8c53b3-0981-43c0-815d-2a21ab17427c/width=1800/cb8c53b3-0981-43c0-815d-2a21ab17427c.jpeg",
            "hash": "ULD+xWoyrqM{_Nt7IBRjpIV@Ios:S2aKs-t7",
            "width": 2600,
            "height": 3800,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-05T22:36:06.015Z",
            "postId": 7556445,
            "stats": {
                "cryCount": 3,
                "laughCount": 19,
                "likeCount": 282,
                "dislikeCount": 0,
                "heartCount": 86,
                "commentCount": 1
            },
            "meta": {
                "VAE": "ae.safetensors",
                "seed": 460861723077568,
                "Model": "flux_dev_FP32.safetensors",
                "https": "//civitai.com/models/642589",
                "steps": 30,
                "Artist": "Abraxas (Abrakzas)",
                "hashes": {
                    "vae": "afc8e28272",
                    "model": "4610115bb0",
                    "lora:FLUX-FluxMythP0rtr4itStyle": "c12dbc5885",
                    "lora:FLUX-BLUE_mk4_angel_FLUX_01": "a8c8bec94b",
                    "lora:FLUX-Dieselpunk Delight - s0_9 g4": "bbe21426d5"
                },
                "prompt": "A very detailed illustration of a Japanese Geisha standing gracefully amidst the vibrant chaos of a distant future in Neo-Tokyo. She wears an exquisite kimono made of shimmering fabric that reflects neon lights, featuring intricate patterns of cherry blossoms and flowing water. The kimono has a traditional silhouette, but you can see subtle mechanical components integrated into its design, such as reinforced cuffs and a high-tech obi belt that glows softly.Her hands are distinctly mechanical, showcasing intricate gears and elegant metalwork, blending seamlessly with her delicate appearance. The mechanical fingers are slender and articulate, allowing for graceful movements, and one hand delicately holds a beautifully crafted fan adorned with holographic patterns that change colors and designs with each flick of her wrist.The Geisha's face is painted with traditional white makeup, accentuated by bold red and black designs around her eyes and lips, while her delicate features radiate beauty. Her hair is styled in an elaborate updo, adorned with intricate kanzashi hairpins made of metal and glass that shimmer with bioluminescent colors, blending traditional craftsmanship with modern technology.She also has visible cyborg parts, such as elegant, mechanical joints at her elbows and knees, giving her a lithe, yet enhanced appearance. Her movements exude a blend of traditional grace and advanced agility.",
                "Creator": "Abraxas (Abrakzas)",
                "sampler": "euler_beta",
                "Copyright": "\u00c2\u00a9 2024 Alain G.",
                "resources": [
                    {
                        "hash": "4610115bb0",
                        "name": "flux_dev_FP32.safetensors",
                        "type": "model"
                    }
                ],
                "Model hash": "4610115bb0",
                "Lora_0 Model hash": "bbe21426d5",
                "Lora_0 Model name": "FLUX-Dieselpunk Delight - s0_9 g4.safetensors",
                "Lora_1 Model hash": "a8c8bec94b",
                "Lora_1 Model name": "FLUX-BLUE_mk4_angel_FLUX_01.safetensors",
                "Lora_2 Model hash": "c12dbc5885",
                "Lora_2 Model name": "FLUX-FluxMythP0rtr4itStyle.safetensors",
                "Lora_0 Strength clip": "1",
                "Lora_1 Strength clip": "1",
                "Lora_2 Strength clip": "1",
                "Lora_0 Strength model": "1",
                "Lora_1 Strength model": "1",
                "Lora_2 Strength model": "1"
            },
            "username": "Abrakzas",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 32822799,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6947b082-973d-404f-b253-fdec186cb4c3/width=1248/6947b082-973d-404f-b253-fdec186cb4c3.jpeg",
            "hash": "UPG9N._2Y4NH*0R+J:NI5HjE^+-:Ocn#xbxt",
            "width": 1248,
            "height": 1824,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-10-04T19:05:22.541Z",
            "postId": 7511361,
            "stats": {
                "cryCount": 10,
                "laughCount": 25,
                "likeCount": 234,
                "dislikeCount": 0,
                "heartCount": 121,
                "commentCount": 0
            },
            "meta": {
                "": {},
                "VAE": "sdxl_vae_fixed.safetensors",
                "Size": "1248x1824",
                "seed": 4117313344,
                "Model": "snowpony_v10",
                "steps": 20,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "d6f941b46b",
                    "lora:floox_style_v2_pdxl_goofy": "d3bcb1ebc262"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up,<lora:floox_style_v2_pdxl_goofy:1>1girl, huge breasts,unohana retsu,  single braid, japanese clothes, mature female, long hair, outdoors, sitting, closed eyes, cleavage, black kimono, blue sky, black hakama, haori, parted lips, parted bangs, braided ponytail, day, hair over shoulder, black hair, cloud, curvy, white sash, collarbone, sweat, long sleeves, mountain, patreon username, skirt, thighs, blush",
                "Version": "v1.10.1",
                "sampler": "DPM++ 2M",
                "{Method": {},
                "Upscaler": {},
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "d3bcb1ebc262",
                        "name": "floox_style_v2_pdxl_goofy",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "d6f941b46b",
                        "name": "snowpony_v10",
                        "type": "model"
                    }
                ],
                "Model hash": "d6f941b46b",
                "Tile Overlap": "48",
                "Schedule type": "Karras",
                "Upscale factor": "1.5",
                "negativePrompt": "realistic,monochrome,greyscale, artist name, signature, watermark,censored,",
                "ADetailer model": "face_yolov8n.pt",
                "Keep input size": "true}",
                "Tile batch size": "6",
                "Tile tile width": "160",
                "Tiled Diffusion": {},
                "Tile tile height": "160",
                "ADetailer version": "24.8.0",
                "Denoising strength": "0.35",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "Tiled Diffusion upscaler": "4x-UltraSharp",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "Tiled Diffusion scale factor": "1.5",
                "ADetailer inpaint only masked": "True"
            },
            "username": "Goofy_Ai",
            "baseModel": "Pony"
        },
        {
            "id": 32774802,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c101a2bf-010f-4fc4-8e6d-1c736dc02f0b/width=1440/c101a2bf-010f-4fc4-8e6d-1c736dc02f0b.jpeg",
            "hash": "UIE4ZH%~HD?wB:%gyYMdTKR-m+RPX.IArW%M",
            "width": 1440,
            "height": 1920,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-04T13:03:16.718Z",
            "postId": 7500567,
            "stats": {
                "cryCount": 4,
                "laughCount": 73,
                "likeCount": 244,
                "dislikeCount": 0,
                "heartCount": 69,
                "commentCount": 0
            },
            "meta": {
                "seed": 918030505385330,
                "vaes": [
                    "ae.safetensors"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"316\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"306\": {\"inputs\": {\"lora_name\": \"0\\\\IsabellaFluxTAV102.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"385\", 0], \"clip\": [\"387\", 0]}, \"class_type\": \"LoraLoader\"}, \"307\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\"}, \"313\": {\"inputs\": {\"width\": 960, \"height\": 1280, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"314\": {\"inputs\": {\"text\": \"[2][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, outdoors, shirt, tree, looking at viewer, blue skirt, white shirt, parted lips, sky, day, collared shirt, pleated skirt, short sleeves, building, blue sky, shirt tucked in\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"315\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"316\": {\"inputs\": {\"seed\": 918030505385330, \"steps\": 30, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"389\", 0], \"negative\": [\"315\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"331\": {\"inputs\": {\"text\": \"[1][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, shirt, outdoors, white footwear, short sleeves, blue skirt, shoes, shadow, tree, pleated skirt, looking at viewer, day, holding, standing, white shirt, collared shirt, realistic, pocket, breast pocket, sky, building, artist name, school uniform, brown eyes, \", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"332\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"333\": {\"inputs\": {\"seed\": 369072530556137, \"steps\": 20, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"388\", 0], \"negative\": [\"332\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"337\": {\"inputs\": {\"samples\": [\"333\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"339\": {\"inputs\": {\"text\": \"[3][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. looking at viewer, shirt, indoors, chair, white shirt, skirt, short sleeves, sitting, brown eyes, realistic, black skirt, lips, collared shirt, plant, window, closed mouth\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"340\": {\"inputs\": {\"text\": \"[4][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, looking at viewer, indoors, realistic, shirt, short sleeves, brown eyes, pencil skirt, lips, white shirt, black skirt, chair, collared shirt, artist name\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"341\": {\"inputs\": {\"text\": \"[5][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, looking at viewer, smile, brown eyes, chair, shirt, black skirt, lips, indoors, short sleeves, realistic, white shirt, parted lips\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"342\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"343\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"344\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"345\": {\"inputs\": {\"seed\": 653616993950626, \"steps\": 30, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"390\", 0], \"negative\": [\"342\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"346\": {\"inputs\": {\"seed\": 870436998277415, \"steps\": 30, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"391\", 0], \"negative\": [\"343\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"347\": {\"inputs\": {\"seed\": 1090158081688031, \"steps\": 30, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"392\", 0], \"negative\": [\"344\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"348\": {\"inputs\": {\"samples\": [\"345\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"349\": {\"inputs\": {\"samples\": [\"346\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"350\": {\"inputs\": {\"samples\": [\"347\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"355\": {\"inputs\": {\"text\": \"[6][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, pencil skirt, shirt, indoors, looking at viewer, window, chair, black skirt, white shirt, jewelry, brown eyes, short sleeves, office lady, standing, bracelet, lips\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"356\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"357\": {\"inputs\": {\"seed\": 792283694795691, \"steps\": 30, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"393\", 0], \"negative\": [\"356\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"358\": {\"inputs\": {\"samples\": [\"357\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"360\": {\"inputs\": {\"text\": \"[7][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, multiple girls, shirt, pencil skirt, 3girls, brown eyes, solo focus, black skirt, looking at viewer, white shirt, indoors, lips, realistic, chair\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"361\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"362\": {\"inputs\": {\"seed\": 311413183197100, \"steps\": 30, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"394\", 0], \"negative\": [\"361\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"363\": {\"inputs\": {\"samples\": [\"362\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"365\": {\"inputs\": {\"text\": \"[8][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. necktie, looking at viewer, shirt, skirt, white shirt, realistic, brown eyes, lips, sitting, short sleeves, collared shirt, black skirt, black necktie, office lady, indoors\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"366\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"367\": {\"inputs\": {\"seed\": 853412980131936, \"steps\": 30, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"395\", 0], \"negative\": [\"366\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"368\": {\"inputs\": {\"samples\": [\"367\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"370\": {\"inputs\": {\"text\": \"[9][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, sitting, shirt, pencil skirt, black skirt, chair, white shirt, looking at viewer, parted lips, tree, plant, short sleeves, indoors, brown eyes, window, office lady, realistic\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"371\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"372\": {\"inputs\": {\"seed\": 755680058850451, \"steps\": 30, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"396\", 0], \"negative\": [\"371\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"373\": {\"inputs\": {\"samples\": [\"372\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"375\": {\"inputs\": {\"text\": \"[10][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, sitting, shirt, looking at viewer, white shirt, pencil skirt, short sleeves, indoors, black skirt, brown eyes, parted lips, plant, collared shirt, window, smile\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"376\": {\"inputs\": {\"text\": \"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", \"speak_and_recognation\": true, \"clip\": [\"306\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"377\": {\"inputs\": {\"seed\": 1081256756379998, \"steps\": 30, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"306\", 0], \"positive\": [\"397\", 0], \"negative\": [\"376\", 0], \"latent_image\": [\"313\", 0]}, \"class_type\": \"KSampler\"}, \"378\": {\"inputs\": {\"samples\": [\"377\", 0], \"vae\": [\"307\", 0]}, \"class_type\": \"VAEDecode\"}, \"385\": {\"inputs\": {\"unet_name\": \"flux1-dev.safetensors\", \"weight_dtype\": \"default\"}, \"class_type\": \"UNETLoader\"}, \"387\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"388\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"331\", 0]}, \"class_type\": \"FluxGuidance\"}, \"389\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"314\", 0]}, \"class_type\": \"FluxGuidance\"}, \"390\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"339\", 0]}, \"class_type\": \"FluxGuidance\"}, \"391\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"340\", 0]}, \"class_type\": \"FluxGuidance\"}, \"392\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"341\", 0]}, \"class_type\": \"FluxGuidance\"}, \"393\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"355\", 0]}, \"class_type\": \"FluxGuidance\"}, \"394\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"360\", 0]}, \"class_type\": \"FluxGuidance\"}, \"395\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"365\", 0]}, \"class_type\": \"FluxGuidance\"}, \"396\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"370\", 0]}, \"class_type\": \"FluxGuidance\"}, \"397\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"375\", 0]}, \"class_type\": \"FluxGuidance\"}, \"398\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"400\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"400\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"337\", 0]}, \"class_type\": \"ImageScale\"}, \"401\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"402\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"402\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"8\", 0]}, \"class_type\": \"ImageScale\"}, \"403\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"404\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"404\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"348\", 0]}, \"class_type\": \"ImageScale\"}, \"405\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"406\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"406\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"349\", 0]}, \"class_type\": \"ImageScale\"}, \"407\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"408\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"408\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"350\", 0]}, \"class_type\": \"ImageScale\"}, \"409\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"410\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"410\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"358\", 0]}, \"class_type\": \"ImageScale\"}, \"411\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"412\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"412\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"363\", 0]}, \"class_type\": \"ImageScale\"}, \"413\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"414\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"414\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"368\", 0]}, \"class_type\": \"ImageScale\"}, \"415\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"416\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"416\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"373\", 0]}, \"class_type\": \"ImageScale\"}, \"417\": {\"inputs\": {\"filename_prefix\": \"Flux_Batch_\", \"filename_keys\": \"unet_name\", \"foldername_prefix\": \"\", \"foldername_keys\": \"lora_name\", \"delimiter\": \"underscore\", \"save_job_data\": \"disabled\", \"job_data_per_image\": \"disabled\", \"job_custom_text\": \"\", \"save_metadata\": \"enabled\", \"counter_digits\": 4, \"counter_position\": \"last\", \"one_counter_per_folder\": \"disabled\", \"image_preview\": \"enabled\", \"images\": [\"418\", 0]}, \"class_type\": \"SaveImageExtended\"}, \"418\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"width\": 1440, \"height\": 1920, \"crop\": \"disabled\", \"image\": [\"378\", 0]}, \"class_type\": \"ImageScale\"}}, \"workflow\": {\"last_node_id\": 418, \"last_link_id\": 753, \"nodes\": [{\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 501, \"1\": 1531}, \"size\": {\"0\": 398.8052978515625, \"1\": 49.140262603759766}, \"flags\": {\"pinned\": true}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 647, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 586, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [737], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 306, \"type\": \"LoraLoader\", \"pos\": {\"0\": 501, \"1\": 331}, \"size\": {\"0\": 399.0330505371094, \"1\": 139.19271850585938}, \"flags\": {\"pinned\": true}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 709, \"label\": \"model\"}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 710, \"slot_index\": 1, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [597, 620, 640, 641, 642, 688, 689, 690, 691, 692], \"slot_index\": 0, \"label\": \"MODEL\", \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [596, 613, 615, 616, 628, 629, 630, 631, 633, 658, 683, 684, 685, 686, 687, 704, 705, 706, 707, 708], \"slot_index\": 1, \"label\": \"CLIP\", \"shape\": 3}], \"title\": \"Load LoRA (\\u8b80\\u53d6LoRA)\", \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"0\\\\IsabellaFluxTAV102.safetensors\", 1, 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 307, \"type\": \"VAELoader\", \"pos\": {\"0\": 1001, \"1\": 332}, \"size\": {\"0\": 398.98345947265625, \"1\": 58.30403137207031}, \"flags\": {\"pinned\": true}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [586, 651, 652, 653, 657, 693, 694, 695, 696, 697], \"slot_index\": 0, \"shape\": 3, \"label\": \"VAE\"}], \"title\": \"Load VAE (\\u8a2d\\u5b9aVAE)\", \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 313, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 1501, \"1\": 331}, \"size\": {\"0\": 398.8632507324219, \"1\": 109.17365264892578}, \"flags\": {\"pinned\": true}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [619, 643, 644, 645, 646, 698, 699, 700, 701, 702], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"Image Size (\\u8a2d\\u5b9a\\u5c3a\\u5bf8)\", \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [960, 1280, 1], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 314, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 501, \"1\": 531}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"pinned\": true}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 613, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [715], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[2][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, outdoors, shirt, tree, looking at viewer, blue skirt, white shirt, parted lips, sky, day, collared shirt, pleated skirt, short sleeves, building, blue sky, shirt tucked in\", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 315, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 501, \"1\": 831}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"pinned\": true}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 596, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [600], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 316, \"type\": \"KSampler\", \"pos\": {\"0\": 500, \"1\": 1131}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 597, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 716, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 600, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 643, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [647], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [918030505385330, \"randomize\", 30, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 331, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1, \"1\": 531}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"pinned\": true}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 615, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [714], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[1][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, shirt, outdoors, white footwear, short sleeves, blue skirt, shoes, shadow, tree, pleated skirt, looking at viewer, day, holding, standing, white shirt, collared shirt, realistic, pocket, breast pocket, sky, building, artist name, school uniform, brown eyes, \", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 332, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1, \"1\": 831}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"pinned\": true}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 616, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [618], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 333, \"type\": \"KSampler\", \"pos\": {\"0\": 1, \"1\": 1131}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 620, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 712, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 618, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 619, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [621], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [369072530556137, \"randomize\", 20, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 337, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1, \"1\": 1531}, \"size\": {\"0\": 398.6345520019531, \"1\": 48.785953521728516}, \"flags\": {\"pinned\": true}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 621, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 657, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [734], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 339, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1001, \"1\": 531}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"pinned\": true}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 628, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [717], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[3][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. looking at viewer, shirt, indoors, chair, white shirt, skirt, short sleeves, sitting, brown eyes, realistic, black skirt, lips, collared shirt, plant, window, closed mouth\", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 340, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1501, \"1\": 531}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"pinned\": true}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 629, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [719], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[4][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, looking at viewer, indoors, realistic, shirt, short sleeves, brown eyes, pencil skirt, lips, white shirt, black skirt, chair, collared shirt, artist name\", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 341, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2001, \"1\": 531}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"collapsed\": false, \"pinned\": true}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 630, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [721], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[5][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, looking at viewer, smile, brown eyes, chair, shirt, black skirt, lips, indoors, short sleeves, realistic, white shirt, parted lips\", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 342, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1001, \"1\": 831}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"pinned\": true}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 631, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [637], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 343, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1501, \"1\": 831}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"collapsed\": false, \"pinned\": true}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 658, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [638], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 344, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2001, \"1\": 831}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"pinned\": true}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 633, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [639], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 345, \"type\": \"KSampler\", \"pos\": {\"0\": 1001, \"1\": 1131}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 640, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 718, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 637, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 644, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [648], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [653616993950626, \"randomize\", 30, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 346, \"type\": \"KSampler\", \"pos\": {\"0\": 1501, \"1\": 1131}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 641, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 720, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 638, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 645, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [649], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [870436998277415, \"randomize\", 30, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 347, \"type\": \"KSampler\", \"pos\": {\"0\": 2000, \"1\": 1130}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 642, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 722, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 639, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 646, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [650], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1090158081688031, \"randomize\", 30, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 348, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1001, \"1\": 1531}, \"size\": {\"0\": 398.3175354003906, \"1\": 49.39474868774414}, \"flags\": {\"pinned\": true}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 648, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 651, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [739], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 349, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1500, \"1\": 1530}, \"size\": {\"0\": 399.3598327636719, \"1\": 49.72642517089844}, \"flags\": {\"pinned\": true}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 649, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 652, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [742], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 350, \"type\": \"VAEDecode\", \"pos\": {\"0\": 2001, \"1\": 1531}, \"size\": {\"0\": 398.55914306640625, \"1\": 49.51240921020508}, \"flags\": {\"pinned\": true}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 650, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 653, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [743], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 355, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2500, \"1\": 530}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"collapsed\": false, \"pinned\": true}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 683, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [723], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[6][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, pencil skirt, shirt, indoors, looking at viewer, window, chair, black skirt, white shirt, jewelry, brown eyes, short sleeves, office lady, standing, bracelet, lips\", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 356, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2500, \"1\": 830}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"pinned\": true}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 704, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [660], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 357, \"type\": \"KSampler\", \"pos\": {\"0\": 2500, \"1\": 1130}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 692, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 724, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 660, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 698, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [661], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [792283694795691, \"randomize\", 30, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 358, \"type\": \"VAEDecode\", \"pos\": {\"0\": 2500, \"1\": 1530}, \"size\": {\"0\": 398.55914306640625, \"1\": 49.51240921020508}, \"flags\": {\"pinned\": true}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 661, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 693, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [746], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 360, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 3000, \"1\": 530}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"collapsed\": false, \"pinned\": true}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 684, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [725], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[7][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, multiple girls, shirt, pencil skirt, 3girls, brown eyes, solo focus, black skirt, looking at viewer, white shirt, indoors, lips, realistic, chair\", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 361, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 3000, \"1\": 830}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"pinned\": true}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 705, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [664], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 362, \"type\": \"KSampler\", \"pos\": {\"0\": 3000, \"1\": 1130}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 691, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 726, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 664, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 699, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [665], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [311413183197100, \"randomize\", 30, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 363, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3000, \"1\": 1530}, \"size\": {\"0\": 398.55914306640625, \"1\": 49.51240921020508}, \"flags\": {\"pinned\": true}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 665, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 694, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [747], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 365, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 3500, \"1\": 530}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"collapsed\": false, \"pinned\": true}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 685, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [727], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[8][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. necktie, looking at viewer, shirt, skirt, white shirt, realistic, brown eyes, lips, sitting, short sleeves, collared shirt, black skirt, black necktie, office lady, indoors\", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 366, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 3500, \"1\": 830}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"pinned\": true}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 706, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [668], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 367, \"type\": \"KSampler\", \"pos\": {\"0\": 3500, \"1\": 1130}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 690, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 729, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 668, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 700, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [669], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [853412980131936, \"randomize\", 30, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 368, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3500, \"1\": 1530}, \"size\": {\"0\": 398.55914306640625, \"1\": 49.51240921020508}, \"flags\": {\"pinned\": true}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 669, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 695, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [750], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 370, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 4000, \"1\": 530}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"collapsed\": false, \"pinned\": true}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 686, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [730], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[9][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, sitting, shirt, pencil skirt, black skirt, chair, white shirt, looking at viewer, parted lips, tree, plant, short sleeves, indoors, brown eyes, window, office lady, realistic\", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 371, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 4000, \"1\": 830}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"pinned\": true}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 707, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [672], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 372, \"type\": \"KSampler\", \"pos\": {\"0\": 4000, \"1\": 1130}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 689, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 731, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 672, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 701, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [673], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [755680058850451, \"randomize\", 30, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 373, \"type\": \"VAEDecode\", \"pos\": {\"0\": 4000, \"1\": 1530}, \"size\": {\"0\": 398.55914306640625, \"1\": 49.51240921020508}, \"flags\": {\"pinned\": true}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 673, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 696, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [751], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 375, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 4500, \"1\": 530}, \"size\": {\"0\": 399.1121520996094, \"1\": 229.15310668945312}, \"flags\": {\"collapsed\": false, \"pinned\": true}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 687, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [732], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Positive Prompt Main (\\u8f38\\u5165\\u6b63\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"[10][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, sitting, shirt, looking at viewer, white shirt, pencil skirt, short sleeves, indoors, black skirt, brown eyes, parted lips, plant, collared shirt, window, smile\", true], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 376, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 4500, \"1\": 830}, \"size\": {\"0\": 399.59918212890625, \"1\": 169.88729858398438}, \"flags\": {\"pinned\": true}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 708, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [676], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"title\": \"Negative Prompt (\\u8f38\\u5165\\u8ca0\\u5411\\u63d0\\u793a\\u8a5e)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,\", true], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 377, \"type\": \"KSampler\", \"pos\": {\"0\": 4500, \"1\": 1130}, \"size\": {\"0\": 398.97100830078125, \"1\": 330.4149475097656}, \"flags\": {\"pinned\": true}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 688, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 733, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 676, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 702, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [677], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"title\": \"KSampler (\\u8a2d\\u5b9a\\u63a1\\u6a23\\u5668/Steps\\u6b65\\u6578/CFG))\", \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1081256756379998, \"randomize\", 30, 1, \"euler\", \"simple\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 378, \"type\": \"VAEDecode\", \"pos\": {\"0\": 4500, \"1\": 1530}, \"size\": {\"0\": 398.55914306640625, \"1\": 49.51240921020508}, \"flags\": {\"pinned\": true}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 677, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 697, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [753], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 385, \"type\": \"UNETLoader\", \"pos\": {\"0\": 0, \"1\": 200}, \"size\": {\"0\": 400, \"1\": 100}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [709], \"slot_index\": 0, \"shape\": 3, \"label\": \"MODEL\"}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev.safetensors\", \"default\"]}, {\"id\": 387, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 0, \"1\": 330}, \"size\": {\"0\": 400, \"1\": 110}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [710], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 388, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 0, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 714, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [712], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 389, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 500, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 715, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [716], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 390, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 1000, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 717, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [718], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 391, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 1500, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 719, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [720], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 392, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 2000, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 721, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [722], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 393, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 2500, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 723, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [724], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 394, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 3000, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 725, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [726], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 395, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 3500, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 727, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [729], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 396, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 4000, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 730, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [731], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 397, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 4500, \"1\": 1040}, \"size\": {\"0\": 400, \"1\": 60}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 732, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [733], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 398, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 0, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 66, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 735, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 400, \"type\": \"ImageScale\", \"pos\": {\"0\": 0, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 734, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [735], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}, {\"id\": 401, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 500, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 736, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 402, \"type\": \"ImageScale\", \"pos\": {\"0\": 500, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 737, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [736], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}, {\"id\": 403, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 1000, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 738, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 404, \"type\": \"ImageScale\", \"pos\": {\"0\": 1000, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 739, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [738], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}, {\"id\": 405, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 1500, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 68, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 740, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 406, \"type\": \"ImageScale\", \"pos\": {\"0\": 1500, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 742, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [740], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}, {\"id\": 407, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 2000, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 69, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 741, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 408, \"type\": \"ImageScale\", \"pos\": {\"0\": 2000, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 743, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [741], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}, {\"id\": 409, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 2500, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 70, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 744, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 410, \"type\": \"ImageScale\", \"pos\": {\"0\": 2500, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 746, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [744], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}, {\"id\": 411, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 3000, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 71, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 745, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 412, \"type\": \"ImageScale\", \"pos\": {\"0\": 3000, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 747, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [745], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}, {\"id\": 413, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 3500, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 72, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 748, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 414, \"type\": \"ImageScale\", \"pos\": {\"0\": 3500, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 750, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [748], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}, {\"id\": 415, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 4000, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 73, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 749, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 416, \"type\": \"ImageScale\", \"pos\": {\"0\": 4000, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 63, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 751, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [749], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}, {\"id\": 417, \"type\": \"SaveImageExtended\", \"pos\": {\"0\": 4500, \"1\": 1810}, \"size\": {\"0\": 400, \"1\": 690}, \"flags\": {}, \"order\": 74, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 752, \"label\": \"images\"}, {\"name\": \"positive_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive_text_opt\"}, \"label\": \"positive_text_opt\"}, {\"name\": \"negative_text_opt\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative_text_opt\"}, \"label\": \"negative_text_opt\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImageExtended\"}, \"widgets_values\": [\"Flux_Batch_\", \"unet_name\", \"\", \"lora_name\", \"underscore\", \"disabled\", \"disabled\", \"\", \"enabled\", 4, \"last\", \"disabled\", \"enabled\", \"\", \"\"]}, {\"id\": 418, \"type\": \"ImageScale\", \"pos\": {\"0\": 4500, \"1\": 1630}, \"size\": {\"0\": 400, \"1\": 130}, \"flags\": {}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 753, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [752], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"lanczos\", 1440, 1920, \"disabled\"]}], \"links\": [[586, 307, 0, 8, 1, \"VAE\"], [596, 306, 1, 315, 0, \"CLIP\"], [597, 306, 0, 316, 0, \"MODEL\"], [600, 315, 0, 316, 2, \"CONDITIONING\"], [613, 306, 1, 314, 0, \"CLIP\"], [615, 306, 1, 331, 0, \"CLIP\"], [616, 306, 1, 332, 0, \"CLIP\"], [618, 332, 0, 333, 2, \"CONDITIONING\"], [619, 313, 0, 333, 3, \"LATENT\"], [620, 306, 0, 333, 0, \"MODEL\"], [621, 333, 0, 337, 0, \"LATENT\"], [628, 306, 1, 339, 0, \"CLIP\"], [629, 306, 1, 340, 0, \"CLIP\"], [630, 306, 1, 341, 0, \"CLIP\"], [631, 306, 1, 342, 0, \"CLIP\"], [633, 306, 1, 344, 0, \"CLIP\"], [637, 342, 0, 345, 2, \"CONDITIONING\"], [638, 343, 0, 346, 2, \"CONDITIONING\"], [639, 344, 0, 347, 2, \"CONDITIONING\"], [640, 306, 0, 345, 0, \"MODEL\"], [641, 306, 0, 346, 0, \"MODEL\"], [642, 306, 0, 347, 0, \"MODEL\"], [643, 313, 0, 316, 3, \"LATENT\"], [644, 313, 0, 345, 3, \"LATENT\"], [645, 313, 0, 346, 3, \"LATENT\"], [646, 313, 0, 347, 3, \"LATENT\"], [647, 316, 0, 8, 0, \"LATENT\"], [648, 345, 0, 348, 0, \"LATENT\"], [649, 346, 0, 349, 0, \"LATENT\"], [650, 347, 0, 350, 0, \"LATENT\"], [651, 307, 0, 348, 1, \"VAE\"], [652, 307, 0, 349, 1, \"VAE\"], [653, 307, 0, 350, 1, \"VAE\"], [657, 307, 0, 337, 1, \"VAE\"], [658, 306, 1, 343, 0, \"CLIP\"], [660, 356, 0, 357, 2, \"CONDITIONING\"], [661, 357, 0, 358, 0, \"LATENT\"], [664, 361, 0, 362, 2, \"CONDITIONING\"], [665, 362, 0, 363, 0, \"LATENT\"], [668, 366, 0, 367, 2, \"CONDITIONING\"], [669, 367, 0, 368, 0, \"LATENT\"], [672, 371, 0, 372, 2, \"CONDITIONING\"], [673, 372, 0, 373, 0, \"LATENT\"], [676, 376, 0, 377, 2, \"CONDITIONING\"], [677, 377, 0, 378, 0, \"LATENT\"], [683, 306, 1, 355, 0, \"CLIP\"], [684, 306, 1, 360, 0, \"CLIP\"], [685, 306, 1, 365, 0, \"CLIP\"], [686, 306, 1, 370, 0, \"CLIP\"], [687, 306, 1, 375, 0, \"CLIP\"], [688, 306, 0, 377, 0, \"MODEL\"], [689, 306, 0, 372, 0, \"MODEL\"], [690, 306, 0, 367, 0, \"MODEL\"], [691, 306, 0, 362, 0, \"MODEL\"], [692, 306, 0, 357, 0, \"MODEL\"], [693, 307, 0, 358, 1, \"VAE\"], [694, 307, 0, 363, 1, \"VAE\"], [695, 307, 0, 368, 1, \"VAE\"], [696, 307, 0, 373, 1, \"VAE\"], [697, 307, 0, 378, 1, \"VAE\"], [698, 313, 0, 357, 3, \"LATENT\"], [699, 313, 0, 362, 3, \"LATENT\"], [700, 313, 0, 367, 3, \"LATENT\"], [701, 313, 0, 372, 3, \"LATENT\"], [702, 313, 0, 377, 3, \"LATENT\"], [704, 306, 1, 356, 0, \"CLIP\"], [705, 306, 1, 361, 0, \"CLIP\"], [706, 306, 1, 366, 0, \"CLIP\"], [707, 306, 1, 371, 0, \"CLIP\"], [708, 306, 1, 376, 0, \"CLIP\"], [709, 385, 0, 306, 0, \"MODEL\"], [710, 387, 0, 306, 1, \"CLIP\"], [712, 388, 0, 333, 1, \"CONDITIONING\"], [714, 331, 0, 388, 0, \"CONDITIONING\"], [715, 314, 0, 389, 0, \"CONDITIONING\"], [716, 389, 0, 316, 1, \"CONDITIONING\"], [717, 339, 0, 390, 0, \"CONDITIONING\"], [718, 390, 0, 345, 1, \"CONDITIONING\"], [719, 340, 0, 391, 0, \"CONDITIONING\"], [720, 391, 0, 346, 1, \"CONDITIONING\"], [721, 341, 0, 392, 0, \"CONDITIONING\"], [722, 392, 0, 347, 1, \"CONDITIONING\"], [723, 355, 0, 393, 0, \"CONDITIONING\"], [724, 393, 0, 357, 1, \"CONDITIONING\"], [725, 360, 0, 394, 0, \"CONDITIONING\"], [726, 394, 0, 362, 1, \"CONDITIONING\"], [727, 365, 0, 395, 0, \"CONDITIONING\"], [729, 395, 0, 367, 1, \"CONDITIONING\"], [730, 370, 0, 396, 0, \"CONDITIONING\"], [731, 396, 0, 372, 1, \"CONDITIONING\"], [732, 375, 0, 397, 0, \"CONDITIONING\"], [733, 397, 0, 377, 1, \"CONDITIONING\"], [734, 337, 0, 400, 0, \"IMAGE\"], [735, 400, 0, 398, 0, \"IMAGE\"], [736, 402, 0, 401, 0, \"IMAGE\"], [737, 8, 0, 402, 0, \"IMAGE\"], [738, 404, 0, 403, 0, \"IMAGE\"], [739, 348, 0, 404, 0, \"IMAGE\"], [740, 406, 0, 405, 0, \"IMAGE\"], [741, 408, 0, 407, 0, \"IMAGE\"], [742, 349, 0, 406, 0, \"IMAGE\"], [743, 350, 0, 408, 0, \"IMAGE\"], [744, 410, 0, 409, 0, \"IMAGE\"], [745, 412, 0, 411, 0, \"IMAGE\"], [746, 358, 0, 410, 0, \"IMAGE\"], [747, 363, 0, 412, 0, \"IMAGE\"], [748, 414, 0, 413, 0, \"IMAGE\"], [749, 416, 0, 415, 0, \"IMAGE\"], [750, 368, 0, 414, 0, \"IMAGE\"], [751, 373, 0, 416, 0, \"IMAGE\"], [752, 418, 0, 417, 0, \"IMAGE\"], [753, 378, 0, 418, 0, \"IMAGE\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.8140274938684746, \"offset\": [146.0115419572993, 162.6282998037258]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"316\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"333\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"345\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"346\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"347\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"357\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"362\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"367\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"372\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"377\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}}}",
                "steps": 30,
                "width": 960,
                "height": 1280,
                "models": [],
                "prompt": "[2][24_94]Against a soft, true gradient blue background, a stunning real large breasts Japanese woman with long, flowing dark hair, her piercing gaze directly addressing the viewer. skirt, outdoors, shirt, tree, looking at viewer, blue skirt, white shirt, parted lips, sky, day, collared shirt, pleated skirt, short sleeves, building, blue sky, shirt tucked in",
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 1,
                "modelIds": [],
                "scheduler": "simple",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "worst quality,low quality,worst detail,low detail,source_furry, source_pony, source_cartoon,2d,bad anatomy, bad hands, text, error, missing fingers, (extra digit:1.4), fewer digits, cropped, bad artist, outlines, jpeg artifacts, signature, watermark, username, blurry, 3d,",
                "additionalResources": [
                    {
                        "name": "0\\IsabellaFluxTAV102.safetensors",
                        "type": "lora",
                        "strength": 1,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "SinsinWang",
            "baseModel": null
        },
        {
            "id": 31509873,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9e654e78-601a-4e59-a076-b91e8cb19ff4/width=832/9e654e78-601a-4e59-a076-b91e8cb19ff4.jpeg",
            "hash": "UiFD}NI:9]$%}YNbEMso%LniNHSzTJw{aKS#",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-27T00:00:45.668Z",
            "postId": 7043823,
            "stats": {
                "cryCount": 0,
                "laughCount": 17,
                "likeCount": 306,
                "dislikeCount": 0,
                "heartCount": 69,
                "commentCount": 1
            },
            "meta": null,
            "username": "Rhailo",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 31395643,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e97a3b31-5771-4244-9261-80c282a6bcf3/width=1216/e97a3b31-5771-4244-9261-80c282a6bcf3.jpeg",
            "hash": "U6CZIc-=McI9HWpJ4TVX_3jX4;DiAH.8$%IV",
            "width": 1216,
            "height": 832,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-26T06:19:36.823Z",
            "postId": 7018174,
            "stats": {
                "cryCount": 12,
                "laughCount": 71,
                "likeCount": 259,
                "dislikeCount": 0,
                "heartCount": 48,
                "commentCount": 0
            },
            "meta": {
                "Size": "1216x832",
                "seed": 670661999,
                "extra": {
                    "remixOfId": 30258509
                },
                "steps": 20,
                "prompt": "a man in a cap and shortspushing out a jeep rubicon stuck in mud and a large puddle, a bear helps a man push a jeep out from behind, detailmaximizer",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-09-25T0609:24.0799117Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 735063,
                        "modelVersionName": "FLUX v0.1"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 720252,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "White_Rabbit_A",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 31109096,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0be2f80c-c9b4-4171-a4ef-2ffb47c9370f/width=920/0be2f80c-c9b4-4171-a4ef-2ffb47c9370f.jpeg",
            "hash": "UPKU1eIq?^-oNG%MxuRPE1WB%Layx]ayaej[",
            "width": 920,
            "height": 1224,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-24T12:49:28.771Z",
            "postId": 6954016,
            "stats": {
                "cryCount": 2,
                "laughCount": 17,
                "likeCount": 267,
                "dislikeCount": 0,
                "heartCount": 104,
                "commentCount": 0
            },
            "meta": {
                "": {},
                "VAE": "vae-ft-mse-840000-ema-pruned.safetensors",
                "Size": "920x1224",
                "seed": 3175162507,
                "Model": "boleromix",
                "steps": 20,
                "hashes": {
                    "vae": "faa610c52d",
                    "model": "d86a4e4dff",
                    "lora:off shoulder sweater_SD_V1.0": "7eee40e182f1"
                },
                "prompt": "(masterpiece,ultra-detailed,best quality,8K,CG,illustration,shaved:1.0),(girl:1.0) simple background,  <lora:off shoulder sweater_SD_V1.0:0.8> off-shoulder sweater",
                "Version": "v1.7.0",
                "sampler": "DPM++ 2M Karras",
                "{Method": {},
                "Upscaler": {},
                "cfgScale": 7,
                "clipSkip": 2,
                "TI hashes": {
                    "badhandv4": "5e40d722fc3d",
                    "bad-hands-5": "aa7651be154c",
                    "EasyNegativeV2": "339cc9210f70"
                },
                "resources": [
                    {
                        "hash": "7eee40e182f1",
                        "name": "off shoulder sweater_SD_V1.0",
                        "type": "lora"
                    },
                    {
                        "hash": "d86a4e4dff",
                        "name": "boleromix",
                        "type": "model"
                    }
                ],
                "Model hash": "d86a4e4dff",
                "Tile Overlap": "48",
                "Upscale factor": "1.2",
                "negativePrompt": "EasyNegativeV2,bad-hands-5,badhandv4,(flat color, flat shading,retro style, poor quality, bad facepastiese, extra legs,extra arms,extra ears,bad fingers, bad anatomy, missing fingers, lowres, cropped, signature, watermark, username, artist name, text,pubic hair,onlooker,blurry,cartoon,bar censor,censored,multipul angle,split view,JPEG artifacts,grid view:1.0)",
                "Keep input size": "true}",
                "Tile batch size": "4",
                "Tile tile width": "96",
                "Tiled Diffusion": {},
                "Tile tile height": "96",
                "Denoising strength": "0.4",
                "Tiled Diffusion upscaler": "R-ESRGAN 4x+ Anime6B",
                "Tiled Diffusion scale factor": "1.2"
            },
            "username": "bolero537",
            "baseModel": "SD 1.5"
        },
        {
            "id": 30491949,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7ff8f51d-402c-4337-ae64-a2da26e5e4ee/width=1072/7ff8f51d-402c-4337-ae64-a2da26e5e4ee.jpeg",
            "hash": "UjIz}6xtM_RP~ASKbbae-pxus:Ri~Ws+s+W=",
            "width": 1072,
            "height": 1880,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-21T00:26:22.466Z",
            "postId": 6822330,
            "stats": {
                "cryCount": 23,
                "laughCount": 57,
                "likeCount": 239,
                "dislikeCount": 0,
                "heartCount": 71,
                "commentCount": 0
            },
            "meta": {
                "seed": 3534,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"dpm_2\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 30, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 3534}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 6.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 768, \"height\": 1344, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": 768, \"height\": 1344, \"model\": [\"52\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"51\": {\"inputs\": {\"lora_name\": \"flux1\\\\detailer_flux_v1.safetensors\", \"strength_model\": 0.45, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"52\": {\"inputs\": {\"lora_name\": \"flux1\\\\realism_lora_comfy flux_converted.safetensors\", \"strength_model\": 0.75, \"strength_clip\": 1.0, \"model\": [\"51\", 0], \"clip\": [\"51\", 1]}, \"class_type\": \"LoraLoader\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.1, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"52\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"71\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.35000000000000003, \"alpha\": 0.35000000000000003, \"image\": [\"72\", 0]}, \"class_type\": \"ImageSharpen\"}, \"72\": {\"inputs\": {\"hdr_intensity\": 0.5, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"69\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"73\": {\"inputs\": {\"intensity\": 0.07, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"71\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.35000000000000003, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 25, \"denoise\": 0.2, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"A serene, photorealistic image of a beautiful lady with red hair and green eyes,  at the edge of a lake as the sun sets. She wears White flowy maxi dress with lace details highlights her slim waist and ample bosom. The purple sky casts dramatic lighting across the tranquil nature scene. Perfect hands and body anatomy.Additional background details are a tree, stone walkway, utility pole, resort building seen farway near the mountain, mountainous horizon, \\n\\nRipples in the lake water reflecting the sky, Intricate floral patterns on the maxi dress ,Detailed reflections of the sky on her dress\\n\\nSitting on a large stone, with her legs crossed, hands resting casually on her knees, looking calm and serene\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n, \\n\\n\\n\\n\\n\", \"clip\": [\"52\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"109\": {\"inputs\": {\"tile_size\": 512}, \"class_type\": \"VAEEncodeTiled\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"141\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"144\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"147\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"149\": {\"inputs\": {\"scale_method\": \"lanczos\", \"scale_factor\": 1.5, \"use_tiled_vae\": false}, \"class_type\": \"LatentPixelScale\"}}, \"workflow\": {\"last_node_id\": 149, \"last_link_id\": 314, \"nodes\": [{\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1300, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 293, \"1\": -192}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 153}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 126, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 768, 1344]}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1801, \"1\": 21}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 159}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 355, \"1\": 764}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 112, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [768, 1344, 1]}, {\"id\": 109, \"type\": \"VAEEncodeTiled\", \"pos\": {\"0\": -510, \"1\": 806}, \"size\": {\"0\": 248.89723205566406, \"1\": 78}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncodeTiled\"}, \"widgets_values\": [512]}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1813, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [260, 299], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 117, \"type\": \"SaveImagePlus\", \"pos\": {\"0\": 4366, \"1\": 456}, \"size\": {\"0\": 832.2413940429688, \"1\": 1183.025634765625}, \"flags\": {}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 282}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImagePlus\"}, \"widgets_values\": [\"ComfyUI\", \"JPEG\", true]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 5, \"1\": 172}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [304], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [294, 305], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [295, 306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [296, 307], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186, 297, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3079, \"1\": -575}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 311}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 148, \"type\": \"SaveImage\", \"pos\": {\"0\": 3061, \"1\": -483}, \"size\": {\"0\": 281.4468078613281, \"1\": 480.5931091308594}, \"flags\": {}, \"order\": 64, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 313}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 146, \"type\": \"DZ_Face_Detailer\", \"pos\": {\"0\": 2658, \"1\": -843}, \"size\": {\"0\": 309.8262939453125, \"1\": 842.9425659179688}, \"flags\": {}, \"order\": 59, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 305}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 306}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 307}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DZ_Face_Detailer\"}, \"widgets_values\": [1, \"fixed\", 20, 4, \"euler\", \"sgm_uniform\", 0.5, 32, \"face\", \"dilate\", 3, 3]}, {\"id\": 142, \"type\": \"SaveImage\", \"pos\": {\"0\": 3204, \"1\": 556}, \"size\": {\"0\": 813.5270385742188, \"1\": 1236.560546875}, \"flags\": {}, \"order\": 66, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 300}], \"outputs\": [], \"title\": \"FinalPass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": 8, \"1\": 851}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": 19, \"1\": 1194}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 140, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2769, \"1\": 86}, \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 63, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 294}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 295}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 296}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 297}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 298}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.5, 1, \"fixed\", 25, 3, \"euler\", \"sgm_uniform\", 0.1, \"Linear\", 1344, 768, 24, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 700, \"1\": 54}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 133, \"1\": 321}, \"size\": {\"0\": 214.54766845703125, \"1\": 58}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 900, \"1\": 94}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 892, \"1\": 570}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 149, \"type\": \"LatentPixelScale\", \"pos\": {\"0\": 465, \"1\": 1483}, \"size\": {\"0\": 243.60000610351562, \"1\": 146}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model_opt\", \"type\": \"UPSCALE_MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentPixelScale\"}, \"widgets_values\": [\"lanczos\", 1.5, false]}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1512, \"1\": -35}, \"size\": {\"0\": 140, \"1\": 46}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 879, \"1\": 949}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.1, 10, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 507, \"1\": 1336}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 314}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1192, \"1\": 46}, \"size\": {\"0\": 243.6832733154297, \"1\": 82}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 2206, \"1\": 1366}, \"size\": {\"0\": 848.405029296875, \"1\": 898.4495849609375}, \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 879, \"1\": 1133}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 893, \"1\": 720}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 314], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 141, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2036, \"1\": 41}, \"size\": {\"0\": 428.9556884765625, \"1\": 78}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": 34, \"1\": 42}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [252], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": 2156, \"1\": 435}, \"size\": {\"0\": 591.3112182617188, \"1\": 532.275634765625}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1275, \"1\": 1367}, \"size\": {\"0\": 848.655029296875, \"1\": 899.4495849609375}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 820, \"1\": 1282}, \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [3534, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1812, \"1\": 375}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168, 282], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.07, 10, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1473, \"1\": 40}, \"size\": {\"0\": 284.1048889160156, \"1\": 619.9912719726562}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 287, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [159, 308], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 474, \"1\": 893}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpm_2\"]}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1212, \"1\": 178}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [287], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1804, \"1\": 560}, \"size\": {\"0\": 235.1806640625, \"1\": 106}, \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 25, 0.2], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 617, \"1\": 645}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1344, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 374, \"1\": 646}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [112, 115], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [768, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 52, \"type\": \"LoraLoader\", \"pos\": {\"0\": -119, \"1\": 428}, \"size\": {\"0\": 455.3192138671875, \"1\": 131.6434326171875}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 125}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 301}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [126], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [153], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\realism_lora_comfy flux_converted.safetensors\", 0.75, 1]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 896, \"1\": 29}, \"size\": {\"0\": 247.96473693847656, \"1\": 470.63494873046875}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 486, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 30, 1]}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 403, \"1\": 39}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [6], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 2058, \"1\": 261}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 260}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.35000000000000003, 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 51, \"type\": \"LoraLoader\", \"pos\": {\"0\": -119, \"1\": 616}, \"size\": {\"0\": 462.208251953125, \"1\": 134.61793518066406}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 252}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 304}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [125], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [301], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\detailer_flux_v1.safetensors\", 0.45, 1]}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 382, \"1\": 140}, \"size\": {\"0\": 488.2522277832031, \"1\": 387.7407531738281}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"A serene, photorealistic image of a beautiful lady with red hair and green eyes,  at the edge of a lake as the sun sets. She wears White flowy maxi dress with lace details highlights her slim waist and ample bosom. The purple sky casts dramatic lighting across the tranquil nature scene. Perfect hands and body anatomy.Additional background details are a tree, stone walkway, utility pole, resort building seen farway near the mountain, mountainous horizon, \\n\\nRipples in the lake water reflecting the sky, Intricate floral patterns on the maxi dress ,Detailed reflections of the sky on her dress\\n\\nSitting on a large stone, with her legs crossed, hands resting casually on her knees, looking calm and serene\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n, \\n\\n\\n\\n\\n\"]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [112, 34, 0, 27, 0, \"INT\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [125, 51, 0, 52, 0, \"MODEL\"], [126, 52, 0, 30, 0, \"MODEL\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [153, 52, 1, 49, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [159, 42, 0, 69, 0, \"LATENT\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [252, 12, 0, 51, 0, \"MODEL\"], [260, 72, 0, 71, 0, \"IMAGE\"], [282, 73, 0, 117, 0, \"IMAGE\"], [285, 75, 0, 59, 0, \"IMAGE\"], [287, 134, 0, 42, 2, \"SAMPLER\"], [288, 62, 0, 41, 0, \"IMAGE\"], [294, 96, 0, 140, 1, \"MODEL\"], [295, 64, 0, 140, 2, \"CONDITIONING\"], [296, 65, 0, 140, 3, \"CONDITIONING\"], [297, 70, 0, 140, 4, \"VAE\"], [298, 141, 0, 140, 5, \"UPSCALE_MODEL\"], [299, 72, 0, 140, 0, \"IMAGE\"], [300, 140, 0, 142, 0, \"IMAGE\"], [301, 51, 1, 52, 1, \"CLIP\"], [304, 11, 0, 51, 1, \"CLIP\"], [305, 96, 0, 146, 0, \"MODEL\"], [306, 64, 0, 146, 1, \"CONDITIONING\"], [307, 65, 0, 146, 2, \"CONDITIONING\"], [308, 42, 0, 146, 3, \"LATENT\"], [310, 70, 0, 146, 4, \"VAE\"], [311, 146, 0, 147, 0, \"LATENT\"], [312, 81, 0, 147, 1, \"VAE\"], [313, 147, 0, 148, 0, \"IMAGE\"], [314, 61, 0, 77, 1, \"IMAGE\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.7513148009015777, \"offset\": [-629.1577552808957, 270.40224625997115]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}, \"140\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"146\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"140\": 1, \"146\": 0}}}",
                "steps": 30,
                "models": [],
                "prompt": "A serene, photorealistic image of a beautiful lady with red hair and green eyes,  at the edge of a lake as the sun sets. She wears White flowy maxi dress with lace details highlights her slim waist and ample bosom. The purple sky casts dramatic lighting across the tranquil nature scene. Perfect hands and body anatomy.Additional background details are a tree, stone walkway, utility pole, resort building seen farway near the mountain, mountainous horizon, \n\nRipples in the lake water reflecting the sky, Intricate floral patterns on the maxi dress ,Detailed reflections of the sky on her dress\n\nSitting on a large stone, with her legs crossed, hands resting casually on her knees, looking calm and serene\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n, \n\n\n\n\n",
                "denoise": 1,
                "sampler": "DPM2",
                "cfgScale": 6,
                "modelIds": [],
                "scheduler": "sgm_uniform",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux1\\detailer_flux_v1.safetensors",
                        "type": "lora",
                        "strength": 0.45,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux1\\realism_lora_comfy flux_converted.safetensors",
                        "type": "lora",
                        "strength": 0.75,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "salammy",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 28671704,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9c8509c5-b906-4cf1-887e-eb6dbe23b191/width=832/9c8509c5-b906-4cf1-887e-eb6dbe23b191.jpeg",
            "hash": "UHCP-S_3S#rq~W-obbt7NGxZxZxuE2NIr=ay",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-10T05:46:47.176Z",
            "postId": 6413224,
            "stats": {
                "cryCount": 0,
                "laughCount": 11,
                "likeCount": 296,
                "dislikeCount": 0,
                "heartCount": 83,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3357178515,
                "steps": 27,
                "prompt": "extremely detailed, landscape of an unknown planet, (futuristic monolith:1.8), the monolith is (covered:1.1) with minerals and rare crystals of an alien type, The crystal has sharp, geometric facets in shades of deep orange and blue, amethyst, and emerald, with a subtle internal glow, futuristic landscape, lake, cloudy weather, unreal engine 5, perfect composition, vibrant, rtx, hbao, extremely detailed, maximum resolution, 8k, (perfect composition:1.2), superior color grading,  (realistic:1.4), (panoramic composition:1.5), (night photography:1.5), complementary colors, foggy atmosphere, lord of the rings style",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-09-09T0720:56.3751363Z",
                "negativePrompt": "(octane render, render, drawing, anime, bad photo, bad photography:1.3), (worst quality, low quality, blurry:1.2), (close up photo:2.0), saturated, artificial colors, artificial textures, (moon:1.0)",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 641087,
                        "modelVersionName": "v9.0"
                    }
                ]
            },
            "username": "endhon",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 27232425,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/39bdf699-10b4-4ecf-b8f5-0e6847c3ba0d/width=1248/39bdf699-10b4-4ecf-b8f5-0e6847c3ba0d.jpeg",
            "hash": "UHFNuPYk0|Q,L2}@RjInFaOY}sSNJC%1xaIp",
            "width": 1248,
            "height": 1608,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-01T14:44:02.278Z",
            "postId": 6090521,
            "stats": {
                "cryCount": 0,
                "laughCount": 7,
                "likeCount": 310,
                "dislikeCount": 0,
                "heartCount": 73,
                "commentCount": 0
            },
            "meta": {
                "seed": 100000000000004,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"dpm_2\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 45, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 100000000000004}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 5.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 896, \"height\": 1152, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": 896, \"height\": 1152, \"model\": [\"52\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4}, \"class_type\": \"RandomNoise\"}, \"52\": {\"inputs\": {\"lora_name\": \"flux1\\\\midjourney_whisper_flux_lora_v01.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.4, \"alpha\": 0.4, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.03, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"52\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"71\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"118\", 0]}, \"class_type\": \"ImageSharpen\"}, \"73\": {\"inputs\": {\"intensity\": 0.05, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"71\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.35000000000000003, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"62\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 25, \"denoise\": 0.15, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"extremely photorealistic of an Inferno-born demoness,  A character with fair skin, glowing cracks, and fiery eyes that radiate heat and power.Molten Tears, crying tears of  glowing lava running down the character\\u2019s face.\", \"clip\": [\"52\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"106\": {\"inputs\": {}, \"class_type\": \"easy cleanGpuUsed\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"108\": {\"inputs\": {\"tile_size\": 3072, \"fast\": true, \"color_fix\": true}, \"class_type\": \"VAEEncodeTiled_TiledDiffusion\"}, \"109\": {\"inputs\": {\"tile_size\": 512}, \"class_type\": \"VAEEncodeTiled\"}, \"113\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Neutral_115000_swaG.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"115\": {\"inputs\": {\"sharpen_radius\": 1, \"alpha\": 0.2}, \"class_type\": \"Sharpen\"}, \"116\": {\"inputs\": {\"hdr_intensity\": 1, \"shadow_intensity\": 0.75, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.35000000000000003, \"enhance_color\": 0.5, \"image\": [\"69\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"117\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"118\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.5, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.35000000000000003, \"enhance_color\": 0.5, \"image\": [\"69\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}}, \"workflow\": {\"last_node_id\": 118, \"last_link_id\": 256, \"nodes\": [{\"id\": 28, \"type\": \"Note\", \"pos\": [2, 841], \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": [517, 28], \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 53, \"type\": \"Reroute\", \"pos\": [752, -118], \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": [753, -88], \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": [1300, -53], \"size\": [75, 26], \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": [137, 330], \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": [295, -230], \"size\": [75, 26], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": [294, -299], \"size\": [75, 26], \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": [1295, -200], \"size\": [75, 26], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": [-234, -196], \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": [293, -192], \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 153}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": [1294, -167], \"size\": [75, 26], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": [36, 173], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [127], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": [34, 42], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [124], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": [888, 567], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.4, 0.4], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": [467, 621], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 112, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [896, 1152, 1]}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": [919, 50], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": [400, -165], \"size\": [75, 26], \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": [753, -53], \"size\": [75, 26], \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": [938, 1256], \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 182}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": [1685, -167], \"size\": [75, 26], \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": [1297, -118], \"size\": [75, 26], \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": [1299, -85], \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [138, 196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": [1292, -300], \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": [294, -266], \"size\": [75, 26], \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": [888, 940], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [147, 182], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.03, 10, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": [774, 1345], \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 37, \"type\": \"Note\", \"pos\": [39, 1204], \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": [1739, 20], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 159}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": [887, 719], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 108, \"type\": \"VAEEncodeTiled_TiledDiffusion\", \"pos\": [-586, 499], \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncodeTiled_TiledDiffusion\"}, \"widgets_values\": [3072, true, true]}, {\"id\": 109, \"type\": \"VAEEncodeTiled\", \"pos\": [-592, 672], \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncodeTiled\"}, \"widgets_values\": [512]}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": [1429, 159], \"size\": {\"0\": 287.8871154785156, \"1\": 537.7322387695312}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 138, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [159], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": [1482, 22], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 184}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": [2216, -220], \"size\": [75, 26], \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": [2219, -184], \"size\": [75, 26], \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": [1747, 594], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 25, 0.15], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": [2218, -289], \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [236], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": [2216, -254], \"size\": [75, 26], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [237], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": [1294, -267], \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [238], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": [1294, -233], \"size\": [75, 26], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [239], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": [1168, 194], \"size\": {\"0\": 245.11636352539062, \"1\": 82}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": [1762, 379], \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 66, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 10, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 113, \"type\": \"UpscaleModelLoader\", \"pos\": [1983, 26], \"size\": {\"0\": 263.07012939453125, \"1\": 58}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [235], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Neutral_115000_swaG.pth\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": [882, 1127], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [184], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 114, \"type\": \"LayerFilter: HDREffects\", \"pos\": [2633, -72], \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 63, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 240}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [249], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 115, \"type\": \"Sharpen\", \"pos\": [2633, 177], \"size\": [210, 82], \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Sharpen\"}, \"widgets_values\": [1, 0.2]}, {\"id\": 116, \"type\": \"LayerFilter: HDREffects\", \"pos\": [2965, -69], \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 249}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [250], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.75, 0.75, 0.25, 0.35000000000000003, 0.5], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": [851, 1508], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": [457, 1158], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 126, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 896, 1152]}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": [2091, 962], \"size\": [813.5270385742188, 1236.560546875], \"flags\": {}, \"order\": 68, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\", \"locked\": true}, {\"id\": 112, \"type\": \"UltimateSDUpscale\", \"pos\": [2310, -69], \"size\": {\"0\": 276.0959167480469, \"1\": 826}, \"flags\": {}, \"order\": 61, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 248}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 236}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 238}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 239}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 237}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 235}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [240], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 1, \"fixed\", 20, 1, \"euler\", \"sgm_uniform\", 0.2, \"Linear\", 832, 1216, 20, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": [490, 115], \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [5], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 52, \"type\": \"LoraLoader\", \"pos\": [16, 615], \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 125}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 128}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [126], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [153], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\midjourney_whisper_flux_lora_v01.safetensors\", 1, 1]}, {\"id\": 117, \"type\": \"LoadImage\", \"pos\": [-17, 1386], \"size\": [736.7395170202891, 649.7912286572164], \"flags\": {}, \"order\": 13, \"mode\": 0, \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": [1755, 136], \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 60, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [248, 255], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": [2069, 434], \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 256}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 51, \"type\": \"LoraLoader\", \"pos\": [16, 442], \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 20, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 124}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 127}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [125], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [128], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"SDXL\\\\Korean_Photo_Studio_Style_XL.safetensors\", 0.4, 1]}, {\"id\": 118, \"type\": \"LayerFilter: HDREffects\", \"pos\": [2970, 185], \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 255}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [256], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.5, 0.75, 0.25, 0.35000000000000003, 0.5], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": [473, 893], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpm_2\"]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": [917, 134], \"size\": {\"0\": 236.8000030517578, \"1\": 392.4609680175781}, \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": [1245, 969], \"size\": [813.2683715820312, 1239.0855712890625], \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 147}], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\", \"locked\": true}, {\"id\": 95, \"type\": \"SaveImage\", \"pos\": [2961, 965], \"size\": {\"0\": 808.7037963867188, \"1\": 1233.263916015625}, \"flags\": {}, \"order\": 67, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 250}], \"title\": \"Final Image\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": [472, 766], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [100000000000004, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": [655, 485], \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1152, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": [426, 483], \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [112, 115], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [896, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 106, \"type\": \"easy cleanGpuUsed\", \"pos\": [1390, 822], \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": false}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": null}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": [486, 994], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 45, 1]}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": [488, 231], \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"extremely photorealistic of an Inferno-born demoness,  A character with fair skin, glowing cracks, and fiery eyes that radiate heat and power.Molten Tears, crying tears of  glowing lava running down the character\\u2019s face.\"]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [112, 34, 0, 27, 0, \"INT\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [124, 12, 0, 51, 0, \"MODEL\"], [125, 51, 0, 52, 0, \"MODEL\"], [126, 52, 0, 30, 0, \"MODEL\"], [127, 11, 0, 51, 1, \"CLIP\"], [128, 51, 1, 52, 1, \"CLIP\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [138, 56, 0, 42, 2, \"SAMPLER\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [147, 62, 0, 41, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [153, 52, 1, 49, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [159, 42, 0, 69, 0, \"LATENT\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [182, 62, 0, 77, 1, \"IMAGE\"], [183, 77, 0, 75, 0, \"IMAGE\"], [184, 75, 0, 59, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [235, 113, 0, 112, 5, \"UPSCALE_MODEL\"], [236, 96, 0, 112, 1, \"MODEL\"], [237, 81, 0, 112, 4, \"VAE\"], [238, 64, 0, 112, 2, \"CONDITIONING\"], [239, 65, 0, 112, 3, \"CONDITIONING\"], [240, 112, 0, 114, 0, \"IMAGE\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [248, 72, 0, 112, 0, \"IMAGE\"], [249, 114, 0, 116, 0, \"IMAGE\"], [250, 116, 0, 95, 0, \"IMAGE\"], [255, 72, 0, 118, 0, \"IMAGE\"], [256, 118, 0, 71, 0, \"IMAGE\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 2.853116706110003, \"offset\": [-477.4500838043585, -183.56176542859748]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"112\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"112\": 1}}}",
                "steps": 45,
                "models": [],
                "prompt": "extremely photorealistic of an Inferno-born demoness,  A character with fair skin, glowing cracks, and fiery eyes that radiate heat and power.Molten Tears, crying tears of  glowing lava running down the character\u2019s face.",
                "denoise": 1,
                "sampler": "DPM2",
                "cfgScale": 5,
                "modelIds": [],
                "scheduler": "sgm_uniform",
                "upscalers": [
                    "4x_UniversalUpscalerV2-Neutral_115000_swaG.pth"
                ],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux1\\midjourney_whisper_flux_lora_v01.safetensors",
                        "type": "lora",
                        "strength": 1,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "salammy",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 25662682,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2404b773-14a8-4bc4-865e-433fe805cc37/width=1248/2404b773-14a8-4bc4-865e-433fe805cc37.jpeg",
            "hash": "UCELsU03q4R7%}MgIFSvyBIWN3obx@xpsXtQ",
            "width": 1248,
            "height": 1872,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-23T00:21:27.174Z",
            "postId": 5737338,
            "stats": {
                "cryCount": 4,
                "laughCount": 22,
                "likeCount": 260,
                "dislikeCount": 0,
                "heartCount": 104,
                "commentCount": 0
            },
            "meta": {
                "RNG": "CPU",
                "VAE": "sdxl_vae.safetensors",
                "Size": "832x1248",
                "seed": 28240472,
                "Model": "monstercoffeecelsiusMix_v10",
                "steps": 28,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "b0940d6746",
                    "lora:berengaria-pdxl-nvwls-v1-000006": "adfdadbe505d"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime, 1girl, solo,  <lora:berengaria-pdxl-nvwls-v1-000006:1> berengaria, black hair, short hair, purple eyes, hair over one eye, maroon bodysuit, long sleeves, black armor, gauntlets, big breasts, lying on back, looking at you, hand on own chest, parted lips, blush, from above, field",
                "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
                "sampler": "Euler a",
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "adfdadbe505d",
                        "name": "berengaria-pdxl-nvwls-v1-000006",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "b0940d6746",
                        "name": "monstercoffeecelsiusMix_v10",
                        "type": "model"
                    }
                ],
                "Model hash": "b0940d6746",
                "Hires steps": "10",
                "Hires upscale": "1.5",
                "Schedule type": "Automatic",
                "Hires upscaler": "4x-AnimeSharp",
                "negativePrompt": "monochrome, greyscale",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.4.2",
                "Denoising strength": "0.5",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "novowels",
            "baseModel": "Pony"
        },
        {
            "id": 25323512,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d7efd190-8351-43cf-9198-6cad42fa2db8/width=832/d7efd190-8351-43cf-9198-6cad42fa2db8.jpeg",
            "hash": "U9A^wg4m01?^My=|9EIomPQ,s;MdE1pI%hkD",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-20T21:29:59.104Z",
            "postId": 5658828,
            "stats": {
                "cryCount": 19,
                "laughCount": 28,
                "likeCount": 252,
                "dislikeCount": 0,
                "heartCount": 91,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 814803080,
                "steps": 25,
                "prompt": "Masterpiece, 4k, 8k, concept art, high quality, highly detailed, a photorealistic white cat on its back, holding a tiny planet earth as if it were a toy ball, highly detailed eyes, cosmos background, stars, nebulae, fantastic lighting, nebulae in background, aurora borealis lights,",
                "sampler": "Undefined",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-14T1534:14.2121170Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    }
                ]
            },
            "username": "BuzzGuzzler",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 22017287,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8ab9959e-a429-48c4-be9a-2f592ae530b7/width=832/8ab9959e-a429-48c4-be9a-2f592ae530b7.jpeg",
            "hash": "UNHngIE1lo-ooiWBIrt79^ofR.Si%h$fEkj[",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-30T16:00:00.000Z",
            "postId": 4908002,
            "stats": {
                "cryCount": 2,
                "laughCount": 16,
                "likeCount": 284,
                "dislikeCount": 0,
                "heartCount": 88,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "fixFP16ErrorsSDXLLowerMemoryUse_v10.safetensors",
                "Size": "832x1216",
                "seed": 1065567900,
                "Model": "incursiosMemeDiffusion_v16PDXL",
                "steps": 24,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "c8c641fa3a",
                    "lora:TyingPonytail_pdxl_Incrs_v1": "289283235b10"
                },
                "prompt": "score_9, score_8_up, score_7_up, arms up, ponytail, tying hair, adjusting hair, upper body, <lora:TyingPonytail_pdxl_Incrs_v1:1>, from behind, yoimiya \\(genshin impact\\),",
                "Version": "f0.0.17v1.8.0rc-latest-287-g77bdb920",
                "sampler": "Euler a",
                "cfgScale": 6,
                "resources": [
                    {
                        "hash": "289283235b10",
                        "name": "TyingPonytail_pdxl_Incrs_v1",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "c8c641fa3a",
                        "name": "incursiosMemeDiffusion_v16PDXL",
                        "type": "model"
                    }
                ],
                "Model hash": "c8c641fa3a",
                "negativePrompt": "monochrome",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.6.0",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer negative prompt": "3d",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "FallenIncursio",
            "baseModel": "Pony"
        }
    ],
    "metadata": {
        "nextCursor": "12650|1727677502809",
        "nextPage": "https://civitai.com/api/v1/images?sort=Most%20Reactions&nsfw=Soft&cursor=12650%7C1727677502809"
    }
}