{
    "items": [
        {
            "id": 6850596,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5c3243e4-7205-4bf9-8868-b7c8e2d32409/width=1800/5c3243e4-7205-4bf9-8868-b7c8e2d32409.jpeg",
            "hash": "UDLyvJ^j:+EL?aNaPAEL}YtR~BR*{1VYU_xa",
            "width": 4112,
            "height": 5376,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-19T22:25:12.207Z",
            "postId": 1478255,
            "stats": {
                "cryCount": 0,
                "laughCount": 14,
                "likeCount": 96,
                "dislikeCount": 0,
                "heartCount": 59,
                "commentCount": 0
            },
            "meta": {
                "VAE": "Grapefruit.vae.pt",
                "Size": "64x64",
                "seed": 3620699511,
                "Model": "dreamshaperXL_v21TurboDPMSDE",
                "steps": 7,
                "hashes": {
                    "model": "4496b36d48"
                },
                "prompt": "red and white, nuka cola poster, nuka girl wearing a sci-fi suit and space helmet, holding sci-fi ray-gun, painted by gil elvgren, Coby Whitmore, pin-up, leyendecker",
                "Version": "v1.7.0",
                "sampler": "DPM++ SDE Karras",
                "VAE hash": "513d68f522",
                "cfgScale": 1.5,
                "Mask blur": "0",
                "resources": [
                    {
                        "hash": "4496b36d48",
                        "name": "dreamshaperXL_v21TurboDPMSDE",
                        "type": "model"
                    }
                ],
                "Model hash": "4496b36d48",
                "Denoising strength": "1e-05"
            },
            "username": "theq1017752",
            "baseModel": "SDXL Turbo"
        },
        {
            "id": 6419499,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/91c4bded-b1b4-435f-916f-31d445cafc55/width=1024/91c4bded-b1b4-435f-916f-31d445cafc55.jpeg",
            "hash": "UFA0:@.TXo9a*0%$NYROkstmj]xaa0ogoztl",
            "width": 1024,
            "height": 1536,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-09T01:41:39.886Z",
            "postId": 1386302,
            "stats": {
                "cryCount": 1,
                "laughCount": 5,
                "likeCount": 101,
                "dislikeCount": 0,
                "heartCount": 62,
                "commentCount": 0
            },
            "meta": {
                "RNG": "CPU",
                "VAE": "vae-ft-mse-840000-ema-pruned.ckpt",
                "Size": "512x768",
                "seed": 7839543,
                "Model": "fcanimemixFcAnime_v50",
                "steps": 22,
                "\"fcNeg": "f257fca13352\"",
                "hashes": {
                    "model": "5709c2059c",
                    "embed:fcNeg": "f257fca133"
                },
                "prompt": "masterpiece, best quality, <lora:kamishiroalice-nvwls-v1-000009:0.8> kamishiro alice, witch hat, hair ornament, black dress, black skirt, long dress, black cape, yellow bow, profile, night sky",
                "Version": "v1.6.0-2-g4afaaf8a",
                "sampler": "DPM++ 2M Karras",
                "VAE hash": "63aeecb90f",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "5709c2059c",
                        "name": "fcanimemixFcAnime_v50",
                        "type": "model"
                    }
                ],
                "Model hash": "5709c2059c",
                "Hires steps": "10",
                "Hires upscale": "2",
                "Hires upscaler": "4x-AnimeSharp",
                "negativePrompt": "(worst quality, low quality:1.4), fcNeg, text, watermark",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "23.11.1",
                "Denoising strength": "0.5",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "32",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True",
                "\"kamishiroalice-nvwls-v1-000009": "0d5f6f114f2b\""
            },
            "username": "novowels",
            "baseModel": "SD 1.5"
        },
        {
            "id": 5930170,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7263770a-edad-4bb1-97a7-348cccc2835c/width=1024/7263770a-edad-4bb1-97a7-348cccc2835c.jpeg",
            "hash": "U15##0IU00_NRoMyH;tQxARjx^ROD%ofxtIU",
            "width": 1024,
            "height": 1536,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-01-27T04:59:01.740Z",
            "postId": 1286547,
            "stats": {
                "cryCount": 4,
                "laughCount": 10,
                "likeCount": 92,
                "dislikeCount": 0,
                "heartCount": 63,
                "commentCount": 0
            },
            "meta": {
                "ENSD": "31337",
                "Size": "512x768",
                "seed": 2465312996,
                "Model": "wildcardxXL_v4Rundiffusion",
                "steps": 20,
                "hashes": {
                    "model": "1170aa1935",
                    "lora:Faceless_Cyborgs-000014": "c178bfd632"
                },
                "prompt": "Full figure,full body shot,18 years old,wearing transparent science fiction clothes,exquisite face,details,hands,ultimate details,breathtaking grandeur,LED internal lighting,cyberpunk style,fibre optic hair,glowing blue iris,<lora:Faceless_Cyborgs-000014:1>, NOFACE,CYBORG,",
                "Version": "v1.6.0-2-g4afaaf8a0",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "1170aa1935",
                        "name": "wildcardxXL_v4Rundiffusion",
                        "type": "model"
                    }
                ],
                "Model hash": "1170aa1935",
                "Hires upscale": "2",
                "Hires upscaler": "R-ESRGAN 4x+",
                "Denoising strength": "0.7",
                "\"Faceless_Cyborgs-000014": "bb54cf425f08\""
            },
            "username": "CHINGEL",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 5744130,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/21ac5189-a75d-4197-a921-1c85cfa3bb75/width=1384/21ac5189-a75d-4197-a921-1c85cfa3bb75.jpeg",
            "hash": "URF%0N8{IVxt?]IURRxtNGM|sqR+a^oJWFn,",
            "width": 1384,
            "height": 1072,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-01-22T00:12:45.607Z",
            "postId": 1249918,
            "stats": {
                "cryCount": 0,
                "laughCount": 4,
                "likeCount": 82,
                "dislikeCount": 0,
                "heartCount": 83,
                "commentCount": 2
            },
            "meta": {
                "prompt": "Cute realistic chubby fluffy mini panda, (tilt-shift:1.5), macro photography, (lush bamboo:1.2), (morning dew:1.3), playful, (tiny:1.4), tiny flowers, whimsical, miniature world, (fine fur details:1.1), soft focus, dreamy, (tranquil:1.2), nature-inspired, imaginative, serene, realistic"
            },
            "username": "NaomiVK",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 5276962,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/34c03c24-9877-4deb-9772-c4ea4f625b00/width=832/34c03c24-9877-4deb-9772-c4ea4f625b00.jpeg",
            "hash": "UYM6-V$*WFnh~Vj[IpWBw^Wrxaoe%0Ipxas:",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-01-08T06:11:44.101Z",
            "postId": 1152378,
            "stats": {
                "cryCount": 2,
                "laughCount": 58,
                "likeCount": 72,
                "dislikeCount": 0,
                "heartCount": 37,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2009963517,
                "steps": 30,
                "prompt": "ral-friedegg, The Scream by Edvard Munch",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "clipSkip": 1,
                "resources": [],
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 263609
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 288399
                    }
                ]
            },
            "username": "NobodyButMeow",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 5153949,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/13cbe856-d889-4e9d-b385-39125e820022/width=1024/13cbe856-d889-4e9d-b385-39125e820022.jpeg",
            "hash": "UVDl4c-6V[j=~9s+afn$-Qs+ofWBxro0j]R.",
            "width": 1024,
            "height": 1536,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-01-04T08:26:56.187Z",
            "postId": 1126960,
            "stats": {
                "cryCount": 0,
                "laughCount": 6,
                "likeCount": 114,
                "dislikeCount": 0,
                "heartCount": 49,
                "commentCount": 6
            },
            "meta": {
                "VAE": "vae-ft-mse-840000-ema-pruned.safetensors",
                "ENSD": "31337",
                "Size": "512x768",
                "seed": 613410242,
                "Model": "LSPrealistic_NSFW",
                "steps": 30,
                "hashes": {
                    "model": "83076108ad"
                },
                "prompt": "1girl,flower,plant,leaf,blue flower,<lora:\u00e9\u00ba\u00bb\u00e8\u00a2\u008b2024-002:0.7>,peacock,, masterpiece,best quality,ultra-detailed,",
                "Version": "v1.7.0",
                "sampler": "Euler a",
                "VAE hash": "63aeecb90f",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "83076108ad",
                        "name": "LSPrealistic_NSFW",
                        "type": "model"
                    }
                ],
                "Model hash": "83076108ad",
                "Hires upscale": "2",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "ng_deepnegative_v1_75t,badhandv4,(worst quality:1.5),(low quality:1.5),(normal quality:1.5),lowres,bad anatomy,bad hands,normal quality,((monochrome)),((grayscale)),EasyNegative,",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "23.11.1",
                "Denoising strength": "0.3",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "\"\u00e9\u00ba\u00bb\u00e8\u00a2\u008b2024-002": "b48d1636c5d1\"",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "woshimadai",
            "baseModel": null
        },
        {
            "id": 5033826,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ba40001b-062c-4b05-8650-9214c3959cd2/width=832/ba40001b-062c-4b05-8650-9214c3959cd2.jpeg",
            "hash": "UPH^9a$fXTIpw0IpxaWB|2I;WV$%wI$*oMWB",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2023-12-31T01:59:12.543Z",
            "postId": 1100328,
            "stats": {
                "cryCount": 0,
                "laughCount": 95,
                "likeCount": 50,
                "dislikeCount": 0,
                "heartCount": 24,
                "commentCount": 3
            },
            "meta": {
                "steps": 8,
                "prompt": "book cover of a vintage romance novel called \"Darth Vader the panty raider\"",
                "cfgScale": 2
            },
            "username": "WizardWhitebeard",
            "baseModel": null
        },
        {
            "id": 4985397,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3f74683c-ffc7-4c2e-98af-d5e1c67694c0/width=1800/3f74683c-ffc7-4c2e-98af-d5e1c67694c0.jpeg",
            "hash": "UTFF4?WB%LbI~VRk-ot7ENNGt7%1WYR+Ipt6",
            "width": 2160,
            "height": 1440,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-12-29T11:14:43.521Z",
            "postId": 1089265,
            "stats": {
                "cryCount": 6,
                "laughCount": 4,
                "likeCount": 83,
                "dislikeCount": 0,
                "heartCount": 76,
                "commentCount": 0
            },
            "meta": null,
            "username": "Yuki_Hotaru",
            "baseModel": ""
        },
        {
            "id": 4569400,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0cc003d6-48bc-47fc-b0f1-b1d1e719b8fe/width=896/0cc003d6-48bc-47fc-b0f1-b1d1e719b8fe.jpeg",
            "hash": "U6E_gj000LTGBq=w10$%0M?H={9Zi%ACVY~V",
            "width": 896,
            "height": 1344,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-12-14T06:55:05.707Z",
            "postId": 997153,
            "stats": {
                "cryCount": 16,
                "laughCount": 60,
                "likeCount": 53,
                "dislikeCount": 0,
                "heartCount": 41,
                "commentCount": 2
            },
            "meta": {
                "Size": "104x112",
                "seed": 1396699234,
                "Model": "meinamix_meinaV11",
                "steps": 20,
                "hashes": {
                    "model": "54ef3e3610",
                    "embed:badhandv4": "5e40d722fc",
                    "embed:Negfeet-neg": "b08c449185",
                    "embed:easynegative": "c74b4e810b",
                    "lora:bocchi_gotoh-17": "55cf256cb7",
                    "lora:scaredExpression_v157": "5736a8fa47",
                    "lora:yomama_fighter_jet_pilot_selfie_v2-10": "3920a1166c"
                },
                "prompt": "<lora:yomama_fighter_jet_pilot_selfie_v2-10:0.8>yomama_fighter_jet_pilot_selfie_v2, 1girl, ((young girl)),teenage,  small girl, <lora:bocchi_gotoh-17:0.8> gotohdef, one side up, cube hair ornament, pink jacket, track jacket, long sleeves,  long pink hair,  <lora:scaredExpression_v157:0.6> scared expression, clenched teeth, open mouth",
                "Version": "v1.6.0",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "Mask blur": "10",
                "resources": [
                    {
                        "name": "scaredExpression_v157",
                        "type": "lora",
                        "weight": 0.6
                    },
                    {
                        "hash": "54ef3e3610",
                        "name": "meinamix_meinaV11",
                        "type": "model"
                    }
                ],
                "\"badhandv4": "5e40d722fc3d",
                "Model hash": "54ef3e3610",
                "Negfeet-neg": "b08c449185b4\"",
                "easynegative": "c74b4e810b03",
                "negativePrompt": "(worst quality, low quality:1.4), badhandv4, easynegative,  (NEGFEET-NEG:1.5) watermark, logo, helmet, gas mask, pipe, eye shield",
                "bocchi_gotoh-17": "e557f26aa5a8",
                "Denoising strength": "0.03",
                "scaredExpression_v157": "118afcb8a7ab\"",
                "\"yomama_fighter_jet_pilot_selfie_v2-10": "43a706e5a7c5"
            },
            "username": "yomama123556778",
            "baseModel": "SD 1.5"
        },
        {
            "id": 4140650,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c0159c89-e700-4614-9e9f-f626e575f1ff/width=1440/c0159c89-e700-4614-9e9f-f626e575f1ff.jpeg",
            "hash": "U5AdiV.t}Hxv80%WzGIJ1Txu03DlGgM+yfmT",
            "width": 1440,
            "height": 2560,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-24T06:32:03.881Z",
            "postId": 921808,
            "stats": {
                "cryCount": 15,
                "laughCount": 12,
                "likeCount": 88,
                "dislikeCount": 0,
                "heartCount": 54,
                "commentCount": 1
            },
            "meta": {
                "Size": "576x1024",
                "seed": 2489395972,
                "Model": "V10 Turbo Edition",
                "steps": 15,
                "hashes": {
                    "model": "6d5732c731"
                },
                "prompt": "oniric portrait of a tall cloaked figure with a purple mask and green neon clothing, Azem the Traveler, yearning to explore the ends of the world to discover its wonders and help its denizens, by Andy Kehoe, a gradient masterpiece, blue cyan yellow, Rococopunk, luminism, seamless, China ink, Ink Bubbles, Gold leaf lines, alcohol ink elements, curved lines, cinematic, realism, chiaroscuro, Shadow play, Gold leaf small lines, bright splashes of alcohol ink puddles, volumetric light, auras, rays of sunlight, bright colors reflect, isometric, digital art, smog, pollution, toxic waste, chimneys and railroads, 3d render, chromatic aberration, octane render, volumetrics, by greg rutkowski",
                "Version": "1.5.1",
                "sampler": "Euler a",
                "cfgScale": 5,
                "resources": [
                    {
                        "hash": "6d5732c731",
                        "name": "V10 Turbo Edition",
                        "type": "model"
                    }
                ],
                "Model hash": "6d5732c731",
                "Hires steps": "25",
                "Hires upscale": "2.5",
                "Hires upscaler": "4x_foolhardy_Remacri",
                "negativePrompt": "bad quality, bad anatomy, worst quality, low quality, low resolution, extra fingers, blur, blurry, ugly, wrong proportions, watermark, image artifacts, lowres, ugly, jpeg artifacts, deformed, noisy image",
                "Denoising strength": "0.25"
            },
            "username": "Yamer",
            "baseModel": "SDXL Turbo"
        },
        {
            "id": 3670735,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/47efd60c-3c11-425f-8988-feb671f2d34a/width=600/47efd60c-3c11-425f-8988-feb671f2d34a.jpeg",
            "hash": "UIEfD;t69Fxa_MbHRij?~pof4ooexuoyD*M|",
            "width": 600,
            "height": 904,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-11-16T17:02:54.558Z",
            "postId": 830731,
            "stats": {
                "cryCount": 0,
                "laughCount": 57,
                "likeCount": 72,
                "dislikeCount": 0,
                "heartCount": 40,
                "commentCount": 0
            },
            "meta": {
                "VAE": "sdxl_vae.safetensors",
                "Size": "600x904",
                "seed": 2244636216,
                "Model": "RealitiesEdgeXL_5",
                "steps": 20,
                "hashes": {
                    "model": "0364819244"
                },
                "prompt": "((\"Cat Lord of the Rings\" (text logo:1.8))) <lora:Harrlogos_v2.0:1.8>, (full body), (((fat cats))), (screensaver for the movie \"The Lord of the Rings\", fat cats, fat cats in the costumes of the movie The Lord of the Rings), predominant green and gold and white color, hyper-detailed, hyper-realism, sharp shot, cinematic, background action-packed,  <lora:xl_more_art-full_v1:1>,",
                "Version": "1.6.1",
                "sampler": "DPM++ 3M SDE Karras",
                "VAE hash": "235745af8d",
                "cfgScale": 3,
                "resources": [
                    {
                        "name": "Harrlogos_v2.0",
                        "type": "lora",
                        "weight": 1.8
                    },
                    {
                        "hash": "0364819244",
                        "name": "RealitiesEdgeXL_5",
                        "type": "model"
                    }
                ],
                "Model hash": "0364819244",
                "\"Harrlogos_v2.0": "911cff375341",
                "xl_more_art-full_v1": "fe3b4816be83\""
            },
            "username": "Svetlyi",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 2510163,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/85f416f8-c5ab-4556-8d57-16e0158c0f41/width=1440/85f416f8-c5ab-4556-8d57-16e0158c0f41.jpeg",
            "hash": "UUKBO400?v~qxrIURQRiIox]t7RjoIkDj]oe",
            "width": 1440,
            "height": 1920,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-09-15T10:38:01.550Z",
            "postId": 598493,
            "stats": {
                "cryCount": 0,
                "laughCount": 2,
                "likeCount": 78,
                "dislikeCount": 0,
                "heartCount": 89,
                "commentCount": 1
            },
            "meta": null,
            "username": "Yuki_Hotaru",
            "baseModel": ""
        },
        {
            "id": 2087752,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0fd8c767-504d-489e-a145-dafa1976055f/width=1024/0fd8c767-504d-489e-a145-dafa1976055f.jpeg",
            "hash": "ULC~k;xa#mx]uit6WBtR?uoJEMo}={jFwJtQ",
            "width": 1024,
            "height": 1280,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-14T00:01:38.679Z",
            "postId": 512533,
            "stats": {
                "cryCount": 1,
                "laughCount": 68,
                "likeCount": 72,
                "dislikeCount": 0,
                "heartCount": 28,
                "commentCount": 5
            },
            "meta": {
                "VAE": "dreamshaperXL10_alpha2Xl10_vae.safetensors",
                "Size": "1024x1280",
                "seed": 2116430269,
                "Model": "RealitiesEdgeXL_",
                "steps": 35,
                "hashes": {
                    "model": "ac64085ddf"
                },
                "prompt": "fantasy illustration,anime,art by Tsutomu Nihei,manga,oil paint,thomas the train in hell,beksinski",
                "Version": "v1.5.1-495-g541ef924",
                "sampler": "DPM++ 2M SDE Heun Karras",
                "VAE hash": "b3165c12ca",
                "cfgScale": 10,
                "resources": [
                    {
                        "hash": "ac64085ddf",
                        "name": "RealitiesEdgeXL_",
                        "type": "model"
                    }
                ],
                "Model hash": "ac64085ddf",
                "Color Enhance": "1",
                "Token merging ratio": "0.2"
            },
            "username": "succupon",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 2000936,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bcd01a3c-5aa6-48a6-a5f7-3e5efa1fdd30/width=512/bcd01a3c-5aa6-48a6-a5f7-3e5efa1fdd30.jpeg",
            "hash": "UE9*4XE2Hq}_z~tlI,rvDNMwT^I-NWSvnUbb",
            "width": 512,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-13T11:01:13.999Z",
            "postId": 492272,
            "stats": {
                "cryCount": 1,
                "laughCount": 4,
                "likeCount": 119,
                "dislikeCount": 0,
                "heartCount": 45,
                "commentCount": 0
            },
            "meta": {
                "NGMS": "2",
                "Size": "512x768",
                "seed": 3148533280,
                "Model": "sd_xl_base_1.0",
                "steps": 15,
                "hashes": {
                    "model": "31e35c80fc"
                },
                "prompt": "<lora:PE_SpectralStyle:1> PESpectral,glow,\nportrait of cat",
                "Version": "v1.5.1",
                "sampler": "Euler",
                "cfgScale": 7,
                "resources": [
                    {
                        "name": "PE_SpectralStyle",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "31e35c80fc",
                        "name": "sd_xl_base_1.0",
                        "type": "model"
                    }
                ],
                "Model hash": "31e35c80fc",
                "\"PE_SpectralStyle": "ed5fd65d12dc\"",
                "Token merging ratio": "0.5"
            },
            "username": "Proompt_Engineer",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 2000933,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c2a842eb-7a7b-48d1-b0e2-ed21167b5c7f/width=512/c2a842eb-7a7b-48d1-b0e2-ed21167b5c7f.jpeg",
            "hash": "U56+|x8jv2*QV[qvQRl98wx1SgKaI8XLIRm@",
            "width": 512,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-13T23:34:50.690Z",
            "postId": 492272,
            "stats": {
                "cryCount": 1,
                "laughCount": 7,
                "likeCount": 152,
                "dislikeCount": 0,
                "heartCount": 9,
                "commentCount": 0
            },
            "meta": {
                "NGMS": "2",
                "Size": "512x768",
                "seed": 2894600001,
                "Model": "sd_xl_base_1.0",
                "steps": 15,
                "hashes": {
                    "model": "31e35c80fc"
                },
                "prompt": "<lora:PE_SpectralStyle:1> PESpectral,glow,neon,sci-fi,future\nmage,robe,casting a spell,arcane,lightning,hooded",
                "Version": "v1.5.1",
                "sampler": "Euler",
                "cfgScale": 7,
                "resources": [
                    {
                        "name": "PE_SpectralStyle",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "31e35c80fc",
                        "name": "sd_xl_base_1.0",
                        "type": "model"
                    }
                ],
                "Model hash": "31e35c80fc",
                "\"PE_SpectralStyle": "ed5fd65d12dc\"",
                "Token merging ratio": "0.5"
            },
            "username": "Proompt_Engineer",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 1942120,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/def05645-afa3-4085-a85a-06e67439f6cf/width=1024/def05645-afa3-4085-a85a-06e67439f6cf.jpeg",
            "hash": "URHeF6-o4.Ip$%xu-;ae%1oe%M-p~WWBRj%M",
            "width": 1024,
            "height": 1536,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-02-13T23:46:23.602Z",
            "postId": 477585,
            "stats": {
                "cryCount": 1,
                "laughCount": 6,
                "likeCount": 57,
                "dislikeCount": 0,
                "heartCount": 105,
                "commentCount": 0
            },
            "meta": {
                "ENSD": "31337",
                "Size": "512x768",
                "seed": 2547494008,
                "Model": "hassakuHentaiModel_v13",
                "steps": 20,
                "hashes": {
                    "vae": "15e96204c9",
                    "model": "7eb674963a"
                },
                "prompt": "<lora:ass_support_object_v0.2:1.5>\n1girl, ass support, baseball bat, baseball uniform, holding baseball bat,, masterpiece, best quality, highly detailed",
                "Version": "v1.3.2",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "ass_support_object_v0.2",
                        "type": "lora",
                        "weight": 1.5
                    },
                    {
                        "hash": "7eb674963a",
                        "name": "hassakuHentaiModel_v13",
                        "type": "model"
                    }
                ],
                "Model hash": "7eb674963a",
                "Hires upscale": "2",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "(worst quality, low quality:1.4)",
                "Denoising strength": "0.3",
                "\"ass_support_object_v0.2": "3831a0c2c80b\""
            },
            "username": "psoft",
            "baseModel": "SD 1.5"
        },
        {
            "id": 1775940,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bba0db5d-7d4a-4ea4-833e-b49c52739470/width=1024/bba0db5d-7d4a-4ea4-833e-b49c52739470.jpeg",
            "hash": "UXFh3OkCsnxG~Us:$*WV-obbxuaex[f6bvju",
            "width": 1024,
            "height": 1536,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-10T16:19:55.110Z",
            "postId": 441885,
            "stats": {
                "cryCount": 1,
                "laughCount": 10,
                "likeCount": 78,
                "dislikeCount": 0,
                "heartCount": 80,
                "commentCount": 1
            },
            "meta": {
                "Size": "512x768",
                "seed": 2939616757,
                "Model": "meinamix_meinaV11",
                "steps": 20,
                "hashes": {
                    "model": "54ef3e3610"
                },
                "prompt": "(best quality, masterpiece:1.3),  (illustration:1.15), (abstract, zentangle, psychedelic:1.2), [(a beautiful girl, face, neck, slim waist, legs:0.08) | | a beautiful rose, stem, thorns, roots:1.69] art  by Georgia O'Keeffe's, trending on devianart,  ambiguity, mystery, red color palate",
                "Version": "v1.5.1",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 6,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "54ef3e3610",
                        "name": "meinamix_meinaV11",
                        "type": "model"
                    }
                ],
                "\"badhandv4": "5e40d722fc3d",
                "Model hash": "54ef3e3610",
                "Hires steps": "20",
                "Hires upscale": "2",
                "Hires upscaler": "4x_fatal_Anime_500000_G",
                "negativePrompt": "(worst quality, low quality:2),  badhandv4,  By bad artist -neg, NSFW, (TEXT:1.4), (large breasts, thick thighs:1.3),",
                "By bad artist -neg": "2d356134903e\"",
                "Denoising strength": "0.6",
                "Token merging ratio": "0.7",
                "Token merging ratio hr": "0.7"
            },
            "username": "darkknessmatter",
            "baseModel": "SD 1.5SD 1.5"
        },
        {
            "id": 1565561,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/30fe5f27-3ad7-4a6e-8590-e201cdfe03e3/width=1536/30fe5f27-3ad7-4a6e-8590-e201cdfe03e3.jpeg",
            "hash": "U89RhC?^4TMxY7%#ngDiIoM|iwxC8{R5xutR",
            "width": 1536,
            "height": 1980,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-07-17T09:57:15.928Z",
            "postId": 396119,
            "stats": {
                "cryCount": 0,
                "laughCount": 11,
                "likeCount": 79,
                "dislikeCount": 0,
                "heartCount": 79,
                "commentCount": 7
            },
            "meta": null,
            "username": "Redpriest9527",
            "baseModel": "SD 1.5"
        },
        {
            "id": 1499576,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d715c0b4-7651-4c08-a0aa-cd76cbfbe2cc/width=1176/d715c0b4-7651-4c08-a0aa-cd76cbfbe2cc.jpeg",
            "hash": "UlKw;2Rkf*xu_Nj]t7ay%Na}j]RP%NofM_ae",
            "width": 1176,
            "height": 1760,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-11T21:13:04.984Z",
            "postId": 381495,
            "stats": {
                "cryCount": 0,
                "laughCount": 122,
                "likeCount": 35,
                "dislikeCount": 0,
                "heartCount": 12,
                "commentCount": 0
            },
            "meta": {
                "Size": "512x768",
                "seed": 3759926659,
                "Model": "epicrealism_pureEvolutionV3",
                "steps": 40,
                "hashes": {
                    "model": "52484e6845"
                },
                "prompt": "a man (jimkong) wearing (sunglases) sprinkling salt (SaltBaeMeme:1.2) onto a (cute puppy on a dish) outdoor. (backdrop of rockets and missles firing:1.3).\n <lyco:KimJongUnDogu:0.69>, <lora:SaltBaeMeme:0.9>",
                "Version": "v1.4.0",
                "sampler": "DPM++ SDE Karras",
                "cfgScale": 5,
                "resources": [
                    {
                        "name": "SaltBaeMeme",
                        "type": "lora",
                        "weight": 0.9
                    },
                    {
                        "hash": "52484e6845",
                        "name": "epicrealism_pureEvolutionV3",
                        "type": "model"
                    }
                ],
                "Model hash": "52484e6845",
                "\"SaltBaeMeme": "479e57982aaf\"",
                "Hires upscale": "2.3",
                "Hires upscaler": "4x_NMKD-Siax_200k",
                "negativePrompt": "BadDream UnrealisticDream,",
                "Denoising strength": "0.3"
            },
            "username": "futurafree",
            "baseModel": "SD 1.5"
        },
        {
            "id": 1340260,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8072532e-5c15-4bf1-bdc4-3c23d85ee421/width=864/8072532e-5c15-4bf1-bdc4-3c23d85ee421.jpeg",
            "hash": "UQHKnc~C5kAY?^x]$*=xV[xa%MS#9GM{t7WX",
            "width": 864,
            "height": 1192,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-02-10T09:05:38.655Z",
            "postId": 346039,
            "stats": {
                "cryCount": 3,
                "laughCount": 15,
                "likeCount": 73,
                "dislikeCount": 0,
                "heartCount": 78,
                "commentCount": 0
            },
            "meta": {
                "ENSD": "31337",
                "Size": "512x704",
                "seed": 3441877735,
                "Model": "hassakuV1_3",
                "steps": 20,
                "hashes": {
                    "model": "7eb674963a"
                },
                "prompt": "1girl, yellow eyes, long hair, white hair, sitting, red kimono, large breasts, light smile, arms behind back, hair ornament, animal ears, car,",
                "Version": "## 1.4.0",
                "sampler": "Euler a",
                "cfgScale": 7,
                "Clip skip": 2,
                "resources": [
                    {
                        "hash": "7eb674963a",
                        "name": "hassakuV1_3",
                        "type": "model"
                    }
                ],
                "Model hash": "7eb674963a",
                "Hires steps": "20",
                "Hires upscale": "1.7",
                "Hires upscaler": "Latent (nearest-exact)",
                "negativePrompt": "(worst quality, low quality:1.4), signature,",
                "Denoising strength": "0.55"
            },
            "username": "Ikena",
            "baseModel": "SD 1.5"
        },
        {
            "id": 894076,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/77a4af0e-1da3-4732-869a-97d8028db751/width=1800/77a4af0e-1da3-4732-869a-97d8028db751.jpeg",
            "hash": "UMF62uxaWBxa*0tQW;R+yXNHjZt6cGn$s:bF",
            "width": 2048,
            "height": 3584,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-05-24T10:07:51.879Z",
            "postId": 238758,
            "stats": {
                "cryCount": 0,
                "laughCount": 2,
                "likeCount": 95,
                "dislikeCount": 0,
                "heartCount": 72,
                "commentCount": 3
            },
            "meta": null,
            "username": "Junnnnnn",
            "baseModel": "SD 1.5"
        },
        {
            "id": 822960,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1603c524-ab99-4b25-88f4-824e661a02e2/width=512/1603c524-ab99-4b25-88f4-824e661a02e2.jpeg",
            "hash": "UTH_AP0es:xu=}V?WCWB~WV?R*WUNKaxRjfl",
            "width": 512,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-05-18T02:32:59.367Z",
            "postId": 221861,
            "stats": {
                "cryCount": 0,
                "laughCount": 102,
                "likeCount": 66,
                "dislikeCount": 0,
                "heartCount": 1,
                "commentCount": 3
            },
            "meta": {
                "ENSD": "31337",
                "Size": "512x768",
                "seed": 582871019,
                "Model": "perfect world",
                "steps": 25,
                "hashes": {
                    "model": "0f49d1caa2"
                },
                "prompt": "1boy, basketball,  <lora:DingZhenLora_v1:1>,detailed_face,8k, indoors,photorealistic,looking at viewer,white belt,",
                "sampler": "DPM++ SDE Karras",
                "cfgScale": 7,
                "Clip skip": "2",
                "Mask blur": "4",
                "resources": [
                    {
                        "name": "DingZhenLora_v1",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "0f49d1caa2",
                        "name": "perfect world",
                        "type": "model"
                    }
                ],
                "Model hash": "0f49d1caa2",
                "negativePrompt": "(worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, skin spots, acnes, skin blemishes, age spot, glans, (watermark:2),",
                "Denoising strength": "0.9"
            },
            "username": "chronicAI",
            "baseModel": "Other"
        },
        {
            "id": 741816,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/76027779-7a48-4578-8c0d-02aa93a22b2e/width=1024/76027779-7a48-4578-8c0d-02aa93a22b2e.jpeg",
            "hash": "UGC?o$00%Lt7~pD%Rjxa?aD*oea}-;RjRjWX",
            "width": 1024,
            "height": 1536,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-09T05:48:33.435Z",
            "postId": 201925,
            "stats": {
                "cryCount": 0,
                "laughCount": 1,
                "likeCount": 95,
                "dislikeCount": 0,
                "heartCount": 73,
                "commentCount": 0
            },
            "meta": {
                "Size": "512x768",
                "seed": 2958810892,
                "Model": "rpg_V4",
                "steps": 30,
                "hashes": {
                    "vae": "95f26a5ab0",
                    "model": "e04b020012",
                    "lora:mshn": "aa0f66b8e9",
                    "hypernet:dr0ne": "24bfd767b7",
                    "embed:bad-artist": "2d35613490",
                    "lora:epiNoiseoffset": "81680c064e",
                    "embed:badhandsv5-neg": "aa7651be15",
                    "lora:hipoly3DModelLora": "3be24d2e6d",
                    "hypernet:LuisapSciFiHard": "5086c49dcd",
                    "lora:cyberhelmetWearable": "11eb8dde45",
                    "lora:urbanSamuraiClothing": "c7150ad13f",
                    "embed:bad-picture-chill-32v": "6705729fb3",
                    "embed:bad-picture-chill-75v": "7d9cc5f549",
                    "embed:bad_prompt_version2-neg": "6f35e7dd81"
                },
                "prompt": "((best quality)), ((masterpiece:1.2)), (8k, high quality, cinematic, hyper realistic, illustration), (autodesk maya, vray render, ray tracing, hdr), (DSLR, full frame, 16mm focal length, f/4 aperture, dynamic perspective, deep depth of field), (A black and gold, humanoid bounty hunter, clad in a reinforced exoskeleton and adaptive techwear, stalking their prey through the dark, neon-lit alleyways of a cyberpunk city), <lora:mshn:0.35> (mshn robot:0.55, mshn:0.25), <hypernet:dr0ne:0.55> (subdivision, cyber muscle, angular design, mechanical, carbon-fiber, high-tech, pistons, robotic frame, metal joints, rubber cables), <hypernet:LuisapSciFiHard:0.25> (scifi, hard surface, armor, metal bolts, robotic, industrial, structures, sub-d), <lora:urbanSamuraiClothing:0.25> (urbansamurai, techwear), <lora:hipoly3DModelLora:0.25> (CGI, 3D, realistic), <lora:epiNoiseoffset:0.5> (bloom, rim lighting, studio lighting, soft lighting, low key),  <lora:cyberhelmetWearable:0.5> (cyberhelmet:0.25, glowing robotic eyes, full of battlegear)",
                "sampler": "Euler a",
                "cfgScale": 5,
                "Clip skip": "2",
                "resources": [
                    {
                        "name": "mshn",
                        "type": "lora",
                        "weight": 0.35
                    },
                    {
                        "name": "dr0ne",
                        "type": "hypernet",
                        "weight": 0.55
                    },
                    {
                        "name": "LuisapSciFiHard",
                        "type": "hypernet",
                        "weight": 0.25
                    },
                    {
                        "name": "urbanSamuraiClothing",
                        "type": "lora",
                        "weight": 0.25
                    },
                    {
                        "name": "hipoly3DModelLora",
                        "type": "lora",
                        "weight": 0.25
                    },
                    {
                        "name": "epiNoiseoffset",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "name": "cyberhelmetWearable",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "hash": "e04b020012",
                        "name": "rpg_V4",
                        "type": "model"
                    }
                ],
                "Model hash": "e04b020012",
                "Hires steps": "15",
                "Hires upscale": "2",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "(low quality, worst quality:1.4), [bad-picture-chill-75v:bad-picture-chill-32v:0.5], (bad_prompt_version2-neg:0.75), ((render by bad-artist:0.5)), 3D, CGI, realistic, ((mask)), (EasyNegative:0.5), ((badhandsv5-neg:0.8)), imperfect bolts, imperfect circle, bad anatomy:0.8, detailed",
                "Face restoration": "CodeFormer",
                "Denoising strength": "0.5"
            },
            "username": "realitylvn",
            "baseModel": "SD 1.5"
        },
        {
            "id": 41555241,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/24174872-9a47-4b39-9c81-b9b0bb0d4a83/width=1412/24174872-9a47-4b39-9c81-b9b0bb0d4a83.jpeg",
            "hash": "ULIM]B-Uo#^j%j-U-Vxb0Nn,R-EO-Vj^IpIp",
            "width": 1412,
            "height": 2064,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-11-23T01:05:00.000Z",
            "postId": 9462123,
            "stats": {
                "cryCount": 2,
                "laughCount": 15,
                "likeCount": 107,
                "dislikeCount": 0,
                "heartCount": 44,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 203246043042289,
                "Model": "prefectPonyXL_v40",
                "steps": 50,
                "hashes": {
                    "model": "95ded7d685",
                    "LORA:add-detail-xl": "0d9bd1b873",
                    "LORA:princess_xl_v2": "80aa67913a"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, Masterpiece, beautiful, perfect eyes, perfect face, sexy, Violet Parr (Incredibles, medium teardrop breasts, long black hair, dark purple eyes, purple crop top, petite body, sunglasses on head, pleated skirt, winking, smiling), sitting on bench, legs crossed, face focus, upskirt, looking at viewer, boardwalk, sunset, beautiful cinematic lighting, volumetric lighting, dramatic lighting, low angle view, view from below <lora:add-detail-xl:1.0.7> <lora:princess_xl_v2:1>",
                "Version": "ComfyUI",
                "sampler": "DPM++ 2M SDE Karras",
                "cfgScale": 5,
                "resources": [
                    {
                        "name": "add-detail-xl",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "name": "princess_xl_v2",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "95ded7d685",
                        "name": "prefectPonyXL_v40",
                        "type": "model"
                    }
                ],
                "Model hash": "95ded7d685",
                "negativePrompt": "score_6, score_5, score_4, easynegative, distorted face, distorted eyes, ugly face, low res, blurry face, black and white, muscular female, flat chested, (out of frame), disembodied hand, extra limbs, watermark, signature, patreon username, web address, artist name, compression artifacts <easynegative>"
            },
            "username": "Sutekh",
            "baseModel": "Pony"
        },
        {
            "id": 41505707,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f297ddfd-4e88-4b30-806b-ff7b3458fabc/width=1216/f297ddfd-4e88-4b30-806b-ff7b3458fabc.jpeg",
            "hash": "U9CPCftQ00a05jsl-VxuIUw{%LS}.mo|DOMx",
            "width": 1216,
            "height": 832,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-22T16:38:44.439Z",
            "postId": 9451691,
            "stats": {
                "cryCount": 5,
                "laughCount": 12,
                "likeCount": 112,
                "dislikeCount": 0,
                "heartCount": 39,
                "commentCount": 0
            },
            "meta": {
                "Size": "1216x832",
                "nsfw": true,
                "seed": 1875820254,
                "draft": false,
                "steps": 25,
                "width": 1216,
                "height": 832,
                "prompt": "grandma sat on a chair,blanket, holding a sign say \"need some buzz\"",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "fluxMode": "urn:air:flux1:checkpoint:civitai:618692@691639",
                "quantity": 2,
                "workflow": "txt2img",
                "baseModel": "Flux1",
                "resources": [],
                "Created Date": "2024-11-22T1638:19.5662840Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    }
                ]
            },
            "username": "cenat",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 41248604,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc6af4c9-3d3b-4e30-9dde-dccb317edf29/width=1248/cc6af4c9-3d3b-4e30-9dde-dccb317edf29.jpeg",
            "hash": "UOEV:ENGkDxv?dR-NfNHI@RjNHxa59jFj]j?",
            "width": 1248,
            "height": 1872,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-21T03:52:09.881Z",
            "postId": 9394160,
            "stats": {
                "cryCount": 0,
                "laughCount": 5,
                "likeCount": 127,
                "dislikeCount": 0,
                "heartCount": 36,
                "commentCount": 0
            },
            "meta": {
                "RNG": "CPU",
                "VAE": "sdxl_vae.safetensors",
                "Size": "832x1248",
                "seed": 3800161750,
                "Model": "hosekiLustrousmix_illustriousV1",
                "steps": 24,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "35c7d75822",
                    "lora:felucina-illu-nvwls-v1-000005": "003c4b5a63dc"
                },
                "prompt": "masterpiece, best quality, 1girl, solo,  <lora:felucina-illu-nvwls-v1-000005:1> dfLuc, long hair, tiara, cape, shoulder armor, blue tunic, long sleeves, cuffs, blue scarf, fingerless gloves, belt, looking at viewer, smile, blush, clenched hand, hand on own chest, blue sky, clouds, mountains, sunset, upper body, portrait",
                "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
                "sampler": "Euler a",
                "Emphasis": "No norm",
                "cfgScale": 6,
                "resources": [
                    {
                        "hash": "003c4b5a63dc",
                        "name": "felucina-illu-nvwls-v1-000005",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "35c7d75822",
                        "name": "hosekiLustrousmix_illustriousV1",
                        "type": "model"
                    }
                ],
                "Model hash": "35c7d75822",
                "Hires steps": "10",
                "Hires upscale": "1.5",
                "Schedule type": "Automatic",
                "Hires upscaler": "4x-AnimeSharp",
                "negativePrompt": "(lowres:1.2), (worst quality:1.4), (low quality:1.4), (bad anatomy:1.4), bad hands, multiple views, comic, jpeg artifacts, patreon logo, patreon username, web address, signature, watermark, text, logo, artist name, censored",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.4.2",
                "Denoising strength": "0.4",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "novowels",
            "baseModel": "Illustrious"
        },
        {
            "id": 41205927,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0966b75d-9acd-4dfc-b7ff-61c42cb38c0b/width=1248/0966b75d-9acd-4dfc-b7ff-61c42cb38c0b.jpeg",
            "hash": "UeLX77?b_Nozxts:-;M{kqaysTjZjsbHV[jZ",
            "width": 1248,
            "height": 1824,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-20T22:48:43.435Z",
            "postId": 9384781,
            "stats": {
                "cryCount": 0,
                "laughCount": 0,
                "likeCount": 137,
                "dislikeCount": 0,
                "heartCount": 31,
                "commentCount": 0
            },
            "meta": {
                "VAE": "sdxl_vae.safetensors",
                "ENSD": "31337",
                "Size": "832x1216",
                "seed": 459725442,
                "Model": "NoobKonanMix",
                "steps": 25,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "5b3bb776af",
                    "lora:FlipherrNoobLocon_byKonan": "1d6fb2068b25",
                    "lora:ShadowHeartIllustrious_byKonan": "a2fa0a2eaa52"
                },
                "prompt": "best quality, amazing quality, very aesthetic, absurdres,\nBREAK\n1girl, solo, shadowheart, black hair, braided ponytail, green eyes, scar on face, circlet, armor, large breasts,\nsmile, looking at viewer, upper body, simple background, white background, <lora:ShadowHeartIllustrious_byKonan:1>,   <lora:FlipherrNoobLocon_byKonan:1>",
                "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "Mask blur": "4",
                "resources": [
                    {
                        "hash": "a2fa0a2eaa52",
                        "name": "ShadowHeartIllustrious_byKonan",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "1d6fb2068b25",
                        "name": "FlipherrNoobLocon_byKonan",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "5b3bb776af",
                        "name": "NoobKonanMix",
                        "type": "model"
                    }
                ],
                "Model hash": "5b3bb776af",
                "Inpaint area": "Only masked",
                "Hires upscale": "1.5",
                "Hires upscaler": "4x-AnimeSharp",
                "negativePrompt": "worst quality, low quality, jpeg artifacts, sketch, monochrome, bad anatomy, bad hands, multiple views, 4koma, watermark, censored",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.3.2",
                "Denoising strength": "0.4",
                "ADetailer mask blur": "4",
                "Masked area padding": "32",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "Konan",
            "baseModel": "Illustrious"
        },
        {
            "id": 40967578,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/aa73bdee-5651-4a21-ac7f-b37d6f8315d0/width=832/aa73bdee-5651-4a21-ac7f-b37d6f8315d0.jpeg",
            "hash": "UGJ7dS~D8_^MXkR7RPxCD*WnXSIrrpEN?Hxa",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-19T15:29:50.927Z",
            "postId": 9333215,
            "stats": {
                "cryCount": 13,
                "laughCount": 18,
                "likeCount": 99,
                "dislikeCount": 0,
                "heartCount": 38,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "nsfw": false,
                "seed": 1304397941,
                "draft": false,
                "steps": 17,
                "width": 832,
                "height": 1216,
                "prompt": "Create a vibrant, impressionistic painting that captures a picturesque scene of a sunlit balcony . In the foreground, a wooden chair with a wicker seat is visible on the left. The chair is adorned with a patterned cushion in shades of brown and beige. In the center of the painting, a small, round wooden table sits with a bright orange vase holding a bouquet of pink flowers.The background shows a lush, tropical scene through an open window. The window frames are painted a soft shade of pink, with green shutters partially open to let sunlight in. Behind the window stands a bright green palm tree, its leaves gently swaying in the breeze. The foliage outside the window is a mix of green and yellow, with hints of blue and white on the distant horizon, reminiscent of a coastal or island setting.On the right, a large, leafy green plant in a pot sits on the floor, adding to the tropical atmosphere. The overall color palette is dominated by warm tones, with soft pink, green and orange tones that create a cheerful and inviting atmosphere, masterpiece, award winning,",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 3,
                "clipSkip": 2,
                "quantity": 1,
                "workflow": "txt2img",
                "baseModel": "SDXL",
                "resources": [],
                "Created Date": "2024-11-19T0924:25.2706525Z",
                "negativePrompt": "blurry, bad anatomy, watermark, signature, cut off, draft, text, logo, deformed,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 345685,
                        "modelVersionName": "FUSION OG"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Lady_Luminous",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 40631839,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cdd7c85e-a4b6-4c11-80f6-a9ac300e52ba/width=1024/cdd7c85e-a4b6-4c11-80f6-a9ac300e52ba.jpeg",
            "hash": "UVGb9m_Nu5xv%ztR$*t7IUV@i_X8M{M{NGt7",
            "width": 1024,
            "height": 1024,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-17T15:49:00.000Z",
            "postId": 9257355,
            "stats": {
                "cryCount": 4,
                "laughCount": 19,
                "likeCount": 122,
                "dislikeCount": 0,
                "heartCount": 23,
                "commentCount": 0
            },
            "meta": {
                "Size": "1024x1024",
                "nsfw": true,
                "seed": 1939841534,
                "draft": false,
                "steps": 4,
                "width": 1024,
                "height": 1024,
                "prompt": "Masterpiece, 32k, photo realistic, semi side view, beautiful European woman, 29 years old with perfect big brown eyes, looks happy, sits at her desk, looking at viewer,  she wears a golden necklaces, Christmas sweater,  jeans, brown knee high boots, makeup, and jewelry. She is a natural beauty with a our glass figure and is very attractive and sexy. A few of her beauty features are red lips, toned body, seductive smile, cute face. She has blond wavy hair. Her sexy contour is clearly visible. She is looking at viewer and is sitting at her desk, full with piles of paperwork. A speak bubble above her head that says \"I need 700 BUZZ extra to move\".",
                "sampler": "Undefined",
                "cfgScale": 1,
                "clipSkip": 2,
                "fluxMode": "urn:air:flux1:checkpoint:civitai:618692@699279",
                "quantity": 4,
                "workflow": "txt2img",
                "baseModel": "Flux1",
                "resources": [],
                "Created Date": "2024-11-17T1542:35.5286560Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 699279,
                        "modelVersionName": "Schnell"
                    }
                ]
            },
            "username": "ALTE3344",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 40231447,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8ac2888f-d76a-4039-a3c4-ec7257f61201/width=832/8ac2888f-d76a-4039-a3c4-ec7257f61201.jpeg",
            "hash": "UIIEtubcJVWBROIAkrRP.T%2%1xuaytRR4tR",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-15T09:20:47.754Z",
            "postId": 9169437,
            "stats": {
                "cryCount": 10,
                "laughCount": 30,
                "likeCount": 92,
                "dislikeCount": 0,
                "heartCount": 36,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 237382599,
                "steps": 22,
                "prompt": "buzz, Gym, fit blonde woman, pleading look, holding an empty dinner plate with text \"NEED BUZZ FOR PROTEIN\"",
                "sampler": "Euler",
                "cfgScale": 10,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-11-15T0915:23.5548185Z",
                "negativePrompt": "score_6, score_5, score_4, score_3, score_1, source_furry, source_comic",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 128078,
                        "modelVersionName": "v1.0 VAE fix"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 749933,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "baconsandwich1764",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 39667036,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/83652ba6-8025-4d19-b2eb-c5bb18a2b747/width=1216/83652ba6-8025-4d19-b2eb-c5bb18a2b747.jpeg",
            "hash": "UWI;qoE3^%%L?]WBkWkWyCM|IpxsI?WB$~NH",
            "width": 1216,
            "height": 832,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-12T04:03:15.109Z",
            "postId": 9046063,
            "stats": {
                "cryCount": 6,
                "laughCount": 19,
                "likeCount": 110,
                "dislikeCount": 0,
                "heartCount": 33,
                "commentCount": 0
            },
            "meta": {
                "Size": "1216x832",
                "seed": 3472426279,
                "extra": {
                    "remixOfId": 35577464
                },
                "steps": 50,
                "prompt": "A rugged, dust-covered warrior grips the wheel of a beat-up, armored car, roaring across a wasteland landscape. The car is an intimidating machine\u2014cobbled together with scraps of metal, reinforced windows, and rows of buzz coins welded along the hood as makeshift armor. Its tires kick up clouds of sand and debris as it speeds forward, dodging jagged rocks and twisted remnants of an old highway.\nInside, the driver is decked out in worn leather armor, a spiked shoulder pad on one side, and a pair of cracked goggles that glow faintly with a lightning bolt emblem reflecting on each lens. His gloves are fingerless, revealing scarred, dirt-streaked hands gripping the wheel, and a tattered bandana covers the lower half of his face. Just visible on the dashboard is a handwritten note scrawled on a torn piece of metal: \u201cBuzz or Bust.\u201d\nAbove him, a speech bubble reads:\n\u201cOut here, buzz is life!\u201d\nBehind him, a desert filled with twisted metal structures and scorched earth stretches endlessly, while other ragged vehicles can be seen in pursuit. The whole scene feels tense and wild, capturing the desperation and intensity of a wasteland warrior\u2019s hunt for that elusive \u201cbuzz.\u201d",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-11-12T0402:12.0446651Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    }
                ]
            },
            "username": "Elredai",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 39501050,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/59c683d0-6a7d-4572-b4b8-bbc350a1602d/width=768/59c683d0-6a7d-4572-b4b8-bbc350a1602d.jpeg",
            "hash": "UACZ35}N1IJX?aT1DkaK025]zqv|=L,lgzXA",
            "width": 768,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-11T05:55:15.313Z",
            "postId": 9009724,
            "stats": {
                "cryCount": 0,
                "laughCount": 17,
                "likeCount": 123,
                "dislikeCount": 0,
                "heartCount": 29,
                "commentCount": 0
            },
            "meta": {
                "seed": 3402222320,
                "vaes": [],
                "comfy": "{\"prompt\": {\"10001\": {\"class_type\": \"ECHOCheckpointLoaderSimple\", \"inputs\": {\"ckpt_name\": \"EMS-446170-EMS.safetensors\"}, \"_properties\": null}, \"10007\": {\"class_type\": \"DualCLIPLoader\", \"inputs\": {\"clip_name1\": \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"clip_l_sdxl_base.safetensors\", \"type\": \"flux\"}, \"_properties\": null}, \"10010\": {\"class_type\": \"LoraTagLoader\", \"inputs\": {\"clip\": [\"10007\", 0], \"model\": [\"10001\", 0], \"text\": \"ECHO_EMPTY\"}, \"_properties\": null}, \"10013\": {\"class_type\": \"EmptySD3LatentImage\", \"inputs\": {\"batch_size\": 2, \"height\": 1152, \"width\": 768}, \"_properties\": null}, \"10024\": {\"class_type\": \"CLIPTextEncode\", \"inputs\": {\"clip\": [\"10010\", 1], \"text\": \"Crash of clans mobile game title text \\\"Choose Your Perk\\\" big text on top. 3 windows to choose from:\\nfirst window on left with text \\\"100 buzz\\\" big letters on left., first window: on left with yellow silhouette of a lightning.\\nsecond window on center with text \\\"Catgirl\\\" big letters on center, second window: on left with red silhouette of a catgirl.\\nthird window on rightwith text \\\"1 day premium\\\" big letters on right, third window: on left with blue silhouette of a crown.\", \"token_normalization\": \"none\", \"weight_interpretation\": \"comfy\"}, \"_properties\": null}, \"10025\": {\"class_type\": \"CLIPTextEncode\", \"inputs\": {\"clip\": [\"10010\", 1], \"text\": \"\\n\\nembedding:EasyNegative\", \"token_normalization\": \"none\", \"weight_interpretation\": \"comfy\"}, \"_properties\": null}, \"10026\": {\"class_type\": \"FluxGuidance\", \"inputs\": {\"conditioning\": [\"10024\", 0], \"guidance\": 3.5}, \"_properties\": null}, \"11001\": {\"class_type\": \"KSampler\", \"inputs\": {\"cfg\": 1.0, \"denoise\": 1.0, \"ensd\": 31337, \"latent_image\": [\"10013\", 0], \"model\": [\"10010\", 0], \"negative\": [\"10025\", 0], \"positive\": [\"10026\", 0], \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"seed\": 3402222320, \"seed_mode\": \"A1111\", \"steps\": 25}, \"_properties\": null}, \"11016\": {\"class_type\": \"VAEDecode\", \"inputs\": {\"samples\": [\"11001\", 0], \"vae\": [\"10001\", 2]}, \"_properties\": null}, \"12004\": {\"class_type\": \"SaveImage\", \"inputs\": {\"filename_prefix\": \"794707196305759409\", \"images\": [\"11016\", 0]}, \"_properties\": null}}, \"workflow\": undefined}",
                "steps": 25,
                "width": 768,
                "height": 1152,
                "models": [],
                "prompt": "Crash of clans mobile game title text \"Choose Your Perk\" big text on top. 3 windows to choose from:\nfirst window on left with text \"100 buzz\" big letters on left., first window: on left with yellow silhouette of a lightning.\nsecond window on center with text \"Catgirl\" big letters on center, second window: on left with red silhouette of a catgirl.\nthird window on rightwith text \"1 day premium\" big letters on right, third window: on left with blue silhouette of a crown.",
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 1,
                "modelIds": [],
                "scheduler": "simple",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": []
            },
            "username": "Sentnofifty",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 39440436,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a3a02343-e32f-4542-bda5-0645f473a2e5/width=832/a3a02343-e32f-4542-bda5-0645f473a2e5.jpeg",
            "hash": "UGDulEV@58={EO$%$$NINexFs9a#~BWVV@t6",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-10T23:29:11.986Z",
            "postId": 8997141,
            "stats": {
                "cryCount": 4,
                "laughCount": 4,
                "likeCount": 97,
                "dislikeCount": 0,
                "heartCount": 63,
                "commentCount": 0
            },
            "meta": {
                "seed": 749350628103810,
                "vaes": [],
                "Model": "ponyDiffusionV6XL_v6StartWithThisOne",
                "comfy": "{\"prompt\": {\"10\": {\"inputs\": {\"ckpt_name\": \"ponyDiffusionV6XL_v6StartWithThisOne.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"11\": {\"inputs\": {\"text\": \"score_9, score_8_up, score_7_up, score_6_up, bsdbn, 1girl, breasts, black hair, solo, cleavage, yellow eyes, looking at viewer, ahoge, slit pupils, short hair, fangs, open mouth, smile, medium breasts, scales, upper body, tank top, collarbone\", \"clip\": [\"10\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"12\": {\"inputs\": {\"CONDITIONING\": [\"13\", 0]}, \"class_type\": \"Prompts Everywhere\"}, \"13\": {\"inputs\": {\"text\": \"score_5, score_4, score_3, ugly, fat\", \"clip\": [\"10\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"22\": {\"inputs\": {\"VAE\": [\"10\", 2]}, \"class_type\": \"Anything Everywhere\"}, \"23\": {\"inputs\": {\"CLIP\": [\"10\", 1]}, \"class_type\": \"Anything Everywhere\"}, \"29\": {\"inputs\": {\"samples\": [\"64\", 0], \"vae\": [\"10\", 2]}, \"class_type\": \"VAEDecode\"}, \"32\": {\"inputs\": {\"filename_prefix\": \"BSS\", \"images\": [\"29\", 0]}, \"class_type\": \"SaveImage\"}, \"33\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"34\": {\"inputs\": {\"LATENT\": [\"33\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"53\": {\"inputs\": {\"MODEL\": [\"55\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"55\": {\"inputs\": {\"lora_name\": \"MyLoRas\\\\BSDBN-24.safetensors\", \"strength_model\": 0.8, \"model\": [\"10\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"62\": {\"inputs\": {\"IMAGE\": [\"29\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"64\": {\"inputs\": {\"seed\": 749350628103810, \"steps\": 26, \"cfg\": 7.0, \"sampler_name\": \"euler_ancestral\", \"scheduler\": \"karras\", \"denoise\": 1.0, \"model\": [\"55\", 0], \"positive\": [\"11\", 0], \"negative\": [\"13\", 0], \"latent_image\": [\"33\", 0]}, \"class_type\": \"KSampler\"}}, \"workflow\": {\"last_node_id\": 64, \"last_link_id\": 87, \"nodes\": [{\"id\": 12, \"type\": \"Prompts Everywhere\", \"pos\": [360, 470], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"CONDITIONING\", \"type\": \"*\", \"link\": 10, \"color_on\": \"#cf876f\"}, {\"name\": \"CONDITIONING\", \"type\": \"*\", \"link\": 11, \"color_on\": \"#cf876f\"}], \"properties\": {\"Node name for S&R\": \"Prompts Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 53, \"type\": \"Anything Everywhere\", \"pos\": [650, 240], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"MODEL\", \"type\": \"*\", \"link\": 50, \"color_on\": \"#8978a7\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 29, \"type\": \"VAEDecode\", \"pos\": [690, 450], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 63}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [53], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 59, \"type\": \"UpscaleModelLoader\", \"pos\": [1270, 130], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": true}, \"order\": 0, \"mode\": 2, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [52], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x_NMKD-Superscale-SP178000_G.pth\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 61, \"type\": \"ImageUpscaleWithModel\", \"pos\": [1270, 170], \"size\": {\"0\": 240, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 7, \"mode\": 2, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 52}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [54], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}}, {\"id\": 46, \"type\": \"LoraLoaderModelOnly\", \"pos\": [210, 210], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {\"pinned\": true}, \"order\": 9, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 46}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [47], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"MyLoRas\\\\SLVTK-2.safetensors\", 0.8], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 34, \"type\": \"Anything Everywhere\", \"pos\": [390, 130], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"LATENT\", \"type\": \"*\", \"link\": 38, \"color_on\": \"#b38ead\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 33, \"type\": \"EmptyLatentImage\", \"pos\": [210, 130], \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [38], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [832, 1216, 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 23, \"type\": \"Anything Everywhere\", \"pos\": [370, 170], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"CLIP\", \"type\": \"*\", \"link\": 43, \"color_on\": \"#eacb8b\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 22, \"type\": \"Anything Everywhere\", \"pos\": [560, 170], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"VAE\", \"type\": \"*\", \"link\": 44, \"color_on\": \"#be616b\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 62, \"type\": \"Anything Everywhere\", \"pos\": [690, 490], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"IMAGE\", \"type\": \"*\", \"link\": 53, \"color_on\": \"#80a1c0\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 32, \"type\": \"SaveImage\", \"pos\": [870, 210], \"size\": {\"0\": 370, \"1\": 590}, \"flags\": {\"pinned\": true}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": null}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"BSS\"]}, {\"id\": 54, \"type\": \"LoraLoaderModelOnly\", \"pos\": [430, 210], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {\"pinned\": true}, \"order\": 15, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 47}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [49], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"MyLoRas\\\\BSDBN.safetensors\", 0.5], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 10, \"type\": \"CheckpointLoaderSimple\", \"pos\": [210, 170], \"size\": {\"0\": 320, \"1\": 100}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 3, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [46], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [43], \"shape\": 3, \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [44], \"shape\": 3, \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"ponyDiffusionV6XL_v6StartWithThisOne.safetensors\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 63, \"type\": \"SaveImage\", \"pos\": [1270, 210], \"size\": {\"0\": 370, \"1\": 590}, \"flags\": {}, \"order\": 14, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 54}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"BSS_upscale\"]}, {\"id\": 64, \"type\": \"KSampler\", \"pos\": [650, 330], \"size\": [210, 470], \"flags\": {\"pinned\": true}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [63], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [749350628103810, \"randomize\", 26, 7, \"euler_ancestral\", \"karras\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 13, \"type\": \"CLIPTextEncode\", \"pos\": [210, 600], \"size\": {\"0\": 430, \"1\": 200}, \"flags\": {\"pinned\": true}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [11], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_5, score_4, score_3, ugly, fat\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 55, \"type\": \"LoraLoaderModelOnly\", \"pos\": [650, 210], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {\"pinned\": true}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 49}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [50], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"MyLoRas\\\\BSDBN-24.safetensors\", 0.8], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 11, \"type\": \"CLIPTextEncode\", \"pos\": [210, 330], \"size\": {\"0\": 430, \"1\": 230}, \"flags\": {\"pinned\": true}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [10], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_9, score_8_up, score_7_up, score_6_up, bsdbn, 1girl, breasts, black hair, solo, cleavage, yellow eyes, looking at viewer, ahoge, slit pupils, short hair, fangs, open mouth, smile, medium breasts, scales, upper body, tank top, collarbone\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}], \"links\": [[10, 11, 0, 12, 0, \"CONDITIONING\"], [11, 13, 0, 12, 1, \"CONDITIONING\"], [38, 33, 0, 34, 0, \"LATENT\"], [43, 10, 1, 23, 0, \"CLIP\"], [44, 10, 2, 22, 0, \"VAE\"], [46, 10, 0, 46, 0, \"MODEL\"], [47, 46, 0, 54, 0, \"MODEL\"], [49, 54, 0, 55, 0, \"MODEL\"], [50, 55, 0, 53, 0, \"MODEL\"], [52, 59, 0, 61, 0, \"UPSCALE_MODEL\"], [53, 29, 0, 62, 0, \"IMAGE\"], [54, 61, 0, 63, 0, \"IMAGE\"], [55, 10, 2, 29, 1, \"VAE\"], [56, 29, 0, 32, 0, \"IMAGE\"], [57, 10, 1, 13, 0, \"CLIP\"], [58, 10, 1, 11, 0, \"CLIP\"], [59, 55, 0, 52, 0, \"MODEL\"], [60, 11, 0, 52, 1, \"CONDITIONING\"], [61, 13, 0, 52, 2, \"CONDITIONING\"], [62, 33, 0, 52, 3, \"LATENT\"], [63, 64, 0, 29, 0, \"LATENT\"], [64, 10, 2, 29, 1, \"VAE\"], [65, 55, 0, 64, 0, \"MODEL\"], [66, 11, 0, 64, 1, \"CONDITIONING\"], [67, 13, 0, 64, 2, \"CONDITIONING\"], [68, 33, 0, 64, 3, \"LATENT\"], [69, 29, 0, 32, 0, \"IMAGE\"], [70, 10, 1, 13, 0, \"CLIP\"], [71, 10, 1, 11, 0, \"CLIP\"], [72, 10, 2, 29, 1, \"VAE\"], [73, 29, 0, 32, 0, \"IMAGE\"], [74, 55, 0, 64, 0, \"MODEL\"], [75, 11, 0, 64, 1, \"CONDITIONING\"], [76, 13, 0, 64, 2, \"CONDITIONING\"], [77, 33, 0, 64, 3, \"LATENT\"], [78, 10, 1, 13, 0, \"CLIP\"], [79, 10, 1, 11, 0, \"CLIP\"], [80, 10, 2, 29, 1, \"VAE\"], [81, 29, 0, 32, 0, \"IMAGE\"], [82, 55, 0, 64, 0, \"MODEL\"], [83, 11, 0, 64, 1, \"CONDITIONING\"], [84, 13, 0, 64, 2, \"CONDITIONING\"], [85, 33, 0, 64, 3, \"LATENT\"], [86, 10, 1, 13, 0, \"CLIP\"], [87, 10, 1, 11, 0, \"CLIP\"]], \"groups\": [{\"title\": \"Upscale\", \"bounding\": [1260, 50, 390, 760], \"color\": \"#b19139\", \"font_size\": 24, \"locked\": false}, {\"title\": \"Generate\", \"bounding\": [200, 50, 1050, 760], \"color\": \"#8A8\", \"font_size\": 24, \"locked\": false}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.553522046476897, \"offset\": [-188.83813267509885, -237.26667959123643]}}, \"version\": 0.4, \"widget_idx_map\": {\"64\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"64\": 0}}}",
                "steps": 26,
                "width": 832,
                "height": 1216,
                "models": [
                    "ponyDiffusionV6XL_v6StartWithThisOne.safetensors"
                ],
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, bsdbn, 1girl, breasts, black hair, solo, cleavage, yellow eyes, looking at viewer, ahoge, slit pupils, short hair, fangs, open mouth, smile, medium breasts, scales, upper body, tank top, collarbone",
                "denoise": 1,
                "sampler": "Euler a",
                "cfgScale": 7,
                "modelIds": [],
                "scheduler": "karras",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "score_5, score_4, score_3, ugly, fat",
                "additionalResources": [
                    {
                        "name": "MyLoRas\\BSDBN-24.safetensors",
                        "type": "lora",
                        "strength": 0.8
                    }
                ]
            },
            "username": "blacksnowskill",
            "baseModel": null
        },
        {
            "id": 39120406,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cc7edc17-6327-40d3-8179-92b0c38adabf/width=832/cc7edc17-6327-40d3-8179-92b0c38adabf.jpeg",
            "hash": "USKc#7tm0*Nd~CW=EKoxWGs:oFs*s=n+Sws+",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-09T02:32:28.078Z",
            "postId": 8926981,
            "stats": {
                "cryCount": 2,
                "laughCount": 15,
                "likeCount": 109,
                "dislikeCount": 0,
                "heartCount": 42,
                "commentCount": 1
            },
            "meta": null,
            "username": "porterw64",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 39087430,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/aae902a0-fd38-4af4-9220-a01ec05e0a48/width=1664/aae902a0-fd38-4af4-9220-a01ec05e0a48.jpeg",
            "hash": "U069LHT|00.m00$evzH?lUD*~pxtAv-olox]",
            "width": 1664,
            "height": 2432,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-09T06:49:12.365Z",
            "postId": 8919777,
            "stats": {
                "cryCount": 1,
                "laughCount": 2,
                "likeCount": 132,
                "dislikeCount": 0,
                "heartCount": 33,
                "commentCount": 3
            },
            "meta": null,
            "username": "NaomiVK",
            "baseModel": "SD 3.5 Large"
        },
        {
            "id": 38352412,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e9697ad1-878c-46d2-90ad-fc849dc2f369/width=1088/e9697ad1-878c-46d2-90ad-fc849dc2f369.jpeg",
            "hash": "U1AvXz0e0M=}7V=MKI~Adr?Z,C={C8=aIU0h",
            "width": 1088,
            "height": 1824,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-11-04T20:37:11.979Z",
            "postId": 8755942,
            "stats": {
                "cryCount": 4,
                "laughCount": 0,
                "likeCount": 114,
                "dislikeCount": 0,
                "heartCount": 50,
                "commentCount": 1
            },
            "meta": {
                "seed": 125904100470217,
                "steps": 50,
                "prompt": "A hyper-realistic close-up, full-body digital painting of a stunning gypsy woman with dark, flowing black hair, filling the entire frame. She wears a traditional, colorful gypsy costume with a deep V-neckline down to the waist, showcasing detailed patterns, vibrant fabrics, and intricate jewelry, including large hoop earrings and multiple necklaces. Her pose is graceful and confident, with one hand resting on her waist and the other holding a tambourine or shawl. Her eyes are striking and expressive, filled with mystery and stories. The lighting highlights her golden jewelry, with soft moonlight enhancing the vibrancy of her clothing and the intricate details of her dress. The background is minimal and blurred, keeping the focus entirely on her captivating figure and ornate costume. Inspired by the sensuality of Milo Manara and the atmospheric storytelling of Luis Royo, the artwork emphasizes hyper-detailed textures and bold, enchanting designs.",
                "sampler": "Euler",
                "cfgScale": 3,
                "negativePrompt": "ugly, bad quality, noisy, blurry, grainy"
            },
            "username": "elmarkrueger72107",
            "baseModel": ""
        },
        {
            "id": 38120591,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f1833f47-bd39-46de-ab9f-21cd60bb9683/width=832/f1833f47-bd39-46de-ab9f-21cd60bb9683.jpeg",
            "hash": "UPI;*Uof-TxZ~pofR*t6-;j[E1R*xvt7IUR*",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-04T00:03:00.000Z",
            "postId": 8704534,
            "stats": {
                "cryCount": 7,
                "laughCount": 11,
                "likeCount": 106,
                "dislikeCount": 0,
                "heartCount": 44,
                "commentCount": 0
            },
            "meta": null,
            "username": "Aetius91",
            "baseModel": "Pony"
        },
        {
            "id": 38092549,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4fb59862-d43a-4b6d-885f-6c9c35991ca6/width=1280/4fb59862-d43a-4b6d-885f-6c9c35991ca6.jpeg",
            "hash": "UBEe*?~qF0WYL4yEo~Rl?^x^IWV@%#%NxtWA",
            "width": 1280,
            "height": 1856,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-11-03T11:56:46.727Z",
            "postId": 8698751,
            "stats": {
                "cryCount": 2,
                "laughCount": 7,
                "likeCount": 114,
                "dislikeCount": 0,
                "heartCount": 45,
                "commentCount": 1
            },
            "meta": null,
            "username": "paulmuc",
            "baseModel": "PonyPonyPony"
        },
        {
            "id": 37818861,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4cd19501-62b1-4aaf-b3bd-fbfffd8b219e/width=832/4cd19501-62b1-4aaf-b3bd-fbfffd8b219e.jpeg",
            "hash": "U76ku3-U.TvzysOApwaxS0t6x]tmwwv}%Mxu",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-01T23:49:57.033Z",
            "postId": 8637631,
            "stats": {
                "cryCount": 1,
                "laughCount": 3,
                "likeCount": 133,
                "dislikeCount": 0,
                "heartCount": 31,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3460197318,
                "steps": 4,
                "prompt": "highly detailed, realistic, crisp image, clear image, sharp image, sharp focus, cinematic lighting, dark, chiaroscuro, low-key, dramatic lighting, ultra photo-realistic, 35mm photography, wide shot,\nSubject is a male space pirate or roughly 45 years old, he mans the helm of his ancient space freighter that has been converted into a gunship.  His fellow space pirates celebrate in the background.  He wears a spacesuit with flexible form fitting armor plates, a futuristic long jacket with epaulettes that calls back to the 18th century, his long black hair is stringy and dreadlocked with streaks of gray, and half of his face is covered by a cybernetic eye implant.  As he steers the spaceship, he stares maniacally at a holographic heads up display, his expression conveys extreme excitement to the point of obsession.  The scene is a mix of dark scifi aesthetic with a hint of 18th century pirate high adventure, dimly lit, dark space, stars, windows, more details, epic",
                "sampler": "Undefined",
                "cfgScale": 1,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-11-01T2334:40.9863328Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 922358,
                        "modelVersionName": "Pro 1.1"
                    }
                ]
            },
            "username": "DeRivitiveKraftwork",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 37549612,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ec1fd07e-5bfe-4439-9f9e-d95776bb8e18/width=832/ec1fd07e-5bfe-4439-9f9e-d95776bb8e18.jpeg",
            "hash": "URG*pkt8xwW?~DWBxCoeNIR*IoflbJf,I;s+",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-31T11:05:01.835Z",
            "postId": 8577437,
            "stats": {
                "cryCount": 9,
                "laughCount": 3,
                "likeCount": 118,
                "dislikeCount": 0,
                "heartCount": 38,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 152726407,
                "extra": {
                    "remixOfId": 9087387
                },
                "steps": 24,
                "prompt": "A hyper-realistic portrait of a young man with brown skin, taken from a low angle with the camera at floor level, capturing his upper body as he gazes contemplatively downward. He wears a vibrant blue **Sherwani** adorned with intricate golden motifs, each pattern accentuating the luxurious texture of his attire. His look is complemented by ornate gold accessories: a majestic necklace, detailed rings, and a traditional turban set with a sparkling brooch, enhancing his dignified appearance. Behind him, a surreal background of concentric circles draws the eye\u2014each layer is a distinct, vivid color, beginning with a large outer circle and progressing through smaller circles until reaching a single, central point. This kaleidoscope of colored circles creates a mesmerizing contrast that highlights the rich blue of his Sherwani, giving the entire scene a dreamlike quality. The harmonious blend of the intricate patterns in his clothing with the concentric circles in the background transforms the portrait into a captivating fusion of elegance and surrealism.",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-31T1044:16.1827472Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.5,
                        "modelVersionId": 753053,
                        "modelVersionName": "Flux Original"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 908156,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 863655,
                        "modelVersionName": "Balance_v2.0"
                    }
                ]
            },
            "username": "Nixst3r",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 37330252,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5a9ae656-dc9b-442c-8d21-3c0ac2249fb6/width=512/5a9ae656-dc9b-442c-8d21-3c0ac2249fb6.jpeg",
            "hash": "U6DSwKT29s~pExM|01oa00r;^+IV9bWV%1R*",
            "width": 512,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-30T05:05:52.379Z",
            "postId": 8525760,
            "stats": {
                "cryCount": 11,
                "laughCount": 9,
                "likeCount": 107,
                "dislikeCount": 0,
                "heartCount": 41,
                "commentCount": 0
            },
            "meta": {
                "Size": "512x768",
                "seed": 3872857032,
                "steps": 6,
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, 1girl, white hair, long hair, ponytail,\nschool uniform, classroom, sitting, crossed legs, on desk,\ndetailed background,\nBREAK\n(realistic:1.7),\n(masterpiece:1.4),\n(best quality:1.2),\n<lora:RM_realify_v1.0: 1.5@0, 0@10 >\n<lora:rpg_portrait: 0@0, 2.2@10 > rpg portrait,\n<lora:real_dream_pony_realistic_lora_3: 0@0, 0@29, 1@30 >\n<lora:RMSDXL_Enhance: 0@0, 4@5 >\n  <lora:Add_more_details_pony: 0@0, 1@5 >\n<lora:hd_4k_ntc: 0@0, 1@5 >\n (Depth of field), low saturation,Kodak Portra 400 analog film stocks, \n<lora:hd_4k_ntc: 0@0, 1@5 >\n<lora:CartoonyMJ-v2:0.5>, <lora:moxy_draws:0.5>, \nmasterpiece, high resolution, cinematic, absurdres, photorealistic, realistic. masterpiece, newest, ruby ring, (bright lighting),<lora:S1_Dramatic_Lighting_v2:0.15> <lora:g4n1m3XLP:0.8> <lora:d3t41l3dXLP:0.5>\n,Small saggy breasts,\ngorgeous:4,detailed<lora:anime_retro:3.14> <lora:surrealidescent_v1:3.14> <lora:FLUX-Sword Sakura:3.14> <lora:flux dtmh:3.14> <lora:Hand v2:3.14> <lora:flux-dystopian-anime:3.14>\n(spread legs:0.7)",
                "sampler": "LCM",
                "cfgScale": 1,
                "clipSkip": 1,
                "resources": [
                    {
                        "name": "CartoonyMJ-v2",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "name": "moxy_draws",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "name": "S1_Dramatic_Lighting_v2",
                        "type": "lora",
                        "weight": 0.15
                    },
                    {
                        "name": "g4n1m3XLP",
                        "type": "lora",
                        "weight": 0.8
                    },
                    {
                        "name": "d3t41l3dXLP",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "name": "anime_retro",
                        "type": "lora",
                        "weight": 3.14
                    },
                    {
                        "name": "surrealidescent_v1",
                        "type": "lora",
                        "weight": 3.14
                    },
                    {
                        "name": "flux-dystopian-anime",
                        "type": "lora",
                        "weight": 3.14
                    }
                ],
                "Created Date": "2024-10-30T0459:51.8273970Z",
                "negativePrompt": "Extra limbs, extra fingers, gaping, censored, child, kid, chibi, 3d, monochrome, elven ears, anime, multiple cocks, extra legs, extra hands, mutated legs, mutated hands, ugly face, weird eyes, ugly eyes, artist name, artist signature, patreon watermark, watermark, blurry, double eyelids , makeup",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 325142,
                        "modelVersionName": "v6.0"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 42247,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 60938,
                        "modelVersionName": "negative_hand"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 91028,
                        "modelVersionName": "aid291"
                    },
                    {
                        "type": "lycoris",
                        "weight": 0.5,
                        "modelVersionId": 70587,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 649182,
                        "modelVersionName": "v3.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 173934,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 47111,
                        "modelVersionName": "v2"
                    },
                    {
                        "type": "lora",
                        "modelVersionId": 424706,
                        "modelVersionName": "LCM for SD 1.5"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250708,
                        "modelVersionName": "safe_pos"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250712,
                        "modelVersionName": "safe_neg"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Jshmr",
            "baseModel": "SD 1.5"
        },
        {
            "id": 36702161,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a32be0d0-ec20-4134-807f-5bb03f7a1312/width=1280/a32be0d0-ec20-4134-807f-5bb03f7a1312.jpeg",
            "hash": "UmHL#a%MRORj.TtRaJR*ROWCaxj[MvawWYkC",
            "width": 1280,
            "height": 1920,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-26T18:16:00.982Z",
            "postId": 8383404,
            "stats": {
                "cryCount": 12,
                "laughCount": 15,
                "likeCount": 109,
                "dislikeCount": 0,
                "heartCount": 32,
                "commentCount": 0
            },
            "meta": {
                "NGMS": "0.95",
                "Size": "1280x1920",
                "seed": 2181810611,
                "Model": "fluxUnchainedBySCG_hyfu8StepHybridV10",
                "steps": 8,
                "hashes": {
                    "model": "fc881d6c63"
                },
                "prompt": "beautiful fantasy landscape photography, photo, Sigma 16 mm f/5.6, ((very detailed)), sharp focus, small rock,  fallen leaves, swan, sunflower, field, bush floor, reflections, (castle),  pond, medieval forest, ((village)), stunning nature aquatic environment , medieval land, (bright sunny sky), (high contrast), cinematic (lights), backlight, (shadows), lens flare, vibrant colors, colorful, (Sea Blue flowers) and leaves, (lovely), (beautiful), <lora:no-blur:1",
                "Version": "f2.0.1v1.10.1-previous-554-g2467c88c",
                "sampler": "Euler",
                "Emphasis": "No norm",
                "Module 1": "ae",
                "Module 2": "clip_l",
                "Module 3": "t5xxl_fp8_e4m3fn",
                "cfgScale": 1.1,
                "resources": [
                    {
                        "hash": "fc881d6c63",
                        "name": "fluxUnchainedBySCG_hyfu8StepHybridV10",
                        "type": "model"
                    }
                ],
                "Model hash": "fc881d6c63",
                "Schedule type": "Beta",
                "negativePrompt": "(blurry), out of focus, undetailed, (worst quality, low quality, normal quality:2), saturated colors",
                "Beta schedule beta": "0.6",
                "Beta schedule alpha": "0.6",
                "Diffusion in Low Bits": "float8-e4m3fn (fp16 LoRA)",
                "latent_modifier_enabled": "True",
                "latent_modifier_affect_uncond": "None",
                "latent_modifier_combat_method": "subtract",
                "latent_modifier_tonemap_method": "reinhard",
                "latent_modifier_rescale_cfg_phi": "0",
                "latent_modifier_combat_cfg_drift": "0",
                "latent_modifier_extra_noise_type": "gaussian",
                "latent_modifier_sharpness_method": "anisotropic",
                "latent_modifier_spectral_mod_mode": "hard_clamp",
                "latent_modifier_divisive_norm_size": "127",
                "latent_modifier_extra_noise_method": "add",
                "latent_modifier_tonemap_multiplier": "0",
                "latent_modifier_tonemap_percentile": "100",
                "latent_modifier_contrast_multiplier": "0",
                "latent_modifier_extra_noise_lowpass": "100",
                "latent_modifier_dyn_cfg_augmentation": "None",
                "latent_modifier_sharpness_multiplier": "10",
                "latent_modifier_extra_noise_multiplier": "0",
                "latent_modifier_spectral_mod_multiplier": "0",
                "latent_modifier_spectral_mod_percentile": "5",
                "latent_modifier_divisive_norm_multiplier": "0"
            },
            "username": "Edurock",
            "baseModel": ""
        },
        {
            "id": 36326419,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9e47b4fd-1edc-4087-9cee-8a9b7448cee2/width=832/9e47b4fd-1edc-4087-9cee-8a9b7448cee2.jpeg",
            "hash": "UQHe2k%gTeJVpyx^gNo}k@a%s.%1?aoJMxWD",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-24T15:23:54.411Z",
            "postId": 8298247,
            "stats": {
                "cryCount": 11,
                "laughCount": 19,
                "likeCount": 92,
                "dislikeCount": 0,
                "heartCount": 46,
                "commentCount": 0
            },
            "meta": {
                "seed": 148644979891357,
                "vaes": [
                    "ae.safetensors"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"2024-10-24/flux\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"10\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"model.safetensors\", \"clip_name2\": \"t5xxl_fp8_e4m3fn.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"35\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"beta\", \"steps\": 12, \"denoise\": 1.0, \"model\": [\"39\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"39\", 0], \"conditioning\": [\"31\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 148644979891357}, \"class_type\": \"RandomNoise\"}, \"29\": {\"inputs\": {\"unet_name\": \"flux1-dev-Q4_0.gguf\"}, \"class_type\": \"UnetLoaderGGUF\"}, \"31\": {\"inputs\": {\"clip_l\": [\"32\", 0], \"t5xxl\": [\"32\", 0], \"guidance\": 3.5, \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncodeFlux\"}, \"32\": {\"inputs\": {\"text\": \"crying girl holding a sign  that says \\\" i need buzz for new puppy\\\",pixar anime style\\n\"}, \"class_type\": \"Text Prompt (JPS)\"}, \"33\": {\"inputs\": {\"dimensions\": \" 832 x 1216  (portrait)\", \"clip_scale\": 1.5, \"batch_size\": 1}, \"class_type\": \"SDXL Empty Latent Image (rgthree)\"}, \"35\": {\"inputs\": {\"multiplier\": 1.0, \"samples\": [\"33\", 0]}, \"class_type\": \"LatentMultiply\"}, \"38\": {\"inputs\": {\"lora_name\": \"Cinematic_style_2_(FLUX).safetensors\", \"strength_model\": 0.3, \"model\": [\"40\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"39\": {\"inputs\": {\"lora_name\": \"flux_realism_lora.safetensors\", \"strength_model\": 0.66, \"model\": [\"38\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"40\": {\"inputs\": {\"lora_name\": \"35mm_joycap.safetensors\", \"strength_model\": 0.5, \"model\": [\"29\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}}, \"workflow\": {\"last_node_id\": 40, \"last_link_id\": 78, \"nodes\": [{\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 614, \"1\": 68}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 75, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 55, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [30], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 31, \"type\": \"CLIPTextEncodeFlux\", \"pos\": {\"0\": 585, \"1\": 179}, \"size\": {\"0\": 302.1147155761719, \"1\": 127.60980987548828}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 54}, {\"name\": \"clip_l\", \"type\": \"STRING\", \"link\": 56, \"widget\": {\"name\": \"clip_l\"}}, {\"name\": \"t5xxl\", \"type\": \"STRING\", \"link\": 57, \"widget\": {\"name\": \"t5xxl\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [55], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncodeFlux\"}, \"widgets_values\": [\"Allie Sin is seen with a cocktail in her hand at a holiday resort as she rushes back to her lawnchair. her tiny bikini struggles to hide her breasts. She has tattos on her lower abodmen\", \"\", 3.5]}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 904, \"1\": 143}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1393, \"1\": 125}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [9], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 35, \"type\": \"LatentMultiply\", \"pos\": {\"0\": 596, \"1\": 354}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 59}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [60], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentMultiply\"}, \"widgets_values\": [1]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 956, \"1\": 261}, \"size\": {\"0\": 355.20001220703125, \"1\": 326}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 30, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 60, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 596, \"1\": 460}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [148644979891357, \"randomize\"]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 213, \"1\": 468}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [54], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"model.safetensors\", \"t5xxl_fp8_e4m3fn.safetensors\", \"flux\"]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 607, \"1\": 582}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 40, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": -157, \"1\": 220}, \"size\": {\"0\": 346.4001159667969, \"1\": 82}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 78}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [77], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"35mm_joycap.safetensors\", 0.5]}, {\"id\": 33, \"type\": \"SDXL Empty Latent Image (rgthree)\", \"pos\": {\"0\": 211, \"1\": 610}, \"size\": {\"0\": 325.2254943847656, \"1\": 166.7161407470703}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [59], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP_WIDTH\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"CLIP_HEIGHT\", \"type\": \"INT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SDXL Empty Latent Image (rgthree)\"}, \"widgets_values\": [\" 832 x 1216  (portrait)\", 1.5, 1]}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": {\"0\": 1460, \"1\": 163}, \"size\": {\"0\": 477.8125915527344, \"1\": 877.87158203125}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 9}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"%date:yyyy-MM-dd%/flux\"]}, {\"id\": 29, \"type\": \"UnetLoaderGGUF\", \"pos\": {\"0\": -146, \"1\": 113}, \"size\": {\"0\": 339.2254943847656, \"1\": 70.7161636352539}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [78], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q4_0.gguf\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 610, \"1\": 673}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 76, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"beta\", 12, 1]}, {\"id\": 39, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": 210, \"1\": 210}, \"size\": {\"0\": 344.22552490234375, \"1\": 95.7161636352539}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 74}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [75, 76], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"flux_realism_lora.safetensors\", 0.66]}, {\"id\": 38, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": 213, \"1\": 351}, \"size\": {\"0\": 346.4001159667969, \"1\": 82}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 77}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [74], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"Cinematic_style_2_(FLUX).safetensors\", 0.3]}, {\"id\": 32, \"type\": \"Text Prompt (JPS)\", \"pos\": {\"0\": 935, \"1\": 636}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"links\": [56, 57], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Text Prompt (JPS)\"}, \"widgets_values\": [\"crying girl holding a sign  that says \\\" i need buzz for new puppy\\\",pixar anime style\\n\"]}], \"links\": [[9, 8, 0, 9, 0, \"IMAGE\"], [12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [24, 13, 0, 8, 0, \"LATENT\"], [30, 22, 0, 13, 1, \"GUIDER\"], [37, 25, 0, 13, 0, \"NOISE\"], [54, 11, 0, 31, 0, \"CLIP\"], [55, 31, 0, 22, 1, \"CONDITIONING\"], [56, 32, 0, 31, 1, \"STRING\"], [57, 32, 0, 31, 2, \"STRING\"], [59, 33, 0, 35, 0, \"LATENT\"], [60, 35, 0, 13, 4, \"LATENT\"], [74, 38, 0, 39, 0, \"MODEL\"], [75, 39, 0, 22, 0, \"MODEL\"], [76, 39, 0, 17, 0, \"MODEL\"], [77, 40, 0, 38, 0, \"MODEL\"], [78, 29, 0, 40, 0, \"MODEL\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.9090909090909091, \"offset\": [256.69652374620716, -145.07360134483892]}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}}}}",
                "steps": 12,
                "models": [],
                "denoise": 1,
                "sampler": "Euler",
                "modelIds": [],
                "scheduler": "beta",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "Cinematic_style_2_(FLUX).safetensors",
                        "type": "lora",
                        "strength": 0.3
                    },
                    {
                        "name": "flux_realism_lora.safetensors",
                        "type": "lora",
                        "strength": 0.66
                    },
                    {
                        "name": "35mm_joycap.safetensors",
                        "type": "lora",
                        "strength": 0.5
                    }
                ]
            },
            "username": "H3ll99",
            "baseModel": ""
        },
        {
            "id": 36208259,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/df97fdf9-6615-46fa-94b8-839a7499701c/width=1800/df97fdf9-6615-46fa-94b8-839a7499701c.jpeg",
            "hash": "UEDS8V02_KMzyo4=-moL,pNHI;tPyBIW%0Wo",
            "width": 4032,
            "height": 2304,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-24T00:16:12.462Z",
            "postId": 8272331,
            "stats": {
                "cryCount": 1,
                "laughCount": 3,
                "likeCount": 127,
                "dislikeCount": 0,
                "heartCount": 37,
                "commentCount": 1
            },
            "meta": {
                "seed": 731,
                "vaes": [
                    "ae-dev.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 1], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"9\": {\"inputs\": {\"filename_prefix\": \"flux-llm/october2024/fluxtm_pass1\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}, \"10\": {\"inputs\": {\"vae_name\": \"ae-dev.sft\"}, \"class_type\": \"VAELoader\", \"_meta\": {\"title\": \"Load VAE\"}}, \"11\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp16.safetensors\", \"clip_name2\": \"Long-ViT-L-14-GmP-ft.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\", \"_meta\": {\"title\": \"DualCLIPLoader\"}}, \"12\": {\"inputs\": {\"unet_name\": \"flux1-dev.sft\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\", \"_meta\": {\"title\": \"1-Load Diffusion Model\"}}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"149\", 0], \"sampler\": [\"318\", 0], \"sigmas\": [\"88\", 1], \"latent_image\": [\"32\", 0]}, \"class_type\": \"SamplerCustomAdvanced\", \"_meta\": {\"title\": \"SamplerCustomAdvanced\"}}, \"16\": {\"inputs\": {\"sampler_name\": \"dpmpp_2m\"}, \"class_type\": \"KSamplerSelect\", \"_meta\": {\"title\": \"KSamplerSelect\"}}, \"17\": {\"inputs\": {\"scheduler\": \"beta\", \"steps\": 35, \"denoise\": 1.0, \"model\": [\"152\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"25\": {\"inputs\": {\"noise_seed\": 731}, \"class_type\": \"RandomNoise\", \"_meta\": {\"title\": \"RandomNoise\"}}, \"32\": {\"inputs\": {\"resolution\": \"1344x768 (1.75)\", \"batch_size\": 1, \"width_override\": 0, \"height_override\": 0}, \"class_type\": \"SDXLEmptyLatentSizePicker+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Empty Latent Size Picker\"}}, \"88\": {\"inputs\": {\"step\": 0, \"sigmas\": [\"17\", 0]}, \"class_type\": \"SplitSigmas\", \"_meta\": {\"title\": \"SplitSigmas\"}}, \"113\": {\"inputs\": {\"blur_radius\": 2, \"sigma\": 2.0, \"image\": [\"177\", 0]}, \"class_type\": \"ImageBlur\", \"_meta\": {\"title\": \"ImageBlur\"}}, \"114\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.5, \"alpha\": 0.39999999999999997, \"image\": [\"177\", 0]}, \"class_type\": \"ImageSharpen\", \"_meta\": {\"title\": \"ImageSharpen\"}}, \"115\": {\"inputs\": {\"blend_factor\": 0.39999999999999997, \"blend_mode\": \"normal\", \"image1\": [\"113\", 0], \"image2\": [\"114\", 0]}, \"class_type\": \"ImageBlend\", \"_meta\": {\"title\": \"ImageBlend\"}}, \"123\": {\"inputs\": {\"images\": [\"129\", 0]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"129\": {\"inputs\": {\"blend_factor\": 0.5, \"blend_mode\": \"overlay\", \"image1\": [\"115\", 0], \"image2\": [\"130\", 0]}, \"class_type\": \"ImageBlend\", \"_meta\": {\"title\": \"ImageBlend\"}}, \"130\": {\"inputs\": {\"image\": \"noise_1.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"_meta\": {\"title\": \"Load Grain\"}, \"is_changed\": [\"99e01496bc4d77d83110b432080d06ba6c2b4c47506185d5e017ecd823f26712\"]}, \"131\": {\"inputs\": {\"width\": 2048, \"height\": 2048, \"interpolation\": \"bilinear\", \"method\": \"keep proportion\", \"condition\": \"always\", \"multiple_of\": 16}, \"class_type\": \"ImageResize+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Image Resize\"}}, \"135\": {\"inputs\": {\"pixels\": [\"292\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\", \"_meta\": {\"title\": \"VAE Encode\"}}, \"149\": {\"inputs\": {\"model\": [\"152\", 0], \"conditioning\": [\"241\", 0]}, \"class_type\": \"BasicGuider\", \"_meta\": {\"title\": \"BasicGuider\"}}, \"152\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": [\"32\", 1], \"height\": [\"32\", 2], \"model\": [\"310\", 0]}, \"class_type\": \"ModelSamplingFlux\", \"_meta\": {\"title\": \"ModelSamplingFlux\"}}, \"159\": {\"inputs\": {\"filename_prefix\": \"flux-llm/october2024/fluxtm_pass2\", \"images\": [\"177\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}, \"162\": {\"inputs\": {\"max_shift\": 0.9349999999999999, \"base_shift\": 0.96, \"width\": [\"169\", 0], \"height\": [\"170\", 0], \"model\": [\"310\", 0]}, \"class_type\": \"ModelSamplingFlux\", \"_meta\": {\"title\": \"ModelSamplingFlux\"}}, \"168\": {\"inputs\": {\"image\": [\"8\", 0]}, \"class_type\": \"GetImageSize+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Get Image Size\"}}, \"169\": {\"inputs\": {\"value\": \"a*b\", \"a\": [\"168\", 0], \"b\": [\"206\", 0]}, \"class_type\": \"SimpleMath+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Simple Math\"}}, \"170\": {\"inputs\": {\"value\": \"a*b\", \"a\": [\"168\", 1], \"b\": [\"206\", 0]}, \"class_type\": \"SimpleMath+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Simple Math\"}}, \"171\": {\"inputs\": {\"noise\": [\"175\", 0], \"guider\": [\"176\", 0], \"sampler\": [\"172\", 0], \"sigmas\": [\"173\", 0], \"latent_image\": [\"179\", 0]}, \"class_type\": \"SamplerCustomAdvanced\", \"_meta\": {\"title\": \"SamplerCustomAdvanced\"}}, \"172\": {\"inputs\": {\"sampler_name\": \"dpmpp_2m\"}, \"class_type\": \"KSamplerSelect\", \"_meta\": {\"title\": \"KSamplerSelect\"}}, \"173\": {\"inputs\": {\"scheduler\": \"beta\", \"steps\": 20, \"denoise\": 0.52, \"model\": [\"329\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"175\": {\"inputs\": {\"noise_seed\": 4390}, \"class_type\": \"RandomNoise\", \"_meta\": {\"title\": \"RandomNoise\"}}, \"176\": {\"inputs\": {\"model\": [\"162\", 0], \"conditioning\": [\"241\", 0]}, \"class_type\": \"BasicGuider\", \"_meta\": {\"title\": \"BasicGuider\"}}, \"177\": {\"inputs\": {\"samples\": [\"171\", 1], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"179\": {\"inputs\": {\"upscale_method\": \"bicubic\", \"scale_by\": [\"206\", 0], \"samples\": [\"299\", 0]}, \"class_type\": \"LatentUpscaleBy\", \"_meta\": {\"title\": \"Upscale Latent By\"}}, \"182\": {\"inputs\": {\"upscale_model\": [\"183\", 0], \"image\": [\"129\", 0]}, \"class_type\": \"ImageUpscaleWithModel\", \"_meta\": {\"title\": \"Upscale Image (using Model)\"}}, \"183\": {\"inputs\": {\"model_name\": \"002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth\"}, \"class_type\": \"UpscaleModelLoader\", \"_meta\": {\"title\": \"Load Upscale Model\"}}, \"190\": {\"inputs\": {\"image\": \"noise_1.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"_meta\": {\"title\": \"Load Grain\"}, \"is_changed\": [\"99e01496bc4d77d83110b432080d06ba6c2b4c47506185d5e017ecd823f26712\"]}, \"193\": {\"inputs\": {\"blend_factor\": 0.585, \"blend_mode\": \"overlay\", \"image1\": [\"203\", 0], \"image2\": [\"190\", 0]}, \"class_type\": \"ImageBlend\", \"_meta\": {\"title\": \"ImageBlend\"}}, \"203\": {\"inputs\": {\"blend_factor\": 0.25, \"blend_mode\": \"overlay\", \"image1\": [\"232\", 0], \"image2\": [\"232\", 0]}, \"class_type\": \"ImageBlend\", \"_meta\": {\"title\": \"ImageBlend\"}}, \"206\": {\"inputs\": {\"Number\": \"1.5\"}, \"class_type\": \"Float\", \"_meta\": {\"title\": \"Upscale Amount\"}}, \"229\": {\"inputs\": {\"images\": [\"235\", 0]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"232\": {\"inputs\": {\"brightness\": 0.0, \"contrast\": 1.0, \"saturation\": 0.8999999999999999, \"sharpness\": 1.0, \"blur\": 0, \"gaussian_blur\": 0.5, \"edge_enhance\": 0.0, \"detail_enhance\": \"false\", \"image\": [\"182\", 0]}, \"class_type\": \"Image Filter Adjustments\", \"_meta\": {\"title\": \"Image Filter Adjustments\"}}, \"233\": {\"inputs\": {\"noise_radius\": 7, \"preserve_edges\": 0.6, \"sharpen\": 4.0, \"ratio\": 0.3, \"image\": [\"193\", 0]}, \"class_type\": \"ImageSmartSharpen+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Image Smart Sharpen\"}}, \"235\": {\"inputs\": {\"noise_radius\": 7, \"preserve_edges\": 0.09999999999999999, \"sharpen\": 5.0, \"ratio\": 0.3, \"image\": [\"177\", 0]}, \"class_type\": \"ImageSmartSharpen+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Image Smart Sharpen\"}}, \"241\": {\"inputs\": {\"clip_l\": [\"328\", 0], \"t5xxl\": [\"327\", 0], \"guidance\": 2.9000000000000004, \"clip\": [\"310\", 1]}, \"class_type\": \"CLIPTextEncodeFlux\", \"_meta\": {\"title\": \"CLIPTextEncodeFlux\"}}, \"247\": {\"inputs\": {\"solver\": \"bosh3\", \"log_relative_tolerance\": -2.5, \"log_absolute_tolerance\": -3.5, \"max_steps\": 30}, \"class_type\": \"ODESamplerSelect\", \"_meta\": {\"title\": \"ODE Sampler\"}}, \"250\": {\"inputs\": {\"unet_name\": \"flux1-dev-Q8_0.gguf\"}, \"class_type\": \"UnetLoaderGGUF\", \"_meta\": {\"title\": \"2-Unet Loader (GGUF)\"}}, \"257\": {\"inputs\": {\"text\": [\"327\", 0], \"text2\": \"Illustration, low-angle shot, dramatic lighting with an intense glow from the fiery ground casting red and orange hues across the scene. The central figure is a dark, armored warrior with a tall, spiked crown, standing with his back to the viewer. He wears a tattered, blood-red, flowing cape that appears to disintegrate into fiery embers. The warrior grips a large, gleaming sword in his right hand, its blade reflecting the eerie light. He faces a towering, ancient, intricately-carved stone monolith on the right side of the composition, partially illuminated by a mysterious golden glow. The ground is littered with twisted, blackened roots, and scorched earth, glowing with embers. In the background, dark, ominous storm clouds loom overhead, creating a foreboding and dystopian atmosphere. The composition uses rule of thirds, giving prominence to both the warrior and the monolith, while the background remains blurred with a shallow depth of field.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"LLM Prompt\"}}, \"259\": {\"inputs\": {\"text\": [\"327\", 2], \"text2\": \"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Troubleshooting\"}}, \"260\": {\"inputs\": {\"text\": \"Hyperrealism, low-angle shot, cold, diffused lighting with a bluish tint, illuminating the hulking bear warrior clad in spiked, frost-covered armor. His muscular form, topped by a massive white bear head with glowing blue eyes, wields a massive double-bladed axe made of ice, frost vapor rising from its surface. His fur, adorned with various talismans and furs, flows in the wind as snow swirls around him. The backdrop features jagged, ice-encrusted mountains under a bleak, overcast sky, creating a foreboding arctic battleground.\\n\\nBear warrior, ice axe, spiked armor, icy mountains, snowstorm.\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Examples\"}}, \"261\": {\"inputs\": {\"text\": \"Act as a creative agent who generates highly creative detailed, comma-delimited formatted prompt of up to 150 words for the image. Begin each prompt by specifying an art style (for example, cartoon, impasto, absurdres, oil or acrylic or watercolor painting, or charcoal drawing or engraving or sculpture, etc.)  Include information about lighting. Include information about camera angle. Include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.Do NOT mention any text that is in the image.Specify the depth of field and whether the background is in focus or blurred.Do NOT use any ambiguous language. Include the pose of the subject. Then, continue with descriptive visual elements of the subject, surroundings, and background. Please do not omit any details, especially objects, lighting, colors, and textures, even subtle ones hidden in the background! It is imperative that you carefully consider every aspect of the image, and provide satisfactory descriptions! Also, please be very careful when considering whether the image really is a photograph or actually a detailed painting or illustration.\\n\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"System: Instructions\"}}, \"262\": {\"inputs\": {\"text\": \"Create an image prompt from the image provided, be sure to include all details\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"User: Prompt\"}}, \"263\": {\"inputs\": {\"image\": \"the_crimson_king_s_oath_by_socialgatheringstar_dib9tr5-pre.jpg\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"_meta\": {\"title\": \"Load Image\"}, \"is_changed\": [\"60bd0896b089b3d4d4ea1ba60066cdb611cc8d4b68d04b8f29bdbe7903025908\"]}, \"265\": {\"inputs\": {\"images\": [\"233\", 0]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"266\": {\"inputs\": {\"filename_prefix\": \"flux-llm/october2024/face-detailer-fluxtm_pass3\", \"images\": [\"233\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}, \"282\": {\"inputs\": {\"custom_path\": \"D:\\\\20240703-ComfyUI_windows_portable\\\\ComfyUI\\\\output\\\\JPG\", \"filename_prefix\": \"flux-jpg_\", \"timestamp\": \"None\", \"format\": \"jpg\", \"quality\": 100, \"meta_data\": false, \"blind_watermark\": \"\", \"save_workflow_as_json\": false, \"preview\": true, \"images\": [\"233\", 0]}, \"class_type\": \"LayerUtility: SaveImagePlus\", \"_meta\": {\"title\": \"LayerUtility: SaveImage Plus\"}}, \"283\": {\"inputs\": {\"image\": \"the_queen_s_last_stand_by_socialgatheringstar_dicxt1r-pre.jpg\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"_meta\": {\"title\": \"Load Image\"}, \"is_changed\": [\"ef03847dfec4e3b35e32682122b58130bd08d874de15266c63fff22af2729255\"]}, \"292\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"upscale_method\": \"bicubic\", \"keep_proportion\": true, \"divisible_by\": 16, \"crop\": \"disabled\", \"image\": [\"283\", 0], \"get_image_size\": [\"283\", 0]}, \"class_type\": \"ImageResizeKJ\", \"_meta\": {\"title\": \"Resize Image\"}}, \"294\": {\"inputs\": {\"VAE\": [\"10\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"295\": {\"inputs\": {\"CONDITIONING\": [\"241\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"298\": {\"inputs\": {\"CLIP\": [\"310\", 1]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"299\": {\"inputs\": {\"noise_seed\": 456550, \"noise_strength\": 0.9, \"normalize\": \"false\", \"latent\": [\"13\", 1]}, \"class_type\": \"InjectLatentNoise+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Inject Latent Noise\"}}, \"303\": {\"inputs\": {\"text\": [\"328\", 0], \"text2\": \"dark fantasy illustration, ominous warrior in tattered red cape, spiked crown, holding a large sword, facing a towering ancient stone monolith with intricate carvings, glowing embers and ash in the air, dark stormy sky, desolate landscape with twisted black trees, red and black color palette, epic, moody atmosphere, high contrast, cinematic lighting, highly detailed, concept art style\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"LLM Prompt\"}}, \"304\": {\"inputs\": {\"text\": [\"328\", 2], \"text2\": \"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Troubleshooting\"}}, \"305\": {\"inputs\": {\"text\": \"Hyperrealism, low-angle shot, cold, diffused lighting with a bluish tint, illuminating the hulking bear warrior clad in spiked, frost-covered armor. His muscular form, topped by a massive white bear head with glowing blue eyes, wields a massive double-bladed axe made of ice, frost vapor rising from its surface. His fur, adorned with various talismans and furs, flows in the wind as snow swirls around him. The backdrop features jagged, ice-encrusted mountains under a bleak, overcast sky, creating a foreboding arctic battleground.\\n\\nBear warrior, ice axe, spiked armor, icy mountains, snowstorm.\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Examples\"}}, \"306\": {\"inputs\": {\"text\": \"Enhance this prompt for a Stable Diffusion image to optimize it for Clip-L text encoder.\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\\nEmphasize key information about the subject, scene, details, effects as needed. Stick with short comma-delimited prompts. start with the art style, then subject, then details like pose, camera angle.\\n\\nNote that Clip-L focuses on specific visual elements and technical details. It lists concrete objects, visual attributes, and effects. Use for specific visual elements and attributes.\\n\\nHere is an example Clip-L prompt that you might model:\\noil painting, Iron Man, space, satellite repair, extreme close-up, helmet reflections, Earth, stars, Rodenstock HR Digaron-W 50mm lens, f/5.6, 1/2000s, ISO 100, high dynamic range, lens flares, atmospheric glow, cold metallic tones, warm Earth glow\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"System: Instructions\"}}, \"307\": {\"inputs\": {\"text\": \"Create an image prompt from the image provided, be sure to include all details\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"User: Prompt\"}}, \"310\": {\"inputs\": {\"PowerLoraLoaderHeaderWidget\": {\"type\": \"PowerLoraLoaderHeaderWidget\"}, \"lora_1\": {\"on\": false, \"lora\": \"flux\\\\style\\\\Fresco-000003.safetensors\", \"strength\": 0.6}, \"lora_2\": {\"on\": false, \"lora\": \"flux\\\\details\\\\FluxDFaeTasticDetails.safetensors\", \"strength\": 0.51}, \"lora_3\": {\"on\": false, \"lora\": \"flux\\\\style\\\\Watercolor_ALDMHT.safetensors\", \"strength\": 0.35}, \"lora_4\": {\"on\": false, \"lora\": \"flux\\\\style\\\\ob-watercolor.safetensors\", \"strength\": 0.5}, \"lora_5\": {\"on\": false, \"lora\": \"flux\\\\details\\\\Dever_Flux_Enhancer.safetensors\", \"strength\": 1}, \"lora_6\": {\"on\": false, \"lora\": \"flux\\\\FredFraiStyle-FLUX-Share.safetensors\", \"strength\": 0.55}, \"lora_7\": {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Wraith_BW_Flux.safetensors\", \"strength\": 0.4}, \"lora_8\": {\"on\": true, \"lora\": \"flux\\\\andreac\\\\The Desolation - s0_7 c7_5.safetensors\", \"strength\": 0.25}, \"lora_9\": {\"on\": true, \"lora\": \"flux\\\\andreac\\\\Dystopia - s0_8 g4.safetensors\", \"strength\": 0.45}, \"lora_10\": {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Luminous_Shadowscape-000016.safetensors\", \"strength\": 0.2}, \"lora_11\": {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Wraith_BW_Flux.safetensors\", \"strength\": 1}, \"lora_12\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\qiu_crayon.safetensors\", \"strength\": 0.4}, \"lora_13\": {\"on\": false, \"lora\": \"flux\\\\style\\\\Eldritch_Parchment_Art_for_Flux_1.0.safetensors\", \"strength\": 0.45}, \"lora_14\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\l0fi2.safetensors\", \"strength\": 0.87}, \"lora_15\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\waterc0l0r3.safetensors\", \"strength\": 0.35}, \"lora_16\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\rosin4.safetensors\", \"strength\": 0.4}, \"lora_17\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\fe4r.safetensors\", \"strength\": 0.6}, \"lora_18\": {\"on\": true, \"lora\": \"flux\\\\mine\\\\gr1m2.safetensors\", \"strength\": 0.78}, \"lora_19\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\PinkiePastelWatercolorFLUX.safetensors\", \"strength\": 0.3}, \"lora_20\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\flat2100.safetensors\", \"strength\": 0.35}, \"lora_21\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\creepcute-000001.safetensors\", \"strength\": 0.57}, \"lora_22\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\CozySpookyStyleFlux.safetensors\", \"strength\": 0.5}, \"lora_23\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\c4mille.safetensors\", \"strength\": 0.25}, \"lora_24\": {\"on\": false, \"lora\": \"flux\\\\illustration-concept.safetensors\", \"strength\": 0.5}, \"lora_25\": {\"on\": false, \"lora\": \"flux\\\\anime\\\\CP-anime.safetensors\", \"strength\": 0.75}, \"\\u2795 Add Lora\": \"\", \"model\": [\"250\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"Power Lora Loader (rgthree)\", \"_meta\": {\"title\": \"Power Lora Loader (rgthree)\"}}, \"317\": {\"inputs\": {\"eta1\": 0, \"eta2\": 0, \"eta3\": 0.5, \"eta_var1\": 0, \"eta_var2\": 0, \"eta_var3\": 0, \"s_noise1\": 1, \"s_noise2\": 1, \"s_noise3\": 1, \"alpha\": 0, \"k\": 1, \"noise_sampler_type1\": \"brownian\", \"noise_sampler_type2\": \"hard\", \"noise_sampler_type3\": 0.5, \"noise_mode\": 1, \"c2\": false, \"c3\": 0, \"auto_c2\": 0, \"iter_c2\": 1, \"iter_c3\": 1, \"iter\": 1, \"reverse_weight_c2\": 1, \"reverse_weight_c3\": 0.1, \"reverse_weight\": 1, \"tol\": 0.1, \"latent_guide_weight\": 1}, \"class_type\": \"SamplerRES3_Implicit\", \"_meta\": {\"title\": \"SamplerRES3_Implicit\"}}, \"318\": {\"inputs\": {\"eta1\": 0.5, \"eta2\": 0.0, \"eta_var1\": 0.0, \"eta_var2\": 0.0, \"s_noise1\": 1.0, \"s_noise2\": 1.0, \"alpha\": 0.0, \"k\": 1.0, \"noise_sampler_type\": \"brownian\", \"noise_mode\": \"hard\", \"c2\": 1.0, \"auto_c2\": false, \"iter_c2\": 0, \"iter\": 1, \"reverse_weight_c2\": 1.0, \"reverse_weight\": 1.0, \"tol\": 0.1, \"latent_guide_weight\": 0.04}, \"class_type\": \"SamplerRES_Implicit\", \"_meta\": {\"title\": \"SamplerRES_Implicit\"}}, \"327\": {\"inputs\": {\"AI_service\": \"ChatGPT\", \"ChatGPT_model\": \"chatgpt-4o-latest\", \"Groq_model\": \"none\", \"Anthropic_model\": \"none\", \"Ollama_model\": \"none\", \"Optional_model\": \"none\", \"creative_latitude\": 0.7, \"tokens\": 300, \"seed\": 1113614524899378, \"examples_delimiter\": \"Two newlines\", \"LLM_URL\": \"https://api.groq.com/openai/v1\", \"Instruction\": [\"261\", 0], \"Examples_or_Context\": [\"260\", 0], \"Prompt\": [\"262\", 0], \"image\": [\"263\", 0]}, \"class_type\": \"AdvPromptEnhancer\", \"_meta\": {\"title\": \"Advanced Prompt Enhancer\"}}, \"328\": {\"inputs\": {\"AI_service\": \"ChatGPT\", \"ChatGPT_model\": \"chatgpt-4o-latest\", \"Groq_model\": \"none\", \"Anthropic_model\": \"none\", \"Ollama_model\": \"none\", \"Optional_model\": \"none\", \"creative_latitude\": 0.7, \"tokens\": 500, \"seed\": 341641286596912, \"examples_delimiter\": \"Two newlines\", \"LLM_URL\": \"https://api.groq.com/openai/v1\", \"Instruction\": [\"306\", 0], \"Prompt\": [\"307\", 0], \"image\": [\"263\", 0]}, \"class_type\": \"AdvPromptEnhancer\", \"_meta\": {\"title\": \"Advanced Prompt Enhancer\"}}, \"329\": {\"inputs\": {\"PowerLoraLoaderHeaderWidget\": {\"type\": \"PowerLoraLoaderHeaderWidget\"}, \"lora_1\": {\"on\": false, \"lora\": \"flux\\\\style\\\\Fresco-000003.safetensors\", \"strength\": 0.6}, \"lora_2\": {\"on\": false, \"lora\": \"flux\\\\details\\\\FluxDFaeTasticDetails.safetensors\", \"strength\": 0.26}, \"lora_3\": {\"on\": false, \"lora\": \"flux\\\\style\\\\Watercolor_ALDMHT.safetensors\", \"strength\": 0.35}, \"lora_4\": {\"on\": false, \"lora\": \"flux\\\\style\\\\ob-watercolor.safetensors\", \"strength\": 0.5}, \"lora_5\": {\"on\": false, \"lora\": \"flux\\\\details\\\\Dever_Flux_Enhancer.safetensors\", \"strength\": 1}, \"lora_6\": {\"on\": false, \"lora\": \"flux\\\\FredFraiStyle-FLUX-Share.safetensors\", \"strength\": 0.4}, \"lora_7\": {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Wraith_BW_Flux.safetensors\", \"strength\": 0.4}, \"lora_8\": {\"on\": true, \"lora\": \"flux\\\\andreac\\\\The Desolation - s0_7 c7_5.safetensors\", \"strength\": 0.11}, \"lora_9\": {\"on\": true, \"lora\": \"flux\\\\andreac\\\\Dystopia - s0_8 g4.safetensors\", \"strength\": 0.35}, \"lora_10\": {\"on\": true, \"lora\": \"flux\\\\andreac\\\\Luminous_Shadowscape-000016.safetensors\", \"strength\": 0.1}, \"lora_11\": {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Wraith_BW_Flux.safetensors\", \"strength\": 1}, \"lora_12\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\qiu_crayon.safetensors\", \"strength\": 0.4}, \"lora_13\": {\"on\": false, \"lora\": \"flux\\\\style\\\\Eldritch_Parchment_Art_for_Flux_1.0.safetensors\", \"strength\": 0.45}, \"lora_14\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\l0fi2.safetensors\", \"strength\": 0.87}, \"lora_15\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\waterc0l0r3.safetensors\", \"strength\": 0.35}, \"lora_16\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\rosin4.safetensors\", \"strength\": 0.4}, \"lora_17\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\fe4r.safetensors\", \"strength\": 0.6}, \"lora_18\": {\"on\": true, \"lora\": \"flux\\\\mine\\\\gr1m2.safetensors\", \"strength\": 0.33}, \"lora_19\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\PinkiePastelWatercolorFLUX.safetensors\", \"strength\": 0.3}, \"lora_20\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\flat2100.safetensors\", \"strength\": 0.35}, \"lora_21\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\creepcute-000001.safetensors\", \"strength\": 0.57}, \"lora_22\": {\"on\": false, \"lora\": \"flux\\\\cute\\\\CozySpookyStyleFlux.safetensors\", \"strength\": 0.5}, \"lora_23\": {\"on\": false, \"lora\": \"flux\\\\mine\\\\c4mille.safetensors\", \"strength\": 0.25}, \"lora_24\": {\"on\": false, \"lora\": \"flux\\\\illustration-concept.safetensors\", \"strength\": 0.5}, \"lora_25\": {\"on\": false, \"lora\": \"flux\\\\anime\\\\CP-anime.safetensors\", \"strength\": 0.75}, \"\\u2795 Add Lora\": \"\", \"model\": [\"162\", 0], \"clip\": [\"310\", 1]}, \"class_type\": \"Power Lora Loader (rgthree)\", \"_meta\": {\"title\": \"Power Lora Loader (rgthree)\"}}}, \"workflow\": {\"last_node_id\": 329, \"last_link_id\": 1197, \"nodes\": [{\"id\": 113, \"type\": \"ImageBlur\", \"pos\": {\"0\": 5131.90478515625, \"1\": 543.0499877929688}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 79, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1010}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlur\"}, \"widgets_values\": [2, 2]}, {\"id\": 114, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 5131.90478515625, \"1\": 673.0499877929688}, \"size\": {\"0\": 210, \"1\": 110}, \"flags\": {}, \"order\": 80, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1011}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [245], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.5, 0.39999999999999997]}, {\"id\": 115, \"type\": \"ImageBlend\", \"pos\": {\"0\": 5431.90478515625, \"1\": 553.0499877929688}, \"size\": {\"0\": 210, \"1\": 102}, \"flags\": {}, \"order\": 83, \"mode\": 0, \"inputs\": [{\"name\": \"image1\", \"type\": \"IMAGE\", \"link\": 244}, {\"name\": \"image2\", \"type\": \"IMAGE\", \"link\": 245}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [264], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlend\"}, \"widgets_values\": [0.39999999999999997, \"normal\"]}, {\"id\": 122, \"type\": \"ImageApplyLUT+\", \"pos\": {\"0\": 5431.90478515625, \"1\": 703.0499877929688}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 84, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 264}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [441], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageApplyLUT+\"}, \"widgets_values\": [\"FGCineBasic.cube\", true, false, 0.25]}, {\"id\": 131, \"type\": \"ImageResize+\", \"pos\": {\"0\": 5164.080078125, \"1\": 264.54248046875}, \"size\": {\"0\": 210, \"1\": 220}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"width\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageResize+\"}, \"widgets_values\": [2048, 2048, \"bilinear\", \"keep proportion\", \"always\", 16]}, {\"id\": 183, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 6206.048828125, \"1\": 291.586181640625}, \"size\": {\"0\": 220, \"1\": 60}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [522], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 195, \"type\": \"Image Chromatic Aberration\", \"pos\": {\"0\": 6221.583984375, \"1\": 787.2619018554688}, \"size\": {\"0\": 290, \"1\": 154}, \"flags\": {\"pinned\": false}, \"order\": 89, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 413}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [545], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Chromatic Aberration\"}, \"widgets_values\": [2, -1, 1, 0.145, 12]}, {\"id\": 201, \"type\": \"MX_LensOpticAxis\", \"pos\": {\"0\": 6221.583984375, \"1\": 1487.26123046875}, \"size\": {\"0\": 300, \"1\": 200}, \"flags\": {\"pinned\": false}, \"order\": 94, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 418}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [427], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"MX_LensOpticAxis\"}, \"widgets_values\": [\"circle\", \"around\", 8, 2, 0.3, 20]}, {\"id\": 202, \"type\": \"MX_LensBokeh\", \"pos\": {\"0\": 6221.583984375, \"1\": 1257.26123046875}, \"size\": {\"0\": 290, \"1\": 180}, \"flags\": {\"pinned\": false}, \"order\": 92, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 419}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [555], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"MX_LensBokeh\"}, \"widgets_values\": [5, 5, 0, 21, \"bilateral\", \"dilate\"]}, {\"id\": 214, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 2359.248779296875, \"1\": 1280.499755859375}, \"size\": {\"0\": 240, \"1\": 50}, \"flags\": {}, \"order\": 62, \"mode\": 4, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 497, \"slot_index\": 0}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 461}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [463], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"widgets_values\": []}, {\"id\": 232, \"type\": \"Image Filter Adjustments\", \"pos\": {\"0\": 6700.7216796875, \"1\": 783.7971801757812}, \"size\": {\"0\": 290, \"1\": 230}, \"flags\": {}, \"order\": 90, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 545}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [546], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Filter Adjustments\"}, \"widgets_values\": [0, 1, 0.8999999999999999, 1, 0, 0.5, 0, \"false\"]}, {\"id\": 193, \"type\": \"ImageBlend\", \"pos\": {\"0\": 6712.7216796875, \"1\": 1062.796630859375}, \"size\": {\"0\": 300, \"1\": 102}, \"flags\": {\"pinned\": false}, \"order\": 95, \"mode\": 0, \"inputs\": [{\"name\": \"image1\", \"type\": \"IMAGE\", \"link\": 427}, {\"name\": \"image2\", \"type\": \"IMAGE\", \"link\": 426, \"label\": \"grain\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [716], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlend\"}, \"widgets_values\": [0.585, \"overlay\"]}, {\"id\": 190, \"type\": \"LoadImage\", \"pos\": {\"0\": 6672.7216796875, \"1\": 1222.796630859375}, \"size\": {\"0\": 380, \"1\": 470}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [426], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"title\": \"Load Grain\", \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"noise_1.png\", \"image\"]}, {\"id\": 233, \"type\": \"ImageSmartSharpen+\", \"pos\": {\"0\": 6486.048828125, \"1\": 311.586181640625}, \"size\": {\"0\": 320, \"1\": 150}, \"flags\": {}, \"order\": 96, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 716}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [548], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSmartSharpen+\"}, \"widgets_values\": [7, 0.6, 4, 0.3], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 268, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2914.23779296875, \"1\": 272.8445129394531}, \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 3, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [742], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 270, \"type\": \"SAMLoader\", \"pos\": {\"0\": 2922.238037109375, \"1\": 400.8444519042969}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 4, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [743], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 274, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2924.619384765625, \"1\": 536.167724609375}, \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 5, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [744], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/Eyes.pt\"]}, {\"id\": 275, \"type\": \"ImpactNegativeConditioningPlaceholder\", \"pos\": {\"0\": 2968.23828125, \"1\": 791.845703125}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {}, \"order\": 6, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImpactNegativeConditioningPlaceholder\"}, \"widgets_values\": []}, {\"id\": 177, \"type\": \"VAEDecode\", \"pos\": {\"0\": 2587.1826171875, \"1\": 409.3358459472656}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 73, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 651}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [382, 549, 749], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 215, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 2282.248779296875, \"1\": 1160.499755859375}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 7, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [497], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth\"]}, {\"id\": 217, \"type\": \"VAEEncode\", \"pos\": {\"0\": 2647.24853515625, \"1\": 1264.499755859375}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 559}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 210, \"type\": \"ImageApplyLUT+\", \"pos\": {\"0\": 6866.048828125, \"1\": 321.586181640625}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 97, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 548}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [739, 740, 856], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageApplyLUT+\"}, \"widgets_values\": [\"FGCineBasic.cube\", true, false, 0.15]}, {\"id\": 216, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 2315.263427734375, \"1\": 1405.06298828125}, \"size\": {\"0\": 320, \"1\": 82}, \"flags\": {}, \"order\": 66, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 463}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [559], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.75]}, {\"id\": 307, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1465.7099609375, \"1\": 1496.0283203125}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [1166], \"slot_index\": 0, \"shape\": 3}], \"title\": \"User: Prompt\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Create an image prompt from the image provided, be sure to include all details\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 304, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -559.35498046875, \"1\": 1583.5316162109375}, \"size\": {\"0\": 330, \"1\": 240}, \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 1169, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"title\": \"Troubleshooting\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 182, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 6155.048828125, \"1\": 419.5861511230469}, \"size\": {\"0\": 230, \"1\": 50}, \"flags\": {}, \"order\": 87, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 522, \"slot_index\": 0}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1012}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [542], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"widgets_values\": [], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 203, \"type\": \"ImageBlend\", \"pos\": {\"0\": 6732.7216796875, \"1\": 632.7972412109375}, \"size\": {\"0\": 210, \"1\": 102}, \"flags\": {\"pinned\": false}, \"order\": 93, \"mode\": 0, \"inputs\": [{\"name\": \"image1\", \"type\": \"IMAGE\", \"link\": 961}, {\"name\": \"image2\", \"type\": \"IMAGE\", \"link\": 555}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [418], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlend\"}, \"widgets_values\": [0.25, \"overlay\"]}, {\"id\": 197, \"type\": \"Image Bloom Filter\", \"pos\": {\"0\": 6221.583984375, \"1\": 647.2620849609375}, \"size\": {\"0\": 290, \"1\": 82}, \"flags\": {\"pinned\": false}, \"order\": 88, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 542}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [413], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Bloom Filter\"}, \"widgets_values\": [7.5, 0.15]}, {\"id\": 200, \"type\": \"CR Vignette Filter\", \"pos\": {\"0\": 6221.583984375, \"1\": 987.2616577148438}, \"size\": {\"0\": 290, \"1\": 220}, \"flags\": {\"pinned\": false}, \"order\": 91, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 546}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [419, 961], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR Vignette Filter\"}, \"widgets_values\": [\"oval\", 290, 0, 0, 2.5, \"no\"]}, {\"id\": 130, \"type\": \"LoadImage\", \"pos\": {\"0\": 5729.080078125, \"1\": 399.54248046875}, \"size\": {\"0\": 350, \"1\": 430}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [269], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"title\": \"Load Grain\", \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"noise_1.png\", \"image\"]}, {\"id\": 129, \"type\": \"ImageBlend\", \"pos\": {\"0\": 5751.90478515625, \"1\": 243.04981994628906}, \"size\": {\"0\": 310, \"1\": 102}, \"flags\": {\"pinned\": false}, \"order\": 85, \"mode\": 0, \"inputs\": [{\"name\": \"image1\", \"type\": \"IMAGE\", \"link\": 441}, {\"name\": \"image2\", \"type\": \"IMAGE\", \"link\": 269, \"label\": \"grain\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [437, 1012], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlend\"}, \"widgets_values\": [0.5, \"overlay\"]}, {\"id\": 271, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4420.125, \"1\": 302.3706359863281}, \"size\": {\"0\": 602.697509765625, \"1\": 603.713134765625}, \"flags\": {}, \"order\": 78, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 745}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 273, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4151.125, \"1\": 414.3705749511719}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 82, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 747}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 272, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4165.125, \"1\": 742.3707275390625}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 81, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 746}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 279, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2920.1240234375, \"1\": 928.3704833984375}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {}, \"order\": 10, \"mode\": 4, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [756], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"4k, detailed\"]}, {\"id\": 277, \"type\": \"ConditioningZeroOut\", \"pos\": {\"0\": 2943.1240234375, \"1\": 1245.370361328125}, \"size\": {\"0\": 317.4000244140625, \"1\": 26}, \"flags\": {}, \"order\": 11, \"mode\": 4, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [754], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningZeroOut\"}, \"widgets_values\": []}, {\"id\": 88, \"type\": \"SplitSigmas\", \"pos\": {\"0\": 642.6203002929688, \"1\": 926.5843505859375}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 201}], \"outputs\": [{\"name\": \"high_sigmas\", \"type\": \"SIGMAS\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"low_sigmas\", \"type\": \"SIGMAS\", \"links\": [574], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SplitSigmas\"}, \"widgets_values\": [0], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 235, \"type\": \"ImageSmartSharpen+\", \"pos\": {\"0\": 3596, \"1\": -1134}, \"size\": {\"0\": 320, \"1\": 150}, \"flags\": {}, \"order\": 75, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 549}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [550], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSmartSharpen+\"}, \"widgets_values\": [7, 0.09999999999999999, 5, 0.3]}, {\"id\": 266, \"type\": \"SaveImage\", \"pos\": {\"0\": 6914, \"1\": -806}, \"size\": {\"0\": 1233.49755859375, \"1\": 910.6647338867188}, \"flags\": {}, \"order\": 99, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 740}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux-llm/october2024/face-detailer-fluxtm_pass3\"]}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": {\"0\": 1514, \"1\": -684}, \"size\": {\"0\": 1311.5146484375, \"1\": 846.7225341796875}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 270}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux-llm/october2024/fluxtm_pass1\"]}, {\"id\": 229, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4214, \"1\": -746}, \"size\": {\"0\": 1205.792236328125, \"1\": 893.1575927734375}, \"flags\": {}, \"order\": 77, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 550}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 282, \"type\": \"LayerUtility: SaveImagePlus\", \"pos\": {\"0\": 7200, \"1\": 298}, \"size\": {\"0\": 959.8567504882812, \"1\": 800.9364013671875}, \"flags\": {}, \"order\": 100, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 856}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"LayerUtility: SaveImagePlus\"}, \"widgets_values\": [\"D:\\\\20240703-ComfyUI_windows_portable\\\\ComfyUI\\\\output\\\\JPG\", \"flux-jpg_\", \"None\", \"jpg\", 100, false, \"\", false, true], \"color\": \"rgba(38, 73, 116, 0.7)\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 640.6203002929688, \"1\": 639.5843505859375}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpmpp_2m\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 265, \"type\": \"PreviewImage\", \"pos\": {\"0\": 8221, \"1\": 190}, \"size\": {\"0\": 868.730712890625, \"1\": 1047.8509521484375}, \"flags\": {}, \"order\": 98, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 739}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 634.6203002929688, \"1\": 764.5843505859375}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 512, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [201], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"beta\", 35, 1], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1208.6202392578125, \"1\": 257.5846252441406}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 649}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [270, 357, 461], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 321, \"type\": \"ImageResize+\", \"pos\": {\"0\": 284.45709228515625, \"1\": 2003.6904296875}, \"size\": {\"0\": 315, \"1\": 218}, \"flags\": {}, \"order\": 40, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1123}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 1130, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 1131, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1126], \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"links\": null}, {\"name\": \"height\", \"type\": \"INT\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"ImageResize+\"}, \"widgets_values\": [512, 512, \"nearest-exact\", \"stretch\", \"always\", 0]}, {\"id\": 324, \"type\": \"CR Draw Shape\", \"pos\": {\"0\": 649.4569091796875, \"1\": 1915.6904296875}, \"size\": {\"0\": 315, \"1\": 318}, \"flags\": {}, \"order\": 13, \"mode\": 4, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [], \"slot_index\": 0}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"CR Draw Shape\"}, \"widgets_values\": [512, 512, \"circle\", \"maroon\", \"custom\", 0, 0, 1, 0, \"#000000\", \"#000000\"]}, {\"id\": 325, \"type\": \"CR Image Input Switch\", \"pos\": {\"0\": 598.4569091796875, \"1\": 1737.6904296875}, \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 50, \"mode\": 4, \"inputs\": [{\"name\": \"image1\", \"type\": \"IMAGE\", \"link\": 1125, \"shape\": 7}, {\"name\": \"image2\", \"type\": \"IMAGE\", \"link\": 1126, \"shape\": 7}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1122], \"slot_index\": 0}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"CR Image Input Switch\"}, \"widgets_values\": [1]}, {\"id\": 320, \"type\": \"VAEEncode\", \"pos\": {\"0\": 602.4569091796875, \"1\": 1625.6904296875}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 54, \"mode\": 4, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 1122}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [1127], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 292, \"type\": \"ImageResizeKJ\", \"pos\": {\"0\": 1544.219482421875, \"1\": 1783.855224609375}, \"size\": {\"0\": 221.56483459472656, \"1\": 238}, \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 821}, {\"name\": \"get_image_size\", \"type\": \"IMAGE\", \"link\": 823, \"shape\": 7}, {\"name\": \"width_input\", \"type\": \"INT\", \"link\": null, \"widget\": {\"name\": \"width_input\"}}, {\"name\": \"height_input\", \"type\": \"INT\", \"link\": null, \"widget\": {\"name\": \"height_input\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [822], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"width\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageResizeKJ\"}, \"widgets_values\": [1024, 1024, \"bicubic\", true, 16, 0, 0, \"disabled\"]}, {\"id\": 135, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1060.437255859375, \"1\": 1622.234375}, \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 822}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 123, \"type\": \"PreviewImage\", \"pos\": {\"0\": 5489, \"1\": -792}, \"size\": {\"0\": 1368.8475341796875, \"1\": 917.8621826171875}, \"flags\": {}, \"order\": 86, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 437}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 262, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1434.1796875, \"1\": 689.438232421875}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [1160], \"slot_index\": 0, \"shape\": 3}], \"title\": \"User: Prompt\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Create an image prompt from the image provided, be sure to include all details\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 260, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1422.1796875, \"1\": 870.438232421875}, \"size\": {\"0\": 390, \"1\": 220}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [1159], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Examples\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Hyperrealism, low-angle shot, cold, diffused lighting with a bluish tint, illuminating the hulking bear warrior clad in spiked, frost-covered armor. His muscular form, topped by a massive white bear head with glowing blue eyes, wields a massive double-bladed axe made of ice, frost vapor rising from its surface. His fur, adorned with various talismans and furs, flows in the wind as snow swirls around him. The backdrop features jagged, ice-encrusted mountains under a bleak, overcast sky, creating a foreboding arctic battleground.\\n\\nBear warrior, ice axe, spiked armor, icy mountains, snowstorm.\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 149, \"type\": \"BasicGuider\", \"pos\": {\"0\": 705.6202392578125, \"1\": 524.5843505859375}, \"size\": {\"0\": 220, \"1\": 50}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 701, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": null, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [306], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": [], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 306, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1449.394775390625, \"1\": 1261.063232421875}, \"size\": {\"0\": 390.9617004394531, \"1\": 174.10166931152344}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [1170], \"slot_index\": 0, \"shape\": 3}], \"title\": \"System: Instructions\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Enhance this prompt for a Stable Diffusion image to optimize it for Clip-L text encoder.\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\\nEmphasize key information about the subject, scene, details, effects as needed. Stick with short comma-delimited prompts. start with the art style, then subject, then details like pose, camera angle.\\n\\nNote that Clip-L focuses on specific visual elements and technical details. It lists concrete objects, visual attributes, and effects. Use for specific visual elements and attributes.\\n\\nHere is an example Clip-L prompt that you might model:\\noil painting, Iron Man, space, satellite repair, extreme close-up, helmet reflections, Earth, stars, Rodenstock HR Digaron-W 50mm lens, f/5.6, 1/2000s, ISO 100, high dynamic range, lens flares, atmospheric glow, cold metallic tones, warm Earth glow\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 305, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1449.394775390625, \"1\": 1651.0634765625}, \"size\": {\"0\": 390, \"1\": 220}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Examples\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Hyperrealism, low-angle shot, cold, diffused lighting with a bluish tint, illuminating the hulking bear warrior clad in spiked, frost-covered armor. His muscular form, topped by a massive white bear head with glowing blue eyes, wields a massive double-bladed axe made of ice, frost vapor rising from its surface. His fur, adorned with various talismans and furs, flows in the wind as snow swirls around him. The backdrop features jagged, ice-encrusted mountains under a bleak, overcast sky, creating a foreboding arctic battleground.\\n\\nBear warrior, ice axe, spiked armor, icy mountains, snowstorm.\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 328, \"type\": \"AdvPromptEnhancer\", \"pos\": {\"0\": -992.3955078125, \"1\": 1311.0631103515625}, \"size\": {\"0\": 400, \"1\": 434}, \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"Add_Parameter\", \"type\": \"LIST\", \"link\": null, \"shape\": 7}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1171, \"shape\": 7}, {\"name\": \"Instruction\", \"type\": \"STRING\", \"link\": 1170, \"widget\": {\"name\": \"Instruction\"}, \"shape\": 7}, {\"name\": \"Examples_or_Context\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"Examples_or_Context\"}, \"shape\": 7}, {\"name\": \"Prompt\", \"type\": \"STRING\", \"link\": 1166, \"widget\": {\"name\": \"Prompt\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"LLMprompt\", \"type\": \"STRING\", \"links\": [1167, 1168]}, {\"name\": \"Context\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"Help\", \"type\": \"STRING\", \"links\": [1169]}, {\"name\": \"Troubleshooting\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"AdvPromptEnhancer\"}, \"widgets_values\": [\"ChatGPT\", \"chatgpt-4o-latest\", \"none\", \"none\", \"none\", \"none\", 0.7, 500, 341641286596912, \"randomize\", \"Two newlines\", \"https://api.groq.com/openai/v1\", \"\", \"\", \"\"]}, {\"id\": 261, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1459.1796875, \"1\": 251.43829345703125}, \"size\": {\"0\": 425.0143127441406, \"1\": 360.5466613769531}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [1164], \"slot_index\": 0, \"shape\": 3}], \"title\": \"System: Instructions\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Act as a creative agent who generates highly creative detailed, comma-delimited formatted prompt of up to 150 words for the image. Begin each prompt by specifying an art style (for example, cartoon, impasto, absurdres, oil or acrylic or watercolor painting, or charcoal drawing or engraving or sculpture, etc.)  Include information about lighting. Include information about camera angle. Include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.Do NOT mention any text that is in the image.Specify the depth of field and whether the background is in focus or blurred.Do NOT use any ambiguous language. Include the pose of the subject. Then, continue with descriptive visual elements of the subject, surroundings, and background. Please do not omit any details, especially objects, lighting, colors, and textures, even subtle ones hidden in the background! It is imperative that you carefully consider every aspect of the image, and provide satisfactory descriptions! Also, please be very careful when considering whether the image really is a photograph or actually a detailed painting or illustration.\\n\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 294, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 825.6202392578125, \"1\": 1429.5845947265625}, \"size\": {\"0\": 159.60000610351562, \"1\": 26}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"VAE\", \"type\": \"*\", \"link\": 817, \"color_on\": \"#FF6E6E\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 822.6202392578125, \"1\": 1322.5845947265625}, \"size\": {\"0\": 210, \"1\": 60}, \"flags\": {\"collapsed\": true}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [817], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae-dev.sft\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 283, \"type\": \"LoadImage\", \"pos\": {\"0\": 1077.437255859375, \"1\": 1748.234375}, \"size\": {\"0\": 436.0301513671875, \"1\": 315.822021484375}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [821, 823], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"the_queen_s_last_stand_by_socialgatheringstar_dicxt1r-pre.jpg\", \"image\"]}, {\"id\": 269, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 3576.124267578125, \"1\": 276.3706359863281}, \"size\": {\"0\": 506.4000244140625, \"1\": 1272}, \"flags\": {}, \"order\": 76, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 749, \"slot_index\": 0}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 751}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null, \"slot_index\": 2}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null, \"slot_index\": 3}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 756, \"slot_index\": 4}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 754, \"slot_index\": 5}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 742}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 743, \"shape\": 7}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 744, \"shape\": 7}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null, \"shape\": 7}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [745, 1010, 1011], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [746], \"slot_index\": 1, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [747], \"slot_index\": 2, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [1024, true, 1536, 822633388397867, \"randomize\", 15, 1, \"euler\", \"simple\", 0.25, 7, true, true, 0.7000000000000001, 50, 2, \"center-1\", 11, 0.93, 10, 0.7, \"False\", 30, \"\", 1, false, 10]}, {\"id\": 159, \"type\": \"SaveImage\", \"pos\": {\"0\": 2953, \"1\": -758}, \"size\": {\"0\": 1150.7386474609375, \"1\": 882.4022827148438}, \"flags\": {}, \"order\": 74, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 382}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux-llm/october2024/fluxtm_pass2\"]}, {\"id\": 318, \"type\": \"SamplerRES_Implicit\", \"pos\": {\"0\": 1090.6202392578125, \"1\": 947.5843505859375}, \"size\": {\"0\": 315, \"1\": 526}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"alphas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide\", \"type\": \"LATENT\", \"link\": 1127, \"shape\": 7}, {\"name\": \"latent_guide_weights\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [1087], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SamplerRES_Implicit\"}, \"widgets_values\": [0.5, 0, 0, 0, 1, 1, 0, 1, \"brownian\", \"hard\", 1, false, 0, 1, 1, 1, 0.1, 0.04]}, {\"id\": 303, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -579, \"1\": 1340}, \"size\": {\"0\": 396.9629211425781, \"1\": 178.00289916992188}, \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 1167, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 6}], \"title\": \"LLM Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"dark fantasy painting, ominous armored warrior, dark spiked crown, tattered red cape blowing in the wind, holding a glowing sword, facing a massive ancient stone monolith with intricate carvings, swirling stormy sky, burning embers in the air, charred ground with dead twisted trees, dramatic lighting, apocalyptic atmosphere, highly detailed, dark and moody colors, epic scale\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 322, \"type\": \"CR Color Gradient\", \"pos\": {\"0\": -98, \"1\": 1599}, \"size\": {\"0\": 315, \"1\": 270}, \"flags\": {}, \"order\": 39, \"mode\": 4, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 1128, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 1129, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1124, 1125], \"slot_index\": 0}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"CR Color Gradient\"}, \"widgets_values\": [512, 512, \"black\", \"orange\", 0.7000000000000001, 0.5, \"vertical\", \"#000000\", \"#000000\"]}, {\"id\": 323, \"type\": \"PreviewImage\", \"pos\": {\"0\": 286, \"1\": 1642}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 49, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 1124}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 319, \"type\": \"LoadImage\", \"pos\": {\"0\": -98, \"1\": 1922}, \"size\": {\"0\": 315, \"1\": 314}, \"flags\": {}, \"order\": 21, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1123], \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ComfyUI_CS_00041_.png\", \"image\"]}, {\"id\": 327, \"type\": \"AdvPromptEnhancer\", \"pos\": {\"0\": -1004.1797485351562, \"1\": 253.43829345703125}, \"size\": {\"0\": 400, \"1\": 434}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"Add_Parameter\", \"type\": \"LIST\", \"link\": null, \"shape\": 7}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1165, \"shape\": 7}, {\"name\": \"Instruction\", \"type\": \"STRING\", \"link\": 1164, \"widget\": {\"name\": \"Instruction\"}, \"shape\": 7}, {\"name\": \"Examples_or_Context\", \"type\": \"STRING\", \"link\": 1159, \"widget\": {\"name\": \"Examples_or_Context\"}, \"shape\": 7}, {\"name\": \"Prompt\", \"type\": \"STRING\", \"link\": 1160, \"widget\": {\"name\": \"Prompt\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"LLMprompt\", \"type\": \"STRING\", \"links\": [1161, 1162]}, {\"name\": \"Context\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"Help\", \"type\": \"STRING\", \"links\": [1163]}, {\"name\": \"Troubleshooting\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"AdvPromptEnhancer\"}, \"widgets_values\": [\"ChatGPT\", \"chatgpt-4o-latest\", \"none\", \"none\", \"none\", \"none\", 0.7, 300, 1113614524899378, \"randomize\", \"Two newlines\", \"https://api.groq.com/openai/v1\", \"\", \"\", \"\"]}, {\"id\": 257, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -583, \"1\": 256}, \"size\": {\"0\": 414.07562255859375, \"1\": 249.64144897460938}, \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 1161, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 6}], \"title\": \"LLM Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"Dark fantasy painting, low-angle side shot, dramatic lighting with a strong contrast between the glowing orange-red ground and the cloudy, foreboding sky. A towering, armored figure stands in profile, holding a massive sword with an ornate hilt that gleams faintly in the dim light. The figure wears a tattered, blood-red cape, blowing in the wind, the fabric fraying into sharp tendrils. The figure's head is crowned with sharp, spiked horns. In front of the figure is a massive, intricately carved stone monolith, partially illuminated with a soft yellow glow, casting deep shadows across its surface. The ground is a mix of barren black branches and glowing embers, creating a hellish atmosphere. The background is a stormy sky, with dark clouds swirling ominously, giving the scene an apocalyptic tone. The composition uses leading lines from the ground toward the monolith, enhancing the figure's sense of purpose.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 259, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -537, \"1\": 604}, \"size\": {\"0\": 330, \"1\": 240}, \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 1163, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"title\": \"Troubleshooting\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 171, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 2457, \"1\": 525}, \"size\": {\"0\": 360, \"1\": 510}, \"flags\": {}, \"order\": 72, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 370, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 373, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 1076, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 824, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 708, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [651], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 206, \"type\": \"Float\", \"pos\": {\"0\": 2255, \"1\": 969}, \"size\": {\"0\": 234.21751403808594, \"1\": 71.93257141113281}, \"flags\": {\"collapsed\": true}, \"order\": 22, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": [433, 434, 435], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Upscale Amount\", \"properties\": {\"Node name for S&R\": \"Float\"}, \"widgets_values\": [\"1.5\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 179, \"type\": \"LatentUpscaleBy\", \"pos\": {\"0\": 2250, \"1\": 913}, \"size\": {\"0\": 230, \"1\": 290}, \"flags\": {\"collapsed\": true}, \"order\": 63, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 864}, {\"name\": \"scale_by\", \"type\": \"FLOAT\", \"link\": 433, \"widget\": {\"name\": \"scale_by\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [708], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentUpscaleBy\"}, \"widgets_values\": [\"bicubic\", 1.5], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 172, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 2204, \"1\": 761}, \"size\": {\"0\": 213.107421875, \"1\": 75.3262710571289}, \"flags\": {\"collapsed\": false}, \"order\": 23, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [1076], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpmpp_2m\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 176, \"type\": \"BasicGuider\", \"pos\": {\"0\": 2192, \"1\": 652}, \"size\": {\"0\": 220, \"1\": 50}, \"flags\": {}, \"order\": 69, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 702, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": null, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [373], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": [], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 175, \"type\": \"RandomNoise\", \"pos\": {\"0\": 2179, \"1\": 511}, \"size\": {\"0\": 240, \"1\": 82}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [370], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4390, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 169, \"type\": \"SimpleMath+\", \"pos\": {\"0\": 1963, \"1\": 447}, \"size\": {\"0\": 210, \"1\": 98}, \"flags\": {\"collapsed\": true}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"a\", \"type\": \"*\", \"link\": 358, \"shape\": 7}, {\"name\": \"b\", \"type\": \"*\", \"link\": 435, \"shape\": 7}, {\"name\": \"c\", \"type\": \"*\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [360], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SimpleMath+\"}, \"widgets_values\": [\"a*b\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 168, \"type\": \"GetImageSize+\", \"pos\": {\"0\": 1957, \"1\": 504}, \"size\": {\"0\": 210, \"1\": 70}, \"flags\": {\"collapsed\": true}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 357}], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [358], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [359], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"count\", \"type\": \"INT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"GetImageSize+\"}, \"widgets_values\": [], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 170, \"type\": \"SimpleMath+\", \"pos\": {\"0\": 1975, \"1\": 562}, \"size\": {\"0\": 210, \"1\": 98}, \"flags\": {\"collapsed\": true}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"a\", \"type\": \"*\", \"link\": 359, \"shape\": 7}, {\"name\": \"b\", \"type\": \"*\", \"link\": 434, \"shape\": 7}, {\"name\": \"c\", \"type\": \"*\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [361], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SimpleMath+\"}, \"widgets_values\": [\"a*b\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 173, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1926, \"1\": 625}, \"size\": {\"0\": 214.2251739501953, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 71, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 1183, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [824], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"beta\", 20, 0.52], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 299, \"type\": \"InjectLatentNoise+\", \"pos\": {\"0\": 1922, \"1\": 805}, \"size\": {\"0\": 249.36546325683594, \"1\": 153.384765625}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"latent\", \"type\": \"LATENT\", \"link\": 863}, {\"name\": \"mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [864], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"InjectLatentNoise+\"}, \"widgets_values\": [456550, \"fixed\", 0.9, \"false\"]}, {\"id\": 162, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 1891, \"1\": 278}, \"size\": {\"0\": 210, \"1\": 122}, \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 966}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 360, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 361, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [702, 751, 1182], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [0.9349999999999999, 0.96, 1024, 1024], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1010, \"1\": 355}, \"size\": {\"0\": 410, \"1\": 530}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 306, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 1087, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 574, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 1115, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [649, 863], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 284, \"type\": \"Fast Groups Bypasser (rgthree)\", \"pos\": {\"0\": 238, \"1\": 270}, \"size\": {\"0\": 348.9783935546875, \"1\": 370}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -102, \"1\": 290}, \"size\": {\"0\": 250, \"1\": 82}, \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"title\": \"1-Load Diffusion Model\", \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev.sft\", \"fp8_e4m3fn\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 250, \"type\": \"UnetLoaderGGUF\", \"pos\": {\"0\": -100, \"1\": 429}, \"size\": {\"0\": 249.33106994628906, \"1\": 58}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [1089], \"slot_index\": 0, \"shape\": 3}], \"title\": \"2-Unet Loader (GGUF)\", \"properties\": {\"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q8_0.gguf\"]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -101, \"1\": 548}, \"size\": {\"0\": 262.3774719238281, \"1\": 106}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [964], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp16.safetensors\", \"Long-ViT-L-14-GmP-ft.safetensors\", \"flux\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 298, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": -84, \"1\": 716}, \"size\": {\"0\": 239.40000915527344, \"1\": 26}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"CLIP\", \"type\": \"*\", \"link\": 967, \"color_on\": \"#FFD500\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 295, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": -83, \"1\": 811}, \"size\": {\"0\": 239.40000915527344, \"1\": 26}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"CONDITIONING\", \"type\": \"*\", \"link\": 819, \"color_on\": \"#FFA931\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 241, \"type\": \"CLIPTextEncodeFlux\", \"pos\": {\"0\": -113, \"1\": 904}, \"size\": {\"0\": 276.3254699707031, \"1\": 164.0474090576172}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"t5xxl\", \"type\": \"STRING\", \"link\": 1162, \"widget\": {\"name\": \"t5xxl\"}}, {\"name\": \"clip_l\", \"type\": \"STRING\", \"link\": 1168, \"widget\": {\"name\": \"clip_l\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [819], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncodeFlux\"}, \"widgets_values\": [\"hyper-detailed, 4k, art deco, d13s3lp2nk,\", \"\", 2.9000000000000004]}, {\"id\": 317, \"type\": \"SamplerRES3_Implicit\", \"pos\": {\"0\": 248, \"1\": 706}, \"size\": {\"0\": 315, \"1\": 738}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"alphas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide\", \"type\": \"LATENT\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_weights\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}, {\"name\": \"automation\", \"type\": \"AUTOMATION\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SamplerRES3_Implicit\"}, \"widgets_values\": [0, 0, 0.5, 0, 0, 0, 1, 1, 1, 0, 1, \"brownian\", \"hard\", 0.5, 1, false, 0, 0, 1, 1, 1, 1, 0.1, 1, 0.1, 1]}, {\"id\": 247, \"type\": \"ODESamplerSelect\", \"pos\": {\"0\": 802, \"1\": 860}, \"size\": {\"0\": 350.1330261230469, \"1\": 174.8228759765625}, \"flags\": {\"collapsed\": true}, \"order\": 30, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ODESamplerSelect\"}, \"widgets_values\": [\"bosh3\", -2.5, -3.5, 30]}, {\"id\": 152, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 663, \"1\": 1114}, \"size\": {\"0\": 210, \"1\": 122}, \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 965}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 318, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 319, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [512, 701], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 1024, 1024], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 669.6202392578125, \"1\": 369.5846252441406}, \"size\": {\"0\": 280, \"1\": 82}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [731, \"increment\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 329, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": {\"0\": 949, \"1\": -579}, \"size\": {\"0\": 360.3953857421875, \"1\": 733.7875366210938}, \"flags\": {}, \"order\": 70, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 1182, \"dir\": 3}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null, \"dir\": 3}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [1183], \"slot_index\": 0, \"shape\": 3, \"dir\": 4}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [], \"shape\": 3, \"dir\": 4}], \"properties\": {\"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": false, \"lora\": \"flux\\\\style\\\\Fresco-000003.safetensors\", \"strength\": 0.6, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\details\\\\FluxDFaeTasticDetails.safetensors\", \"strength\": 0.26, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\style\\\\Watercolor_ALDMHT.safetensors\", \"strength\": 0.35, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\style\\\\ob-watercolor.safetensors\", \"strength\": 0.5, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\details\\\\Dever_Flux_Enhancer.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\FredFraiStyle-FLUX-Share.safetensors\", \"strength\": 0.4, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Wraith_BW_Flux.safetensors\", \"strength\": 0.4, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"flux\\\\andreac\\\\The Desolation - s0_7 c7_5.safetensors\", \"strength\": 0.11, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"flux\\\\andreac\\\\Dystopia - s0_8 g4.safetensors\", \"strength\": 0.35, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"flux\\\\andreac\\\\Luminous_Shadowscape-000016.safetensors\", \"strength\": 0.1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Wraith_BW_Flux.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\qiu_crayon.safetensors\", \"strength\": 0.4, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\style\\\\Eldritch_Parchment_Art_for_Flux_1.0.safetensors\", \"strength\": 0.45, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\l0fi2.safetensors\", \"strength\": 0.87, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\waterc0l0r3.safetensors\", \"strength\": 0.35, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\rosin4.safetensors\", \"strength\": 0.4, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\fe4r.safetensors\", \"strength\": 0.6, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"flux\\\\mine\\\\gr1m2.safetensors\", \"strength\": 0.33, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\PinkiePastelWatercolorFLUX.safetensors\", \"strength\": 0.3, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\flat2100.safetensors\", \"strength\": 0.35, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\creepcute-000001.safetensors\", \"strength\": 0.57, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\CozySpookyStyleFlux.safetensors\", \"strength\": 0.5, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\c4mille.safetensors\", \"strength\": 0.25, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\illustration-concept.safetensors\", \"strength\": 0.5, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\anime\\\\CP-anime.safetensors\", \"strength\": 0.75, \"strengthTwo\": null}, null, \"\"]}, {\"id\": 263, \"type\": \"LoadImage\", \"pos\": {\"0\": -975.1797485351562, \"1\": 798.438232421875}, \"size\": {\"0\": 320, \"1\": 314}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1165, 1171], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"the_crimson_king_s_oath_by_socialgatheringstar_dib9tr5-pre.jpg\", \"image\"], \"color\": \"#155588\", \"bgcolor\": \"#29699c\"}, {\"id\": 32, \"type\": \"SDXLEmptyLatentSizePicker+\", \"pos\": {\"0\": -102, \"1\": 1204}, \"size\": {\"0\": 270, \"1\": 170}, \"flags\": {\"collapsed\": false}, \"order\": 33, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [1115], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"width\", \"type\": \"INT\", \"links\": [318, 1128, 1130], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [319, 1129, 1131], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SDXLEmptyLatentSizePicker+\"}, \"widgets_values\": [\"1344x768 (1.75)\", 1, 0, 0], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 310, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": {\"0\": 542, \"1\": -575}, \"size\": {\"0\": 360.3953857421875, \"1\": 733.7875366210938}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 1089, \"dir\": 3}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 964, \"dir\": 3}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [965, 966], \"shape\": 3, \"dir\": 4}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [967], \"shape\": 3, \"dir\": 4}], \"properties\": {\"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": false, \"lora\": \"flux\\\\style\\\\Fresco-000003.safetensors\", \"strength\": 0.6, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\details\\\\FluxDFaeTasticDetails.safetensors\", \"strength\": 0.51, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\style\\\\Watercolor_ALDMHT.safetensors\", \"strength\": 0.35, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\style\\\\ob-watercolor.safetensors\", \"strength\": 0.5, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\details\\\\Dever_Flux_Enhancer.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\FredFraiStyle-FLUX-Share.safetensors\", \"strength\": 0.55, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Wraith_BW_Flux.safetensors\", \"strength\": 0.4, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"flux\\\\andreac\\\\The Desolation - s0_7 c7_5.safetensors\", \"strength\": 0.25, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"flux\\\\andreac\\\\Dystopia - s0_8 g4.safetensors\", \"strength\": 0.45, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Luminous_Shadowscape-000016.safetensors\", \"strength\": 0.2, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\andreac\\\\Wraith_BW_Flux.safetensors\", \"strength\": 1, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\qiu_crayon.safetensors\", \"strength\": 0.4, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\style\\\\Eldritch_Parchment_Art_for_Flux_1.0.safetensors\", \"strength\": 0.45, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\l0fi2.safetensors\", \"strength\": 0.87, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\waterc0l0r3.safetensors\", \"strength\": 0.35, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\rosin4.safetensors\", \"strength\": 0.4, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\fe4r.safetensors\", \"strength\": 0.6, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"flux\\\\mine\\\\gr1m2.safetensors\", \"strength\": 0.78, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\PinkiePastelWatercolorFLUX.safetensors\", \"strength\": 0.3, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\flat2100.safetensors\", \"strength\": 0.35, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\creepcute-000001.safetensors\", \"strength\": 0.57, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\cute\\\\CozySpookyStyleFlux.safetensors\", \"strength\": 0.5, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\mine\\\\c4mille.safetensors\", \"strength\": 0.25, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\illustration-concept.safetensors\", \"strength\": 0.5, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\anime\\\\CP-anime.safetensors\", \"strength\": 0.75, \"strengthTwo\": null}, null, \"\"]}], \"links\": [[37, 25, 0, 13, 0, \"NOISE\"], [201, 17, 0, 88, 0, \"SIGMAS\"], [244, 113, 0, 115, 0, \"IMAGE\"], [245, 114, 0, 115, 1, \"IMAGE\"], [264, 115, 0, 122, 0, \"IMAGE\"], [269, 130, 0, 129, 1, \"IMAGE\"], [270, 8, 0, 9, 0, \"IMAGE\"], [306, 149, 0, 13, 1, \"GUIDER\"], [318, 32, 1, 152, 1, \"INT\"], [319, 32, 2, 152, 2, \"INT\"], [357, 8, 0, 168, 0, \"IMAGE\"], [358, 168, 0, 169, 0, \"INT,FLOAT\"], [359, 168, 1, 170, 0, \"INT,FLOAT\"], [360, 169, 0, 162, 1, \"INT\"], [361, 170, 0, 162, 2, \"INT\"], [370, 175, 0, 171, 0, \"NOISE\"], [373, 176, 0, 171, 1, \"GUIDER\"], [382, 177, 0, 159, 0, \"IMAGE\"], [413, 197, 0, 195, 0, \"IMAGE\"], [418, 203, 0, 201, 0, \"IMAGE\"], [419, 200, 0, 202, 0, \"IMAGE\"], [426, 190, 0, 193, 1, \"IMAGE\"], [427, 201, 0, 193, 0, \"IMAGE\"], [433, 206, 0, 179, 1, \"FLOAT\"], [434, 206, 0, 170, 1, \"INT,FLOAT\"], [435, 206, 0, 169, 1, \"INT,FLOAT\"], [437, 129, 0, 123, 0, \"IMAGE\"], [441, 122, 0, 129, 0, \"IMAGE\"], [461, 8, 0, 214, 1, \"IMAGE\"], [463, 214, 0, 216, 0, \"IMAGE\"], [497, 215, 0, 214, 0, \"UPSCALE_MODEL\"], [512, 152, 0, 17, 0, \"MODEL\"], [522, 183, 0, 182, 0, \"UPSCALE_MODEL\"], [542, 182, 0, 197, 0, \"IMAGE\"], [545, 195, 0, 232, 0, \"IMAGE\"], [546, 232, 0, 200, 0, \"IMAGE\"], [548, 233, 0, 210, 0, \"IMAGE\"], [549, 177, 0, 235, 0, \"IMAGE\"], [550, 235, 0, 229, 0, \"IMAGE\"], [555, 202, 0, 203, 1, \"IMAGE\"], [559, 216, 0, 217, 0, \"IMAGE\"], [574, 88, 1, 13, 3, \"SIGMAS\"], [649, 13, 1, 8, 0, \"LATENT\"], [651, 171, 1, 177, 0, \"LATENT\"], [701, 152, 0, 149, 0, \"MODEL\"], [702, 162, 0, 176, 0, \"MODEL\"], [708, 179, 0, 171, 4, \"LATENT\"], [716, 193, 0, 233, 0, \"IMAGE\"], [739, 210, 0, 265, 0, \"IMAGE\"], [740, 210, 0, 266, 0, \"IMAGE\"], [742, 268, 0, 269, 6, \"BBOX_DETECTOR\"], [743, 270, 0, 269, 7, \"SAM_MODEL\"], [744, 274, 1, 269, 8, \"SEGM_DETECTOR\"], [745, 269, 0, 271, 0, \"IMAGE\"], [746, 269, 1, 272, 0, \"IMAGE\"], [747, 269, 2, 273, 0, \"IMAGE\"], [749, 177, 0, 269, 0, \"IMAGE\"], [751, 162, 0, 269, 1, \"MODEL\"], [754, 277, 0, 269, 5, \"CONDITIONING\"], [756, 279, 0, 269, 4, \"CONDITIONING\"], [817, 10, 0, 294, 0, \"VAE\"], [819, 241, 0, 295, 0, \"CONDITIONING\"], [821, 283, 0, 292, 0, \"IMAGE\"], [822, 292, 0, 135, 0, \"IMAGE\"], [823, 283, 0, 292, 1, \"IMAGE\"], [824, 173, 0, 171, 3, \"SIGMAS\"], [826, 10, 0, 177, 1, \"VAE\"], [827, 10, 0, 8, 1, \"VAE\"], [828, 10, 0, 135, 1, \"VAE\"], [829, 241, 0, 149, 1, \"CONDITIONING\"], [830, 241, 0, 176, 1, \"CONDITIONING\"], [831, 10, 0, 177, 1, \"VAE\"], [832, 10, 0, 8, 1, \"VAE\"], [833, 10, 0, 135, 1, \"VAE\"], [834, 241, 0, 149, 1, \"CONDITIONING\"], [835, 241, 0, 176, 1, \"CONDITIONING\"], [836, 10, 0, 177, 1, \"VAE\"], [837, 10, 0, 8, 1, \"VAE\"], [838, 10, 0, 135, 1, \"VAE\"], [839, 241, 0, 149, 1, \"CONDITIONING\"], [840, 241, 0, 176, 1, \"CONDITIONING\"], [848, 10, 0, 177, 1, \"VAE\"], [849, 10, 0, 8, 1, \"VAE\"], [850, 241, 0, 149, 1, \"CONDITIONING\"], [851, 241, 0, 176, 1, \"CONDITIONING\"], [852, 10, 0, 135, 1, \"VAE\"], [856, 210, 0, 282, 0, \"IMAGE\"], [863, 13, 1, 299, 0, \"LATENT\"], [864, 299, 0, 179, 0, \"LATENT\"], [867, 10, 0, 177, 1, \"VAE\"], [868, 241, 0, 149, 1, \"CONDITIONING\"], [869, 241, 0, 176, 1, \"CONDITIONING\"], [870, 249, 1, 269, 2, \"CLIP\"], [871, 10, 0, 269, 3, \"VAE\"], [872, 249, 1, 279, 0, \"CLIP\"], [873, 241, 0, 277, 0, \"CONDITIONING\"], [874, 10, 0, 135, 1, \"VAE\"], [875, 10, 0, 8, 1, \"VAE\"], [876, 249, 1, 241, 0, \"CLIP\"], [881, 10, 0, 177, 1, \"VAE\"], [882, 241, 0, 149, 1, \"CONDITIONING\"], [883, 241, 0, 176, 1, \"CONDITIONING\"], [884, 249, 1, 279, 0, \"CLIP\"], [885, 241, 0, 277, 0, \"CONDITIONING\"], [886, 10, 0, 8, 1, \"VAE\"], [887, 10, 0, 135, 1, \"VAE\"], [888, 249, 1, 241, 0, \"CLIP\"], [891, 10, 0, 177, 1, \"VAE\"], [892, 241, 0, 149, 1, \"CONDITIONING\"], [893, 241, 0, 176, 1, \"CONDITIONING\"], [894, 249, 1, 269, 2, \"CLIP\"], [895, 10, 0, 269, 3, \"VAE\"], [896, 249, 1, 279, 0, \"CLIP\"], [897, 241, 0, 277, 0, \"CONDITIONING\"], [898, 10, 0, 8, 1, \"VAE\"], [899, 10, 0, 135, 1, \"VAE\"], [900, 249, 1, 241, 0, \"CLIP\"], [901, 10, 0, 177, 1, \"VAE\"], [902, 241, 0, 149, 1, \"CONDITIONING\"], [903, 241, 0, 176, 1, \"CONDITIONING\"], [904, 249, 1, 269, 2, \"CLIP\"], [905, 10, 0, 269, 3, \"VAE\"], [906, 249, 1, 279, 0, \"CLIP\"], [907, 241, 0, 277, 0, \"CONDITIONING\"], [908, 10, 0, 8, 1, \"VAE\"], [909, 10, 0, 135, 1, \"VAE\"], [910, 249, 1, 241, 0, \"CLIP\"], [917, 10, 0, 177, 1, \"VAE\"], [918, 241, 0, 149, 1, \"CONDITIONING\"], [919, 241, 0, 176, 1, \"CONDITIONING\"], [920, 300, 1, 269, 2, \"CLIP\"], [921, 10, 0, 269, 3, \"VAE\"], [922, 300, 1, 279, 0, \"CLIP\"], [923, 241, 0, 277, 0, \"CONDITIONING\"], [924, 10, 0, 8, 1, \"VAE\"], [925, 10, 0, 135, 1, \"VAE\"], [926, 300, 1, 241, 0, \"CLIP\"], [927, 10, 0, 177, 1, \"VAE\"], [928, 241, 0, 149, 1, \"CONDITIONING\"], [929, 241, 0, 176, 1, \"CONDITIONING\"], [930, 300, 1, 269, 2, \"CLIP\"], [931, 10, 0, 269, 3, \"VAE\"], [932, 300, 1, 279, 0, \"CLIP\"], [933, 241, 0, 277, 0, \"CONDITIONING\"], [934, 10, 0, 8, 1, \"VAE\"], [935, 10, 0, 135, 1, \"VAE\"], [936, 300, 1, 241, 0, \"CLIP\"], [937, 10, 0, 177, 1, \"VAE\"], [938, 241, 0, 149, 1, \"CONDITIONING\"], [939, 241, 0, 176, 1, \"CONDITIONING\"], [940, 300, 1, 279, 0, \"CLIP\"], [941, 241, 0, 277, 0, \"CONDITIONING\"], [942, 10, 0, 8, 1, \"VAE\"], [943, 10, 0, 135, 1, \"VAE\"], [944, 300, 1, 241, 0, \"CLIP\"], [961, 200, 0, 203, 0, \"IMAGE\"], [964, 11, 0, 310, 1, \"CLIP\"], [965, 310, 0, 152, 0, \"MODEL\"], [966, 310, 0, 162, 0, \"MODEL\"], [967, 310, 1, 298, 0, \"CLIP\"], [968, 10, 0, 177, 1, \"VAE\"], [969, 241, 0, 149, 1, \"CONDITIONING\"], [970, 241, 0, 176, 1, \"CONDITIONING\"], [971, 310, 1, 279, 0, \"CLIP\"], [972, 241, 0, 277, 0, \"CONDITIONING\"], [973, 10, 0, 8, 1, \"VAE\"], [974, 10, 0, 135, 1, \"VAE\"], [975, 310, 1, 241, 0, \"CLIP\"], [976, 10, 0, 177, 1, \"VAE\"], [977, 241, 0, 149, 1, \"CONDITIONING\"], [978, 241, 0, 176, 1, \"CONDITIONING\"], [979, 310, 1, 269, 2, \"CLIP\"], [980, 10, 0, 269, 3, \"VAE\"], [981, 310, 1, 279, 0, \"CLIP\"], [982, 241, 0, 277, 0, \"CONDITIONING\"], [983, 10, 0, 8, 1, \"VAE\"], [984, 10, 0, 135, 1, \"VAE\"], [985, 310, 1, 241, 0, \"CLIP\"], [986, 10, 0, 177, 1, \"VAE\"], [987, 241, 0, 149, 1, \"CONDITIONING\"], [988, 241, 0, 176, 1, \"CONDITIONING\"], [989, 310, 1, 279, 0, \"CLIP\"], [990, 241, 0, 277, 0, \"CONDITIONING\"], [991, 10, 0, 8, 1, \"VAE\"], [992, 10, 0, 135, 1, \"VAE\"], [993, 310, 1, 241, 0, \"CLIP\"], [994, 10, 0, 177, 1, \"VAE\"], [995, 241, 0, 149, 1, \"CONDITIONING\"], [996, 241, 0, 176, 1, \"CONDITIONING\"], [997, 310, 1, 279, 0, \"CLIP\"], [998, 241, 0, 277, 0, \"CONDITIONING\"], [999, 10, 0, 8, 1, \"VAE\"], [1000, 10, 0, 135, 1, \"VAE\"], [1001, 310, 1, 241, 0, \"CLIP\"], [1002, 10, 0, 177, 1, \"VAE\"], [1003, 241, 0, 149, 1, \"CONDITIONING\"], [1004, 241, 0, 176, 1, \"CONDITIONING\"], [1005, 310, 1, 279, 0, \"CLIP\"], [1006, 241, 0, 277, 0, \"CONDITIONING\"], [1007, 10, 0, 8, 1, \"VAE\"], [1008, 10, 0, 135, 1, \"VAE\"], [1009, 310, 1, 241, 0, \"CLIP\"], [1010, 269, 0, 113, 0, \"IMAGE\"], [1011, 269, 0, 114, 0, \"IMAGE\"], [1012, 129, 0, 182, 1, \"IMAGE\"], [1013, 10, 0, 177, 1, \"VAE\"], [1014, 241, 0, 149, 1, \"CONDITIONING\"], [1015, 241, 0, 176, 1, \"CONDITIONING\"], [1016, 310, 1, 279, 0, \"CLIP\"], [1017, 241, 0, 277, 0, \"CONDITIONING\"], [1018, 10, 0, 8, 1, \"VAE\"], [1019, 10, 0, 135, 1, \"VAE\"], [1020, 310, 1, 241, 0, \"CLIP\"], [1023, 10, 0, 177, 1, \"VAE\"], [1024, 241, 0, 149, 1, \"CONDITIONING\"], [1025, 241, 0, 176, 1, \"CONDITIONING\"], [1026, 310, 1, 279, 0, \"CLIP\"], [1027, 241, 0, 277, 0, \"CONDITIONING\"], [1028, 10, 0, 8, 1, \"VAE\"], [1029, 310, 1, 241, 0, \"CLIP\"], [1030, 10, 0, 135, 1, \"VAE\"], [1032, 10, 0, 177, 1, \"VAE\"], [1033, 241, 0, 149, 1, \"CONDITIONING\"], [1034, 241, 0, 176, 1, \"CONDITIONING\"], [1035, 310, 1, 279, 0, \"CLIP\"], [1036, 241, 0, 277, 0, \"CONDITIONING\"], [1037, 10, 0, 8, 1, \"VAE\"], [1038, 310, 1, 241, 0, \"CLIP\"], [1039, 10, 0, 135, 1, \"VAE\"], [1040, 10, 0, 177, 1, \"VAE\"], [1041, 241, 0, 149, 1, \"CONDITIONING\"], [1042, 241, 0, 176, 1, \"CONDITIONING\"], [1043, 10, 0, 8, 1, \"VAE\"], [1044, 310, 1, 241, 0, \"CLIP\"], [1045, 10, 0, 135, 1, \"VAE\"], [1046, 310, 1, 279, 0, \"CLIP\"], [1047, 241, 0, 277, 0, \"CONDITIONING\"], [1048, 10, 0, 177, 1, \"VAE\"], [1049, 241, 0, 149, 1, \"CONDITIONING\"], [1050, 241, 0, 176, 1, \"CONDITIONING\"], [1051, 10, 0, 8, 1, \"VAE\"], [1052, 310, 1, 241, 0, \"CLIP\"], [1053, 10, 0, 135, 1, \"VAE\"], [1054, 310, 1, 279, 0, \"CLIP\"], [1055, 241, 0, 277, 0, \"CONDITIONING\"], [1056, 10, 0, 177, 1, \"VAE\"], [1057, 241, 0, 149, 1, \"CONDITIONING\"], [1058, 241, 0, 176, 1, \"CONDITIONING\"], [1059, 10, 0, 8, 1, \"VAE\"], [1060, 10, 0, 135, 1, \"VAE\"], [1061, 310, 1, 279, 0, \"CLIP\"], [1062, 241, 0, 277, 0, \"CONDITIONING\"], [1063, 310, 1, 241, 0, \"CLIP\"], [1067, 10, 0, 177, 1, \"VAE\"], [1068, 241, 0, 149, 1, \"CONDITIONING\"], [1069, 241, 0, 176, 1, \"CONDITIONING\"], [1070, 10, 0, 135, 1, \"VAE\"], [1071, 310, 1, 279, 0, \"CLIP\"], [1072, 241, 0, 277, 0, \"CONDITIONING\"], [1073, 310, 1, 241, 0, \"CLIP\"], [1074, 10, 0, 8, 1, \"VAE\"], [1076, 172, 0, 171, 2, \"SAMPLER\"], [1079, 10, 0, 177, 1, \"VAE\"], [1080, 241, 0, 176, 1, \"CONDITIONING\"], [1081, 10, 0, 135, 1, \"VAE\"], [1082, 310, 1, 279, 0, \"CLIP\"], [1083, 241, 0, 277, 0, \"CONDITIONING\"], [1084, 310, 1, 241, 0, \"CLIP\"], [1085, 10, 0, 8, 1, \"VAE\"], [1086, 241, 0, 149, 1, \"CONDITIONING\"], [1087, 318, 0, 13, 2, \"SAMPLER\"], [1089, 250, 0, 310, 0, \"MODEL\"], [1090, 10, 0, 177, 1, \"VAE\"], [1091, 10, 0, 135, 1, \"VAE\"], [1092, 310, 1, 279, 0, \"CLIP\"], [1093, 241, 0, 277, 0, \"CONDITIONING\"], [1094, 310, 1, 241, 0, \"CLIP\"], [1095, 10, 0, 8, 1, \"VAE\"], [1096, 241, 0, 149, 1, \"CONDITIONING\"], [1097, 241, 0, 176, 1, \"CONDITIONING\"], [1098, 10, 0, 177, 1, \"VAE\"], [1099, 10, 0, 135, 1, \"VAE\"], [1100, 310, 1, 279, 0, \"CLIP\"], [1101, 241, 0, 277, 0, \"CONDITIONING\"], [1102, 310, 1, 241, 0, \"CLIP\"], [1103, 10, 0, 8, 1, \"VAE\"], [1104, 241, 0, 149, 1, \"CONDITIONING\"], [1105, 241, 0, 176, 1, \"CONDITIONING\"], [1106, 10, 0, 177, 1, \"VAE\"], [1107, 10, 0, 135, 1, \"VAE\"], [1108, 310, 1, 279, 0, \"CLIP\"], [1109, 241, 0, 277, 0, \"CONDITIONING\"], [1110, 310, 1, 241, 0, \"CLIP\"], [1111, 10, 0, 8, 1, \"VAE\"], [1112, 241, 0, 149, 1, \"CONDITIONING\"], [1113, 241, 0, 176, 1, \"CONDITIONING\"], [1115, 32, 0, 13, 4, \"LATENT\"], [1116, 10, 0, 177, 1, \"VAE\"], [1117, 310, 1, 241, 0, \"CLIP\"], [1118, 10, 0, 8, 1, \"VAE\"], [1119, 241, 0, 149, 1, \"CONDITIONING\"], [1120, 241, 0, 176, 1, \"CONDITIONING\"], [1121, 10, 0, 135, 1, \"VAE\"], [1122, 325, 0, 320, 0, \"IMAGE\"], [1123, 319, 0, 321, 0, \"IMAGE\"], [1124, 322, 0, 323, 0, \"IMAGE\"], [1125, 322, 0, 325, 0, \"IMAGE\"], [1126, 321, 0, 325, 1, \"IMAGE\"], [1127, 320, 0, 318, 1, \"LATENT\"], [1128, 32, 1, 322, 0, \"INT\"], [1129, 32, 2, 322, 1, \"INT\"], [1130, 32, 1, 321, 1, \"INT\"], [1131, 32, 2, 321, 2, \"INT\"], [1132, 10, 0, 177, 1, \"VAE\"], [1133, 310, 1, 241, 0, \"CLIP\"], [1134, 241, 0, 149, 1, \"CONDITIONING\"], [1135, 241, 0, 176, 1, \"CONDITIONING\"], [1136, 10, 0, 8, 1, \"VAE\"], [1137, 10, 0, 320, 1, \"VAE\"], [1138, 10, 0, 135, 1, \"VAE\"], [1139, 10, 0, 177, 1, \"VAE\"], [1140, 310, 1, 241, 0, \"CLIP\"], [1141, 241, 0, 149, 1, \"CONDITIONING\"], [1142, 241, 0, 176, 1, \"CONDITIONING\"], [1143, 10, 0, 8, 1, \"VAE\"], [1144, 10, 0, 320, 1, \"VAE\"], [1145, 10, 0, 135, 1, \"VAE\"], [1146, 10, 0, 177, 1, \"VAE\"], [1147, 310, 1, 241, 0, \"CLIP\"], [1148, 241, 0, 149, 1, \"CONDITIONING\"], [1149, 241, 0, 176, 1, \"CONDITIONING\"], [1150, 10, 0, 8, 1, \"VAE\"], [1151, 10, 0, 135, 1, \"VAE\"], [1153, 10, 0, 177, 1, \"VAE\"], [1154, 310, 1, 241, 0, \"CLIP\"], [1155, 10, 0, 8, 1, \"VAE\"], [1156, 10, 0, 135, 1, \"VAE\"], [1157, 241, 0, 149, 1, \"CONDITIONING\"], [1158, 241, 0, 176, 1, \"CONDITIONING\"], [1159, 260, 0, 327, 3, \"STRING\"], [1160, 262, 0, 327, 4, \"STRING\"], [1161, 327, 0, 257, 0, \"STRING\"], [1162, 327, 0, 241, 1, \"STRING\"], [1163, 327, 2, 259, 0, \"STRING\"], [1164, 261, 0, 327, 2, \"STRING\"], [1165, 263, 0, 327, 1, \"IMAGE\"], [1166, 307, 0, 328, 4, \"STRING\"], [1167, 328, 0, 303, 0, \"STRING\"], [1168, 328, 0, 241, 2, \"STRING\"], [1169, 328, 2, 304, 0, \"STRING\"], [1170, 306, 0, 328, 2, \"STRING\"], [1171, 263, 0, 328, 1, \"IMAGE\"], [1172, 10, 0, 177, 1, \"VAE\"], [1173, 310, 1, 269, 2, \"CLIP\"], [1174, 10, 0, 269, 3, \"VAE\"], [1175, 310, 1, 279, 0, \"CLIP\"], [1176, 241, 0, 277, 0, \"CONDITIONING\"], [1177, 10, 0, 8, 1, \"VAE\"], [1178, 10, 0, 135, 1, \"VAE\"], [1179, 241, 0, 149, 1, \"CONDITIONING\"], [1180, 241, 0, 176, 1, \"CONDITIONING\"], [1181, 310, 1, 241, 0, \"CLIP\"], [1182, 162, 0, 329, 0, \"MODEL\"], [1183, 329, 0, 173, 0, \"MODEL\"], [1184, 10, 0, 177, 1, \"VAE\"], [1185, 10, 0, 8, 1, \"VAE\"], [1186, 10, 0, 135, 1, \"VAE\"], [1187, 241, 0, 149, 1, \"CONDITIONING\"], [1188, 241, 0, 176, 1, \"CONDITIONING\"], [1189, 310, 1, 241, 0, \"CLIP\"], [1190, 310, 1, 329, 1, \"CLIP\"], [1191, 10, 0, 177, 1, \"VAE\"], [1192, 10, 0, 8, 1, \"VAE\"], [1193, 10, 0, 135, 1, \"VAE\"], [1194, 241, 0, 149, 1, \"CONDITIONING\"], [1195, 241, 0, 176, 1, \"CONDITIONING\"], [1196, 310, 1, 241, 0, \"CLIP\"], [1197, 310, 1, 329, 1, \"CLIP\"]], \"groups\": [{\"title\": \"Guides\", \"bounding\": [-129, 1516, 1103, 738], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Clip-L\", \"bounding\": [-1476, 1187, 1304, 954], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"face detailer\", \"bounding\": [2904, 177, 2184, 1379], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Post - Less Favourable\", \"bounding\": [6142, 537, 450, 1190], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Pixel Upscale\", \"bounding\": [6146, 172, 980, 330], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Pixel Upscale Post Processing\", \"bounding\": [6623, 533, 490, 1190], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Post Processing\", \"bounding\": [5122, 173, 990, 674], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"1st Pass\", \"bounding\": [-128, 179, 1563, 1297], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Upscale\", \"bounding\": [1457, 199, 1380, 860], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"img2img\", \"bounding\": [1010, 1520, 803, 731], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"LLM T5 captioning\", \"bounding\": [-1480, 158, 1320, 1006], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Upscale by model\", \"bounding\": [2269, 1086, 598, 386], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"lloras\", \"bounding\": [532, -653, 787, 822], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.1577222547666279, \"offset\": [4331.585891351228, 4566.587618580395]}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"172\": {\"sampler_name\": 0}, \"173\": {\"scheduler\": 0}, \"175\": {\"noise_seed\": 0}, \"269\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}, \"299\": {\"noise_seed\": 0}, \"327\": {\"seed\": 8}, \"328\": {\"seed\": 8}}, \"seed_widgets\": {\"25\": 0, \"175\": 0, \"269\": 3, \"299\": 0, \"327\": 8, \"328\": 8}}}",
                "models": [],
                "modelIds": [],
                "upscalers": [
                    "002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth"
                ],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": []
            },
            "username": "NaomiVK",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 36132683,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0efcda25-f18c-4e7e-891a-ea400fb54f1c/width=832/0efcda25-f18c-4e7e-891a-ea400fb54f1c.jpeg",
            "hash": "UFE{9500ysD%%MD%EMxZ0fx[n3tQM{xae-bI",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-10-23T20:15:00.000Z",
            "postId": 8255280,
            "stats": {
                "cryCount": 1,
                "laughCount": 0,
                "likeCount": 123,
                "dislikeCount": 0,
                "heartCount": 44,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 4205758512,
                "steps": 14,
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up, colorful, ((eye_focus, view from the side, looking seductively at viewer)),\n the most beautiful petite model bombshell blonde diminutive rock-and-roll model college girl with flawless, model-like facial features and large captivating silver-blue eyes that exude a sense of strength and defiance. round facial shape with soft youthful skinny facial features. shallow depth of field, punk rock concert background, basement party, warm lights shine on beautiful tan skin and reflect in her big beautiful captivating eyes.  incredibly detailed, photoshoot, (elaborate dark makeup, dark smoked eyes, detailed elaborate artistic exaggerated eyeliner that extends beyond her beautiful eyes, long eyelashes ), hoop earings, beautiful long wavy big bold blonde hair.  youthful charm, slightly parted lipstick sexy sinful thin lips that exude a sense of sinful mischief and a hint of anger. bare shoulders, strapless black corset, slutty punk, slender body, petite body, slender build,prominent perky breasts, busty, big breasts, cleavage, back arch, bubblebutt,\nleaning against a wall,\ndreamlike fantasy image, the shot is looking down on her giving her a diminutive and cute appearance in the frame capturing a moment in time. implied movement, implied crowded room, 2000s nostalgia, photo, grainy",
                "sampler": "Euler a",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-22T1609:52.1125104Z",
                "negativePrompt": "score_5, score_4, ((shaved hair)), watermark, signature, artist name, easynegative, ugly, old, striped face, plain background, monochrome, futa, transexual,shemale, (disfigured), stumpy, irregular, ugly face, mutated hands, low res, blurry face, pumped body, bad anatomy, bad eyes, dot eyes, disembodied,  (weird anatomy), bad anatomy, conjoined, mutated, mixed bodied, fused bodies, shared dildo, disembodied, artifacts, jpeg artifacts, empty panel, (deformed), (unfinished), (lots of white-space filling image), stretched body, long body, weird limbs, eyes rolled back, ahegao, running makeup, Asian, CyberRealistic_Negative_PONY,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640,
                        "modelVersionName": "V6 (start with this one)"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 135867,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 720175,
                        "modelVersionName": "High Quality V3"
                    },
                    {
                        "type": "lora",
                        "weight": 1.5,
                        "modelVersionId": 530673,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 436219,
                        "modelVersionName": "v3.0 (PonyXL Edition)"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 373076,
                        "modelVersionName": "v3"
                    },
                    {
                        "type": "lora",
                        "weight": 0.5,
                        "modelVersionId": 438481,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250708,
                        "modelVersionName": "safe_pos"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250712,
                        "modelVersionName": "safe_neg"
                    }
                ]
            },
            "username": "Prolific_ai",
            "baseModel": "Pony"
        },
        {
            "id": 35849253,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3eb3aec6-5352-48c5-9722-354db5d2b014/width=1664/3eb3aec6-5352-48c5-9722-354db5d2b014.jpeg",
            "hash": "U48zGc9F0NOs~B4:I?={0LV[=x-T9u-=#lI:",
            "width": 1664,
            "height": 2432,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-21T22:35:37.174Z",
            "postId": 8191473,
            "stats": {
                "cryCount": 10,
                "laughCount": 13,
                "likeCount": 112,
                "dislikeCount": 0,
                "heartCount": 33,
                "commentCount": 0
            },
            "meta": {
                "VAE": "sdxl_vae.safetensors",
                "Size": "832x1216",
                "seed": 3932219589,
                "Model": "juggernautXL_v9Rdphoto2Lightning",
                "steps": 10,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "c8df560d29",
                    "lora:sss": "079dc17041d4"
                },
                "prompt": "An Oldman, smoking cigarette, translucent, vibrant, extreme detail, night, rim lighting, black gradient bokeh background, blue/orange tones, glow, 8k  <lora:sss:1>, oil painting art style, rich colors, lush textures, expressive brushwork, blendable layers, dynamic compositions, professional-grade finish, versatile medium, timeless elegance, immersive depth, vibrant hues, intricate detailing, adds depth and dimension, Magic realism painting art style, surreal compositions, vibrant colors, blurs the line between reality and fantasy",
                "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
                "sampler": "DPM++ SDE",
                "cfgScale": 1,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "079dc17041d4",
                        "name": "sss",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "c8df560d29",
                        "name": "juggernautXL_v9Rdphoto2Lightning",
                        "type": "model"
                    }
                ],
                "Model hash": "c8df560d29",
                "Hires steps": "5",
                "ControlNet 0": {
                    "Model": "diffusers_xl_depth_full [2f51180b]",
                    "Module": "depth_midas",
                    "Weight": "1",
                    "Hr Option": "Both",
                    "Resize Mode": "Crop and Resize",
                    "Threshold A": "0.5",
                    "Threshold B": "0.5",
                    "Control Mode": "My prompt is more important",
                    "Guidance End": "1",
                    "Pixel Perfect": "True",
                    "Processor Res": "832",
                    "Guidance Start": "0"
                },
                "Hires prompt": {
                    "sss": "1>"
                },
                "Hires upscale": "2",
                "Hires upscaler": "4x_NMKD-Siax_200k",
                "negativePrompt": "bad, awful, ugly, disfigured, deformed, extra limbs, disfigured hands, disfigured fingers,, signature, watermark, photo, photorealistic, realism, ugly, off-center, deformed, 35mm film, dslr, cropped, frame, worst quality, low quality, lowres, JPEG artifacts, signature, watermark, photo, photorealistic, realism, ugly, off-center, deformed, 35mm film, dslr, cropped, frame, worst quality, low quality, lowres, JPEG artifacts",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.4.0",
                "Denoising strength": "0.3",
                "ADetailer mask blur": "4",
                "ADetailer model 2nd": "hand_yolov8n.pt",
                "ADetailer confidence": "0.3",
                "Style Selector Style": "base",
                "ADetailer dilate erode": "4",
                "Style Selector Enabled": "True",
                "ADetailer mask blur 2nd": "4",
                "ADetailer confidence 2nd": "0.3",
                "Style Selector Randomize": "False",
                "ADetailer inpaint padding": "32",
                "ADetailer dilate erode 2nd": "4",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True",
                "ADetailer inpaint padding 2nd": "32",
                "ADetailer denoising strength 2nd": "0.4",
                "ADetailer inpaint only masked 2nd": "True"
            },
            "username": "Grymauch",
            "baseModel": "SDXL Lightning"
        },
        {
            "id": 35838524,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0220ec33-5e0e-4478-b8d4-460f7bee5ed3/width=720/0220ec33-5e0e-4478-b8d4-460f7bee5ed3.jpeg",
            "hash": "U8DlpGIA01~BK%Ri$,In00%M^+E2:$WFIn%2",
            "width": 720,
            "height": 1080,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-21T21:04:42.794Z",
            "postId": 8189022,
            "stats": {
                "cryCount": 9,
                "laughCount": 15,
                "likeCount": 118,
                "dislikeCount": 0,
                "heartCount": 26,
                "commentCount": 0
            },
            "meta": {
                "Size": "720x1080",
                "seed": 2310670003,
                "Model": "wildcardxXLLIGHTNING_wildcardxXL",
                "steps": 6,
                "hashes": {
                    "model": "f53945ec37"
                },
                "prompt": "cute curvy fairy with short bob black hair sitting down in a fairy house, pink and blue fairy dress, pastel colored fairy wings, huge wings, boots wrapped in flowers, flowers and vines themed stockings, magical forest, dramatic lighting, depth of field",
                "Version": "f0.0.17v1.8.0rc-latest-269-gef35383b4",
                "sampler": "DPM++ SDE Karras",
                "cfgScale": 1.5,
                "resources": [
                    {
                        "hash": "f53945ec37",
                        "name": "wildcardxXLLIGHTNING_wildcardxXL",
                        "type": "model"
                    }
                ],
                "Model hash": "f53945ec37"
            },
            "username": "PBtheCreator",
            "baseModel": "SDXL Lightning"
        },
        {
            "id": 35613628,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7db3f5bb-23cc-4fa9-bbf9-3ce7260fed08/width=832/7db3f5bb-23cc-4fa9-bbf9-3ce7260fed08.jpeg",
            "hash": "U9C~uBEM0M~B9ts.xFE200xa?aM{%MNGV@-p",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-10-21T23:51:00.000Z",
            "postId": 8136559,
            "stats": {
                "cryCount": 3,
                "laughCount": 5,
                "likeCount": 108,
                "dislikeCount": 0,
                "heartCount": 52,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3824741882,
                "steps": 30,
                "prompt": "(score_9, score_8_up, score_7_up), 1girl, (long brown wavy hair), feminine face, petite beautiful face, cute perky nose, tall skinny body, medium firm breasts, white singlet, sideboob, navel, tiny shorts, thick thighs, big ass, wide hips, narrow waist,, gluteal fold, long legs, sexy pose, provocative pose, s1_dram",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-20T1423:06.0746646Z",
                "negativePrompt": "CyberRealistic_Negative_PONY",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 953264,
                        "modelVersionName": "v6.5"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 972770,
                        "modelVersionName": "Pony v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 435334,
                        "modelVersionName": "Gluteal Fold PDXL V1"
                    },
                    {
                        "type": "lora",
                        "weight": 0.25,
                        "modelVersionId": 761452,
                        "modelVersionName": "v2"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250708,
                        "modelVersionName": "safe_pos"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250712,
                        "modelVersionName": "safe_neg"
                    }
                ]
            },
            "username": "0dang",
            "baseModel": "Pony"
        },
        {
            "id": 35504591,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1bc73879-331b-4b76-a175-f55eb7d831b8/width=992/1bc73879-331b-4b76-a175-f55eb7d831b8.jpeg",
            "hash": "UOCZeUMxM{Io_4oLM{NGS1tRaeWAOEW=s:nh",
            "width": 992,
            "height": 1664,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-20T00:11:25.580Z",
            "postId": 8113146,
            "stats": {
                "cryCount": 9,
                "laughCount": 11,
                "likeCount": 93,
                "dislikeCount": 0,
                "heartCount": 55,
                "commentCount": 0
            },
            "meta": {
                "VAE": "sdxl_vae_fix.safetensors",
                "ENSD": "31340",
                "NGMS": "1.1",
                "Size": "992x1664",
                "seed": 1754122979,
                "Model": "Obsession-V2.0",
                "steps": 28,
                "hashes": {
                    "vae": "551eac7037",
                    "model": "47e944532d"
                },
                "prompt": "1girl, ellen joe, wanke, rei \\(sanbonzakura\\), lack, ((from above)), dynamic angle, leaning forward, holding polearm, black polearm, black hair, black pantyhose, feet out of frame, leg up, hairband, large breasts, black dress, looking at viewer, maid headdress, light particles, black background, red eyes, red nails, shark girl, shark tail, solo, broken glass, blurry foreground, motion blur, depth of field, gradient, cinematic, masterpiece, best quality, good quality, newest",
                "Version": "v1.10.1",
                "sampler": "Euler a",
                "cfgScale": 6,
                "clipSkip": 2,
                "Mask blur": "12",
                "resources": [
                    {
                        "hash": "47e944532d",
                        "name": "Obsession-V2.0",
                        "type": "model"
                    }
                ],
                "Model hash": "47e944532d",
                "Schedule type": "Automatic",
                "negativePrompt": "lowres, worst quality, bad quality, bad anatomy, sketch, jpeg artifacts, signature, watermark, artist name, old, oldest",
                "Denoising strength": "0.8"
            },
            "username": "rqdwdw",
            "baseModel": "Illustrious"
        },
        {
            "id": 35329327,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/91b04a06-8419-480e-a6f1-a763ddaeebf9/width=896/91b04a06-8419-480e-a6f1-a763ddaeebf9.jpeg",
            "hash": "UdJcB}oL9bkB~XjrSdo#x^bJXnjXNEkBS5WX",
            "width": 896,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-18T23:41:52.604Z",
            "postId": 8073726,
            "stats": {
                "cryCount": 5,
                "laughCount": 24,
                "likeCount": 112,
                "dislikeCount": 0,
                "heartCount": 27,
                "commentCount": 0
            },
            "meta": null,
            "username": "dan828",
            "baseModel": ""
        }
    ],
    "metadata": {
        "nextCursor": "27600|1727677502809",
        "nextPage": "https://civitai.com/api/v1/images?sort=Most%20Reactions&nsfw=Soft&cursor=27600%7C1727677502809"
    }
}