{
    "items": [
        {
            "id": 34739345,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d825c23b-cae2-4b3a-ad9c-ca8bf6d57b81/width=1024/d825c23b-cae2-4b3a-ad9c-ca8bf6d57b81.jpeg",
            "hash": "U9Jb89%#?+;11Pbb0gi_EHivTMPBAHr?$$Os",
            "width": 1024,
            "height": 1024,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-15T18:00:00.000Z",
            "postId": 7938351,
            "stats": {
                "cryCount": 10,
                "laughCount": 95,
                "likeCount": 215,
                "dislikeCount": 0,
                "heartCount": 64,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "fixFP16ErrorsSDXLLowerMemoryUse_v10.safetensors",
                "Size": "1024x1024",
                "seed": 188969737,
                "Model": "incursiosMemeDiffusion_v27",
                "steps": 24,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "5e37c6849c",
                    "lora:AmongUs_pdxl_Incrs_v1": "9c18eedb825f"
                },
                "prompt": "score_9, score_8_up, score_7_up, crewmate (among us), spacesuit, no humans, space helmet, <lora:AmongUs_pdxl_Incrs_v1:1>, yae miko, full body,",
                "Version": "f0.0.17v1.8.0rc-latest-287-g77bdb920",
                "sampler": "Euler a",
                "cfgScale": 6,
                "resources": [
                    {
                        "hash": "9c18eedb825f",
                        "name": "AmongUs_pdxl_Incrs_v1",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "5e37c6849c",
                        "name": "incursiosMemeDiffusion_v27",
                        "type": "model"
                    }
                ],
                "Model hash": "5e37c6849c",
                "negativePrompt": "monochrome"
            },
            "username": "FallenIncursio",
            "baseModel": "Pony"
        },
        {
            "id": 32634674,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9afabf61-90e4-4eb8-a611-e4dcd418fde9/width=832/9afabf61-90e4-4eb8-a611-e4dcd418fde9.jpeg",
            "hash": "U9GZ.|pbt9ElJ%s9E3EPtM}p0#Iq?H0,o#jG",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-04T04:39:00.000Z",
            "postId": 7469626,
            "stats": {
                "cryCount": 0,
                "laughCount": 50,
                "likeCount": 282,
                "dislikeCount": 0,
                "heartCount": 52,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2265139549,
                "extra": {
                    "remixOfId": 26931305
                },
                "steps": 25,
                "prompt": "upscale, a black fire phoenix, body made of fire, massive gigantic fire phoenix, fierce, roaring, looking at the viewer,  hyperrealistic, fantasy, flying around, angry, highly detailed body, super realistic, hi_res, absurd detailed, very detailed face, in a volcanic environment, volcanic eruption on the background,",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 4.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-03T1755:02.0519844Z",
                "negativePrompt": "Unspeakable-Horrors-Composition-SDXL, deformed body, deformed hands,  SDXL_TI_my_eyes_are_bleeding, unaestheticXL_Alb2, poorly drawn, gloomy, messy, low quality, blurry, doll, deviant, animal ears, topless, breasts, nipples, strange clothing",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 916744,
                        "modelVersionName": "v10.0"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 363593,
                        "modelVersionName": "_Alb2"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 549984,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Genzo93",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 31806516,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ce334414-c951-493b-b331-20fc7ffb6ec1/width=832/ce334414-c951-493b-b331-20fc7ffb6ec1.jpeg",
            "hash": "UCFhSyD~$n^-=?InDz?ITcs;I;t7%4-X9r9s",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-28T23:10:00.000Z",
            "postId": 7207230,
            "stats": {
                "cryCount": 8,
                "laughCount": 41,
                "likeCount": 262,
                "dislikeCount": 0,
                "heartCount": 73,
                "commentCount": 1
            },
            "meta": null,
            "username": "trevizanzan",
            "baseModel": "Pony"
        },
        {
            "id": 31178409,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/527dba44-9df1-49bc-beed-0753316023c5/width=1248/527dba44-9df1-49bc-beed-0753316023c5.jpeg",
            "hash": "UGJHOC~pI+%2I9-;%LtQ00R5t2t5xaD*DiV@",
            "width": 1248,
            "height": 1824,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-24T22:20:56.808Z",
            "postId": 6969138,
            "stats": {
                "cryCount": 0,
                "laughCount": 19,
                "likeCount": 263,
                "dislikeCount": 0,
                "heartCount": 102,
                "commentCount": 0
            },
            "meta": {
                "": {},
                "VAE": "sdxl_vae_fixed.safetensors",
                "Size": "1248x1824",
                "seed": 3124780027,
                "Model": "snowpony_v10",
                "steps": 20,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "d6f941b46b",
                    "lora:nyantcha_style_pdxl_v2_goofy": "f5935c826fdd"
                },
                "prompt": "score_9,score_8_up,score_7_up, <lora:nyantcha_style_pdxl_v2_goofy:1> 1girl, keqing (genshin impact),  cone hair bun, purple hair, twintails, makeup, purple gloves, breasts, purple eyes, hair ornament, lipstick, neck tassel, holding paper, blush, long hair, dress, earrings, hair ears, thick lips, jewelry, detached sleeves, looking at viewer, double bun, braid, purple choker, upper body, bare shoulders, eyeshadow, bra visible through clothes, eyeliner",
                "Version": "v1.10.1",
                "sampler": "Euler a",
                "{Method": {},
                "Upscaler": {},
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "f5935c826fdd",
                        "name": "nyantcha_style_pdxl_v2_goofy",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "d6f941b46b",
                        "name": "snowpony_v10",
                        "type": "model"
                    }
                ],
                "Model hash": "d6f941b46b",
                "Tile Overlap": "48",
                "Schedule type": "Simple",
                "Upscale factor": "1.5",
                "negativePrompt": "realistic,monochrome,greyscale, artist name, signature, watermark,",
                "ADetailer model": "face_yolov9c.pt",
                "Keep input size": "true}",
                "Tile batch size": "6",
                "Tile tile width": "160",
                "Tiled Diffusion": {},
                "Tile tile height": "160",
                "ADetailer version": "24.8.0",
                "Denoising strength": "0.4",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "Tiled Diffusion upscaler": "4x-UltraSharp",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "Tiled Diffusion scale factor": "1.5",
                "ADetailer inpaint only masked": "True"
            },
            "username": "Goofy_Ai",
            "baseModel": "Pony"
        },
        {
            "id": 31035228,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a146b38a-c6e3-4e60-a67f-0ce447e2ddba/width=800/a146b38a-c6e3-4e60-a67f-0ce447e2ddba.jpeg",
            "hash": "UU7y^dloTeaKVrWVbvj[OtozjEV?NFW=ofoJ",
            "width": 800,
            "height": 1432,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-24T01:42:13.549Z",
            "postId": 6937660,
            "stats": {
                "cryCount": 27,
                "laughCount": 46,
                "likeCount": 228,
                "dislikeCount": 0,
                "heartCount": 83,
                "commentCount": 0
            },
            "meta": {
                "seed": 653381643157160,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux_dev.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"dpm_2\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 80, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 653381643157160}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 3.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 576, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 0.5, \"base_shift\": 0.3, \"width\": 576, \"height\": 1024, \"model\": [\"161\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.5, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.05, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"161\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"73\": {\"inputs\": {\"intensity\": 0.07, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"69\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"nearest-exact\", \"scale_by\": 0.35000000000000003, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 40, \"denoise\": 0.25, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"Photorealistic of a potrait shot scene where sw33ny a young and gorgeous beauty as a Holographic Interface Designer with long platinum-blonde hair in the center of a futuristic, holographic interface. The vibrant cyan data rings and geometric shapes from the background are surrounding her, some even seemingly projected from her hands as if she\\u2019s controlling the interface. Her partially unzipped circuit print stylish futuristic engineer uniform and choker contrast with the high-tech environment, creating a visual blend of the modern and the digital. Her eyes are focused on a specific holographic display in front of her, as if she is analyzing data or searching for information.\\n\\nsubtle, dynamic holographic patterns that shift colors along the stripes of her outfit, integrating her more into the digital environment.faintly glowing lines within her outfit\\u2019s fabric, creating a futuristic look that suggests advanced material technology. Her heart pendant have a small, glowing core, pulsing with light in sync with the holographic background. Very realistic overall texture composition.\\n\\nher Hair left loose with a decorative, knotted headband placed at the crown, adding a playful, bohemian touch.\\n\\n\\nvarying levels of transparency to different holographic elements, creating a layered and dynamic interface. a slight reflective glare on her lips to match the ambient light, enhancing their natural appearance.minor, flickering glitches or pixelations on some holographic elements, adding realism and a sense of dynamic interaction.\\n\\nBoth hands forming a triangle shape in front of her eyes, looking through it as if framing a particular part of the interface, lips pursed in concentration.\\n\", \"clip\": [\"161\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"134\": {\"inputs\": {\"sampler_name\": \"dpm_2\"}, \"class_type\": \"KSamplerSelect\"}, \"141\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"144\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"147\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"149\": {\"inputs\": {\"scale_method\": \"nearest-exact\", \"scale_factor\": 1.5, \"use_tiled_vae\": false}, \"class_type\": \"LatentPixelScale\"}, \"161\": {\"inputs\": {\"lora_name\": \"flux1\\\\sydneySweeneyFlux.safetensors\", \"strength_model\": 1.2, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}}, \"workflow\": {\"last_node_id\": 161, \"last_link_id\": 348, \"nodes\": [{\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1300, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 892, \"1\": 13}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1801, \"1\": 21}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 159}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 450, \"1\": 1353}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 289}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 141, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2036, \"1\": 41}, \"size\": {\"0\": 428.9556884765625, \"1\": 78}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": 2156, \"1\": 435}, \"size\": {\"0\": 504.7402648925781, \"1\": 472.86358642578125}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [294, 305], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [295, 306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [296, 307], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186, 297, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3079, \"1\": -575}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 311}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 148, \"type\": \"SaveImage\", \"pos\": {\"0\": 3061, \"1\": -483}, \"size\": {\"0\": 281.4468078613281, \"1\": 480.5931091308594}, \"flags\": {}, \"order\": 67, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 313}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 149, \"type\": \"LatentPixelScale\", \"pos\": {\"0\": 445.9807434082031, \"1\": 1519.1585693359375}, \"size\": {\"0\": 365.4000244140625, \"1\": 146}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model_opt\", \"type\": \"UPSCALE_MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentPixelScale\"}, \"widgets_values\": [\"nearest-exact\", 1.5, false]}, {\"id\": 146, \"type\": \"DZ_Face_Detailer\", \"pos\": {\"0\": 2658, \"1\": -843}, \"size\": {\"0\": 309.8262939453125, \"1\": 842.9425659179688}, \"flags\": {}, \"order\": 62, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 305}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 306}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 307}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DZ_Face_Detailer\"}, \"widgets_values\": [1, \"fixed\", 20, 4, \"euler\", \"sgm_uniform\", 0.25, 32, \"face\", \"dilate\", 3, 3]}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": 14, \"1\": 1284}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 301, \"1\": -171}, \"size\": [75, 26], \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 325}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 28, \"1\": 303}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -29, \"1\": 159}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [333], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1303, \"1\": 949}, \"size\": {\"0\": 848.655029296875, \"1\": 899.4495849609375}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1505, \"1\": 40}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -37, \"1\": 33}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux_dev.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1813, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 63, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [260, 299], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.75, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 884, \"1\": 975}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 10, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 883, \"1\": 758}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 289], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 882, \"1\": 615}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 142, \"type\": \"SaveImage\", \"pos\": {\"0\": 3181, \"1\": 87}, \"size\": {\"0\": 813.5270385742188, \"1\": 1236.560546875}, \"flags\": {}, \"order\": 69, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 300}], \"outputs\": [], \"title\": \"FinalPass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 140, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2769, \"1\": 86}, \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 66, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 294}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 295}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 296}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 297}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 298}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.25, 1, \"fixed\", 25, 3, \"euler\", \"sgm_uniform\", 0.2, \"Linear\", 832, 1216, 24, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 2233, \"1\": 955}, \"size\": {\"0\": 848.405029296875, \"1\": 898.4495849609375}, \"flags\": {}, \"order\": 70, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1819, \"1\": 370}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 68, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168, 282], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.07, 10, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 117, \"type\": \"SaveImagePlus\", \"pos\": {\"0\": 4366, \"1\": 456}, \"size\": {\"0\": 832.2413940429688, \"1\": 1183.025634765625}, \"flags\": {}, \"order\": 71, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 282}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImagePlus\"}, \"widgets_values\": [\"ComfyUI\", \"JPEG\", true]}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": -306, \"1\": 824}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 153, \"type\": \"LoraLoader\", \"pos\": {\"0\": -36, \"1\": 410}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 31, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 326}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 327}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [324], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [325], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\sabrina_carpenter.safetensors\", 1, 1]}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 2061, \"1\": 273}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 65, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 260}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.3, 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1195, \"1\": 46}, \"size\": {\"0\": 245.11636352539062, \"1\": 82}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 258, \"1\": 793}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 342, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [576, 1024, 1]}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [653381643157160, \"randomize\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 156, \"type\": \"LoraLoader\", \"pos\": {\"0\": -399, \"1\": 593}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 23, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 330}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 331}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [346], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [345], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Flux__Semi-realistic_art_style-000004.safetensors\", 0.7000000000000001, 1]}, {\"id\": 155, \"type\": \"LoraLoader\", \"pos\": {\"0\": -23, \"1\": 601}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 19, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 332}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 333}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [330], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [331], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\detailed_skin_portraits-000005.safetensors\", 0.25, 1]}, {\"id\": 154, \"type\": \"LoraLoader\", \"pos\": {\"0\": -401, \"1\": 405}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 30, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 347}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 348}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [326], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [327], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\TransparentDress_v1.safetensors\", 1, 1]}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1454, \"1\": 131}, \"size\": [334.89553917655417, 535.3447223757851], \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 287, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [159, 308], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 160, \"type\": \"LoraLoader\", \"pos\": {\"0\": -763, \"1\": 592}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 26, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 346}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 345}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [343], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [344], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\realism_lora_comfy flux_converted.safetensors\", 0.5, 1]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 474, \"1\": 893}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpm_2\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 487, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 80, 1]}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1214, \"1\": 174}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [287], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpm_2\"]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 494, \"1\": -94}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 473, \"1\": 10}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 837, \"1\": 1291}, \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1829, \"1\": 554}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 40, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 617, \"1\": 645}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1024, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 386, \"1\": 647}, \"size\": [210, 82], \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 342], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [576, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 883, \"1\": 1143}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"nearest-exact\", 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 324, \"1\": 104}, \"size\": [499.7956075509587, 484.89137625980334], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"Photorealistic of a potrait shot scene where sw33ny a young and gorgeous beauty as a Holographic Interface Designer with long platinum-blonde hair in the center of a futuristic, holographic interface. The vibrant cyan data rings and geometric shapes from the background are surrounding her, some even seemingly projected from her hands as if she\\u2019s controlling the interface. Her partially unzipped circuit print stylish futuristic engineer uniform and choker contrast with the high-tech environment, creating a visual blend of the modern and the digital. Her eyes are focused on a specific holographic display in front of her, as if she is analyzing data or searching for information.\\n\\nsubtle, dynamic holographic patterns that shift colors along the stripes of her outfit, integrating her more into the digital environment.faintly glowing lines within her outfit\\u2019s fabric, creating a futuristic look that suggests advanced material technology. Her heart pendant have a small, glowing core, pulsing with light in sync with the holographic background. Very realistic overall texture composition.\\n\\nher Hair left loose with a decorative, knotted headband placed at the crown, adding a playful, bohemian touch.\\n\\n\\nvarying levels of transparency to different holographic elements, creating a layered and dynamic interface. a slight reflective glare on her lips to match the ambient light, enhancing their natural appearance.minor, flickering glitches or pixelations on some holographic elements, adding realism and a sense of dynamic interaction.\\n\\nBoth hands forming a triangle shape in front of her eyes, looking through it as if framing a particular part of the interface, lips pursed in concentration.\\n\"]}, {\"id\": 161, \"type\": \"LoraLoader\", \"pos\": {\"0\": -755, \"1\": 406}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 343}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 344}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [347], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [348], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\sydneySweeneyFlux.safetensors\", 1.2, 1]}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 324, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [0.5, 0.3, 576, 1024]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 863, \"1\": 16}, \"size\": [318.1961990975087, 569.048067717326], \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [159, 42, 0, 69, 0, \"LATENT\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [260, 72, 0, 71, 0, \"IMAGE\"], [282, 73, 0, 117, 0, \"IMAGE\"], [285, 75, 0, 59, 0, \"IMAGE\"], [287, 134, 0, 42, 2, \"SAMPLER\"], [288, 62, 0, 41, 0, \"IMAGE\"], [289, 61, 0, 77, 1, \"IMAGE\"], [294, 96, 0, 140, 1, \"MODEL\"], [295, 64, 0, 140, 2, \"CONDITIONING\"], [296, 65, 0, 140, 3, \"CONDITIONING\"], [297, 70, 0, 140, 4, \"VAE\"], [298, 141, 0, 140, 5, \"UPSCALE_MODEL\"], [299, 72, 0, 140, 0, \"IMAGE\"], [300, 140, 0, 142, 0, \"IMAGE\"], [305, 96, 0, 146, 0, \"MODEL\"], [306, 64, 0, 146, 1, \"CONDITIONING\"], [307, 65, 0, 146, 2, \"CONDITIONING\"], [308, 42, 0, 146, 3, \"LATENT\"], [310, 70, 0, 146, 4, \"VAE\"], [311, 146, 0, 147, 0, \"LATENT\"], [312, 81, 0, 147, 1, \"VAE\"], [313, 147, 0, 148, 0, \"IMAGE\"], [324, 153, 0, 30, 0, \"MODEL\"], [325, 153, 1, 49, 0, \"*\"], [326, 154, 0, 153, 0, \"MODEL\"], [327, 154, 1, 153, 1, \"CLIP\"], [330, 155, 0, 156, 0, \"MODEL\"], [331, 155, 1, 156, 1, \"CLIP\"], [332, 12, 0, 155, 0, \"MODEL\"], [333, 11, 0, 155, 1, \"CLIP\"], [342, 34, 0, 27, 0, \"INT\"], [343, 160, 0, 161, 0, \"MODEL\"], [344, 160, 1, 161, 1, \"CLIP\"], [345, 156, 1, 160, 1, \"CLIP\"], [346, 156, 0, 160, 0, \"MODEL\"], [347, 161, 0, 154, 0, \"MODEL\"], [348, 161, 1, 154, 1, \"CLIP\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.331000000000002, \"offset\": [-289.0163284787424, 121.24665309915152]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}, \"140\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"146\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"140\": 1, \"146\": 0}}}",
                "steps": 80,
                "models": [],
                "prompt": "Photorealistic of a potrait shot scene where  a young and gorgeous beauty as a Holographic Interface Designer with long platinum-blonde hair in the center of a futuristic, holographic interface. The vibrant cyan data rings and geometric shapes from the background are surrounding her, some even seemingly projected from her hands as if she\u2019s controlling the interface. Her partially unzipped circuit print stylish futuristic engineer uniform and choker contrast with the high-tech environment, creating a visual blend of the modern and the digital. Her eyes are focused on a specific holographic display in front of her, as if she is analyzing data or searching for information.\n\nsubtle, dynamic holographic patterns that shift colors along the stripes of her outfit, integrating her more into the digital environment.faintly glowing lines within her outfit\u2019s fabric, creating a futuristic look that suggests advanced material technology. Her heart pendant have a small, glowing core, pulsing with light in sync with the holographic background. Very realistic overall texture composition.\n\nher Hair left loose with a decorative, knotted headband placed at the crown, adding a playful, bohemian touch.\n\n\nvarying levels of transparency to different holographic elements, creating a layered and dynamic interface. a slight reflective glare on her lips to match the ambient light, enhancing their natural appearance.minor, flickering glitches or pixelations on some holographic elements, adding realism and a sense of dynamic interaction.\n\nBoth hands forming a triangle shape in front of her eyes, looking through it as if framing a particular part of the interface, lips pursed in concentration.\n",
                "denoise": 1,
                "sampler": "DPM2",
                "cfgScale": 3,
                "modelIds": [],
                "scheduler": "sgm_uniform",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux1\\sydneySweeneyFlux.safetensors",
                        "type": "lora",
                        "strength": 1.2,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "salammy",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 28984684,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6dfab205-99cd-4c26-b8cc-31b9abbeb478/width=512/6dfab205-99cd-4c26-b8cc-31b9abbeb478.jpeg",
            "hash": "UCBxp5Nx11w|}[S4EjspAJW;$$xFAIbFs,s.",
            "width": 512,
            "height": 512,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-12T03:58:57.916Z",
            "postId": 6485090,
            "stats": {
                "cryCount": 8,
                "laughCount": 25,
                "likeCount": 294,
                "dislikeCount": 0,
                "heartCount": 57,
                "commentCount": 0
            },
            "meta": {
                "Size": "512x512",
                "seed": 827527101,
                "steps": 20,
                "prompt": "Fractal sunset",
                "sampler": "Euler",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-09-12T0357:13.9148541Z",
                "negativePrompt": "Letters - numbers - words",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 128713,
                        "modelVersionName": "8"
                    }
                ]
            },
            "username": null,
            "baseModel": "SD 1.5"
        },
        {
            "id": 28950729,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/601ffd70-6607-440e-ae76-dcce82b8a625/width=832/601ffd70-6607-440e-ae76-dcce82b8a625.jpeg",
            "hash": "UHCFYRQ.Io%2}X$*S3e.4:-oxFRk0}e.%1S4",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-12T00:10:06.094Z",
            "postId": 6477578,
            "stats": {
                "cryCount": 9,
                "laughCount": 30,
                "likeCount": 276,
                "dislikeCount": 0,
                "heartCount": 69,
                "commentCount": 2
            },
            "meta": {
                "seed": 1890645255,
                "steps": 25,
                "prompt": "hyper realistic surreal photography of a knight in full armor stands on the edge of a cliff overlooking a sea of bones stretching to the horizon. His sword is plunged deep into the ground, and around the hilt, vines made of glowing veins pulse faintly with light, crawling up his arm. The sky above is a swirling mass of red and black clouds, with massive, spectral birds circling overhead. Behind him, the decaying remains of a once-grand castle sit on the cliffside, partially consumed by the encroaching bone sea, while distant whispers seem to echo from the abyss below. symmetric composition, low camera angle, bokeh, masterpiece, high quality, professional photography, film grain, hyper detailed, surreal,  <lora:flux_realism_lora:0.7> <lora:fluxenhancer:0.2> <lora:Aura_Flux:0.3> <lora:Dever_Flux_Enhancer:.5>",
                "sampler": "DPM++ 2M",
                "cfgScale": 1
            },
            "username": "CGArtist",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 28516089,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8f0d0718-b950-455d-b25e-4068d208cdd1/width=576/8f0d0718-b950-455d-b25e-4068d208cdd1.jpeg",
            "hash": "U8I:?p~UFL^O9vxZXS?F00IpD*oLI;Ip$fxZ",
            "width": 576,
            "height": 1024,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-09T10:00:39.446Z",
            "postId": 6379211,
            "stats": {
                "cryCount": 5,
                "laughCount": 24,
                "likeCount": 275,
                "dislikeCount": 0,
                "heartCount": 80,
                "commentCount": 1
            },
            "meta": {
                "seed": 256726812468549,
                "vaes": [],
                "Model": "SDXL\\Ich_Will_Mein_Steil_V4",
                "comfy": "{\"prompt\": {\"27\": {\"inputs\": {\"width\": 576, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"55\": {\"inputs\": {\"images\": [\"127\", 0]}, \"class_type\": \"PreviewImage\"}, \"57\": {\"inputs\": {\"filename_prefix\": \"Flux XL FInal\", \"images\": [\"127\", 0]}, \"class_type\": \"SaveImage\"}, \"94\": {\"inputs\": {\"seed\": 1003084097191639, \"steps\": 25, \"cfg\": 3.5, \"sampler_name\": \"euler\", \"scheduler\": \"sgm_uniform\", \"denoise\": 0.35000000000000003, \"preview_method\": \"auto\", \"vae_decode\": \"true\", \"model\": [\"141\", 0], \"positive\": [\"143\", 0], \"negative\": [\"163\", 0], \"latent_image\": [\"162\", 0], \"optional_vae\": [\"139\", 2]}, \"class_type\": \"KSampler (Efficient)\"}, \"103\": {\"inputs\": {\"filename_prefix\": \"Flux XL Small\", \"images\": [\"94\", 5]}, \"class_type\": \"SaveImage\"}, \"127\": {\"inputs\": {\"upscale_by\": [\"130\", 2], \"seed\": 866554430728580, \"steps\": 20, \"cfg\": 8.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.2, \"mode_type\": \"Linear\", \"tile_width\": 1024, \"tile_height\": 1024, \"mask_blur\": 8, \"tile_padding\": 32, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 8, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"94\", 5], \"model\": [\"94\", 0], \"positive\": [\"94\", 1], \"negative\": [\"94\", 2], \"vae\": [\"94\", 4], \"upscale_model\": [\"128\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"128\": {\"inputs\": {\"model_name\": \"4x_foolhardy_Remacri.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"129\": {\"inputs\": {\"image\": [\"94\", 5]}, \"class_type\": \"CM_NearestSDXLResolution\"}, \"130\": {\"inputs\": {\"desiredXSIZE\": [\"134\", 0], \"desiredYSIZE\": [\"131\", 0]}, \"class_type\": \"RecommendedResCalc\"}, \"131\": {\"inputs\": {\"op\": \"Mul\", \"a\": 2, \"b\": [\"129\", 1]}, \"class_type\": \"CM_IntBinaryOperation\"}, \"134\": {\"inputs\": {\"op\": \"Mul\", \"a\": 2, \"b\": [\"129\", 0]}, \"class_type\": \"CM_IntBinaryOperation\"}, \"138\": {\"inputs\": {\"model\": [\"150\", 0], \"conditioning\": [\"156\", 0]}, \"class_type\": \"BasicGuider\"}, \"139\": {\"inputs\": {\"ckpt_name\": \"SDXL\\\\Ich_Will_Mein_Steil_V4.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"141\": {\"inputs\": {\"model\": [\"139\", 0], \"clip\": [\"139\", 1], \"lora_stack\": [\"142\", 0]}, \"class_type\": \"CR Apply LoRA Stack\"}, \"142\": {\"inputs\": {\"switch_1\": \"On\", \"lora_name_1\": \"add-detail-xl.safetensors\", \"model_weight_1\": 1.0, \"clip_weight_1\": 1.0, \"switch_2\": \"On\", \"lora_name_2\": \"Pony Style\\\\Mechanism-pdxl-1.safetensors\", \"model_weight_2\": 1.0, \"clip_weight_2\": 1.0, \"switch_3\": \"On\", \"lora_name_3\": \"Pony Style\\\\Goth_girl_XL-v2.safetensors\", \"model_weight_3\": 0.6, \"clip_weight_3\": 1.0, \"lora_stack\": [\"169\", 0]}, \"class_type\": \"CR LoRA Stack\"}, \"143\": {\"inputs\": {\"text\": [\"148\", 0], \"clip\": [\"144\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"144\": {\"inputs\": {\"stop_at_clip_layer\": -2, \"clip\": [\"141\", 1]}, \"class_type\": \"CLIPSetLastLayer\"}, \"146\": {\"inputs\": {\"text\": \"highly detailed, fantasy art in the style of Alphonse Mucha, WOMAN holding a cup of steaming hot coffee, aesthetic sepia ink drawing, conceptual art, reference illustration, extremely beautiful, professional, dynamic, looking at viewer, high contrast, (intricate details, masterpiece, best quality:1.4),\\n\\nepic action, Unreal Engine, cinematic award winning artwork, many details, extreme detailed, full of details,Wide range of colors., dramatic, Dynamic,Cinematic,Sharp details, Insane quality. Insane resolution. Insane details. Masterpiece. 32k resolution. casting shadow style, cucoloris patterned illumination,  dvr-lnds-sdxl, ral-dissolve, ral-ertmsphr, ral-porcelain, ral-pxlprtcl, Niji, aidma-niji\"}, \"class_type\": \"Text Prompt (JPS)\"}, \"148\": {\"inputs\": {\"string\": [\"146\", 0], \"old\": \"\", \"new\": \"\"}, \"class_type\": \"String Replace (mtb)\"}, \"149\": {\"inputs\": {\"text\": [\"148\", 0], \"clip\": [\"150\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"150\": {\"inputs\": {\"ckpt_name\": \"flux\\\\Ich_Will_Mein_Steil_FLUX.safetensors_00001_.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"156\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"149\", 0]}, \"class_type\": \"FluxGuidance\"}, \"157\": {\"inputs\": {\"noise\": [\"158\", 0], \"guider\": [\"138\", 0], \"sampler\": [\"159\", 0], \"sigmas\": [\"160\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"158\": {\"inputs\": {\"noise_seed\": 256726812468549}, \"class_type\": \"RandomNoise\"}, \"159\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"160\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 20, \"denoise\": 1.0, \"model\": [\"150\", 0]}, \"class_type\": \"BasicScheduler\"}, \"161\": {\"inputs\": {\"samples\": [\"157\", 0], \"vae\": [\"150\", 2]}, \"class_type\": \"VAEDecode\"}, \"162\": {\"inputs\": {\"pixels\": [\"161\", 0], \"vae\": [\"139\", 2]}, \"class_type\": \"VAEEncode\"}, \"163\": {\"inputs\": {\"text\": [\"164\", 0], \"clip\": [\"144\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"164\": {\"inputs\": {\"text\": \"watermark, artist name, cartoon, painting, illustration, (worst quality, low quality, normal quality:2), watermark, logo, child, loli, blurry, cropped, body out of frame, flawed skin, ugly, blonde hair,\"}, \"class_type\": \"Text Prompt (JPS)\"}, \"165\": {\"inputs\": {\"images\": [\"161\", 0]}, \"class_type\": \"PreviewImage\"}, \"168\": {\"inputs\": {\"filename_prefix\": \"Flux Small\", \"images\": [\"161\", 0]}, \"class_type\": \"SaveImage\"}, \"169\": {\"inputs\": {\"switch_1\": \"On\", \"lora_name_1\": \"RMSDXL_Enhance.safetensors\", \"model_weight_1\": 3.0, \"clip_weight_1\": 1.0, \"switch_2\": \"On\", \"lora_name_2\": \"ArsMJStylePony_-_Art_Nouveau.safetensors\", \"model_weight_2\": 1.0, \"clip_weight_2\": 1.0, \"switch_3\": \"On\", \"lora_name_3\": \"PerfectEyesXL.safetensors\", \"model_weight_3\": 1.0, \"clip_weight_3\": 1.0}, \"class_type\": \"CR LoRA Stack\"}, \"171\": {\"inputs\": {\"guide_size\": 512.0, \"guide_size_for\": true, \"max_size\": 1024.0, \"seed\": 73245922584018, \"steps\": 20, \"cfg\": 8.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.5, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.5, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3.0, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"image\": [\"127\", 0], \"model\": [\"94\", 0], \"clip\": [\"139\", 1], \"vae\": [\"94\", 4], \"positive\": [\"94\", 1], \"negative\": [\"94\", 2], \"bbox_detector\": [\"175\", 0], \"sam_model_opt\": [\"176\", 0], \"segm_detector_opt\": [\"177\", 1]}, \"class_type\": \"FaceDetailer\"}, \"173\": {\"inputs\": {\"guide_size\": 512.0, \"guide_size_for\": true, \"max_size\": 1024.0, \"seed\": 261239649947350, \"steps\": 20, \"cfg\": 8.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.5, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.5, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3.0, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"image\": [\"171\", 0], \"model\": [\"94\", 0], \"clip\": [\"139\", 1], \"vae\": [\"94\", 4], \"positive\": [\"94\", 1], \"negative\": [\"94\", 2], \"bbox_detector\": [\"178\", 0], \"sam_model_opt\": [\"179\", 0], \"segm_detector_opt\": [\"180\", 1]}, \"class_type\": \"FaceDetailer\"}, \"174\": {\"inputs\": {\"filename_prefix\": \"Flux Small\", \"images\": [\"173\", 0]}, \"class_type\": \"SaveImage\"}, \"175\": {\"inputs\": {\"model_name\": \"bbox/hand_yolov8s.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"176\": {\"inputs\": {\"model_name\": \"sam_vit_b_01ec64.pth\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\"}, \"177\": {\"inputs\": {\"model_name\": \"segm/person_yolov8m-seg.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"178\": {\"inputs\": {\"model_name\": \"bbox/face_yolov8m.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"179\": {\"inputs\": {\"model_name\": \"sam_vit_b_01ec64.pth\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\"}, \"180\": {\"inputs\": {\"model_name\": \"segm/person_yolov8m-seg.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"181\": {\"inputs\": {\"image\": \"ComfyUI_36295_.png\", \"upload\": \"image\", \"parameter_index\": 0, \"positive\": \"\", \"negative\": \"\", \"setting\": \"The workflow is overly complex, or unsupported custom nodes have been used. Please see the README for more details.\\nhttps://github.com/receyuki/comfyui-prompt-reader-node#prompt-reader-node\"}, \"class_type\": \"SDPromptReader\", \"is_changed\": [\"{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\", \\\"positive_sdxl\\\": {}, \\\"negative_sdxl\\\": {}, \\\"is_sdxl\\\": false, \\\"model\\\": \\\"\\\", \\\"sampler\\\": \\\"\\\", \\\"seed\\\": \\\"\\\", \\\"cfg\\\": \\\"\\\", \\\"steps\\\": \\\"\\\", \\\"size\\\": \\\"\\\", \\\"height\\\": \\\"1344\\\", \\\"width\\\": \\\"768\\\", \\\"setting\\\": \\\"\\\"}\"]}}, \"workflow\": {\"last_node_id\": 181, \"last_link_id\": 395, \"nodes\": [{\"id\": 55, \"type\": \"PreviewImage\", \"pos\": {\"0\": 1532.004638671875, \"1\": 76.18801879882812}, \"size\": {\"0\": 479.5737609863281, \"1\": 619.4911499023438}, \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 294}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 130, \"type\": \"RecommendedResCalc\", \"pos\": {\"0\": 1525.287109375, \"1\": 741.3580932617188}, \"size\": {\"0\": 295.6000061035156, \"1\": 114}, \"flags\": {\"collapsed\": true}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"desiredXSIZE\", \"type\": \"INT\", \"link\": 306, \"widget\": {\"name\": \"desiredXSIZE\"}}, {\"name\": \"desiredYSIZE\", \"type\": \"INT\", \"link\": 307, \"widget\": {\"name\": \"desiredYSIZE\"}}], \"outputs\": [{\"name\": \"recomm width\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"recomm height\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"upscale factor\", \"type\": \"FLOAT\", \"links\": [308], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"reverse upscale for 4x\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}, {\"name\": \"reverse upscale for 2x\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RecommendedResCalc\"}, \"widgets_values\": [1024, 1024]}, {\"id\": 129, \"type\": \"CM_NearestSDXLResolution\", \"pos\": {\"0\": 1096.287109375, \"1\": 865.3580932617188}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 301}], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [312], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CM_NearestSDXLResolution\"}}, {\"id\": 57, \"type\": \"SaveImage\", \"pos\": {\"0\": 3474.28515625, \"1\": -431.9156799316406}, \"size\": {\"0\": 525.0610961914062, \"1\": 582.182373046875}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 295, \"slot_index\": 0}], \"outputs\": [], \"title\": \"Final Image\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"Flux XL FInal\"]}, {\"id\": 159, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": -198.1475830078125, \"1\": -423.43609619140625}, \"size\": {\"0\": 218.6189422607422, \"1\": 58}, \"flags\": {\"collapsed\": true}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [335], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 165, \"type\": \"PreviewImage\", \"pos\": {\"0\": 287, \"1\": -481}, \"size\": {\"0\": 498.2690734863281, \"1\": 427.11993408203125}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 352}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 161, \"type\": \"VAEDecode\", \"pos\": {\"0\": 60.852420806884766, \"1\": -469.43609619140625}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 339}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 340}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [341, 352, 366], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 168, \"type\": \"SaveImage\", \"pos\": {\"0\": 4064.609619140625, \"1\": -431.2122802734375}, \"size\": {\"0\": 525.0610961914062, \"1\": 582.182373046875}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 366}], \"outputs\": [], \"title\": \"Flux Generated Before Detailing and Upscaling Image\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"Flux Small\"]}, {\"id\": 131, \"type\": \"CM_IntBinaryOperation\", \"pos\": {\"0\": 1525, \"1\": 786}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"b\", \"type\": \"INT\", \"link\": 312, \"widget\": {\"name\": \"b\"}}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [307], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CM_IntBinaryOperation\"}, \"widgets_values\": [\"Mul\", 2, 0]}, {\"id\": 134, \"type\": \"CM_IntBinaryOperation\", \"pos\": {\"0\": 1524, \"1\": 832}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"b\", \"type\": \"INT\", \"link\": 311, \"widget\": {\"name\": \"b\"}}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [306], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CM_IntBinaryOperation\"}, \"widgets_values\": [\"Mul\", 2, 0]}, {\"id\": 103, \"type\": \"SaveImage\", \"pos\": {\"0\": 3481.609619140625, \"1\": 199.78773498535156}, \"size\": {\"0\": 525.0610961914062, \"1\": 582.182373046875}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 238}], \"outputs\": [], \"title\": \"Flux Generated Before Detailing and Upscaling Image\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"Flux XL Small\"]}, {\"id\": 158, \"type\": \"RandomNoise\", \"pos\": {\"0\": -203, \"1\": -476}, \"size\": {\"0\": 279.3462219238281, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [334], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [256726812468549, \"randomize\"]}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": -199, \"1\": -382}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": true}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [336], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [576, 1024, 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 138, \"type\": \"BasicGuider\", \"pos\": {\"0\": -517, \"1\": -331}, \"size\": {\"0\": 226.98257446289062, \"1\": 58.645484924316406}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 350}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 332}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [333], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 149, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -551, \"1\": -224}, \"size\": {\"0\": 222.98257446289062, \"1\": 67.73639678955078}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 369}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 327, \"slot_index\": 1, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [373], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 141, \"type\": \"CR Apply LoRA Stack\", \"pos\": {\"0\": -550, \"1\": 398}, \"size\": {\"0\": 254.40000915527344, \"1\": 66}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 315}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 319}, {\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": 316, \"slot_index\": 2}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [344], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [323], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR Apply LoRA Stack\"}}, {\"id\": 163, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -62, \"1\": 410}, \"size\": {\"0\": 210, \"1\": 59.249393463134766}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 346}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 347, \"slot_index\": 1, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [348], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 143, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -283, \"1\": 402}, \"size\": {\"0\": 210, \"1\": 59.249393463134766}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 320}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 326, \"slot_index\": 1, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [345], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 164, \"type\": \"Text Prompt (JPS)\", \"pos\": {\"0\": -229, \"1\": 553}, \"size\": {\"0\": 415.9304504394531, \"1\": 292.1475524902344}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"links\": [347], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Negative Prompt \", \"properties\": {\"Node name for S&R\": \"Text Prompt (JPS)\"}, \"widgets_values\": [\"watermark, artist name, cartoon, painting, illustration, (worst quality, low quality, normal quality:2), watermark, logo, child, loli, blurry, cropped, body out of frame, flawed skin, ugly, blonde hair,\"]}, {\"id\": 127, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 1090.004638671875, \"1\": 175.18801879882812}, \"size\": {\"0\": 421.5822448730469, \"1\": 642.752685546875}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 293}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 296}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 297}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 298}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 360}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 300}, {\"name\": \"upscale_by\", \"type\": \"FLOAT\", \"link\": 308, \"widget\": {\"name\": \"upscale_by\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [294, 295, 374], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [4, 866554430728580, \"randomize\", 20, 8, \"euler\", \"normal\", 0.2, \"Linear\", 1024, 1024, 8, 32, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 173, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 2702, \"1\": -436}, \"size\": {\"0\": 519, \"1\": 900}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 376}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 384}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 395}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 387}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 385}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 386}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 391}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 393}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 392}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [377], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [512, true, 1024, 261239649947350, \"randomize\", 20, 8, \"euler\", \"normal\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 144, \"type\": \"CLIPSetLastLayer\", \"pos\": {\"0\": -553, \"1\": 264}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 323}], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [320, 346], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPSetLastLayer\"}, \"widgets_values\": [-2]}, {\"id\": 171, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 2139, \"1\": -431}, \"size\": {\"0\": 519, \"1\": 900}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 374}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 378}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 394}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 381}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 379}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 380}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 388, \"slot_index\": 6}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 389, \"slot_index\": 7}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 390, \"slot_index\": 8}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [376], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [512, true, 1024, 73245922584018, \"randomize\", 20, 8, \"euler\", \"normal\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 176, \"type\": \"SAMLoader\", \"pos\": {\"0\": 2151, \"1\": 751}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [389], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 177, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2151, \"1\": 628}, \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [390], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/person_yolov8m-seg.pt\"]}, {\"id\": 175, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2142, \"1\": 509}, \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [388], \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/hand_yolov8s.pt\"]}, {\"id\": 179, \"type\": \"SAMLoader\", \"pos\": {\"0\": 2692, \"1\": 754}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [393], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 148, \"type\": \"String Replace (mtb)\", \"pos\": {\"0\": -177, \"1\": 157}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"string\", \"type\": \"STRING\", \"link\": 325, \"widget\": {\"name\": \"string\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [326, 327], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"String Replace (mtb)\"}, \"widgets_values\": [\"\", \"\", \"\"]}, {\"id\": 178, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2690, \"1\": 510}, \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [391], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 128, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 1094.004638671875, \"1\": 66.18801879882812}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x_foolhardy_Remacri.pth\"]}, {\"id\": 180, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2689, \"1\": 628}, \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [392], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/person_yolov8m-seg.pt\"]}, {\"id\": 174, \"type\": \"SaveImage\", \"pos\": {\"0\": 4050.80810546875, \"1\": 214.43017578125}, \"size\": {\"0\": 525.0610961914062, \"1\": 582.182373046875}, \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 377}], \"outputs\": [], \"title\": \"Flux Generated Before Detailing and Upscaling Image\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"Flux Small\"]}, {\"id\": 181, \"type\": \"SDPromptReader\", \"pos\": {\"0\": -1467, \"1\": -240}, \"size\": {\"0\": 315, \"1\": 978}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"POSITIVE\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}, {\"name\": \"NEGATIVE\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}, {\"name\": \"SEED\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"STEPS\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}, {\"name\": \"WIDTH\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"HEIGHT\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"MODEL_NAME\", \"type\": \"*\", \"links\": null, \"shape\": 3}, {\"name\": \"FILENAME\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}, {\"name\": \"SETTINGS\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SDPromptReader\"}, \"widgets_values\": [\"ComfyUI_36295_.png\", \"image\", 0, \"\", \"\", \"The workflow is overly complex, or unsupported custom nodes have been used. Please see the README for more details.\\nhttps://github.com/receyuki/comfyui-prompt-reader-node#prompt-reader-node\"]}, {\"id\": 142, \"type\": \"CR LoRA Stack\", \"pos\": {\"0\": -552, \"1\": 510}, \"size\": {\"0\": 315, \"1\": 342}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": 367}], \"outputs\": [{\"name\": \"LORA_STACK\", \"type\": \"LORA_STACK\", \"links\": [316], \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR LoRA Stack\"}, \"widgets_values\": [\"On\", \"add-detail-xl.safetensors\", 1, 1, \"On\", \"Pony Style\\\\Mechanism-pdxl-1.safetensors\", 1, 1, \"On\", \"Pony Style\\\\Goth_girl_XL-v2.safetensors\", 0.6, 1]}, {\"id\": 169, \"type\": \"CR LoRA Stack\", \"pos\": {\"0\": -917, \"1\": 520}, \"size\": {\"0\": 315, \"1\": 342}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": null}], \"outputs\": [{\"name\": \"LORA_STACK\", \"type\": \"LORA_STACK\", \"links\": [367], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR LoRA Stack\"}, \"widgets_values\": [\"On\", \"RMSDXL_Enhance.safetensors\", 3, 1, \"On\", \"ArsMJStylePony_-_Art_Nouveau.safetensors\", 1, 1, \"On\", \"PerfectEyesXL.safetensors\", 1, 1]}, {\"id\": 150, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": -545.1475830078125, \"1\": -475.43609619140625}, \"size\": {\"0\": 315, \"1\": 98}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [350, 351], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [369], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [340], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"flux\\\\Ich_Will_Mein_Steil_FLUX.safetensors_00001_.safetensors\"]}, {\"id\": 139, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": -552, \"1\": 84}, \"size\": {\"0\": 315, \"1\": 98}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [315], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [319, 394, 395], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [364, 365], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"SDXL\\\\Ich_Will_Mein_Steil_V4.safetensors\"]}, {\"id\": 157, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": -211, \"1\": -477}, \"size\": {\"0\": 236.8000030517578, \"1\": 148.19093322753906}, \"flags\": {\"collapsed\": false}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 334, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 333}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 335, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 337, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 336}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [339], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 94, \"type\": \"KSampler (Efficient)\", \"pos\": {\"0\": 217, \"1\": 61}, \"size\": {\"0\": 799.3107299804688, \"1\": 769.0582885742188}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 344}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 345}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 348}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 343}, {\"name\": \"optional_vae\", \"type\": \"VAE\", \"link\": 364}, {\"name\": \"script\", \"type\": \"SCRIPT\", \"link\": null}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [296, 378, 384], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CONDITIONING+\", \"type\": \"CONDITIONING\", \"links\": [297, 379, 385], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"CONDITIONING-\", \"type\": \"CONDITIONING\", \"links\": [298, 380, 386], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [360, 381, 387], \"slot_index\": 4, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [238, 293, 301], \"slot_index\": 5, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler (Efficient)\"}, \"widgets_values\": [-1, null, 25, 3.5, \"euler\", \"sgm_uniform\", 0.35000000000000003, \"auto\", \"true\"], \"color\": \"#222233\", \"bgcolor\": \"#333355\", \"shape\": 1}, {\"id\": 156, \"type\": \"FluxGuidance\", \"pos\": {\"0\": -296, \"1\": -121}, \"size\": {\"0\": 219.98257446289062, \"1\": 58}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 373}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 162, \"type\": \"VAEEncode\", \"pos\": {\"0\": -31, \"1\": -122}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 341}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 365}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [343], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}}, {\"id\": 160, \"type\": \"BasicScheduler\", \"pos\": {\"0\": -230, \"1\": -282}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 351}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [337], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 20, 1]}, {\"id\": 146, \"type\": \"Text Prompt (JPS)\", \"pos\": {\"0\": -1049, \"1\": -126}, \"size\": {\"0\": 415.9304504394531, \"1\": 292.1475524902344}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"links\": [325], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Positive Prompt \", \"properties\": {\"Node name for S&R\": \"Text Prompt (JPS)\"}, \"widgets_values\": [\"highly detailed, fantasy art in the style of Alphonse Mucha, WOMAN holding a cup of steaming hot coffee, aesthetic sepia ink drawing, conceptual art, reference illustration, extremely beautiful, professional, dynamic, looking at viewer, high contrast, (intricate details, masterpiece, best quality:1.4),\\n\\nepic action, Unreal Engine, cinematic award winning artwork, many details, extreme detailed, full of details,Wide range of colors., dramatic, Dynamic,Cinematic,Sharp details, Insane quality. Insane resolution. Insane details. Masterpiece. 32k resolution. casting shadow style, cucoloris patterned illumination,  dvr-lnds-sdxl, ral-dissolve, ral-ertmsphr, ral-porcelain, ral-pxlprtcl, Niji, aidma-niji\"]}], \"links\": [[238, 94, 5, 103, 0, \"IMAGE\"], [293, 94, 5, 127, 0, \"IMAGE\"], [294, 127, 0, 55, 0, \"IMAGE\"], [295, 127, 0, 57, 0, \"IMAGE\"], [296, 94, 0, 127, 1, \"MODEL\"], [297, 94, 1, 127, 2, \"CONDITIONING\"], [298, 94, 2, 127, 3, \"CONDITIONING\"], [300, 128, 0, 127, 5, \"UPSCALE_MODEL\"], [301, 94, 5, 129, 0, \"IMAGE\"], [306, 134, 0, 130, 0, \"INT\"], [307, 131, 0, 130, 1, \"INT\"], [308, 130, 2, 127, 6, \"FLOAT\"], [311, 129, 0, 134, 0, \"INT\"], [312, 129, 1, 131, 0, \"INT\"], [315, 139, 0, 141, 0, \"MODEL\"], [316, 142, 0, 141, 2, \"LORA_STACK\"], [319, 139, 1, 141, 1, \"CLIP\"], [320, 144, 0, 143, 0, \"CLIP\"], [323, 141, 1, 144, 0, \"CLIP\"], [325, 146, 0, 148, 0, \"STRING\"], [326, 148, 0, 143, 1, \"STRING\"], [327, 148, 0, 149, 1, \"STRING\"], [332, 156, 0, 138, 1, \"CONDITIONING\"], [333, 138, 0, 157, 1, \"GUIDER\"], [334, 158, 0, 157, 0, \"NOISE\"], [335, 159, 0, 157, 2, \"SAMPLER\"], [336, 27, 0, 157, 4, \"LATENT\"], [337, 160, 0, 157, 3, \"SIGMAS\"], [339, 157, 0, 161, 0, \"LATENT\"], [340, 150, 2, 161, 1, \"VAE\"], [341, 161, 0, 162, 0, \"IMAGE\"], [343, 162, 0, 94, 3, \"LATENT\"], [344, 141, 0, 94, 0, \"MODEL\"], [345, 143, 0, 94, 1, \"CONDITIONING\"], [346, 144, 0, 163, 0, \"CLIP\"], [347, 164, 0, 163, 1, \"STRING\"], [348, 163, 0, 94, 2, \"CONDITIONING\"], [350, 150, 0, 138, 0, \"MODEL\"], [351, 150, 0, 160, 0, \"MODEL\"], [352, 161, 0, 165, 0, \"IMAGE\"], [360, 94, 4, 127, 4, \"VAE\"], [364, 139, 2, 94, 4, \"VAE\"], [365, 139, 2, 162, 1, \"VAE\"], [366, 161, 0, 168, 0, \"IMAGE\"], [367, 169, 0, 142, 0, \"LORA_STACK\"], [369, 150, 1, 149, 0, \"CLIP\"], [373, 149, 0, 156, 0, \"CONDITIONING\"], [374, 127, 0, 171, 0, \"IMAGE\"], [376, 171, 0, 173, 0, \"IMAGE\"], [377, 173, 0, 174, 0, \"IMAGE\"], [378, 94, 0, 171, 1, \"MODEL\"], [379, 94, 1, 171, 4, \"CONDITIONING\"], [380, 94, 2, 171, 5, \"CONDITIONING\"], [381, 94, 4, 171, 3, \"VAE\"], [384, 94, 0, 173, 1, \"MODEL\"], [385, 94, 1, 173, 4, \"CONDITIONING\"], [386, 94, 2, 173, 5, \"CONDITIONING\"], [387, 94, 4, 173, 3, \"VAE\"], [388, 175, 0, 171, 6, \"BBOX_DETECTOR\"], [389, 176, 0, 171, 7, \"SAM_MODEL\"], [390, 177, 1, 171, 8, \"SEGM_DETECTOR\"], [391, 178, 0, 173, 6, \"BBOX_DETECTOR\"], [392, 180, 1, 173, 8, \"SEGM_DETECTOR\"], [393, 179, 0, 173, 7, \"SAM_MODEL\"], [394, 139, 1, 171, 2, \"CLIP\"], [395, 139, 1, 173, 2, \"CLIP\"]], \"groups\": [{\"title\": \"Detailers\", \"bounding\": [2080, -513, 1345, 1397], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"SD 1.5 or SDXL\", \"bounding\": [-561, -15, 1622, 897], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Output\", \"bounding\": [3448, -512, 1328, 1338], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"UPSCALER\", \"bounding\": [1074, -16, 961, 899], \"color\": \"#8A8\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"FLUX\", \"bounding\": [-557, -555, 1352, 517], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.2839025177495074, \"offset\": [1057.637813384363, 379.9576629844186]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"94\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"127\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"158\": {\"noise_seed\": 0}, \"159\": {\"sampler_name\": 0}, \"160\": {\"scheduler\": 0}, \"171\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}, \"173\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}}, \"seed_widgets\": {\"94\": 0, \"127\": 1, \"158\": 0, \"171\": 3, \"173\": 3}}}",
                "steps": 20,
                "models": [
                    "SDXL\\Ich_Will_Mein_Steil_V4.safetensors",
                    "flux\\Ich_Will_Mein_Steil_FLUX.safetensors_00001_.safetensors"
                ],
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 3.5,
                "modelIds": [],
                "scheduler": "simple",
                "upscalers": [
                    "4x_foolhardy_Remacri.pth"
                ],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": []
            },
            "username": "serget2",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 27151773,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/85ac5e8f-2169-4306-9ef8-bb70c9be2f54/width=1800/85ac5e8f-2169-4306-9ef8-bb70c9be2f54.jpeg",
            "hash": "UrH_f5NHjYt6~pS4WVoe-:WXkCayo#oeoJWX",
            "width": 2560,
            "height": 3712,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-01T02:29:58.532Z",
            "postId": 6072445,
            "stats": {
                "cryCount": 12,
                "laughCount": 23,
                "likeCount": 253,
                "dislikeCount": 0,
                "heartCount": 97,
                "commentCount": 2
            },
            "meta": {
                "seed": 1258870269,
                "vaes": [],
                "extra": {},
                "steps": 14,
                "models": [],
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, solo, (fluffy:0.8), (feral:1.2), cute, outdoors, (furry), (((mouse))), female, green eyes, grey fur, grey ears, claws, (fluffy cheeks:0.4), (short blue dress), in the style of beatrix potter, flat color, (sitting, leaning back:1.5), dock, pier, wharf, lake, low angle view, contemplative expression, (side view)",
                "sampler": "Euler a",
                "cfgScale": 3.5,
                "modelIds": [],
                "workflow": "img2img-upscale",
                "upscalers": [
                    "urn:air:multi:upscaler:civitai:147759@164821"
                ],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "score_6, score_5, score_4, (cub, young, child, chibi:1.5), busty, ugly face, low res, blurry face, ugly hands, pumped body, black and white, penis, clothing, breasts, big ears, ((hair)), nipples, green fur, belly, extra ears, human, blue fur, panties, simple background, (boring), tail,",
                "civitaiResources": [
                    {
                        "strength": 1,
                        "modelVersionId": 290640
                    },
                    {
                        "strength": 1,
                        "modelVersionId": 290640
                    },
                    {
                        "strength": 0.5,
                        "modelVersionId": 382152
                    },
                    {
                        "strength": 0.9,
                        "modelVersionId": 450029
                    },
                    {
                        "strength": 0.3,
                        "modelVersionId": 423178
                    },
                    {
                        "strength": 0.3,
                        "modelVersionId": 494676
                    },
                    {
                        "type": "upscaler",
                        "modelVersionId": 164821
                    }
                ],
                "additionalResources": []
            },
            "username": "JustAMouse",
            "baseModel": "Pony"
        },
        {
            "id": 26542548,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e0df3731-e14a-4e1b-8a14-2e086b92e712/width=1632/e0df3731-e14a-4e1b-8a14-2e086b92e712.jpeg",
            "hash": "U8FXL[X.8wRN}rEN5SI:00MxTx=}GGtSNGVE",
            "width": 1632,
            "height": 2384,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-28T07:52:44.778Z",
            "postId": 5932146,
            "stats": {
                "cryCount": 11,
                "laughCount": 33,
                "likeCount": 266,
                "dislikeCount": 0,
                "heartCount": 74,
                "commentCount": 0
            },
            "meta": {
                "seed": 1323,
                "vaes": [],
                "comfy": "{\"prompt\": {\"12\": {\"inputs\": {\"seed\": 1323, \"steps\": 50, \"cfg\": 3.0, \"sampler_name\": \"dpmpp_sde\", \"scheduler\": \"karras\", \"denoise\": 1.0, \"model\": [\"66\", 0], \"positive\": [\"66\", 1], \"negative\": [\"66\", 2], \"latent_image\": [\"66\", 3]}, \"class_type\": \"KSampler\"}, \"13\": {\"inputs\": {\"samples\": [\"12\", 0], \"vae\": [\"66\", 4]}, \"class_type\": \"VAEDecode\"}, \"15\": {\"inputs\": {\"images\": [\"42\", 0]}, \"class_type\": \"PreviewImage\"}, \"35\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"39\": {\"inputs\": {\"images\": [\"47\", 0]}, \"class_type\": \"PreviewImage\"}, \"40\": {\"inputs\": {\"upscale_by\": 1.25, \"seed\": 24, \"steps\": 25, \"cfg\": 3.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.4, \"mode_type\": \"Linear\", \"tile_width\": 832, \"tile_height\": 1216, \"mask_blur\": 20, \"tile_padding\": 56, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 8, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"42\", 0], \"model\": [\"66\", 0], \"positive\": [\"95\", 0], \"negative\": [\"95\", 1], \"vae\": [\"66\", 4], \"upscale_model\": [\"35\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"42\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"13\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"44\": {\"inputs\": {\"images\": [\"49\", 0]}, \"class_type\": \"PreviewImage\"}, \"46\": {\"inputs\": {\"upscale_by\": 1.25, \"seed\": 24, \"steps\": 25, \"cfg\": 3.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.35000000000000003, \"mode_type\": \"Linear\", \"tile_width\": 832, \"tile_height\": 1216, \"mask_blur\": 20, \"tile_padding\": 56, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 8, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"47\", 0], \"model\": [\"66\", 0], \"positive\": [\"95\", 0], \"negative\": [\"95\", 1], \"vae\": [\"66\", 4], \"upscale_model\": [\"35\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"47\": {\"inputs\": {\"hdr_intensity\": 0.5, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"52\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"49\": {\"inputs\": {\"hdr_intensity\": 0.25, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"53\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"52\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.25, \"alpha\": 0.25, \"image\": [\"40\", 0]}, \"class_type\": \"ImageSharpen\"}, \"53\": {\"inputs\": {\"sharpen_radius\": 2, \"sigma\": 0.1, \"alpha\": 0.1, \"image\": [\"46\", 0]}, \"class_type\": \"ImageSharpen\"}, \"54\": {\"inputs\": {\"images\": [\"57\", 0]}, \"class_type\": \"PreviewImage\"}, \"57\": {\"inputs\": {\"sharpen_radius\": 2, \"sigma\": 0.1, \"alpha\": 0.1, \"image\": [\"65\", 0]}, \"class_type\": \"ImageSharpen\"}, \"65\": {\"inputs\": {\"upscale_by\": 1.25, \"seed\": 15, \"steps\": 25, \"cfg\": 3.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.3, \"mode_type\": \"Linear\", \"tile_width\": 832, \"tile_height\": 1216, \"mask_blur\": 20, \"tile_padding\": 56, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 8, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"49\", 0], \"model\": [\"66\", 0], \"positive\": [\"95\", 0], \"negative\": [\"95\", 1], \"vae\": [\"66\", 4], \"upscale_model\": [\"35\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"66\": {\"inputs\": {\"ckpt_name\": \"realcartoonXL_v7.safetensors\", \"vae_name\": \"sdxl_vae.safetensors\", \"clip_skip\": -2, \"lora_name\": \"SDXL\\\\Korean_Instagram_XL.safetensors\", \"lora_model_strength\": 0.7000000000000001, \"lora_clip_strength\": 1.0, \"positive\": \"(3d:1.5), \\nDark gothic voluptuous female character with glowing orange eyes,long bangs, two toned hair, cybernetic arms, ornate mask, standing against a digital binary code geometric background, intense contrast, highly detailed.\\n\\nWalking towards the camera, eyes glowing with determination.\\n\\nPlayful smile, with a twinkle in the eyes.\\n\\nSlight lens flare from the neon lights. Glow particles floating in the air, adding a mystical touch.Fine details on the mask, with light playing across the surface.Intricate and complex detail of cybernetic suit design,  \\n\\nWide shot, capturing the entire scene including the wall and geometric patterns.\\n\\n\", \"negative\": \"Blurry background, pixelated textures, distorted proportions, Overexposed lighting, dull colors, lack of contrast.lat 2D design, low detail, inconsistent perspective.Unnatural shadows, awkward pose, poor composition.Cluttered background, noisy textures, poor depth of field.\\n\\nbad anatomy, bad hands, fewer digits, extra digits, \\n\\n\", \"token_normalization\": \"none\", \"weight_interpretation\": \"A1111\", \"empty_latent_width\": 832, \"empty_latent_height\": 1216, \"batch_size\": 1, \"ckpt_override\": \"None\", \"vae_override\": \"None\", \"lora_override\": \"None\"}, \"class_type\": \"AV_CheckpointLoader\"}, \"69\": {\"inputs\": {\"hdr_intensity\": 0.15, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"70\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"70\": {\"inputs\": {\"sharpen_radius\": 2, \"sigma\": 0.1, \"alpha\": 0.1, \"image\": [\"88\", 0]}, \"class_type\": \"ImageSharpen\"}, \"73\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"74\", 0]}, \"class_type\": \"SaveImage\"}, \"74\": {\"inputs\": {\"scale\": 0.5, \"strength\": 0.25, \"saturation\": 0.7, \"toe\": 0.0, \"seed\": 395830794425236, \"image\": [\"69\", 0]}, \"class_type\": \"BetterFilmGrain\"}, \"75\": {\"inputs\": {\"guide_size\": 1024.0, \"guide_size_for\": true, \"max_size\": 1024.0, \"seed\": 167922156589847, \"steps\": 20, \"cfg\": 3.0, \"sampler_name\": \"dpmpp_sde\", \"scheduler\": \"karras\", \"denoise\": 0.5, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.5, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3.0, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"image\": [\"74\", 0], \"model\": [\"66\", 0], \"clip\": [\"66\", 5], \"vae\": [\"66\", 4], \"positive\": [\"95\", 0], \"negative\": [\"95\", 1], \"bbox_detector\": [\"82\", 0], \"sam_model_opt\": [\"83\", 0]}, \"class_type\": \"FaceDetailer\"}, \"82\": {\"inputs\": {\"model_name\": \"bbox/face_yolov8m.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"83\": {\"inputs\": {\"model_name\": \"sam_vit_b_01ec64.pth\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\"}, \"85\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"75\", 0]}, \"class_type\": \"SaveImage\"}, \"86\": {\"inputs\": {\"images\": [\"75\", 1]}, \"class_type\": \"PreviewImage\"}, \"87\": {\"inputs\": {\"images\": [\"75\", 2]}, \"class_type\": \"PreviewImage\"}, \"88\": {\"inputs\": {\"upscale_by\": 1.0, \"seed\": 15, \"steps\": 25, \"cfg\": 3.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.25, \"mode_type\": \"Linear\", \"tile_width\": 832, \"tile_height\": 1216, \"mask_blur\": 20, \"tile_padding\": 56, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 8, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"57\", 0], \"model\": [\"66\", 0], \"positive\": [\"95\", 0], \"negative\": [\"95\", 1], \"vae\": [\"66\", 4], \"upscale_model\": [\"35\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"95\": {\"inputs\": {\"control_net_name\": \"thibaud_xl_openpose.safetensors\", \"strength\": 1.0, \"start_percent\": 0.0, \"end_percent\": 1.0, \"preprocessor\": \"dwpose\", \"control_net_override\": \"None\", \"resolution\": 1024, \"enabled\": true, \"positive\": [\"66\", 1], \"negative\": [\"66\", 2], \"image\": [\"42\", 0]}, \"class_type\": \"AV_ControlNetEfficientLoaderAdvanced\"}, \"98\": {\"inputs\": {\"anything\": [\"75\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}}, \"workflow\": {\"last_node_id\": 98, \"last_link_id\": 194, \"nodes\": [{\"id\": 32, \"type\": \"Reroute\", \"pos\": [1794.5005065105943, -112.57510903620539], \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 21, \"type\": \"Reroute\", \"pos\": [436, -298], \"size\": [75, 26], \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 112}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [26], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 16, \"type\": \"Reroute\", \"pos\": [437, -260], \"size\": [75, 26], \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 114}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [182], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 17, \"type\": \"Reroute\", \"pos\": [439, -224], \"size\": [75, 26], \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 116}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [183], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 18, \"type\": \"Reroute\", \"pos\": [440, -186], \"size\": [75, 26], \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 119}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [29], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 26, \"type\": \"Reroute\", \"pos\": [1146, -108], \"size\": [75, 26], \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 24}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [41], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 27, \"type\": \"Reroute\", \"pos\": [1141, -295], \"size\": [75, 26], \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 26}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [43, 57], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 24, \"type\": \"Reroute\", \"pos\": [1147, -187], \"size\": [75, 26], \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 29}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [46, 60], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 39, \"type\": \"PreviewImage\", \"pos\": [1664, 145], \"size\": {\"0\": 319.58428955078125, \"1\": 497.648193359375}, \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 71}], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 33, \"type\": \"Reroute\", \"pos\": [1789, -300], \"size\": [75, 26], \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 57}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [63, 89], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 28, \"type\": \"Reroute\", \"pos\": [1789.5005065105943, -261.5751090362054], \"size\": [75, 26], \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 58}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [64, 90], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 29, \"type\": \"Reroute\", \"pos\": [1791.5005065105943, -225.5751090362054], \"size\": [75, 26], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 59}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [65, 91], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 30, \"type\": \"Reroute\", \"pos\": [1792.5005065105943, -187.5751090362054], \"size\": [75, 26], \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 60}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [66, 92], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"PreviewImage\", \"pos\": [3205, 50], \"size\": {\"0\": 319.58428955078125, \"1\": 497.648193359375}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 85}], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 73, \"type\": \"SaveImage\", \"pos\": [3916, 51], \"size\": {\"0\": 335.8769836425781, \"1\": 477.0582580566406}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 138}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 80, \"type\": \"Reroute\", \"pos\": [4519.3706345312585, -80.79678440590374], \"size\": [75, 26], \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": [2717.8852576927384, -261.48673329243866], \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 90}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [105, 141, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 59, \"type\": \"Reroute\", \"pos\": [2719.8852576927384, -225.48673329243866], \"size\": [75, 26], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 91}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [106, 142, 164], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 61, \"type\": \"Reroute\", \"pos\": [2721.8852576927384, -149.48673329243866], \"size\": [75, 26], \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": [4513.48537683852, -268.3100511134651], \"size\": [75, 26], \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 140}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 76, \"type\": \"Reroute\", \"pos\": [4514.3706345312585, -229.79678440590374], \"size\": [75, 26], \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [145], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 77, \"type\": \"Reroute\", \"pos\": [4516.3706345312585, -193.79678440590374], \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 142}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [146], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 31, \"type\": \"Reroute\", \"pos\": [1793.5005065105943, -149.5751090362054], \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 147}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [148], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 62, \"type\": \"Reroute\", \"pos\": [2722.8852576927384, -112.48673329243866], \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 148}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [149], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 79, \"type\": \"Reroute\", \"pos\": [4518.3706345312585, -117.79678440590374], \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [193], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 82, \"type\": \"UltralyticsDetectorProvider\", \"pos\": [4280, 284], \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [151], \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 83, \"type\": \"SAMLoader\", \"pos\": [4285, 409], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [152], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 84, \"type\": \"UltralyticsDetectorProvider\", \"pos\": [4284, 540], \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 5, \"mode\": 4, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [153], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/person_yolov8m-seg.pt\"]}, {\"id\": 87, \"type\": \"PreviewImage\", \"pos\": [5731, 451], \"size\": {\"0\": 268.7850036621094, \"1\": 417.07080078125}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 156}], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 60, \"type\": \"Reroute\", \"pos\": [2720.8852576927384, -187.48673329243866], \"size\": [75, 26], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 92}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [107, 157, 165], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 78, \"type\": \"Reroute\", \"pos\": [4517.3706345312585, -155.79678440590374], \"size\": [75, 26], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [158], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 86, \"type\": \"PreviewImage\", \"pos\": [5723, 71], \"size\": {\"0\": 289.0073547363281, \"1\": 339.959716796875}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 155}], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 44, \"type\": \"PreviewImage\", \"pos\": [2448, 43], \"size\": {\"0\": 319.58428955078125, \"1\": 497.648193359375}, \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 75}], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 47, \"type\": \"LayerFilter: HDREffects\", \"pos\": [1675, 866], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 81}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [71, 72], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25]}, {\"id\": 49, \"type\": \"LayerFilter: HDREffects\", \"pos\": [2455, 769], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 84}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [75, 109], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.25, 0.25, 0.75, 0.25, 0.1, 0.25]}, {\"id\": 53, \"type\": \"ImageSharpen\", \"pos\": [2454, 613], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 83}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [84], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [2, 0.1, 0.1]}, {\"id\": 52, \"type\": \"ImageSharpen\", \"pos\": [1666, 697], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 80}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [81], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.25, 0.25]}, {\"id\": 57, \"type\": \"ImageSharpen\", \"pos\": [3191, 600], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 110}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [87], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [2, 0.1, 0.1]}, {\"id\": 56, \"type\": \"LayerFilter: HDREffects\", \"pos\": [3193, 763], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 51, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 87}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [85, 160], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.2, 0.25, 0.09, 0.25, 0.1, 0.25]}, {\"id\": 70, \"type\": \"ImageSharpen\", \"pos\": [3917, 584], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 161}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [2, 0.1, 0.1]}, {\"id\": 69, \"type\": \"LayerFilter: HDREffects\", \"pos\": [3924, 751], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 136}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [137], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.15, 0.25, 0.75, 0.25, 0.1, 0.25]}, {\"id\": 74, \"type\": \"BetterFilmGrain\", \"pos\": [4283, 59], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 137}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [138, 139], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BetterFilmGrain\"}, \"widgets_values\": [0.5, 0.25, 0.7, 0, 395830794425236, \"randomize\"]}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": [2717, -300], \"size\": [75, 26], \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 89}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [104, 140, 162], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 35, \"type\": \"UpscaleModelLoader\", \"pos\": [1676, 38], \"size\": {\"0\": 273.9732360839844, \"1\": 58}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [47, 67, 108, 166], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"]}, {\"id\": 15, \"type\": \"PreviewImage\", \"pos\": [751, 135], \"size\": {\"0\": 394.7203369140625, \"1\": 583.9453125}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 50}], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 20, \"type\": \"Reroute\", \"pos\": [442, -111], \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 167}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [24], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 13, \"type\": \"VAEDecode\", \"pos\": [474, 41], \"size\": {\"0\": 140, \"1\": 46.587867736816406}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 14}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 118}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [77], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 42, \"type\": \"LayerFilter: HDREffects\", \"pos\": [394, 914], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 78}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [50, 167, 186], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.75, 0.25, 0.1, 0.25]}, {\"id\": 23, \"type\": \"Reroute\", \"pos\": [1144, -226], \"size\": [75, 26], \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 185}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [59, 187], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 22, \"type\": \"Reroute\", \"pos\": [1144, -262], \"size\": [75, 26], \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 184}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [58, 188], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 51, \"type\": \"ImageSharpen\", \"pos\": [391, 776], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 20, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 77}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [78], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.4, 0.4]}, {\"id\": 40, \"type\": \"UltimateSDUpscale\", \"pos\": [1303, 48], \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 41}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 43}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 188}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 187}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 46}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 47}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [80], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.25, 24, \"fixed\", 25, 3, \"euler\", \"normal\", 0.4, \"Linear\", 832, 1216, 20, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 46, \"type\": \"UltimateSDUpscale\", \"pos\": [2045, 42], \"size\": [289.110095816126, 1021.839005351575], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 72}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 63}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 64}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 65}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 66}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 67}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [83], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.25, 24, \"fixed\", 25, 3, \"euler\", \"normal\", 0.35000000000000003, \"Linear\", 832, 1216, 20, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 65, \"type\": \"UltimateSDUpscale\", \"pos\": [2839, 67], \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 109}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 104}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 105}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 106}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 107}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 108}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [110], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.25, 15, \"fixed\", 25, 3, \"euler\", \"normal\", 0.3, \"Linear\", 832, 1216, 20, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 88, \"type\": \"UltimateSDUpscale\", \"pos\": [3559, 67], \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 160}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 162}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 163}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 164}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 165}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 166}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [161], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1, 15, \"fixed\", 25, 3, \"euler\", \"normal\", 0.25, \"Linear\", 832, 1216, 20, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 85, \"type\": \"SaveImage\", \"pos\": [5202, 71], \"size\": {\"0\": 504.6739196777344, \"1\": 891.2930297851562}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 154}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 66, \"type\": \"AV_CheckpointLoader\", \"pos\": [-4, 22], \"size\": {\"0\": 330.995361328125, \"1\": 1067.3555908203125}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": null}, {\"name\": \"cnet_stack\", \"type\": \"CONTROL_NET_STACK\", \"link\": null}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [111, 112], \"shape\": 3}, {\"name\": \"CONDITIONING+\", \"type\": \"CONDITIONING\", \"links\": [113, 114], \"shape\": 3}, {\"name\": \"CONDITIONING-\", \"type\": \"CONDITIONING\", \"links\": [115, 116], \"shape\": 3}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [117], \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [118, 119], \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [194], \"shape\": 3}, {\"name\": \"DEPENDENCIES\", \"type\": \"DEPENDENCIES\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"AV_CheckpointLoader\"}, \"widgets_values\": [\"realcartoonXL_v7.safetensors\", \"sdxl_vae.safetensors\", -2, \"SDXL\\\\Korean_Instagram_XL.safetensors\", 0.7000000000000001, 1, \"(3d:1.5), \\nDark gothic voluptuous female character with glowing orange eyes,long bangs, two toned hair, cybernetic arms, ornate mask, standing against a digital binary code geometric background, intense contrast, highly detailed.\\n\\nWalking towards the camera, eyes glowing with determination.\\n\\nPlayful smile, with a twinkle in the eyes.\\n\\nSlight lens flare from the neon lights. Glow particles floating in the air, adding a mystical touch.Fine details on the mask, with light playing across the surface.Intricate and complex detail of cybernetic suit design,  \\n\\nWide shot, capturing the entire scene including the wall and geometric patterns.\\n\\n\", \"Blurry background, pixelated textures, distorted proportions, Overexposed lighting, dull colors, lack of contrast.lat 2D design, low detail, inconsistent perspective.Unnatural shadows, awkward pose, poor composition.Cluttered background, noisy textures, poor depth of field.\\n\\nbad anatomy, bad hands, fewer digits, extra digits, \\n\\n\", \"none\", \"A1111\", 832, 1216, 1, \"None\", \"None\", \"None\"]}, {\"id\": 98, \"type\": \"easy cleanGpuUsed\", \"pos\": [5237, -27], \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 192}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 75, \"type\": \"FaceDetailer\", \"pos\": [4660, 58], \"size\": {\"0\": 519, \"1\": 1120}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 139}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 144}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 193}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 158}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 145}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 146}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 151}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 152}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 153}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [154, 192], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [155], \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [156], \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [1024, true, 1024, 167922156589847, \"randomize\", 20, 3, \"dpmpp_sde\", \"karras\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 25, \"type\": \"Reroute\", \"pos\": [1163, 6], \"size\": [75, 26], \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 95, \"type\": \"AV_ControlNetEfficientLoaderAdvanced\", \"pos\": [590, -348], \"size\": [244.9754117641021, 286], \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 182}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 183}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 186}, {\"name\": \"timestep_keyframe\", \"type\": \"TIMESTEP_KEYFRAME\", \"link\": null}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [184], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [185], \"shape\": 3, \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"AV_ControlNetEfficientLoaderAdvanced\"}, \"widgets_values\": [\"thibaud_xl_openpose.safetensors\", 1, 0, 1, \"dwpose\", \"None\", 1024, true]}, {\"id\": 19, \"type\": \"Reroute\", \"pos\": [441, -148], \"size\": [75, 26], \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [147], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 12, \"type\": \"KSampler\", \"pos\": [402, 124], \"size\": [244.44511959211457, 613.3646101085849], \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 111}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 113}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 115}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 117}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [14], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1323, \"increment\", 50, 3, \"dpmpp_sde\", \"karras\", 1]}], \"links\": [[14, 12, 0, 13, 0, \"LATENT\"], [24, 20, 0, 26, 0, \"*\"], [26, 21, 0, 27, 0, \"*\"], [29, 18, 0, 24, 0, \"*\"], [41, 26, 0, 40, 0, \"IMAGE\"], [43, 27, 0, 40, 1, \"MODEL\"], [46, 24, 0, 40, 4, \"VAE\"], [47, 35, 0, 40, 5, \"UPSCALE_MODEL\"], [50, 42, 0, 15, 0, \"IMAGE\"], [57, 27, 0, 33, 0, \"*\"], [58, 22, 0, 28, 0, \"*\"], [59, 23, 0, 29, 0, \"*\"], [60, 24, 0, 30, 0, \"*\"], [63, 33, 0, 46, 1, \"MODEL\"], [64, 28, 0, 46, 2, \"CONDITIONING\"], [65, 29, 0, 46, 3, \"CONDITIONING\"], [66, 30, 0, 46, 4, \"VAE\"], [67, 35, 0, 46, 5, \"UPSCALE_MODEL\"], [71, 47, 0, 39, 0, \"IMAGE\"], [72, 47, 0, 46, 0, \"IMAGE\"], [75, 49, 0, 44, 0, \"IMAGE\"], [77, 13, 0, 51, 0, \"IMAGE\"], [78, 51, 0, 42, 0, \"IMAGE\"], [80, 40, 0, 52, 0, \"IMAGE\"], [81, 52, 0, 47, 0, \"IMAGE\"], [83, 46, 0, 53, 0, \"IMAGE\"], [84, 53, 0, 49, 0, \"IMAGE\"], [85, 56, 0, 54, 0, \"IMAGE\"], [87, 57, 0, 56, 0, \"IMAGE\"], [89, 33, 0, 63, 0, \"*\"], [90, 28, 0, 58, 0, \"*\"], [91, 29, 0, 59, 0, \"*\"], [92, 30, 0, 60, 0, \"*\"], [104, 63, 0, 65, 1, \"MODEL\"], [105, 58, 0, 65, 2, \"CONDITIONING\"], [106, 59, 0, 65, 3, \"CONDITIONING\"], [107, 60, 0, 65, 4, \"VAE\"], [108, 35, 0, 65, 5, \"UPSCALE_MODEL\"], [109, 49, 0, 65, 0, \"IMAGE\"], [110, 65, 0, 57, 0, \"IMAGE\"], [111, 66, 0, 12, 0, \"MODEL\"], [112, 66, 0, 21, 0, \"*\"], [113, 66, 1, 12, 1, \"CONDITIONING\"], [114, 66, 1, 16, 0, \"*\"], [115, 66, 2, 12, 2, \"CONDITIONING\"], [116, 66, 2, 17, 0, \"*\"], [117, 66, 3, 12, 3, \"LATENT\"], [118, 66, 4, 13, 1, \"VAE\"], [119, 66, 4, 18, 0, \"*\"], [136, 70, 0, 69, 0, \"IMAGE\"], [137, 69, 0, 74, 0, \"IMAGE\"], [138, 74, 0, 73, 0, \"IMAGE\"], [139, 74, 0, 75, 0, \"IMAGE\"], [140, 63, 0, 81, 0, \"*\"], [141, 58, 0, 76, 0, \"*\"], [142, 59, 0, 77, 0, \"*\"], [144, 81, 0, 75, 1, \"MODEL\"], [145, 76, 0, 75, 4, \"CONDITIONING\"], [146, 77, 0, 75, 5, \"CONDITIONING\"], [147, 19, 0, 31, 0, \"*\"], [148, 31, 0, 62, 0, \"*\"], [149, 62, 0, 79, 0, \"*\"], [151, 82, 0, 75, 6, \"BBOX_DETECTOR\"], [152, 83, 0, 75, 7, \"SAM_MODEL\"], [153, 84, 1, 75, 8, \"SEGM_DETECTOR\"], [154, 75, 0, 85, 0, \"IMAGE\"], [155, 75, 1, 86, 0, \"IMAGE\"], [156, 75, 2, 87, 0, \"IMAGE\"], [157, 60, 0, 78, 0, \"*\"], [158, 78, 0, 75, 3, \"VAE\"], [160, 56, 0, 88, 0, \"IMAGE\"], [161, 88, 0, 70, 0, \"IMAGE\"], [162, 63, 0, 88, 1, \"MODEL\"], [163, 58, 0, 88, 2, \"CONDITIONING\"], [164, 59, 0, 88, 3, \"CONDITIONING\"], [165, 60, 0, 88, 4, \"VAE\"], [166, 35, 0, 88, 5, \"UPSCALE_MODEL\"], [167, 42, 0, 20, 0, \"*\"], [182, 16, 0, 95, 0, \"CONDITIONING\"], [183, 17, 0, 95, 1, \"CONDITIONING\"], [184, 95, 0, 22, 0, \"*\"], [185, 95, 1, 23, 0, \"*\"], [186, 42, 0, 95, 2, \"IMAGE\"], [187, 23, 0, 40, 3, \"CONDITIONING\"], [188, 22, 0, 40, 2, \"CONDITIONING\"], [192, 75, 0, 98, 0, \"*\"], [193, 79, 0, 75, 2, \"CLIP\"], [194, 66, 5, 19, 0, \"*\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.1918176537727627, \"offset\": [8.139810068148915, 96.56087806919365]}}, \"version\": 0.4, \"widget_idx_map\": {\"12\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"40\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"46\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"65\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"74\": {\"seed\": 4}, \"75\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}, \"88\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}}, \"seed_widgets\": {\"12\": 0, \"40\": 1, \"46\": 1, \"65\": 1, \"74\": 4, \"75\": 3, \"88\": 1}}}",
                "steps": 50,
                "models": [],
                "denoise": 1,
                "sampler": "DPM++ SDE Karras",
                "cfgScale": 3,
                "modelIds": [],
                "scheduler": "karras",
                "upscalers": [
                    "4x-UltraSharp.pth"
                ],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": []
            },
            "username": "salammy",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 25138490,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8844ee52-0144-4e3b-8dc1-419efb10696e/width=832/8844ee52-0144-4e3b-8dc1-419efb10696e.jpeg",
            "hash": "UEBBSUxaFcS#|LniJ7WV6fbHSgbHB9ofW;Sg",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-19T18:19:29.390Z",
            "postId": 5617255,
            "stats": {
                "cryCount": 21,
                "laughCount": 45,
                "likeCount": 248,
                "dislikeCount": 0,
                "heartCount": 70,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3632171966,
                "steps": 25,
                "prompt": "Extremely detailed photograph of a rose made of trypophobic human eyes. Horrific and intriguing.",
                "sampler": "Undefined",
                "cfgScale": 3,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-19T1817:28.9666180Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    }
                ]
            },
            "username": "ElMagoLoco",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 23185578,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/70406161-74da-47f4-a2f4-61f4aae9b3be/width=1216/70406161-74da-47f4-a2f4-61f4aae9b3be.jpeg",
            "hash": "U68zx,^*_2_N?aW=%M-:00E2D%D%01xuD*4:",
            "width": 1216,
            "height": 832,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-27T00:00:00.000Z",
            "postId": 5165332,
            "stats": {
                "cryCount": 8,
                "laughCount": 49,
                "likeCount": 250,
                "dislikeCount": 0,
                "heartCount": 77,
                "commentCount": 0
            },
            "meta": {
                "Size": "1216x832",
                "seed": 2513728992,
                "steps": 25,
                "prompt": "score_9, score_8_up, score_7_up, \nBREAK\nPC with BSOD, PC, blue screan of death, (BSOD:1.1), (error screen:1.1),\n(cat lying on the keyboard:1.1), \nindoors, cozy room, \nretro,",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-07T1204:14.6148130Z",
                "negativePrompt": "3d, censored, human",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 578496,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 607615,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "ohwtfamilookingat",
            "baseModel": "Pony"
        },
        {
            "id": 21672123,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5c118a09-0d43-46cb-aa8d-5cf9fbae78a3/width=832/5c118a09-0d43-46cb-aa8d-5cf9fbae78a3.jpeg",
            "hash": "UAI|{]^kGak=00xa%Lxt*0X9=x$%9ZIVxtt7",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-28T02:34:07.789Z",
            "postId": 4830158,
            "stats": {
                "cryCount": 8,
                "laughCount": 24,
                "likeCount": 281,
                "dislikeCount": 0,
                "heartCount": 71,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2063090864,
                "steps": 14,
                "prompt": "30yo woman wearing white shirt and yoga pants with white textures \nlong black dark hair slick back and smooth. making a kiss face \nsmile. Looking at camera. POV.\nDancing, moving, happy. \nKitchen. Fully furnished.\nNight time.",
                "sampler": "DPM2",
                "cfgScale": 1.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-07-28T0231:07.9392065Z",
                "negativePrompt": "Tattoo. Asian. Black. Japanese. Weird hands. More than 5 fingers in each hands. Werid fingers. Weird toes.",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 672019,
                        "modelVersionName": "v14.0 Crystal Clarity"
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 240247,
                        "modelVersionName": "v0.8"
                    },
                    {
                        "type": "lora",
                        "weight": 0.75,
                        "modelVersionId": 306317,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "VeronicaL",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 20883364,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3a587f5a-7f32-4115-855d-e010208456cf/width=832/3a587f5a-7f32-4115-855d-e010208456cf.jpeg",
            "hash": "U6AS*[s;58,:~C=dj^Io0#,:-;kC0#ay%Mxa",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-22T11:00:46.668Z",
            "postId": 4656978,
            "stats": {
                "cryCount": 6,
                "laughCount": 28,
                "likeCount": 223,
                "dislikeCount": 0,
                "heartCount": 127,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2400324301,
                "steps": 19,
                "prompt": "score_9, score_8_up, score_8,\n[][][]\n(((mouse))), ((feral)), female, solo, (fluffy), (fluffy cheeks:0.7), (cute)\n[][][]\nflat color, in the style of Beatrix Potter,\n[][][][][]\n(black dress, witch hat), grey fur, (black ears), red eyes, (side view:0.8), outdoors, standing, (upper body shot, head focus, close up), holding magic staff, look at viewer, night, stars, (cool color pallet), (evil expression:1.2), forest,",
                "sampler": "Euler a",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-07-22T1007:29.8887082Z",
                "negativePrompt": "score_6, score_5, score_4, (cub, young, child, chibi:1.5), busty, ugly face, low res, blurry face, ugly hands, pumped body, black and white, penis, clothing, breasts, big ears, ((hair)), nipples, green fur, belly, extra ears, human, blue fur, panties,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640,
                        "modelVersionName": "V6 (start with this one)"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 423178,
                        "modelVersionName": "Beatrix potter drawing style"
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 450029,
                        "modelVersionName": "LineArt Mono"
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 494676,
                        "modelVersionName": "Flat Color"
                    }
                ]
            },
            "username": "JustAMouse",
            "baseModel": "Pony"
        },
        {
            "id": 20867079,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2e47dbab-3edd-47ab-a4ac-2ac81d357ec7/width=1152/2e47dbab-3edd-47ab-a4ac-2ac81d357ec7.jpeg",
            "hash": "UF7L.UoMaekCc[a}VEoLrYjZQ,WVn4jZrrja",
            "width": 1152,
            "height": 2016,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-22T07:35:05.181Z",
            "postId": 4653325,
            "stats": {
                "cryCount": 11,
                "laughCount": 20,
                "likeCount": 257,
                "dislikeCount": 0,
                "heartCount": 96,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "fixFP16ErrorsSDXLLowerMemoryUse_v10.safetensors",
                "Size": "768x1344",
                "seed": 612557461,
                "Model": "realcartoonXL_v6",
                "steps": 40,
                "hashes": {
                    "vae": "538255c0d5",
                    "model": "d370e2fbaa"
                },
                "prompt": "2D anime style, eerie feminine figure with glowing blue eyes and a sinister grin, standing tall with arms outstretched, shrouded in a hooded cloak intertwined with vines and roses. Mechanical limbs covered in intricate floral patterns, expressive and haunting presence, detailed and vibrant flowers and leaves. Background features a dark, foggy forest with twisted trees and glowing orbs, extreme complexity and details, bold outlines, flat colors",
                "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
                "sampler": "Restart",
                "cfgScale": 9,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "d370e2fbaa",
                        "name": "realcartoonXL_v6",
                        "type": "model"
                    }
                ],
                "Model hash": "d370e2fbaa",
                "Extra noise": "0.07",
                "Hires upscale": "1.5",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "blurry details, low quality, dull colors, simplistic background, exaggerated features, abnormal hands, deformed fingers\nhands with unnatural shapes, wrong hand,  extra fingers,  fused fingers, misaligned eyes, mouths with abnormal shapes, extra facial features , disproportionate body parts, backgrounds that do not blend well with the foreground, clothing that appears painted on,",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.5.1",
                "Denoising strength": "0.5",
                "ADetailer mask blur": "32",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer ControlNet model": "thibaud_xl_openpose [c7b9cadd]",
                "ADetailer ControlNet module": "dw_openpose_full",
                "ADetailer denoising strength": "0.5",
                "ADetailer inpaint only masked": "True"
            },
            "username": "salammy",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 18484785,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/71111b3d-1e65-4027-96fd-5a6afa1998d9/width=832/71111b3d-1e65-4027-96fd-5a6afa1998d9.jpeg",
            "hash": "U49r|QI[tkD*~W5mxt+[14$hRjjq0g}rM{AD",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-07-05T02:19:28.791Z",
            "postId": 4129132,
            "stats": {
                "cryCount": 11,
                "laughCount": 38,
                "likeCount": 216,
                "dislikeCount": 0,
                "heartCount": 119,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1726853958,
                "steps": 20,
                "prompt": "score_9, score_8_up, score_8, score_7_up, score_7, score_6_up, score_6, score_5_up, Score_5, girl, beautiful face, 1girl, black long hair, bare leg, juice ass, high heel, black tight dress, transparent lace dress, huge teardrop breast, tying hair, sagging breast, city background, makeup,  bare shoulder, red jacket, halfbody, front view, short dress, night, bokeh, smoking, sit on chair, balcony, above",
                "sampler": "Euler a",
                "cfgScale": 10,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-07-04T0940:52.7391512Z",
                "negativePrompt": "core_6, score_5, score_4, worst quality, low quality, text, censored, deformed, bad hand, blurry, (watermark), multiple phones, weights, bunny ears, extra hands, extra leg",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640,
                        "modelVersionName": "V6 (start with this one)"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 9208,
                        "modelVersionName": "EasyNegative"
                    },
                    {
                        "type": "lora",
                        "weight": 0.15,
                        "modelVersionId": 135867,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 382152,
                        "modelVersionName": "ExpressiveH"
                    },
                    {
                        "type": "lora",
                        "weight": 0.25,
                        "modelVersionId": 398847,
                        "modelVersionName": "gothic neon v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 436219,
                        "modelVersionName": "v3.0 (PonyXL Edition)"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250708,
                        "modelVersionName": "safe_pos"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250712,
                        "modelVersionName": "safe_neg"
                    }
                ]
            },
            "username": "Rockies",
            "baseModel": "Pony"
        },
        {
            "id": 17913433,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cb356a49-1b2e-4f8e-8b3c-4f6230643fb6/width=832/cb356a49-1b2e-4f8e-8b3c-4f6230643fb6.jpeg",
            "hash": "U03+ZbDh00r;5vxurUMw00%g?aoe~qDiE1%N",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-01T00:06:16.066Z",
            "postId": 4006439,
            "stats": {
                "cryCount": 8,
                "laughCount": 15,
                "likeCount": 285,
                "dislikeCount": 0,
                "heartCount": 76,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 31450202,
                "steps": 42,
                "prompt": "*Channel_42* *\u4e2d*\n*Question* *Answer* *Solace* *Peace* *Darkness* *Patient* *Waiting* *Silence* *Rest* *Isolation* *Pinnacle* *Comet*",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 4.2,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-06-30T2254:27.4791942Z",
                "negativePrompt": "*I* *Do* *Not* *Use* *Negative* *Prompts*",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 182077,
                        "modelVersionName": "v3"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Channel_42",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 17681861,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d9aca192-1bed-494d-9bcf-a646e75864a0/width=832/d9aca192-1bed-494d-9bcf-a646e75864a0.jpeg",
            "hash": "U9H1*=00.R_3^k0K+^~C~q4.V?%M_ND*?abw",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-29T09:52:53.945Z",
            "postId": 3958094,
            "stats": {
                "cryCount": 22,
                "laughCount": 44,
                "likeCount": 230,
                "dislikeCount": 0,
                "heartCount": 88,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2067228338,
                "steps": 50,
                "prompt": "gorgeous lips, cinematic, (masterpiece), (best quality), (ultra-detailed), very aesthetic, illustration, perfect composition, intricate details, absurdres, detailed face, (anime, masterpiece, intricate:1.3), (best quality, hires textures, high detail:1.2), (4k),(incredibly detailed:1.4) \n(game pixel), (pixel art), (pixelart), (focus character), cartoon, (lofi style), pixel art, cutesycotton, (cyberpunk style)\n1human girl, black hair, (red inner hair), medium hair, bob cut, fang, ((shy)), angry, closed mouth, closed eyes, embarrassed, onsen, steam, towel, after shower towel wrapped, wet",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 8,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-06-28T1656:46.1568924Z",
                "negativePrompt": "loli, child, longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, worst quality, low quality, normal quality, watermark, artist name, signature",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 403131,
                        "modelVersionName": "v3.1"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 534726,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "vae",
                        "weight": 1,
                        "modelVersionId": 333245,
                        "modelVersionName": "SDXL-VAE"
                    }
                ]
            },
            "username": "Fujishimi",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 15893544,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/88cf7bca-7ad4-409f-9e71-25ea1fe5cc6d/width=512/88cf7bca-7ad4-409f-9e71-25ea1fe5cc6d.jpeg",
            "hash": "U4Ee_Z%20d-ouhW.0JbFDjRk4qRk0dR*xCoL",
            "width": 512,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-15T14:51:52.198Z",
            "postId": 3548233,
            "stats": {
                "cryCount": 69,
                "laughCount": 69,
                "likeCount": 70,
                "dislikeCount": 0,
                "heartCount": 176,
                "commentCount": 0
            },
            "meta": {
                "Size": "512x768",
                "seed": 1376693421,
                "steps": 25,
                "prompt": "feli, 1girl,  score_9, score_8_up, score_7_up,, best quality, masterpiece,   huge breasts, , standing , hands on hips",
                "sampler": "DPM++ 2M",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "negativePrompt": "score_6, score_5, score_4, low quality , bad anatomy, bad proportions, extra legs, deformed anatomy, messy color, deformed fingers, bad, distracted, hyperrealistic,source_furry, source_pony, source_cartoon, negativeXL_D, bad anatomy, futanari, sex, realistic, sketch, monochrome,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 432042
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 73202
                    }
                ]
            },
            "username": "serenitytiffani408",
            "baseModel": "SD 1.5"
        },
        {
            "id": 11506123,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/060fa963-a5c8-41ed-b94f-00232b00d5cb/width=832/060fa963-a5c8-41ed-b94f-00232b00d5cb.jpeg",
            "hash": "UA6IE9?[oyH[.7%fkBMyMyRQWBkBRQRjfkoy",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-05-04T10:43:22.219Z",
            "postId": 2530997,
            "stats": {
                "cryCount": 4,
                "laughCount": 69,
                "likeCount": 228,
                "dislikeCount": 0,
                "heartCount": 83,
                "commentCount": 3
            },
            "meta": null,
            "username": "3mcg33",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 8060853,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b04d6fa1-ea9b-4169-8c18-992d90ec3cf7/width=560/b04d6fa1-ea9b-4169-8c18-992d90ec3cf7.jpeg",
            "hash": "UDFOA8020h~AJC=^58Nf?Cn$t7NH4;xtW=n~",
            "width": 560,
            "height": 1008,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-03-16T18:19:43.370Z",
            "postId": 1745010,
            "stats": {
                "cryCount": 20,
                "laughCount": 60,
                "likeCount": 198,
                "dislikeCount": 0,
                "heartCount": 106,
                "commentCount": 5
            },
            "meta": null,
            "username": "patz65",
            "baseModel": null
        },
        {
            "id": 7462167,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/42477472-8446-43f0-a6f2-15ea3f01e56e/width=1664/42477472-8446-43f0-a6f2-15ea3f01e56e.jpeg",
            "hash": "URFF4n~9xatQ~T=_xtoz-W%1tPbcxJs;ofof",
            "width": 1664,
            "height": 2432,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-03-05T02:21:31.320Z",
            "postId": 1615352,
            "stats": {
                "cryCount": 17,
                "laughCount": 35,
                "likeCount": 209,
                "dislikeCount": 0,
                "heartCount": 123,
                "commentCount": 13
            },
            "meta": {
                "VAE": "sdxl_vae.safetensors",
                "Size": "832x1216",
                "seed": 3477108086,
                "Model": "WildCardX-XL-Fusion OG",
                "steps": 32,
                "hashes": {
                    "model": "22ebc61141"
                },
                "prompt": "masterpiece,professional macro photography, small sprouting  Clover  plant  (symbol of hope, love and faith) in the war zone field,chaotic background, fire,war,  soft bounced lighting, amazing depth of field, shot from a low angle, shot on Lumix GH5 (cinematic bokeh, dynamic range, vibrant colors)",
                "Version": "v1.7.0",
                "sampler": "DPM++ 2M Karras",
                "VAE hash": "63aeecb90f",
                "cfgScale": 5.5,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "22ebc61141",
                        "name": "WildCardX-XL-Fusion OG",
                        "type": "model"
                    }
                ],
                "Model hash": "22ebc61141",
                "Hires upscale": "2",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "anime, cartoon, deformed, glitch, noisy, low contrast",
                "Denoising strength": "0.3"
            },
            "username": "Mr_fries1111",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 6059064,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/61e7fe33-e104-4733-87a2-4433cb9d625d/width=1152/61e7fe33-e104-4733-87a2-4433cb9d625d.jpeg",
            "hash": "UMJ7pgt6IuRl~TRjIpWB0OIpE3aeNeM}Rks.",
            "width": 1152,
            "height": 1536,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-01-30T11:29:48.666Z",
            "postId": 1312262,
            "stats": {
                "cryCount": 5,
                "laughCount": 19,
                "likeCount": 225,
                "dislikeCount": 0,
                "heartCount": 135,
                "commentCount": 5
            },
            "meta": {
                "Size": "768x1024",
                "seed": 2208298592,
                "steps": 35,
                "hashes": {
                    "model": "2d1805f294",
                    "lora:add-detail-xl": "0d9bd1b873"
                },
                "prompt": "concept art of a golden lemon slice covered in sweat, magnificent, celestial, ethereal, water drops,   background Cinematic Hollywood Film Style, shallow depth of field, vignette, highly detailed, high budget, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy, <lora:add-detail-xl:1>",
                "Version": "1.7.0",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 6,
                "resources": [],
                "Model hash": "2d1805f294",
                "\"add-detail-xl": "9c783c8ce46c\"",
                "Denoising strength": "0.18",
                "SD upscale overlap": "64",
                "SD upscale upscaler": "4x_NMKD-Siax_200k",
                "Style Selector Style": "base",
                "Style Selector Enabled": "True",
                "Style Selector Randomize": "False"
            },
            "username": "foxm131249",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 5626297,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/50447032-1af6-4492-89c0-9c19cd69da43/width=1072/50447032-1af6-4492-89c0-9c19cd69da43.jpeg",
            "hash": "UACaD89G01~qR$%MQ,X800oeq@R+-OIU9cnM",
            "width": 1072,
            "height": 1696,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-01-18T13:57:19.187Z",
            "postId": 1225122,
            "stats": {
                "cryCount": 6,
                "laughCount": 21,
                "likeCount": 188,
                "dislikeCount": 0,
                "heartCount": 169,
                "commentCount": 0
            },
            "meta": {
                "ENSD": "31337",
                "Size": "768x1216",
                "seed": 2067885435,
                "Model": "AAM_XL_Anime_Mix",
                "steps": 25,
                "hashes": {
                    "model": "d48c2391e0",
                    "embed:negativeXL_D": "fff5d51ab6"
                },
                "prompt": "masterpiece, best quality, hatsune miku, white gown, angel, angel wings, golden halo, dark background, upper body, closed mouth, looking at viewer, arms behind back, blue theme, night, highres, 4k, 8k, intricate detail, cinematic lighting, amazing quality, amazing shading, soft lighting, Detailed Illustration, anime style, wallpaper",
                "Version": "v1.6.1",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "d48c2391e0",
                        "name": "AAM_XL_Anime_Mix",
                        "type": "model"
                    }
                ],
                "Model hash": "d48c2391e0",
                "Hires steps": "15",
                "Hires upscale": "1.4",
                "Hires upscaler": "Latent",
                "negativePrompt": "(low quality, worst quality:1.4), negativeXL_D, cgi,  text, signature, watermark, extra limbs",
                "Denoising strength": "0.52"
            },
            "username": "Lykon",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 3936010,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/976b9897-32e2-4e3e-bb36-e710686874ce/width=832/976b9897-32e2-4e3e-bb36-e710686874ce.jpeg",
            "hash": "UNH_S#-.L~{{yZxZ=WvgEA#l-nV@xJVtoJ-o",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-11-26T10:46:41.697Z",
            "postId": 884702,
            "stats": {
                "cryCount": 5,
                "laughCount": 54,
                "likeCount": 207,
                "dislikeCount": 0,
                "heartCount": 119,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 915601267,
                "steps": 55,
                "prompt": "view from the back on town, high building, 1 vs 1, head to head, one cat fighting with paws versus godzilla on the town, destroyed building, vibrant colors, lineart, airforce silhouette on sky",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "negativePrompt": "(nsfw:1.3), bad-artist\fbad-artist-anime\fbad-hands-5\fbad-image-v2-39000\fbad-picture-chill-75v\fbad_prompt\fbad_prompt_version2\fbadhandv4\fEasyNegative\fNG_DeepNegative_V1_75T\f\n(worst quality:2),(low quality:2),(normal quality:2),lowres,watermark, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 222810
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 177544
                    }
                ]
            },
            "username": "Julianeve",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 3698587,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7d1762c0-5372-4caa-9734-06f138a6260f/width=832/7d1762c0-5372-4caa-9734-06f138a6260f.jpeg",
            "hash": "UID]M4~9%gOu%gV@g3WB594;Ios8IpV@sRt5",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-11-17T18:13:36.831Z",
            "postId": 835903,
            "stats": {
                "cryCount": 21,
                "laughCount": 149,
                "likeCount": 149,
                "dislikeCount": 0,
                "heartCount": 65,
                "commentCount": 9
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1271009902,
                "steps": 34,
                "prompt": "[ 1 Xi Jinping  mirror reflection : Winnie the Pooh  | undead] reflection, intricate body :10]\nBREAK\nthe man, from behind, looking into a mirror  <lora:GeorgianStyle:1> GeorgianStyle",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 5,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "GeorgianStyle",
                        "type": "lora",
                        "weight": 1
                    }
                ],
                "negativePrompt": "gaussian noise, worst quality, lowres, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art, blur, blurry, grainy, morbid, ugly, asymmetrical, mutated, malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, pixelated, soft focus, color fringing, overprocessed, oversharpened",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 182077
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 209543
                    },
                    {
                        "type": "lora",
                        "weight": 0.25,
                        "modelVersionId": 216784
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 173400
                    }
                ]
            },
            "username": "lingko",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 3628673,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0cfa9db1-e806-4551-901f-eef0a321ae7b/width=1440/0cfa9db1-e806-4551-901f-eef0a321ae7b.jpeg",
            "hash": "UZGZpUj?I:sn}roLNHn*RjoeAHWXjEj@JVWX",
            "width": 1440,
            "height": 2560,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-24T06:32:03.881Z",
            "postId": 822497,
            "stats": {
                "cryCount": 23,
                "laughCount": 23,
                "likeCount": 188,
                "dislikeCount": 0,
                "heartCount": 150,
                "commentCount": 0
            },
            "meta": {
                "Size": "576x1024",
                "seed": 375745553,
                "Model": "V9 Divinity Machine VAE",
                "steps": 150,
                "hashes": {
                    "model": "9105666c13"
                },
                "prompt": "Santa Muerte, best quality, digital painting, extremely smooth, fluid, 3d fractals, light particles, dreamy, smooth, shimmering, dreamy glow, conceptual art by alberto seveso, anna dittmann, arthur rackham, harmonious color scheme, 32k, Wet black and orange color inks line art dreamy female portrait with lot of lace filigrees on black canvas illustration described in the perfect fractal style of Vassily Kandinsky, Jackson Pollock, Alphonse Mucha and Jeremy Mann, HQ, 4K Modifiers: 4K 3D",
                "Version": "1.5.1",
                "sampler": "Euler a",
                "cfgScale": 13,
                "resources": [
                    {
                        "hash": "9105666c13",
                        "name": "V9 Divinity Machine VAE",
                        "type": "model"
                    }
                ],
                "Model hash": "9105666c13",
                "Hires steps": "25",
                "Hires upscale": "2.5",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "bad quality, bad anatomy, worst quality, low quality, lowres, extra fingers, blur, blurry, ugly, wrong proportions, watermark, image artifacts",
                "Denoising strength": "0.2"
            },
            "username": "Yamer",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 862133,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f7ded602-a8cc-4b27-9c1f-8a8c403d1455/width=1024/f7ded602-a8cc-4b27-9c1f-8a8c403d1455.jpeg",
            "hash": "UMD0Dl~q.8tS-=%Lxtt7MxV@WCj]S$W=oJe.",
            "width": 1024,
            "height": 1536,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-10T02:11:41.038Z",
            "postId": 231004,
            "stats": {
                "cryCount": 1,
                "laughCount": 7,
                "likeCount": 205,
                "dislikeCount": 0,
                "heartCount": 171,
                "commentCount": 0
            },
            "meta": {
                "ENSD": "31337",
                "Size": "512x768",
                "seed": 4006085557,
                "Model": "GhostMix-V2.0-fp16-BakedVAE",
                "steps": 30,
                "hashes": {
                    "model": "0f5ef4c164",
                    "embed:ng_deepnegative_v1_75t": "54e7e4826d"
                },
                "prompt": "1mechanical girl,((ultra realistic details)), portrait, global illumination, shadows, octane render, 8k, ultra sharp,metal,intricate, ornaments detailed, cold colors, egypician detail, highly intricate details, realistic light, trending on cgsociety, glowing eyes, facing camera, neon details, machanical limbs,blood vessels connected to tubes,mechanical vertebra attaching to back,mechanical cervial attaching to neck,sitting,wires and cables connecting to head",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 5,
                "resources": [
                    {
                        "hash": "0f5ef4c164",
                        "name": "GhostMix-V2.0-fp16-BakedVAE",
                        "type": "model"
                    }
                ],
                "Model hash": "0f5ef4c164",
                "Hires steps": "20",
                "Hires upscale": "2",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "NSFW,3d, cartoon, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name, young, loli, elf, 3d, illustration  ng_deepnegative_v1_75t",
                "Denoising strength": "0.5"
            },
            "username": "_GhostInShell_",
            "baseModel": "SD 1.5"
        },
        {
            "id": 38320792,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a348e0d7-6411-4576-8250-f14f0954f6cc/width=832/a348e0d7-6411-4576-8250-f14f0954f6cc.jpeg",
            "hash": "USEo75R5?Hi_~WnO?HV@OEoe%MofNbj[%LWV",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-04T17:02:28.764Z",
            "postId": 8748939,
            "stats": {
                "cryCount": 16,
                "laughCount": 24,
                "likeCount": 245,
                "dislikeCount": 0,
                "heartCount": 98,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3925757107,
                "extra": {
                    "remixOfId": 33077994
                },
                "steps": 25,
                "prompt": "inksketch in red and black, inksplash image, closeup portrait of female demon knight, soft black hair, bangs, red eyes, dark eyeshadow, red lips, black plate armour emblazoned with heraldic demon, black feathered wings, directional lighting, direct gaze",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-11-04T1622:21.6828310Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 857586,
                        "modelVersionName": "V1"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 726131,
                        "modelVersionName": "inkSketch Flux"
                    }
                ]
            },
            "username": "Stu42",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 38154803,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9549fd79-2640-4d86-8852-31fe06608aa8/width=832/9549fd79-2640-4d86-8852-31fe06608aa8.jpeg",
            "hash": "UDCG1Q-3^-^,oz%MIS%50JbwIT0cD~D~RkM_",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-03T19:37:42.881Z",
            "postId": 8712122,
            "stats": {
                "cryCount": 6,
                "laughCount": 15,
                "likeCount": 266,
                "dislikeCount": 0,
                "heartCount": 96,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 839929083,
                "steps": 30,
                "prompt": "(score_9, score_8_up), score_7_up, long hair, looking at side, eyes focused on viewer, 1girl, standing, full black eyes, female focus, very close-up on face,  portrait, intricate details,  white hair with fringe, outdoors, neon lit tunnel background, night, dynamic pose, military outfit, giant massive gun, weapon, no breasts, cyborg, armor, cyberpunk, robot joints, complex details, mechanical girl, very detailed eyes, deep black eyes, totaly black eyes, water reflections , volumetric light, dust, particles, rim light, diffusion lights, octane rendering",
                "sampler": "DPM2 a",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-11-03T1921:51.5065617Z",
                "negativePrompt": "score_6, score_5, score_4, worst quality, low quality, extra digits, bad hands, deformities, crooked, imperfections, ugly, signature, text, large head, shiny skin,  overexposed, bad anatomy, bad, 3d, male",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 962170,
                        "modelVersionName": "v7.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 559787,
                        "modelVersionName": "TV Static"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250708,
                        "modelVersionName": "safe_pos"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250712,
                        "modelVersionName": "safe_neg"
                    }
                ]
            },
            "username": "RUCHT907",
            "baseModel": "Pony"
        },
        {
            "id": 37657252,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ee5902ef-e810-474d-979d-6f792937eb20/width=1296/ee5902ef-e810-474d-979d-6f792937eb20.jpeg",
            "hash": "UCEo*;Ip~n~UTKWCVss,ENxtMxM|~pt6n#R*",
            "width": 1296,
            "height": 2304,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-01T01:09:46.593Z",
            "postId": 8601620,
            "stats": {
                "cryCount": 25,
                "laughCount": 16,
                "likeCount": 249,
                "dislikeCount": 0,
                "heartCount": 93,
                "commentCount": 1
            },
            "meta": {
                "Size": "720x1280",
                "seed": 3201474326,
                "Model": "ANImergeME + 0.34(commixPonyXL_v10BakedVAE - ANImergeMEijV3)",
                "steps": 70,
                "hashes": {
                    "model": "d5183c6be8"
                },
                "prompt": "score_9, score_8_up, score_7_up, BREAK, 1 woman, jinx, arcane, character, Detailed, intimate, clear, personal, highly contrasted, excellent composition, advanced cinematic perfect light, highly color focused, very cheeky, dynamic, face focus, looking to viewer",
                "Version": "f2.0.1v1.10.1-previous-581-ge4ad1140",
                "sampler": "Euler a",
                "cfgScale": 9,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "d5183c6be8",
                        "name": "ANImergeME + 0.34(commixPonyXL_v10BakedVAE - ANImergeMEijV3)",
                        "type": "model"
                    }
                ],
                "Model hash": "d5183c6be8",
                "Hires upscale": "1.8",
                "Schedule type": "Automatic",
                "Hires upscaler": "4x_NMKD-Superscale-SP_178000_G",
                "negativePrompt": "score_1, score_2, score_3, score_4, score_5, score_6,",
                "ADetailer model": "face_yolov8n.pt",
                "Hires CFG Scale": "7",
                "ADetailer version": "24.9.0",
                "Denoising strength": "0.07",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "reijlita",
            "baseModel": "Pony"
        },
        {
            "id": 36908537,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e266ddf1-62fa-4425-9aa9-638828530a64/width=1664/e266ddf1-62fa-4425-9aa9-638828530a64.jpeg",
            "hash": "UaOp=E%M~qxu%Lay9Fay_3ofD%Rj_3Rjxut7",
            "width": 1664,
            "height": 2432,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-27T21:33:00.980Z",
            "postId": 8429610,
            "stats": {
                "cryCount": 3,
                "laughCount": 0,
                "likeCount": 319,
                "dislikeCount": 0,
                "heartCount": 61,
                "commentCount": 1
            },
            "meta": {
                "seed": 0,
                "vaes": [],
                "Model": "sd3.5_large",
                "comfy": "{\"prompt\": {\"3\": {\"inputs\": {\"seed\": 0, \"steps\": 30, \"cfg\": 5.5, \"sampler_name\": \"euler\", \"scheduler\": \"sgm_uniform\", \"denoise\": 1, \"model\": [\"4\", 0], \"positive\": [\"138\", 0], \"negative\": [\"40\", 0], \"latent_image\": [\"61\", 0]}, \"class_type\": \"KSampler\", \"_meta\": {\"title\": \"KSampler\"}}, \"4\": {\"inputs\": {\"ckpt_name\": \"sd3.5_large.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\", \"_meta\": {\"title\": \"Load Checkpoint\"}}, \"8\": {\"inputs\": {\"samples\": [\"272\", 0], \"vae\": [\"4\", 2]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"16\": {\"inputs\": {\"clip\": [\"43\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Positive Prompt\"}}, \"40\": {\"inputs\": {\"text\": [\"79\", 0], \"clip\": [\"43\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Negative Prompt\"}}, \"43\": {\"inputs\": {\"clip_name1\": \"clip_g.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"clip_name3\": \"t5xxl_fp16.safetensors\"}, \"class_type\": \"TripleCLIPLoader\", \"_meta\": {\"title\": \"TripleCLIPLoader\"}}, \"55\": {\"inputs\": {\"steps\": 50, \"alpha\": 0.5, \"beta\": 0.7, \"model\": [\"4\", 0]}, \"class_type\": \"BetaSamplingScheduler\", \"_meta\": {\"title\": \"BetaSamplingScheduler\"}}, \"59\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 40, \"denoise\": 1, \"model\": [\"4\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"61\": {\"inputs\": {\"width\": [\"62\", 1], \"height\": [\"62\", 2], \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\", \"_meta\": {\"title\": \"EmptySD3LatentImage\"}}, \"62\": {\"inputs\": {\"resolution\": \"832x1216 (0.68)\", \"batch_size\": 1, \"width_override\": 0, \"height_override\": 0}, \"class_type\": \"SDXLEmptyLatentSizePicker+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Empty Latent Size Picker\"}}, \"66\": {\"inputs\": {\"momentum\": 0, \"eta\": 0, \"s_noise\": 1, \"alpha\": 0, \"k\": 1, \"noise_sampler_type\": \"gaussian\", \"noise_mode\": \"hard\", \"noise_scale\": 1, \"deis_mode\": \"tab\", \"step_type\": \"simple\", \"denoised_type\": \"1_2\", \"max_order\": 3, \"latent_guide_weight\": 0}, \"class_type\": \"SamplerDEIS_SDE\", \"_meta\": {\"title\": \"SamplerDEIS_SDE\"}}, \"79\": {\"inputs\": {\"text\": \"\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Text Multiline\"}}, \"87\": {\"inputs\": {\"precision\": \"fp64\", \"set_default\": false, \"cond_pos\": [\"138\", 0], \"cond_neg\": [\"89\", 0], \"sigmas\": [\"55\", 0], \"latent_image\": [\"61\", 0]}, \"class_type\": \"Set Precision Universal\", \"_meta\": {\"title\": \"Set Precision Universal\"}}, \"89\": {\"inputs\": {\"conditioning\": [\"40\", 0]}, \"class_type\": \"ConditioningZeroOut\", \"_meta\": {\"title\": \"ConditioningZeroOut\"}}, \"93\": {\"inputs\": {\"eta1\": 0, \"eta2\": 0, \"eta_var1\": 0, \"eta_var2\": 0, \"s_noise1\": 1, \"s_noise2\": 1, \"alpha\": 1, \"k\": 1, \"noise_sampler_type\": \"brownian\", \"noise_mode\": \"hard\", \"c2\": 1, \"auto_c2\": false, \"iter_c2\": 3, \"iter\": 3, \"reverse_weight_c2\": 1, \"reverse_weight\": 1, \"tol\": 0.1, \"latent_guide_weight\": 0}, \"class_type\": \"SamplerRES_Implicit\", \"_meta\": {\"title\": \"SamplerRES_Implicit\"}}, \"94\": {\"inputs\": {\"sampler_name\": \"dpmpp_2m\"}, \"class_type\": \"KSamplerSelect\", \"_meta\": {\"title\": \"KSamplerSelect\"}}, \"99\": {\"inputs\": {\"text\": \"black pen scribble painting,colorful ink flow: Oil splash, Oil stained, intricate hyperdetailed fluid gouache, portrait of a white pigeon, illustration by artist \\\"Aaron Horkey\\\",                                        bubbles bubbling blips by artist \\\"Don Dixon\\\"\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Text Multiline\"}}, \"102\": {\"inputs\": {\"conditioning\": [\"87\", 1]}, \"class_type\": \"ConditioningZeroOut\", \"_meta\": {\"title\": \"ConditioningZeroOut\"}}, \"121\": {\"inputs\": {\"mode\": \"Repeat last selection\", \"count\": 1, \"images\": [\"8\", 0]}, \"class_type\": \"Preview Chooser\", \"_meta\": {\"title\": \"Preview Chooser\"}, \"is_changed\": [0.7585533333484172]}, \"138\": {\"inputs\": {\"clip_l\": [\"160\", 0], \"clip_g\": [\"161\", 0], \"t5xxl\": [\"162\", 0], \"empty_padding\": \"none\", \"clip\": [\"43\", 0]}, \"class_type\": \"CLIPTextEncodeSD3\", \"_meta\": {\"title\": \"CLIPTextEncodeSD3\"}}, \"139\": {\"inputs\": {\"text\": [\"150\", 0], \"text2\": \"Ink wash painting, low-angle shot, stark, contrasting lighting. A tall, hooded figure stands in profile, shrouded in tattered black robes. Massive, feathered wings extend from their back, rendered in deep, inky strokes that appear to melt into the background. The figure holds a slim, sharp blade in their right hand, the point barely visible through the dripping ink-like shadows. Birds, drawn as tiny, black silhouettes, scatter around the wings, adding movement and chaos to the otherwise still scene. The background is a minimalistic off-white, with splashes of ink and abstract forms subtly bleeding into the edges, giving the image a raw, unfinished feel. The composition follows a rule of thirds, with the figure placed slightly to the right, creating a sense of balance between the black void of the figure and the empty background. The lighting casts soft shadows, leaving the majority of the figure in dark silhouette.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"LLM Prompt\"}}, \"140\": {\"inputs\": {\"text\": [\"150\", 2], \"text2\": \"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Troubleshooting\"}}, \"141\": {\"inputs\": {\"text\": \"oil painting, impasto, low-angle shot, soft, ethereal lighting. A skeletal queen stands regally, adorned in intricate golden armor laced with blue gemstones. Her ribcage is exposed but beautifully crafted, embedded with glowing jewels. She holds an ornate, towering scythe, bedecked with skulls and decorated with delicate, metallic flourishes. Her long, flowing veil, embroidered with gold and blue, trails behind her, cascading down like a river of fabric. She wears a crown of skeletal motifs, with flowers and bones intertwined. The background depicts a serene, reflective lake nestled between massive, misty mountains under a clear, soft cloud-streaked sky. The mountains and trees are reflected perfectly in the water, with the image framed symmetrically. Hints of warm sunlight peek through, casting a gentle glow on the scene, while the queen's figure contrasts against the peaceful landscape, creating an otherworldly, yet serene atmosphere.\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Examples\"}}, \"142\": {\"inputs\": {\"text\": \"Act as a creative agent who generates highly creative detailed, comma-delimited formatted prompt of up to 150 words for the image. Begin each prompt by specifying an art style (for example, cartoon, impasto, absurdres, oil or acrylic or watercolor painting, or charcoal drawing or engraving or sculpture, etc.)  Include information about lighting. Include information about camera angle. Include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.Do NOT mention any text that is in the image.Specify the depth of field and whether the background is in focus or blurred.Do NOT use any ambiguous language. Include the pose of the subject. Then, continue with descriptive visual elements of the subject, surroundings, and background. Please do not omit any details, especially objects, lighting, colors, and textures, even subtle ones hidden in the background! It is imperative that you carefully consider every aspect of the image, and provide satisfactory descriptions! Also, please be very careful when considering whether the image really is a photograph or actually a detailed painting or illustration.\\n\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"System: Instructions\"}}, \"143\": {\"inputs\": {\"text\": \"Create an image prompt from the image provided, be sure to include all details, emphasis on art style, camera angle and composition\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"User: Prompt\"}}, \"144\": {\"inputs\": {\"image\": \"1 (1).webp\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"_meta\": {\"title\": \"Load Image\"}, \"is_changed\": [\"c8ccc48a127524def9a23ac59108e91c5097c56a62a56520a4940978280f1ad1\"]}, \"145\": {\"inputs\": {\"text\": [\"151\", 0], \"text2\": \"dark angel, hooded figure, black wings, silhouette, ink splatter, gothic character, abstract background, dramatic lighting, shadowy figure, mysterious, dripping effect, feathers, cloak, monochrome, fantasy art, surreal, dark atmosphere, birds in flight, minimal color, eerie mood\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"LLM Prompt\"}}, \"146\": {\"inputs\": {\"text\": [\"151\", 2], \"text2\": \"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Troubleshooting\"}}, \"147\": {\"inputs\": {\"text\": \"Traditional Chinese motifs, Chinese paper cut art, color red and blue, festive, cultural celebration, winter scene, snowflakes, lanterns, snowman, silhouetted cut-out art, intricate cut designs, layered compositions, Chinese ornaments,\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Examples\"}}, \"148\": {\"inputs\": {\"text\": \"Describe the image\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\\nEmphasize key information about the subject, scene, details, effects as needed. Stick with short comma-delimited prompts. start with the art style, then subject, then details like pose, camera angle.\\n\\nNote that Clip-L focuses on specific visual elements and technical details. It lists concrete objects, visual attributes, and effects. Use for specific visual elements and attributes.\\n\\n\\n\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"System: Instructions\"}}, \"149\": {\"inputs\": {\"text\": \"Provide comma-separated keywords as a direct string for the provided image\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"User: Prompt\"}}, \"150\": {\"inputs\": {\"AI_service\": \"ChatGPT\", \"ChatGPT_model\": \"chatgpt-4o-latest\", \"Groq_model\": \"none\", \"Anthropic_model\": \"none\", \"Ollama_model\": \"none\", \"Optional_model\": \"none\", \"creative_latitude\": 0.7, \"tokens\": 300, \"seed\": 232693528089113, \"examples_delimiter\": \"Two newlines\", \"LLM_URL\": \"https://api.groq.com/openai/v1\", \"Instruction\": [\"142\", 0], \"Examples_or_Context\": [\"141\", 0], \"Prompt\": [\"143\", 0], \"image\": [\"144\", 0]}, \"class_type\": \"AdvPromptEnhancer\", \"_meta\": {\"title\": \"Advanced Prompt Enhancer\"}}, \"151\": {\"inputs\": {\"AI_service\": \"ChatGPT\", \"ChatGPT_model\": \"chatgpt-4o-latest\", \"Groq_model\": \"none\", \"Anthropic_model\": \"none\", \"Ollama_model\": \"none\", \"Optional_model\": \"none\", \"creative_latitude\": 0.7, \"tokens\": 100, \"seed\": 657252434703020, \"examples_delimiter\": \"Two newlines\", \"LLM_URL\": \"https://api.groq.com/openai/v1\", \"Instruction\": [\"148\", 0], \"Examples_or_Context\": [\"147\", 0], \"Prompt\": [\"149\", 0], \"image\": [\"144\", 0]}, \"class_type\": \"AdvPromptEnhancer\", \"_meta\": {\"title\": \"Advanced Prompt Enhancer\"}}, \"154\": {\"inputs\": {\"text\": [\"159\", 0], \"text2\": \"A dark, hooded figure with large, tattered wings stands solemnly, surrounded by small, flying birds, creating an eerie and mysterious atmosphere.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"LLM Prompt\"}}, \"155\": {\"inputs\": {\"text\": [\"159\", 2], \"text2\": \"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Troubleshooting\"}}, \"156\": {\"inputs\": {\"text\": \"Beautiful Chinese Paper Cutting winter scene with intricately cut Matroshka dolls and snow-covered ornaments, presented in a warm, traditional setting\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Examples\"}}, \"157\": {\"inputs\": {\"text\": \"Describe the image, in one sentence\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"System: Instructions\"}}, \"158\": {\"inputs\": {\"text\": \"provide a single-sentence description of the provided image\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"User: Prompt\"}}, \"159\": {\"inputs\": {\"AI_service\": \"ChatGPT\", \"ChatGPT_model\": \"chatgpt-4o-latest\", \"Groq_model\": \"none\", \"Anthropic_model\": \"none\", \"Ollama_model\": \"none\", \"Optional_model\": \"none\", \"creative_latitude\": 0.7, \"tokens\": 100, \"seed\": 941470813052800, \"examples_delimiter\": \"Two newlines\", \"LLM_URL\": \"https://api.groq.com/openai/v1\", \"Instruction\": [\"157\", 0], \"Examples_or_Context\": [\"156\", 0], \"Prompt\": [\"158\", 0], \"image\": [\"144\", 0]}, \"class_type\": \"AdvPromptEnhancer\", \"_meta\": {\"title\": \"Advanced Prompt Enhancer\"}}, \"160\": {\"inputs\": {\"text\": [\"151\", 0], \"text2\": \"dark angel, hooded figure, black wings, silhouette, ink splatter, gothic character, abstract background, dramatic lighting, shadowy figure, mysterious, dripping effect, feathers, cloak, monochrome, fantasy art, surreal, dark atmosphere, birds in flight, minimal color, eerie mood\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Clip-L Prompt\"}}, \"161\": {\"inputs\": {\"text\": [\"159\", 0], \"text2\": \"A dark, hooded figure with large, tattered wings stands solemnly, surrounded by small, flying birds, creating an eerie and mysterious atmosphere.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Clip-G Prompt\"}}, \"162\": {\"inputs\": {\"text\": [\"274\", 0], \"text2\": \"oil painting with broad three-dimensional brushstrokes and impasto technique Ink wash painting, low-angle shot, stark, contrasting lighting. A tall, hooded figure stands in profile, shrouded in tattered black robes. Massive, feathered wings extend from their back, rendered in deep, inky strokes that appear to melt into the background. The figure holds a slim, sharp blade in their right hand, the point barely visible through the dripping ink-like shadows. Birds, drawn as tiny, black silhouettes, scatter around the wings, adding movement and chaos to the otherwise still scene. The background is a minimalistic off-white, with splashes of ink and abstract forms subtly bleeding into the edges, giving the image a raw, unfinished feel. The composition follows a rule of thirds, with the figure placed slightly to the right, creating a sense of balance between the black void of the figure and the empty background. The lighting casts soft shadows, leaving the majority of the figure in dark silhouette.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"T5 Prompt\"}}, \"175\": {\"inputs\": {\"VAE\": [\"4\", 2]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"176\": {\"inputs\": {\"CLIP\": [\"43\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"263\": {\"inputs\": {\"filename_prefix\": \"sd3/comfyui\", \"images\": [\"264\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}, \"264\": {\"inputs\": {\"upscale_by\": [\"266\", 3], \"seed\": 1000122408342704, \"steps\": 20, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"sgm_uniform\", \"denoise\": 0.24000000000000002, \"mode_type\": \"Linear\", \"tile_width\": [\"266\", 1], \"tile_height\": [\"266\", 2], \"mask_blur\": 16, \"tile_padding\": 32, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 0.25, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 16, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"266\", 0], \"model\": [\"4\", 0], \"positive\": [\"138\", 0], \"negative\": [\"40\", 0], \"upscale_model\": [\"265\", 0], \"vae\": [\"4\", 2]}, \"class_type\": \"UltimateSDUpscale\", \"_meta\": {\"title\": \"Ultimate SD Upscale\"}}, \"265\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"UpscaleModelLoader\", \"_meta\": {\"title\": \"Load Upscale Model\"}}, \"266\": {\"inputs\": {\"slicing\": \"2x2\", \"multiplier\": 2.0, \"image\": [\"281\", 0]}, \"class_type\": \"FL_SDUltimate_Slices\", \"_meta\": {\"title\": \"FL SDUltimate Slices\"}, \"is_changed\": [NaN]}, \"267\": {\"inputs\": {\"rgthree_comparer\": {\"images\": [{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_vxpmq_00001_.png&type=temp&subfolder=&rand=0.4901268530667997\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_vxpmq_00002_.png&type=temp&subfolder=&rand=0.6799037490555551\"}]}, \"image_a\": [\"8\", 0], \"image_b\": [\"264\", 0]}, \"class_type\": \"Image Comparer (rgthree)\", \"_meta\": {\"title\": \"Image Comparer (rgthree)\"}}, \"268\": {\"inputs\": {\"text\": \"4k, detailed\", \"clip\": [\"43\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Prompt)\"}}, \"272\": {\"inputs\": {\"add_noise\": true, \"noise_level\": 1.0, \"noise_normalize\": false, \"noise_is_latent\": false, \"noise_type\": \"fractal\", \"alpha\": 1.0, \"k\": 1.0, \"noise_seed\": 28, \"cfg\": 1.0, \"model\": [\"4\", 0], \"positive\": [\"138\", 0], \"negative\": [\"102\", 0], \"sampler\": [\"273\", 0], \"sigmas\": [\"87\", 2], \"latent_image\": [\"87\", 3]}, \"class_type\": \"SharkSampler\", \"_meta\": {\"title\": \"SharkSampler\"}}, \"273\": {\"inputs\": {\"eta\": 0.25, \"eta_var\": 0.0, \"s_noise\": 1.0, \"alpha\": 0.0, \"k\": 1.0, \"cfgpp\": 1.5, \"noise_sampler_type\": \"brownian\", \"noise_mode\": \"hard\", \"rk_type\": \"res_2s\", \"buffer\": 0}, \"class_type\": \"SamplerRK\", \"_meta\": {\"title\": \"SamplerRK\"}}, \"274\": {\"inputs\": {\"Beginning_tags\": \"oil painting with broad three-dimensional brushstrokes and impasto technique\", \"Middle_tags\": \"\", \"Prefer_middle_tag_after_period\": false, \"End_tags\": \"\", \"text\": [\"150\", 0]}, \"class_type\": \"Tagger\", \"_meta\": {\"title\": \"Tagger\"}}, \"275\": {\"inputs\": {\"text1\": [\"274\", 0], \"text2\": [\"150\", 0], \"separator\": \"\"}, \"class_type\": \"CR Text Concatenate\", \"_meta\": {\"title\": \"\\ud83d\\udd24 CR Text Concatenate\"}}, \"276\": {\"inputs\": {\"guide_size\": 1024.0, \"guide_size_for\": false, \"max_size\": 1024.0, \"seed\": 1416502673417, \"steps\": 10, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"beta\", \"denoise\": 0.35000000000000003, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": false, \"bbox_threshold\": 0.7000000000000001, \"bbox_dilation\": 2, \"bbox_crop_factor\": 1.5, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.75, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.0, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 0, \"image\": [\"121\", 0], \"positive\": [\"138\", 0], \"negative\": [\"40\", 0], \"bbox_detector\": [\"277\", 0], \"sam_model_opt\": [\"280\", 0], \"segm_detector_opt\": [\"277\", 1], \"model\": [\"4\", 0], \"clip\": [\"43\", 0], \"vae\": [\"4\", 2]}, \"class_type\": \"FaceDetailer\", \"_meta\": {\"title\": \"Hands Detailer\"}}, \"277\": {\"inputs\": {\"model_name\": \"bbox/hand_yolov8s.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\", \"_meta\": {\"title\": \"Hands Detector\"}}, \"278\": {\"inputs\": {\"guide_size\": 1024.0, \"guide_size_for\": false, \"max_size\": 1024.0, \"seed\": 1021336613142496, \"steps\": 10, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"beta\", \"denoise\": 0.35000000000000003, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": false, \"bbox_threshold\": 0.7000000000000001, \"bbox_dilation\": 5, \"bbox_crop_factor\": 1.5, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.75, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.0, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 0, \"image\": [\"276\", 0], \"positive\": [\"138\", 0], \"negative\": [\"40\", 0], \"bbox_detector\": [\"279\", 0], \"sam_model_opt\": [\"280\", 0], \"segm_detector_opt\": [\"279\", 1], \"model\": [\"4\", 0], \"clip\": [\"43\", 0], \"vae\": [\"4\", 2]}, \"class_type\": \"FaceDetailer\", \"_meta\": {\"title\": \"EyesDetailer\"}}, \"279\": {\"inputs\": {\"model_name\": \"bbox/Eyes.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\", \"_meta\": {\"title\": \"Eyes Detector\"}}, \"280\": {\"inputs\": {\"model_name\": \"sam_vit_b_01ec64.pth\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\", \"_meta\": {\"title\": \"SAMLoader (Impact)\"}}, \"281\": {\"inputs\": {\"guide_size\": 1024.0, \"guide_size_for\": false, \"max_size\": 1024.0, \"seed\": 80036774007325, \"steps\": 10, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"beta\", \"denoise\": 0.35000000000000003, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": false, \"bbox_threshold\": 0.7000000000000001, \"bbox_dilation\": 5, \"bbox_crop_factor\": 1.5, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.75, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.0, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 0, \"image\": [\"278\", 0], \"positive\": [\"138\", 0], \"negative\": [\"40\", 0], \"bbox_detector\": [\"282\", 0], \"sam_model_opt\": [\"280\", 0], \"segm_detector_opt\": [\"282\", 1], \"model\": [\"4\", 0], \"clip\": [\"43\", 0], \"vae\": [\"4\", 2]}, \"class_type\": \"FaceDetailer\", \"_meta\": {\"title\": \"HandsDetailer\"}}, \"282\": {\"inputs\": {\"model_name\": \"bbox/face_yolov8m.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\", \"_meta\": {\"title\": \"Face Detector\"}}, \"283\": {\"inputs\": {\"images\": [\"278\", 1]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"284\": {\"inputs\": {\"images\": [\"278\", 2]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"285\": {\"inputs\": {\"images\": [\"281\", 1]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"286\": {\"inputs\": {\"images\": [\"281\", 2]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"287\": {\"inputs\": {\"images\": [\"276\", 1]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"288\": {\"inputs\": {\"images\": [\"276\", 2]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"289\": {\"inputs\": {\"MODEL\": [\"4\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"290\": {\"inputs\": {\"lora_name\": \"sd3-5-ghibli.safetensors\", \"strength_model\": 1, \"strength_clip\": 1, \"model\": [\"4\", 0], \"clip\": [\"43\", 0]}, \"class_type\": \"LoraLoader\", \"_meta\": {\"title\": \"Load LoRA\"}}}, \"workflow\": {\"last_node_id\": 290, \"last_link_id\": 586, \"nodes\": [{\"id\": 3, \"type\": \"KSampler\", \"pos\": {\"0\": 864, \"1\": -124}, \"size\": {\"0\": 315, \"1\": 474}, \"flags\": {}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 253, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 477}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 80}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 122}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [0, \"fixed\", 30, 5.5, \"euler\", \"sgm_uniform\", 1]}, {\"id\": 94, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 889, \"1\": -260}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpmpp_2m\"]}, {\"id\": 59, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 189, \"1\": 318}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 255}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 40, 1]}, {\"id\": 66, \"type\": \"SamplerDEIS_SDE\", \"pos\": {\"0\": 130, \"1\": 484}, \"size\": {\"0\": 275.7619934082031, \"1\": 466}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"momentums\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"etas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"s_noises\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"alphas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide\", \"type\": \"LATENT\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_weights\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerDEIS_SDE\"}, \"widgets_values\": [0, 0, 1, 0, 1, \"gaussian\", \"hard\", 1, \"tab\", \"simple\", \"1_2\", 3, 0]}, {\"id\": 136, \"type\": \"Reroute\", \"pos\": {\"0\": 165, \"1\": 154}, \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 324}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [253, 255, 493], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 131, \"type\": \"ImageLoader\", \"pos\": {\"0\": -2450.40869140625, \"1\": -592.9354858398438}, \"size\": {\"0\": 315, \"1\": 334}, \"flags\": {}, \"order\": 2, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null}, {\"name\": \"PATH\", \"type\": \"PATH\", \"links\": [249], \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"ImageLoader\"}, \"widgets_values\": [\"sweet_fox_in_jungle_forest_animal_by_xrebelyellx_dif7107-pre.jpg\", \"image\"]}, {\"id\": 133, \"type\": \"MultiplePathsInput\", \"pos\": {\"0\": -2107.4091796875, \"1\": -592.9354858398438}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 4, \"inputs\": [{\"name\": \"path_1\", \"type\": \"PATH\", \"link\": 249}], \"outputs\": [{\"name\": \"paths\", \"type\": \"PATH\", \"links\": [247], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"MultiplePathsInput\"}, \"widgets_values\": [1, null]}, {\"id\": 130, \"type\": \"Qwen2_VQA\", \"pos\": {\"0\": -2101.4091796875, \"1\": -539.9353637695312}, \"size\": {\"0\": 400, \"1\": 292}, \"flags\": {}, \"order\": 44, \"mode\": 4, \"inputs\": [{\"name\": \"source_path\", \"type\": \"PATH\", \"link\": 247, \"shape\": 7}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [248, 250], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"Qwen2_VQA\"}, \"widgets_values\": [\"Please describe image in detail, emphasis on the art style, camera angle, pose, and composition. Do not include any text that may be part of the image.\", \"Qwen2-VL-7B-Instruct\", \"none\", false, 0.7, 500, 200704, 1003520, 67, \"increment\"]}, {\"id\": 132, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1612.407470703125, \"1\": -516.935302734375}, \"size\": {\"0\": 318.5995788574219, \"1\": 246.82449340820312}, \"flags\": {}, \"order\": 56, \"mode\": 4, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 248, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [\"\", \"The image depicts a cute, cartoon-style fox nestled among lush green foliage and delicate flowers. The fox has large, expressive eyes and a fluffy, orange and white fur coat. The art style is highly detailed and whimsical, with soft, rounded features and vibrant colors. The camera angle is a close-up, focusing on the fox's face and upper body, which is partially obscured by the surrounding plants. The composition is balanced, with the fox positioned centrally and the flowers and leaves framing the scene, creating a sense of depth and natural beauty. The overall effect is endearing and serene, evoking a sense of tranquility and wonder.\"]}, {\"id\": 141, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2599, \"1\": 462}, \"size\": {\"0\": 390, \"1\": 220}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [271], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Examples\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"oil painting, impasto, low-angle shot, soft, ethereal lighting. A skeletal queen stands regally, adorned in intricate golden armor laced with blue gemstones. Her ribcage is exposed but beautifully crafted, embedded with glowing jewels. She holds an ornate, towering scythe, bedecked with skulls and decorated with delicate, metallic flourishes. Her long, flowing veil, embroidered with gold and blue, trails behind her, cascading down like a river of fabric. She wears a crown of skeletal motifs, with flowers and bones intertwined. The background depicts a serene, reflective lake nestled between massive, misty mountains under a clear, soft cloud-streaked sky. The mountains and trees are reflected perfectly in the water, with the image framed symmetrically. Hints of warm sunlight peek through, casting a gentle glow on the scene, while the queen's figure contrasts against the peaceful landscape, creating an otherworldly, yet serene atmosphere.\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 154, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1748.7530517578125, \"1\": 1586.0838623046875}, \"size\": {\"0\": 396.9629211425781, \"1\": 178.00289916992188}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 279, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 6}], \"title\": \"LLM Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"A dark, hooded figure with large, black wings stands in a dramatic, shadowy silhouette, surrounded by abstract splashes and flying birds.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 155, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1729.1080322265625, \"1\": 1829.6156005859375}, \"size\": {\"0\": 330, \"1\": 240}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 280, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"title\": \"Troubleshooting\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 87, \"type\": \"Set Precision Universal\", \"pos\": {\"0\": 535, \"1\": 19}, \"size\": {\"0\": 211.60000610351562, \"1\": 142}, \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"cond_pos\", \"type\": \"CONDITIONING\", \"link\": 482, \"shape\": 7}, {\"name\": \"cond_neg\", \"type\": \"CONDITIONING\", \"link\": 186, \"shape\": 7}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"shape\": 7}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 184, \"shape\": 7}], \"outputs\": [{\"name\": \"cond_pos\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cond_neg\", \"type\": \"CONDITIONING\", \"links\": [196], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"links\": [497], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"links\": [498], \"slot_index\": 3, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Set Precision Universal\"}, \"widgets_values\": [\"fp64\", false]}, {\"id\": 152, \"type\": \"Reroute\", \"pos\": {\"0\": -1210.518798828125, \"1\": 867.8450927734375}, \"size\": [75, 26], \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 278, \"widget\": {\"name\": \"value\"}}], \"outputs\": [{\"name\": \"\", \"type\": \"STRING\", \"links\": [286], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 153, \"type\": \"Reroute\", \"pos\": {\"0\": -1235.518798828125, \"1\": 1256.84521484375}, \"size\": [75, 26], \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 285, \"widget\": {\"name\": \"value\"}}], \"outputs\": [{\"name\": \"\", \"type\": \"STRING\", \"links\": [287], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 89, \"type\": \"ConditioningZeroOut\", \"pos\": {\"0\": 174, \"1\": 241}, \"size\": {\"0\": 211.60000610351562, \"1\": 26}, \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 160}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [186], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningZeroOut\"}, \"widgets_values\": []}, {\"id\": 102, \"type\": \"ConditioningZeroOut\", \"pos\": {\"0\": 425, \"1\": 339}, \"size\": {\"0\": 317.4000244140625, \"1\": 26}, \"flags\": {}, \"order\": 66, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 196}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [495], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"ConditioningZeroOut\"}, \"widgets_values\": []}, {\"id\": 265, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 2115.868408203125, \"1\": 1730.1519775390625}, \"size\": {\"0\": 210, \"1\": 60}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [467], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"]}, {\"id\": 268, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2130.868408203125, \"1\": 1891.1514892578125}, \"size\": {\"0\": 210, \"1\": 201.48159790039062}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"4k, detailed\"]}, {\"id\": 266, \"type\": \"FL_SDUltimate_Slices\", \"pos\": {\"0\": 2108.868408203125, \"1\": 1535.1514892578125}, \"size\": {\"0\": 210, \"1\": 142}, \"flags\": {}, \"order\": 77, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 545}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [466], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"slice_width\", \"type\": \"INT\", \"links\": [469], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"slice_height\", \"type\": \"INT\", \"links\": [470], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"multiplier\", \"type\": \"FLOAT\", \"links\": [468], \"slot_index\": 3, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FL_SDUltimate_Slices\"}, \"widgets_values\": [\"2x2\", 2], \"color\": \"#16727c\", \"bgcolor\": \"#4F0074\"}, {\"id\": 79, \"type\": \"Text Multiline\", \"pos\": {\"0\": 191, \"1\": -152}, \"size\": {\"0\": 323.0578918457031, \"1\": 105.5796890258789}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"\"]}, {\"id\": 99, \"type\": \"Text Multiline\", \"pos\": {\"0\": -51, \"1\": 1033}, \"size\": {\"0\": 330.0619201660156, \"1\": 177.21875}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"black pen scribble painting,colorful ink flow: Oil splash, Oil stained, intricate hyperdetailed fluid gouache, portrait of a white pigeon, illustration by artist \\\"Aaron Horkey\\\",                                        bubbles bubbling blips by artist \\\"Don Dixon\\\"\"]}, {\"id\": 267, \"type\": \"Image Comparer (rgthree)\", \"pos\": {\"0\": 3315.44384765625, \"1\": 1547.0440673828125}, \"size\": {\"0\": 639.7817993164062, \"1\": 506.23114013671875}, \"flags\": {}, \"order\": 82, \"mode\": 0, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"link\": 501, \"dir\": 3}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"link\": 471, \"dir\": 3}], \"outputs\": [], \"properties\": {\"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_vxpmq_00001_.png&type=temp&subfolder=&rand=0.4901268530667997\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_vxpmq_00002_.png&type=temp&subfolder=&rand=0.6799037490555551\"}]]}, {\"id\": 143, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2594.601806640625, \"1\": 302.2427062988281}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [272], \"slot_index\": 0, \"shape\": 3}], \"title\": \"User: Prompt\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Create an image prompt from the image provided, be sure to include all details, emphasis on art style, camera angle and composition\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 142, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2621, \"1\": -119}, \"size\": {\"0\": 425.0143127441406, \"1\": 360.5466613769531}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [270], \"slot_index\": 0, \"shape\": 3}], \"title\": \"System: Instructions\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Act as a creative agent who generates highly creative detailed, comma-delimited formatted prompt of up to 150 words for the image. Begin each prompt by specifying an art style (for example, cartoon, impasto, absurdres, oil or acrylic or watercolor painting, or charcoal drawing or engraving or sculpture, etc.)  Include information about lighting. Include information about camera angle. Include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.Do NOT mention any text that is in the image.Specify the depth of field and whether the background is in focus or blurred.Do NOT use any ambiguous language. Include the pose of the subject. Then, continue with descriptive visual elements of the subject, surroundings, and background. Please do not omit any details, especially objects, lighting, colors, and textures, even subtle ones hidden in the background! It is imperative that you carefully consider every aspect of the image, and provide satisfactory descriptions! Also, please be very careful when considering whether the image really is a photograph or actually a detailed painting or illustration.\\n\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 149, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2636.27490234375, \"1\": 1044.427978515625}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [275], \"slot_index\": 0, \"shape\": 3}], \"title\": \"User: Prompt\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Provide comma-separated keywords as a direct string for the provided image\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 148, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2620.0107421875, \"1\": 809.7274169921875}, \"size\": {\"0\": 390.9617004394531, \"1\": 174.10166931152344}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [274], \"slot_index\": 0, \"shape\": 3}], \"title\": \"System: Instructions\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Describe the image\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\\nEmphasize key information about the subject, scene, details, effects as needed. Stick with short comma-delimited prompts. start with the art style, then subject, then details like pose, camera angle.\\n\\nNote that Clip-L focuses on specific visual elements and technical details. It lists concrete objects, visual attributes, and effects. Use for specific visual elements and attributes.\\n\\n\\n\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 147, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2627, \"1\": 1189}, \"size\": {\"0\": 390, \"1\": 220}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [276], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Examples\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Traditional Chinese motifs, Chinese paper cut art, color red and blue, festive, cultural celebration, winter scene, snowflakes, lanterns, snowman, silhouetted cut-out art, intricate cut designs, layered compositions, Chinese ornaments,\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 157, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2619.19921875, \"1\": 1507.41162109375}, \"size\": {\"0\": 390.9617004394531, \"1\": 174.10166931152344}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [281], \"slot_index\": 0, \"shape\": 3}], \"title\": \"System: Instructions\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Describe the image, in one sentence\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 158, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2635.46337890625, \"1\": 1742.1121826171875}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [283], \"slot_index\": 0, \"shape\": 3}], \"title\": \"User: Prompt\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"provide a single-sentence description of the provided image\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 156, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2619.148193359375, \"1\": 1897.1473388671875}, \"size\": {\"0\": 390, \"1\": 220}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [282], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Examples\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Beautiful Chinese Paper Cutting winter scene with intricately cut Matroshka dolls and snow-covered ornaments, presented in a warm, traditional setting\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 43, \"type\": \"TripleCLIPLoader\", \"pos\": {\"0\": -1214.1949462890625, \"1\": -384.7268371582031}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [314], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"TripleCLIPLoader\"}, \"widgets_values\": [\"clip_g.safetensors\", \"clip_l.safetensors\", \"t5xxl_fp16.safetensors\"]}, {\"id\": 176, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": -839.1956176757812, \"1\": -363.7268371582031}, \"size\": {\"0\": 239.40000915527344, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"CLIP\", \"type\": \"*\", \"link\": 314, \"shape\": 7, \"color_on\": \"#FFD500\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 61, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": -166, \"1\": -172}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 124, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 125, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [122, 184], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [1728, 576, 1]}, {\"id\": 273, \"type\": \"SamplerRK\", \"pos\": {\"0\": 488, \"1\": 476}, \"size\": {\"0\": 315, \"1\": 274}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [500]}], \"properties\": {\"Node name for S&R\": \"SamplerRK\"}, \"widgets_values\": [0.25, 0, 1, 0, 1, 1.5, \"brownian\", \"hard\", \"res_2s\", 0]}, {\"id\": 125, \"type\": \"Reroute\", \"pos\": {\"0\": -1213.518798828125, \"1\": 519.8450927734375}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"title\": \"t5\", \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 275, \"type\": \"CR Text Concatenate\", \"pos\": {\"0\": -1228, \"1\": 635}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"text1\", \"type\": \"STRING\", \"link\": 502, \"widget\": {\"name\": \"text1\"}, \"shape\": 7}, {\"name\": \"text2\", \"type\": \"STRING\", \"link\": 503, \"widget\": {\"name\": \"text2\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"CR Text Concatenate\"}, \"widgets_values\": [\"\", \"\", \"\"]}, {\"id\": 272, \"type\": \"SharkSampler\", \"pos\": {\"0\": 872, \"1\": 457}, \"size\": {\"0\": 355.20001220703125, \"1\": 606}, \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 493}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 494}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 495}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 500}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 497}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 498}, {\"name\": \"latent_noise\", \"type\": \"LATENT\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [499]}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null}, {\"name\": \"latent_batch\", \"type\": \"LATENT\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"SharkSampler\"}, \"widgets_values\": [true, 1, false, false, \"fractal\", 1, 1, 28, \"increment\", 1]}, {\"id\": 16, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -535, \"1\": 206}, \"size\": {\"0\": 210, \"1\": 54}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"title\": \"Positive Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"A woman sits calmly on a worn, ergonomic office chair, her slender frame relaxed against the soft cushioning as she gazes serenely out the shattered glass of her office window. The once-pristine pane now lies in jagged fragments on the floor, its edges sharp and unforgiving. A few shards cling to the surrounding trim, like tiny, deadly splinters. Outside, a horde of zombies thrashes against the broken glass, their twisted faces contorted in a frenzy of hunger and chaos. Their tattered clothing billows behind them like dark, living mist. One zombie's arm is pinned beneath the shattered pane, its hand grasping wildly at the air as it screams silently. Another zombie's face is pressed against the window, its eyes bulging with an unnatural hunger. The woman's expression remains serene, her eyes fixed on some point beyond the chaos outside. A few strands of hair escape her ponytail, framing her heart-shaped face with a soft, gentle glow.\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 151, \"type\": \"AdvPromptEnhancer\", \"pos\": {\"0\": -2188, \"1\": 883}, \"size\": {\"0\": 400, \"1\": 434}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"Add_Parameter\", \"type\": \"LIST\", \"link\": null, \"shape\": 7}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 273, \"shape\": 7}, {\"name\": \"Instruction\", \"type\": \"STRING\", \"link\": 274, \"widget\": {\"name\": \"Instruction\"}, \"shape\": 7}, {\"name\": \"Examples_or_Context\", \"type\": \"STRING\", \"link\": 276, \"widget\": {\"name\": \"Examples_or_Context\"}, \"shape\": 7}, {\"name\": \"Prompt\", \"type\": \"STRING\", \"link\": 275, \"widget\": {\"name\": \"Prompt\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"LLMprompt\", \"type\": \"STRING\", \"links\": [267, 278], \"slot_index\": 0}, {\"name\": \"Context\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"Help\", \"type\": \"STRING\", \"links\": [268]}, {\"name\": \"Troubleshooting\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"AdvPromptEnhancer\"}, \"widgets_values\": [\"ChatGPT\", \"chatgpt-4o-latest\", \"none\", \"none\", \"none\", \"none\", 0.7, 100, 657252434703020, \"randomize\", \"Two newlines\", \"https://api.groq.com/openai/v1\", \"\", \"\", \"\"]}, {\"id\": 145, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1723, \"1\": 839}, \"size\": {\"0\": 396.9629211425781, \"1\": 178.00289916992188}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 267, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 6}], \"title\": \"LLM Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"hooded figure, dark angel, black wings, silhouette, ink splatter, watercolor effect, shadowy, gothic, abstract, mysterious, dripping paint, birds, monochromatic, eerie atmosphere, fantasy\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 146, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1713, \"1\": 1083}, \"size\": {\"0\": 330, \"1\": 240}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 268, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"title\": \"Troubleshooting\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 264, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2497.8681640625, \"1\": 1514.1514892578125}, \"size\": {\"0\": 320, \"1\": 830}, \"flags\": {}, \"order\": 80, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 466}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 474}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 479}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 475}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 467, \"slot_index\": 5}, {\"name\": \"upscale_by\", \"type\": \"FLOAT\", \"link\": 468, \"slot_index\": 6, \"widget\": {\"name\": \"upscale_by\"}}, {\"name\": \"tile_width\", \"type\": \"INT\", \"link\": 469, \"widget\": {\"name\": \"tile_width\"}}, {\"name\": \"tile_height\", \"type\": \"INT\", \"link\": 470, \"widget\": {\"name\": \"tile_height\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [465, 471], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 1000122408342704, \"fixed\", 20, 1, \"euler\", \"sgm_uniform\", 0.24000000000000002, \"Linear\", 1024, 1024, 16, 32, \"None\", 0.25, 64, 16, 16, true, false]}, {\"id\": 280, \"type\": \"SAMLoader\", \"pos\": {\"0\": 3584.256103515625, \"1\": 61.68771743774414}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [517, 521, 525], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 283, \"type\": \"PreviewImage\", \"pos\": {\"0\": 3286.851318359375, \"1\": 286.75164794921875}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 75, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 527}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 284, \"type\": \"PreviewImage\", \"pos\": {\"0\": 3298.47607421875, \"1\": 593.2739868164062}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 76, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 528}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 285, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4110.95703125, \"1\": 398.6062316894531}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 78, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 529}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 286, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4086.489013671875, \"1\": 734.3185424804688}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 79, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 530}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 287, \"type\": \"PreviewImage\", \"pos\": {\"0\": 2511.4228515625, \"1\": 372.012451171875}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 72, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 531}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 288, \"type\": \"PreviewImage\", \"pos\": {\"0\": 2506.4228515625, \"1\": 697.0123901367188}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 73, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 532}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 55, \"type\": \"BetaSamplingScheduler\", \"pos\": {\"0\": 105, \"1\": 26}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 107}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BetaSamplingScheduler\"}, \"widgets_values\": [50, 0.5, 0.7]}, {\"id\": 175, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": -155, \"1\": 191}, \"size\": {\"0\": 167.4224853515625, \"1\": 26}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"VAE\", \"type\": \"*\", \"link\": 313, \"shape\": 7, \"color_on\": \"#FF6E6E\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 4, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": -576, \"1\": 20}, \"size\": {\"0\": 384.75592041015625, \"1\": 98}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [107, 324, 474, 533], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [], \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [313], \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"sd3.5_large.safetensors\"]}, {\"id\": 289, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": -153, \"1\": 32}, \"size\": {\"0\": 167.4224853515625, \"1\": 26}, \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"MODEL\", \"type\": \"*\", \"link\": 533, \"shape\": 7, \"color_on\": \"#B39DDB\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 40, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 436, \"1\": 237}, \"size\": {\"0\": 210, \"1\": 54}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 143, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [80, 160, 475, 537, 538, 539], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Negative Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"low quality, bad quality, blurry, shallow depth of field, bokeh, low resolution, grainy, pixelated, unsharp\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 269, \"type\": \"Reroute\", \"pos\": {\"0\": -17, \"1\": 326}, \"size\": [75, 26], \"flags\": {}, \"order\": 63, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 486}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [477, 479, 482, 494, 540, 541, 542], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 278, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 2783.8515625, \"1\": 225.751708984375}, \"size\": {\"0\": 436.46600341796875, \"1\": 1124.5428466796875}, \"flags\": {}, \"order\": 71, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 543}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 541}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 538}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 520}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 521, \"shape\": 7}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 522, \"shape\": 7}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null, \"shape\": 7}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [544], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [527], \"slot_index\": 1, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [528], \"slot_index\": 2, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 3, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"title\": \"EyesDetailer\", \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [1024, false, 1024, 1021336613142496, \"randomize\", 10, 1, \"euler\", \"beta\", 0.35000000000000003, 5, true, false, 0.7000000000000001, 5, 1.5, \"center-1\", 0, 0.75, 0, 0, \"False\", 10, \"\", 1, false, 0]}, {\"id\": 281, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 3568.70849609375, \"1\": 318.6060791015625}, \"size\": {\"0\": 436.7053527832031, \"1\": 1045.8348388671875}, \"flags\": {}, \"order\": 74, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 544}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 542}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 539}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 524}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 525, \"shape\": 7}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 526, \"shape\": 7}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null, \"shape\": 7}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [545], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [529], \"slot_index\": 1, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [530], \"slot_index\": 2, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 3, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"title\": \"HandsDetailer\", \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [1024, false, 1024, 80036774007325, \"randomize\", 10, 1, \"euler\", \"beta\", 0.35000000000000003, 5, true, false, 0.7000000000000001, 5, 1.5, \"center-1\", 0, 0.75, 0, 0, \"False\", 10, \"\", 1, false, 0]}, {\"id\": 93, \"type\": \"SamplerRES_Implicit\", \"pos\": {\"0\": 495, \"1\": 827}, \"size\": {\"0\": 323.1683044433594, \"1\": 526}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"alphas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide\", \"type\": \"LATENT\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_weights\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerRES_Implicit\"}, \"widgets_values\": [0, 0, 0, 0, 1, 1, 1, 1, \"brownian\", \"hard\", 1, false, 3, 3, 1, 1, 0.1, 0]}, {\"id\": 140, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1687, \"1\": 183}, \"size\": {\"0\": 330, \"1\": 240}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 266, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"title\": \"Troubleshooting\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 159, \"type\": \"AdvPromptEnhancer\", \"pos\": {\"0\": -2162.14892578125, \"1\": 1557.14697265625}, \"size\": {\"0\": 400, \"1\": 434}, \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"Add_Parameter\", \"type\": \"LIST\", \"link\": null, \"shape\": 7}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 295, \"shape\": 7}, {\"name\": \"Instruction\", \"type\": \"STRING\", \"link\": 281, \"widget\": {\"name\": \"Instruction\"}, \"shape\": 7}, {\"name\": \"Examples_or_Context\", \"type\": \"STRING\", \"link\": 282, \"widget\": {\"name\": \"Examples_or_Context\"}, \"shape\": 7}, {\"name\": \"Prompt\", \"type\": \"STRING\", \"link\": 283, \"widget\": {\"name\": \"Prompt\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"LLMprompt\", \"type\": \"STRING\", \"links\": [279, 285], \"slot_index\": 0}, {\"name\": \"Context\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"Help\", \"type\": \"STRING\", \"links\": [280]}, {\"name\": \"Troubleshooting\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"AdvPromptEnhancer\"}, \"widgets_values\": [\"ChatGPT\", \"chatgpt-4o-latest\", \"none\", \"none\", \"none\", \"none\", 0.7, 100, 941470813052800, \"randomize\", \"Two newlines\", \"https://api.groq.com/openai/v1\", \"\", \"\", \"\"]}, {\"id\": 277, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2110, \"1\": 85}, \"size\": {\"0\": 340.20001220703125, \"1\": 78}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [516], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [518], \"slot_index\": 1, \"shape\": 3}], \"title\": \"Hands Detector\", \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/hand_yolov8s.pt\"]}, {\"id\": 279, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2834.8515625, \"1\": 63.75164794921875}, \"size\": {\"0\": 340.20001220703125, \"1\": 78}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [520], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [522], \"slot_index\": 1, \"shape\": 3}], \"title\": \"Eyes Detector\", \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/Eyes.pt\"]}, {\"id\": 282, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 3607.708251953125, \"1\": 186.60609436035156}, \"size\": {\"0\": 340.20001220703125, \"1\": 78}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [524], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [526], \"slot_index\": 1, \"shape\": 3}], \"title\": \"Face Detector\", \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 276, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 2053, \"1\": 227}, \"size\": {\"0\": 442.1853942871094, \"1\": 1120}, \"flags\": {}, \"order\": 70, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 534}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 540}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 537}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 516}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 517, \"shape\": 7}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 518, \"shape\": 7}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null, \"shape\": 7}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [543], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [531], \"slot_index\": 1, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [532], \"slot_index\": 2, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 3, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"title\": \"Hands Detailer\", \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [1024, false, 1024, 1416502673417, \"randomize\", 10, 1, \"euler\", \"beta\", 0.35000000000000003, 5, true, false, 0.7000000000000001, 2, 1.5, \"center-1\", 0, 0.75, 0, 0, \"False\", 10, \"\", 1, false, 0]}, {\"id\": 263, \"type\": \"SaveImage\", \"pos\": {\"0\": 2904, \"1\": 2033}, \"size\": {\"0\": 356.5569152832031, \"1\": 281.8731384277344}, \"flags\": {}, \"order\": 81, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 465, \"slot_index\": 0}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"sd3/comfyui\"]}, {\"id\": 150, \"type\": \"AdvPromptEnhancer\", \"pos\": {\"0\": -2164.60205078125, \"1\": -133.75721740722656}, \"size\": {\"0\": 400, \"1\": 434}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"Add_Parameter\", \"type\": \"LIST\", \"link\": null, \"shape\": 7}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 269, \"shape\": 7}, {\"name\": \"Instruction\", \"type\": \"STRING\", \"link\": 270, \"widget\": {\"name\": \"Instruction\"}, \"shape\": 7}, {\"name\": \"Examples_or_Context\", \"type\": \"STRING\", \"link\": 271, \"widget\": {\"name\": \"Examples_or_Context\"}, \"shape\": 7}, {\"name\": \"Prompt\", \"type\": \"STRING\", \"link\": 272, \"widget\": {\"name\": \"Prompt\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"LLMprompt\", \"type\": \"STRING\", \"links\": [265, 503, 505], \"slot_index\": 0}, {\"name\": \"Context\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"Help\", \"type\": \"STRING\", \"links\": [266]}, {\"name\": \"Troubleshooting\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"AdvPromptEnhancer\"}, \"widgets_values\": [\"ChatGPT\", \"chatgpt-4o-latest\", \"none\", \"none\", \"none\", \"none\", 0.7, 300, 232693528089113, \"randomize\", \"Two newlines\", \"https://api.groq.com/openai/v1\", \"\", \"\", \"\"]}, {\"id\": 139, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1713, \"1\": -125}, \"size\": {\"0\": 414.07562255859375, \"1\": 249.64144897460938}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 265, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 6}], \"title\": \"LLM Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"Ink wash painting, side profile, mid-angle shot, stark contrast lighting. A dark, hooded figure stands with large, shadowy wings unfurled behind them, their face obscured in shadow. The figure's cloak ripples and dissolves into ink-like drips toward the bottom, giving an ethereal, fragmented appearance. The wings are sharp and jagged, with loose feathers falling away and morphing into small birds flying into the distance. The background is minimalist, mostly white with subtle ink splatters and smudges, creating a sense of emptiness and isolation. The overall composition follows the rule of thirds, with the figure positioned slightly off-center to the right. The lighting is soft, creating a moody atmosphere while casting a faint glow on the upper parts of the wings, leaving the lower half in shadow. The texture of the cloak and wings appears rough and tattered, contrasting against the smooth, white background.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 138, \"type\": \"CLIPTextEncodeSD3\", \"pos\": {\"0\": -530, \"1\": 337}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"clip_l\", \"type\": \"STRING\", \"link\": 568, \"widget\": {\"name\": \"clip_l\"}}, {\"name\": \"clip_g\", \"type\": \"STRING\", \"link\": 569, \"widget\": {\"name\": \"clip_g\"}}, {\"name\": \"t5xxl\", \"type\": \"STRING\", \"link\": 567, \"widget\": {\"name\": \"t5xxl\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [486], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncodeSD3\"}, \"widgets_values\": [\"\", \"\", \"\", \"none\"]}, {\"id\": 274, \"type\": \"Tagger\", \"pos\": {\"0\": -1722, \"1\": 468}, \"size\": {\"0\": 400, \"1\": 240}, \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 505, \"widget\": {\"name\": \"text\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"tagged_text\", \"type\": \"STRING\", \"links\": [502, 506], \"slot_index\": 0}, {\"name\": \"help\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"troubleshooting\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"Tagger\"}, \"widgets_values\": [\"oil painting with broad three-dimensional brushstrokes and impasto technique\", \"\", false, \"\", \"\"]}, {\"id\": 117, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1213, \"1\": 98}, \"size\": {\"0\": 315.5251159667969, \"1\": 113.39636993408203}, \"flags\": {}, \"order\": 26, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"title\": \"clip g\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"A whimsical forest tea party with an adorable bunny, panda, and fox enjoying tea and biscuits, surrounded by flowers and glowing fireflies.ganic textures meld into vibrant, gothic adornments in a hauntingly ethereal composition.\"]}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1209, \"1\": 77}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 68, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 499}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [234, 501], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 270, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1204, \"1\": -91}, \"size\": {\"0\": 309.20068359375, \"1\": 126.21521759033203}, \"flags\": {}, \"order\": 27, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"title\": \"clip l\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Whimsical tea party, watercolor, soft pastel colors, fluffy bunny, chubby panda, playful fox, forest clearing, colorful wildflowers, glowing fireflies, joyful gathering.\\n\"]}, {\"id\": 271, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1201, \"1\": 272}, \"size\": {\"0\": 295.72662353515625, \"1\": 168.29624938964844}, \"flags\": {}, \"order\": 28, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"title\": \"T5\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Watercolor painting, soft pastel lighting, slight overhead angle, capturing a whimsical forest tea party with a dreamlike quality. Three adorable animals\\u2014a fluffy bunny with tiny fangs, a chubby panda in a polka-dotted bow tie, and a playful fox with oversized ears\\u2014sit around an intricately detailed tiny table in a lively forest clearing. The scene is framed by colorful wildflowers and softly glowing fireflies, lending a magical atmosphere. The bunny is delicately pouring tea, the panda happily munches a biscuit, and the fox laughs heartily, expressing joy and warmth. Depth of field is shallow, with the characters and table in focus while the background is softly blurred. Composition follows the rule of thirds, drawing attention to the central, joyful gathering.\"]}, {\"id\": 128, \"type\": \"Fast Groups Bypasser (rgthree)\", \"pos\": {\"0\": -474, \"1\": 631}, \"size\": {\"0\": 252, \"1\": 322}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": -2136, \"1\": 370}, \"size\": {\"0\": 320, \"1\": 314}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [269, 273, 295], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"1 (1).webp\", \"image\"], \"color\": \"#155588\", \"bgcolor\": \"#29699c\"}, {\"id\": 162, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -965, \"1\": 542}, \"size\": {\"0\": 344.6795959472656, \"1\": 255.9129638671875}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 506, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [567], \"slot_index\": 0, \"shape\": 6}], \"title\": \"T5 Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"oil painting with broad three-dimensional brushstrokes and impasto technique Ink wash painting, side profile, mid-angle shot, stark contrast lighting. A dark, hooded figure stands with large, shadowy wings unfurled behind them, their face obscured in shadow. The figure's cloak ripples and dissolves into ink-like drips toward the bottom, giving an ethereal, fragmented appearance. The wings are sharp and jagged, with loose feathers falling away and morphing into small birds flying into the distance. The background is minimalist, mostly white with subtle ink splatters and smudges, creating a sense of emptiness and isolation. The overall composition follows the rule of thirds, with the figure positioned slightly off-center to the right. The lighting is soft, creating a moody atmosphere while casting a faint glow on the upper parts of the wings, leaving the lower half in shadow. The texture of the cloak and wings appears rough and tattered, contrasting against the smooth, white background.\"]], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 160, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1030.51904296875, \"1\": 855.8450927734375}, \"size\": {\"0\": 350, \"1\": 290}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 286, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [568], \"slot_index\": 0, \"shape\": 6}], \"title\": \"Clip-L Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"hooded figure, dark angel, black wings, silhouette, ink splatter, watercolor effect, shadowy, gothic, abstract, mysterious, dripping paint, birds, monochromatic, eerie atmosphere, fantasy\"]], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 161, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1026.5189208984375, \"1\": 1208.84521484375}, \"size\": {\"0\": 350, \"1\": 290}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 287, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [569], \"slot_index\": 0, \"shape\": 6}], \"title\": \"Clip-G Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"A dark, hooded figure with large, black wings stands in a dramatic, shadowy silhouette, surrounded by abstract splashes and flying birds.\"]], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 62, \"type\": \"SDXLEmptyLatentSizePicker+\", \"pos\": {\"0\": -554, \"1\": -223}, \"size\": {\"0\": 340.20001220703125, \"1\": 170}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"width\", \"type\": \"INT\", \"links\": [124], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [125], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SDXLEmptyLatentSizePicker+\"}, \"widgets_values\": [\"832x1216 (0.68)\", 1, 0, 0]}, {\"id\": 290, \"type\": \"LoraLoader\", \"pos\": {\"0\": 32, \"1\": -403}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": null}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"sd3-5-ghibli.safetensors\", 1, 1]}, {\"id\": 134, \"type\": \"Reroute\", \"pos\": {\"0\": -745, \"1\": 188}, \"size\": [75, 26], \"flags\": {}, \"order\": 57, \"mode\": 4, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 250}], \"outputs\": [{\"name\": \"\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 121, \"type\": \"Preview Chooser\", \"pos\": {\"0\": 1271, \"1\": 173}, \"size\": {\"0\": 692.0098266601562, \"1\": 498.26287841796875}, \"flags\": {}, \"order\": 69, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 234, \"shape\": 7}, {\"name\": \"latents\", \"type\": \"LATENT\", \"link\": null, \"shape\": 7}, {\"name\": \"masks\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}, {\"name\": \"segs\", \"type\": \"SEGS\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"links\": [534], \"slot_index\": 0}, {\"name\": \"latents\", \"type\": \"LATENT\", \"links\": null}, {\"name\": \"masks\", \"type\": \"MASK\", \"links\": null}, {\"name\": \"selected\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"segs\", \"type\": \"SEGS\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"Preview Chooser\"}, \"widgets_values\": [\"Always pause\", 1, \"\", \"\"]}], \"links\": [[80, 40, 0, 3, 2, \"CONDITIONING\"], [107, 4, 0, 55, 0, \"MODEL\"], [122, 61, 0, 3, 3, \"LATENT\"], [124, 62, 1, 61, 0, \"INT\"], [125, 62, 2, 61, 1, \"INT\"], [143, 79, 0, 40, 1, \"STRING\"], [160, 40, 0, 89, 0, \"CONDITIONING\"], [181, 55, 0, 87, 2, \"SIGMAS\"], [184, 61, 0, 87, 3, \"LATENT\"], [186, 89, 0, 87, 1, \"CONDITIONING\"], [196, 87, 1, 102, 0, \"CONDITIONING\"], [234, 8, 0, 121, 0, \"IMAGE\"], [247, 133, 0, 130, 0, \"PATH\"], [248, 130, 0, 132, 0, \"STRING\"], [249, 131, 2, 133, 0, \"PATH\"], [250, 130, 0, 134, 0, \"*\"], [253, 136, 0, 3, 0, \"MODEL\"], [255, 136, 0, 59, 0, \"MODEL\"], [265, 150, 0, 139, 0, \"STRING\"], [266, 150, 2, 140, 0, \"STRING\"], [267, 151, 0, 145, 0, \"STRING\"], [268, 151, 2, 146, 0, \"STRING\"], [269, 144, 0, 150, 1, \"IMAGE\"], [270, 142, 0, 150, 2, \"STRING\"], [271, 141, 0, 150, 3, \"STRING\"], [272, 143, 0, 150, 4, \"STRING\"], [273, 144, 0, 151, 1, \"IMAGE\"], [274, 148, 0, 151, 2, \"STRING\"], [275, 149, 0, 151, 4, \"STRING\"], [276, 147, 0, 151, 3, \"STRING\"], [278, 151, 0, 152, 0, \"*\"], [279, 159, 0, 154, 0, \"STRING\"], [280, 159, 2, 155, 0, \"STRING\"], [281, 157, 0, 159, 2, \"STRING\"], [282, 156, 0, 159, 3, \"STRING\"], [283, 158, 0, 159, 4, \"STRING\"], [285, 159, 0, 153, 0, \"*\"], [286, 152, 0, 160, 0, \"STRING\"], [287, 153, 0, 161, 0, \"STRING\"], [295, 144, 0, 159, 1, \"IMAGE\"], [313, 4, 2, 175, 0, \"VAE\"], [314, 43, 0, 176, 0, \"CLIP\"], [324, 4, 0, 136, 0, \"*\"], [465, 264, 0, 263, 0, \"IMAGE\"], [466, 266, 0, 264, 0, \"IMAGE\"], [467, 265, 0, 264, 5, \"UPSCALE_MODEL\"], [468, 266, 3, 264, 6, \"FLOAT\"], [469, 266, 1, 264, 7, \"INT\"], [470, 266, 2, 264, 8, \"INT\"], [471, 264, 0, 267, 1, \"IMAGE\"], [474, 4, 0, 264, 1, \"MODEL\"], [475, 40, 0, 264, 3, \"CONDITIONING\"], [477, 269, 0, 3, 1, \"CONDITIONING\"], [479, 269, 0, 264, 2, \"CONDITIONING\"], [482, 269, 0, 87, 0, \"CONDITIONING\"], [486, 138, 0, 269, 0, \"*\"], [493, 136, 0, 272, 0, \"MODEL\"], [494, 269, 0, 272, 1, \"CONDITIONING\"], [495, 102, 0, 272, 2, \"CONDITIONING\"], [497, 87, 2, 272, 4, \"SIGMAS\"], [498, 87, 3, 272, 5, \"LATENT\"], [499, 272, 0, 8, 0, \"LATENT\"], [500, 273, 0, 272, 3, \"SAMPLER\"], [501, 8, 0, 267, 0, \"IMAGE\"], [502, 274, 0, 275, 0, \"STRING\"], [503, 150, 0, 275, 1, \"STRING\"], [505, 150, 0, 274, 0, \"STRING\"], [506, 274, 0, 162, 0, \"STRING\"], [516, 277, 0, 276, 6, \"BBOX_DETECTOR\"], [517, 280, 0, 276, 7, \"SAM_MODEL\"], [518, 277, 1, 276, 8, \"SEGM_DETECTOR\"], [520, 279, 0, 278, 6, \"BBOX_DETECTOR\"], [521, 280, 0, 278, 7, \"SAM_MODEL\"], [522, 279, 1, 278, 8, \"SEGM_DETECTOR\"], [524, 282, 0, 281, 6, \"BBOX_DETECTOR\"], [525, 280, 0, 281, 7, \"SAM_MODEL\"], [526, 282, 1, 281, 8, \"SEGM_DETECTOR\"], [527, 278, 1, 283, 0, \"IMAGE\"], [528, 278, 2, 284, 0, \"IMAGE\"], [529, 281, 1, 285, 0, \"IMAGE\"], [530, 281, 2, 286, 0, \"IMAGE\"], [531, 276, 1, 287, 0, \"IMAGE\"], [532, 276, 2, 288, 0, \"IMAGE\"], [533, 4, 0, 289, 0, \"MODEL\"], [534, 121, 0, 276, 0, \"IMAGE\"], [537, 40, 0, 276, 5, \"CONDITIONING\"], [538, 40, 0, 278, 5, \"CONDITIONING\"], [539, 40, 0, 281, 5, \"CONDITIONING\"], [540, 269, 0, 276, 4, \"CONDITIONING\"], [541, 269, 0, 278, 4, \"CONDITIONING\"], [542, 269, 0, 281, 4, \"CONDITIONING\"], [543, 276, 0, 278, 0, \"IMAGE\"], [544, 278, 0, 281, 0, \"IMAGE\"], [545, 281, 0, 266, 0, \"IMAGE\"], [546, 43, 0, 268, 0, \"CLIP\"], [547, 4, 2, 8, 1, \"VAE\"], [548, 43, 0, 138, 0, \"CLIP\"], [549, 43, 0, 16, 0, \"CLIP\"], [550, 4, 2, 264, 4, \"VAE\"], [551, 43, 0, 40, 0, \"CLIP\"], [552, 4, 0, 276, 1, \"MODEL\"], [553, 43, 0, 276, 2, \"CLIP\"], [554, 4, 2, 276, 3, \"VAE\"], [555, 4, 0, 278, 1, \"MODEL\"], [556, 43, 0, 278, 2, \"CLIP\"], [557, 4, 2, 278, 3, \"VAE\"], [558, 4, 0, 281, 1, \"MODEL\"], [559, 43, 0, 281, 2, \"CLIP\"], [560, 4, 2, 281, 3, \"VAE\"], [567, 162, 0, 138, 3, \"STRING\"], [568, 160, 0, 138, 1, \"STRING\"], [569, 161, 0, 138, 2, \"STRING\"], [570, 43, 0, 268, 0, \"CLIP\"], [571, 43, 0, 16, 0, \"CLIP\"], [572, 4, 2, 264, 4, \"VAE\"], [573, 43, 0, 40, 0, \"CLIP\"], [574, 4, 0, 278, 1, \"MODEL\"], [575, 43, 0, 278, 2, \"CLIP\"], [576, 4, 2, 278, 3, \"VAE\"], [577, 4, 0, 281, 1, \"MODEL\"], [578, 43, 0, 281, 2, \"CLIP\"], [579, 4, 2, 281, 3, \"VAE\"], [580, 4, 0, 276, 1, \"MODEL\"], [581, 43, 0, 276, 2, \"CLIP\"], [582, 4, 2, 276, 3, \"VAE\"], [583, 43, 0, 138, 0, \"CLIP\"], [584, 4, 2, 8, 1, \"VAE\"], [585, 4, 0, 290, 0, \"MODEL\"], [586, 43, 0, 290, 1, \"CLIP\"]], \"groups\": [{\"title\": \"Eyess\", \"bounding\": [2774, -10, 745, 1371], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"T5, Clip L, Clip G\", \"bounding\": [-1246, 463, 701, 1049], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"LLM Clip G\", \"bounding\": [-2645, 1433, 1378, 689], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"LLM Clip L\", \"bounding\": [-2646, 736, 1378, 676], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Upscale\", \"bounding\": [2058, 1438, 1966, 947], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"manual prompt\", \"bounding\": [-1244, -209, 638, 659], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"LLM t5\", \"bounding\": [-2645, -210, 1380, 922], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Different Text Encoder Configurations\", \"bounding\": [-1234, -492, 592, 233], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Qwen\", \"bounding\": [-2456, -681, 1185, 439], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Hands\", \"bounding\": [2027, -8, 705, 1386], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Face\", \"bounding\": [3559, -12, 766, 1384], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.6588450000000233, \"offset\": [2184.8084478786514, -83.46287321377497]}}, \"version\": 0.4, \"widget_idx_map\": {\"3\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"59\": {\"scheduler\": 0}, \"94\": {\"sampler_name\": 0}, \"130\": {\"seed\": 8}, \"150\": {\"seed\": 8}, \"151\": {\"seed\": 8}, \"159\": {\"seed\": 8}, \"264\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"272\": {\"noise_seed\": 7}, \"276\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}, \"278\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}, \"281\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}}, \"seed_widgets\": {\"3\": 0, \"130\": 8, \"150\": 8, \"151\": 8, \"159\": 8, \"264\": 1, \"272\": 7, \"276\": 3, \"278\": 3, \"281\": 3}}}",
                "steps": 30,
                "width": {
                    "_meta": {
                        "title": "\ud83d\udd27 Empty Latent Size Picker"
                    },
                    "inputs": {
                        "batch_size": 1,
                        "resolution": "832x1216 (0.68)",
                        "width_override": 0,
                        "height_override": 0
                    },
                    "class_type": "SDXLEmptyLatentSizePicker+"
                },
                "height": {
                    "_meta": {
                        "title": "\ud83d\udd27 Empty Latent Size Picker"
                    },
                    "inputs": {
                        "batch_size": 1,
                        "resolution": "832x1216 (0.68)",
                        "width_override": 0,
                        "height_override": 0
                    },
                    "class_type": "SDXLEmptyLatentSizePicker+"
                },
                "models": [
                    "sd3.5_large.safetensors"
                ],
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 5.5,
                "modelIds": [],
                "scheduler": "sgm_uniform",
                "upscalers": [
                    "4x-UltraSharp.pth"
                ],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "sd3-5-ghibli.safetensors",
                        "type": "lora",
                        "strength": 1,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "NaomiVK",
            "baseModel": "SD 3.5"
        },
        {
            "id": 36692200,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/693e9bed-7aae-4449-80a6-e4c3f2f0d22f/width=1536/693e9bed-7aae-4449-80a6-e4c3f2f0d22f.jpeg",
            "hash": "U68{{{}?OBM|].^jSza1-UNat6-UJ8JSjFNH",
            "width": 1536,
            "height": 2312,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-26T16:56:27.098Z",
            "postId": 8381108,
            "stats": {
                "cryCount": 5,
                "laughCount": 32,
                "likeCount": 263,
                "dislikeCount": 0,
                "heartCount": 83,
                "commentCount": 1
            },
            "meta": {
                "Size": "1030x1545",
                "seed": 2670912399,
                "Model": "flux_dev",
                "steps": 25,
                "hashes": {
                    "model": "2eda627c8a"
                },
                "Version": "v1.10.1",
                "sampler": "Euler",
                "cfgScale": 1,
                "Mask blur": "4",
                "resources": [
                    {
                        "hash": "2eda627c8a",
                        "name": "flux_dev",
                        "type": "model"
                    }
                ],
                "Model hash": "2eda627c8a",
                "Schedule type": "Automatic",
                "Denoising strength": "0"
            },
            "username": "Castr0",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 35754550,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a28e33e4-33cd-4b30-8f16-feb67294920a/width=832/a28e33e4-33cd-4b30-8f16-feb67294920a.jpeg",
            "hash": "U3F:.0i_01^500oy^*s90OR*0}F1%LS#PTV[",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-10-23T10:00:00.000Z",
            "postId": 8170344,
            "stats": {
                "cryCount": 0,
                "laughCount": 10,
                "likeCount": 292,
                "dislikeCount": 0,
                "heartCount": 81,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3281182787,
                "extra": {
                    "remixOfId": 35517882
                },
                "steps": 40,
                "prompt": "score_9, score_8_up, score_8. score_9, score_8_up, score_7_up, score_6_up, masterpiece, 4k, high quality, (best quality:1.1), ExpressiveH,\n1girl, solo, exotic goddess of randomness, red eyes, broad-shouldered body type, big breasts, light brown skin with tan lines, seductive smirk, short curly hair, swept bangs, dark red hair with black tips, wearing a divine robe of obsidian and glowing lava, adorned with molten gold bracelets, standing in a volcanic landscape with rivers of lava and ash-filled skies.",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-20T2108:46.4927636Z",
                "negativePrompt": "core_6, score_5, score_4, worst quality, low quality, text, censored, deformed, bad hand, blurry, (watermark), weights, extra hands, extra dicks. 3 finger, 5 finger, bangs, bad anatomy, big head, artist signature, artist name, intersex, 3d, earrings,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640,
                        "modelVersionName": "V6 (start with this one)"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 159401,
                        "modelVersionName": "SDXL v1.1"
                    },
                    {
                        "type": "lora",
                        "weight": 0.35,
                        "modelVersionId": 381063,
                        "modelVersionName": "Pony V2.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1.15,
                        "modelVersionId": 382152,
                        "modelVersionName": "ExpressiveH"
                    },
                    {
                        "type": "lora",
                        "weight": 0.35,
                        "modelVersionId": 398847,
                        "modelVersionName": "gothic neon v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.75,
                        "modelVersionId": 436219,
                        "modelVersionName": "v3.0 (PonyXL Edition)"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250708,
                        "modelVersionName": "safe_pos"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250712,
                        "modelVersionName": "safe_neg"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "Mawai2",
            "baseModel": "Pony"
        },
        {
            "id": 34869531,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cbff8a93-a883-44ec-a89a-da383a3e0cdb/width=1216/cbff8a93-a883-44ec-a89a-da383a3e0cdb.jpeg",
            "hash": "UC9QdZv$a0x]c[ENIo%0%0S6V@-6=FjGaKbY",
            "width": 1216,
            "height": 1824,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-16T07:36:57.564Z",
            "postId": 7969111,
            "stats": {
                "cryCount": 17,
                "laughCount": 13,
                "likeCount": 282,
                "dislikeCount": 0,
                "heartCount": 71,
                "commentCount": 7
            },
            "meta": null,
            "username": "Bra2ha",
            "baseModel": null
        },
        {
            "id": 34598624,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7049b058-e260-48b3-8dce-ab457165a96b/width=832/7049b058-e260-48b3-8dce-ab457165a96b.jpeg",
            "hash": "UFFp+~WC-5%0}rbINGNa9ZniEkWXELniNeNx",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-21T17:16:00.000Z",
            "postId": 7905834,
            "stats": {
                "cryCount": 16,
                "laughCount": 38,
                "likeCount": 241,
                "dislikeCount": 0,
                "heartCount": 88,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2189545376,
                "steps": 15,
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, \n1girl, 25 years old, perfect face, (close view), looking at viewer, cute, petite,  \nyellow eyes,\ndemon girl, demon horns, huge horns, striped horns, black horns, purple horns, pointy ears, \nmulticolored hair, streaked hair, grey hair, purple hair, long hair, very long hair, hair between eyes, \nred sweater, bare shoulders, \nautumn, autumn leaves, night, full moon,\n(blush), light smile, \nportrait, face focus, detailed face,",
                "sampler": "DPM2 a",
                "cfgScale": 3,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-14T1559:33.0578666Z",
                "negativePrompt": "score_6, score_5, score_4, pony, furry, monochrome, curvy, fat, pubic hair, watermark, \nartist name, ugly, ugly face, mutated hands, low res, bad anatomy, bad eyes, blurry face, unfinished, sketch, greyscale, (deformed),",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640,
                        "modelVersionName": "V6 (start with this one)"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 9208,
                        "modelVersionName": "EasyNegative"
                    },
                    {
                        "type": "lora",
                        "weight": 0.45,
                        "modelVersionId": 382152,
                        "modelVersionName": "ExpressiveH"
                    },
                    {
                        "type": "lora",
                        "weight": 0.75,
                        "modelVersionId": 244808,
                        "modelVersionName": "v2.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 398847,
                        "modelVersionName": "gothic neon v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.6,
                        "modelVersionId": 436219,
                        "modelVersionName": "v3.0 (PonyXL Edition)"
                    }
                ]
            },
            "username": "carefull_time",
            "baseModel": "Pony"
        },
        {
            "id": 34562602,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/86cbb142-e92d-4025-a566-9278ba10baf1/width=832/86cbb142-e92d-4025-a566-9278ba10baf1.jpeg",
            "hash": "UuJR{zogxuoz_NayozogIUkCRjWBbIoeRjfk",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-14T14:29:59.369Z",
            "postId": 7897327,
            "stats": {
                "cryCount": 7,
                "laughCount": 38,
                "likeCount": 262,
                "dislikeCount": 0,
                "heartCount": 77,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 276069972,
                "steps": 35,
                "prompt": "A futuristic skyscraper made entirely out of broken mirrors, distorting the city\u2019s skyline in a chaotic, reflective mess.\naidmaMJ6, aidmaHyperrealism, aidmaimageupgrader, aidmafluxpro1.1",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-14T1427:12.5576867Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.2,
                        "modelVersionId": 863991,
                        "modelVersionName": "FLUX v0.2"
                    },
                    {
                        "type": "lora",
                        "weight": 0.45,
                        "modelVersionId": 894049,
                        "modelVersionName": "FLUX v0.2"
                    },
                    {
                        "type": "lora",
                        "weight": 0.45,
                        "modelVersionId": 925023,
                        "modelVersionName": "FLUX v0.3"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 955535,
                        "modelVersionName": "FLUX v0.2"
                    }
                ]
            },
            "username": "AIDigitalMediaAgency",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 34097040,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/398fc523-ba07-40b7-8ab8-c058997e2780/width=832/398fc523-ba07-40b7-8ab8-c058997e2780.jpeg",
            "hash": "U55YQY.SDi8x_N%MIBD*%gs:M{M|WBV[oztR",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-12T00:29:15.085Z",
            "postId": 7793796,
            "stats": {
                "cryCount": 14,
                "laughCount": 0,
                "likeCount": 313,
                "dislikeCount": 0,
                "heartCount": 56,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2871106489,
                "extra": {
                    "remixOfId": 33923538
                },
                "steps": 30,
                "prompt": "highly detailed, high quality, digital illustration, intricate details, light reflection, trending on artstation, volumetric lighting, extremely clear 8k wallpaper.\na witch hut stands on a little island between  two red bloody rivers. Green smoke comes out from chimney, moss cover the hut, there's a little dock with a boat on a side of the island.  Menacing touch, Grimdark and haunting atmosphere, Sense of foreboding, (reflective volumetric), raytracing, absurdres, dark, low-key,\nscenery, gloomy, dark atmosphere, midjourneyv6.1",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-11T2012:08.3247964Z",
                "negativePrompt": "score_4, score_5, score_6, simple background, watercolor, lowres, low detail, text, orange leaves, BadDream,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 690310,
                        "modelVersionName": "\ud83d\udd1d\ud83d\udd35 XL PRO"
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 332071,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.5,
                        "modelVersionId": 458270,
                        "modelVersionName": "monsters"
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 510042,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 723149,
                        "modelVersionName": "SDXL"
                    }
                ]
            },
            "username": "Gurdung",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 34073864,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4e752cfb-0d31-4371-b07c-3c904367325d/width=768/4e752cfb-0d31-4371-b07c-3c904367325d.jpeg",
            "hash": "UGDJ;VF3TKIU~VDjRjWBD%V@%2t7l9kq%NV@",
            "width": 768,
            "height": 1344,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-11T21:10:47.985Z",
            "postId": 7788681,
            "stats": {
                "cryCount": 14,
                "laughCount": 18,
                "likeCount": 285,
                "dislikeCount": 0,
                "heartCount": 66,
                "commentCount": 1
            },
            "meta": {
                "Size": "768x1344",
                "seed": 1792674691,
                "Model": "lyhAnimeFlux_v4Niji",
                "steps": 20,
                "hashes": {
                    "model": "6f5dd9e72b",
                    "lora:ILLUSTRATION_2_FLUX v2": "749ada6b9e94",
                    "lora:midjourney_whisper_flux_lora_v01": "ee64e90efc4d"
                },
                "prompt": "Midjourney_Whisper, A hyper-realistic portrait of a stunning supermodel, featuring a beautifully detailed face with captivating eyes and a serene expression.\nStunning illustration. masterpiece. bewitching color, depth of field, soft lighting, sharp focus, anime,  <lora:ILLUSTRATION_2_FLUX v2:0.4> <lora:midjourney_whisper_flux_lora_v01:0.4>\nThe passage describes a highly detailed and ethereal side-profile portrait of a little sexy erotic cute girl. She has short, luminous silver hair with teal highlights and wears an elaborate headpiece adorned with seashells, pearls, and metallic filigree, evoking an underwater kingdom. Her attire blends oceanic textures with baroque elegance and steampunk elements, featuring lace and embroidery in teal, black, and silver. The background is a flowing watercolor-like scene with abstract ink splashes, creating a serene and surreal atmosphere against an ocean at dusk.",
                "Version": "f2.0.1v1.10.1-previous-560-g7eb824a0",
                "sampler": "Euler",
                "Module 1": "ae",
                "Module 2": "clip_l",
                "Module 3": "t5xxl_fp8_e4m3fn",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "ee64e90efc4d",
                        "name": "midjourney_whisper_flux_lora_v01",
                        "type": "lora",
                        "weight": 0.4
                    },
                    {
                        "hash": "749ada6b9e94",
                        "name": "ILLUSTRATION_2_FLUX v2",
                        "type": "lora"
                    },
                    {
                        "hash": "6f5dd9e72b",
                        "name": "lyhAnimeFlux_v4Niji",
                        "type": "model"
                    }
                ],
                "Model hash": "6f5dd9e72b",
                "Schedule type": "Simple",
                "Distilled CFG Scale": "3.5",
                "Diffusion in Low Bits": "Automatic (fp16 LoRA)"
            },
            "username": "Urahotom",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 32082960,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9c0c6cdb-7208-4ace-98e1-0721d7b3010f/width=768/9c0c6cdb-7208-4ace-98e1-0721d7b3010f.jpeg",
            "hash": "ULF$L;}s+IE4-:S2xIxbu5t8I8oK_MwaEMEM",
            "width": 768,
            "height": 1024,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-30T12:12:37.060Z",
            "postId": 7342749,
            "stats": {
                "cryCount": 28,
                "laughCount": 25,
                "likeCount": 251,
                "dislikeCount": 0,
                "heartCount": 80,
                "commentCount": 0
            },
            "meta": {
                "seed": 1032943113839300,
                "vaes": [
                    "ae.safetensors"
                ],
                "comfy": "{\"prompt\": {\"5\": {\"inputs\": {\"width\": 768, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"6\": {\"inputs\": {\"text\": \"The painting is created in a highly detailed sci-fi fantasy style.  The brushstrokes are smooth and precise, bringing out the sleekness and complexity of the robot.  The colors are vivid and rich, with a blend of metallic hues and neon accents.  The texture is a combination of smooth surfaces and intricate patterns.\\nScene Description: In the center of the painting stands a majestic robot, its body a combination of gleaming metal and advanced technology.  The robot's upper body is in a half-portrait view, facing directly forward.  Its face is a transparent reflective visor that shows a complex and magnificent future city.  The city is filled with towering skyscrapers, flying vehicles, and colorful lights.  The robot's body is adorned with intricate designs and symbols, hinting at its advanced capabilities.  The background is a series of strip-like panels that seem like reflective glass, each one showing a different fantastical scene.  Some panels display alien landscapes, others show space battles, and still others show strange technological wonders.\\nComposition: The robot is centered in the frame, commanding attention.  The reflective visor draws the viewer's eye, leading them to explore the details of the future city within.  The strip-like panels in the background create a sense of depth and complexity, adding to the overall sci-fi atmosphere.  The composition is balanced and harmonious, with the different elements working together to create a captivating scene.\\nColor Palette: The colors are a mix of cool blues, purples, and silvers for the robot's body, with accents of neon pink, green, and orange for the future city and background panels.  The reflective visor has a rainbow of colors, reflecting the vividness of the scenes it shows.\\nLight and Shadow: Soft, diffused light bathes the robot and the background, creating a gentle glow.  Shadows are subtle, adding depth without overpowering the colors.  The reflective surfaces of the robot and the panels catch the light, creating a play of light and shadow that enhances the three-dimensional effect.\\nDetail: Every aspect of the painting is filled with intricate details.  The robot's body is covered in fine lines and patterns, with every bolt and panel clearly defined.  The reflective visor shows a detailed cityscape with tiny buildings, vehicles, and people.  The background panels are filled with complex scenes, each one with its own unique elements and colors.\", \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"10\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"5\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 50, \"denoise\": 1.0, \"model\": [\"12\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"12\", 0], \"conditioning\": [\"6\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 1032943113839300}, \"class_type\": \"RandomNoise\"}}, \"workflow\": {\"last_node_id\": 25, \"last_link_id\": 40, \"nodes\": [{\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": 37, \"1\": 46}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"pinned\": true}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [38, 39], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 40, \"1\": 166}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"pinned\": true}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [10], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 5, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 43, \"1\": 317}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"pinned\": true}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [23], \"slot_index\": 0, \"label\": \"Latent\"}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [768, 1024, 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 381, \"1\": 160}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {\"pinned\": true}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24, \"label\": \"Latent\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12, \"label\": \"VAE\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [9], \"slot_index\": 0, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 48, \"1\": 698}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"pinned\": true}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 38, \"slot_index\": 0, \"label\": \"\\u6a21\\u578b\"}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"shape\": 3, \"label\": \"Sigmas\"}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 50, 1], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 39, \"1\": 597}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {\"pinned\": true}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19], \"shape\": 3, \"label\": \"\\u91c7\\u6837\\u5668\"}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 43, \"1\": 464}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"pinned\": true}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"shape\": 3, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [1032943113839300, \"randomize\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 392, \"1\": 476}, \"size\": {\"0\": 416.155029296875, \"1\": 326}, \"flags\": {\"pinned\": true}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 30, \"slot_index\": 1, \"label\": \"\\u5f15\\u5bfc\"}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2, \"label\": \"\\u91c7\\u6837\\u5668\"}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3, \"label\": \"Sigmas\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 23, \"slot_index\": 4, \"label\": \"Latent\"}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u8f93\\u51fa\"}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3, \"label\": \"\\u964d\\u566a\\u8f93\\u51fa\"}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#233\", \"bgcolor\": \"#355\", \"shape\": 1}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 604, \"1\": 161}, \"size\": {\"0\": 202.94503784179688, \"1\": 46}, \"flags\": {\"pinned\": true}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 39, \"slot_index\": 0, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 40, \"slot_index\": 1, \"label\": \"\\u6761\\u4ef6\"}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [30], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u5f15\\u5bfc\"}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 386, \"1\": 55}, \"size\": {\"0\": 422.5250549316406, \"1\": 59.05733871459961}, \"flags\": {\"pinned\": true}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12], \"slot_index\": 0, \"shape\": 3, \"label\": \"VAE\"}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": {\"0\": 836, \"1\": 51}, \"size\": {\"0\": 856.820068359375, \"1\": 895.4721069335938}, \"flags\": {\"pinned\": true}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 9, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\", \"shape\": 1}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 388, \"1\": 263}, \"size\": {\"0\": 422.84503173828125, \"1\": 164.31304931640625}, \"flags\": {\"pinned\": true}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 10, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [40], \"slot_index\": 0, \"label\": \"\\u6761\\u4ef6\"}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"The painting is created in a highly detailed sci-fi fantasy style.  The brushstrokes are smooth and precise, bringing out the sleekness and complexity of the robot.  The colors are vivid and rich, with a blend of metallic hues and neon accents.  The texture is a combination of smooth surfaces and intricate patterns.\\nScene Description: In the center of the painting stands a majestic robot, its body a combination of gleaming metal and advanced technology.  The robot's upper body is in a half-portrait view, facing directly forward.  Its face is a transparent reflective visor that shows a complex and magnificent future city.  The city is filled with towering skyscrapers, flying vehicles, and colorful lights.  The robot's body is adorned with intricate designs and symbols, hinting at its advanced capabilities.  The background is a series of strip-like panels that seem like reflective glass, each one showing a different fantastical scene.  Some panels display alien landscapes, others show space battles, and still others show strange technological wonders.\\nComposition: The robot is centered in the frame, commanding attention.  The reflective visor draws the viewer's eye, leading them to explore the details of the future city within.  The strip-like panels in the background create a sense of depth and complexity, adding to the overall sci-fi atmosphere.  The composition is balanced and harmonious, with the different elements working together to create a captivating scene.\\nColor Palette: The colors are a mix of cool blues, purples, and silvers for the robot's body, with accents of neon pink, green, and orange for the future city and background panels.  The reflective visor has a rainbow of colors, reflecting the vividness of the scenes it shows.\\nLight and Shadow: Soft, diffused light bathes the robot and the background, creating a gentle glow.  Shadows are subtle, adding depth without overpowering the colors.  The reflective surfaces of the robot and the panels catch the light, creating a play of light and shadow that enhances the three-dimensional effect.\\nDetail: Every aspect of the painting is filled with intricate details.  The robot's body is covered in fine lines and patterns, with every bolt and panel clearly defined.  The reflective visor shows a detailed cityscape with tiny buildings, vehicles, and people.  The background panels are filled with complex scenes, each one with its own unique elements and colors.\"], \"color\": \"#232\", \"bgcolor\": \"#353\", \"shape\": 1}], \"links\": [[9, 8, 0, 9, 0, \"IMAGE\"], [10, 11, 0, 6, 0, \"CLIP\"], [12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [23, 5, 0, 13, 4, \"LATENT\"], [24, 13, 0, 8, 0, \"LATENT\"], [30, 22, 0, 13, 1, \"GUIDER\"], [37, 25, 0, 13, 0, \"NOISE\"], [38, 12, 0, 17, 0, \"MODEL\"], [39, 12, 0, 22, 0, \"MODEL\"], [40, 6, 0, 22, 1, \"CONDITIONING\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.6830134553650705, \"offset\": [429.31702744735054, 33.1537900664593]}, \"workspace_info\": {\"id\": \"L7ZoSc9K2Yo3rxKB0iBYv\", \"saveLock\": false, \"cloudID\": null, \"coverMediaPath\": null}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}}, \"seed_widgets\": {\"25\": 0}}}",
                "steps": 50,
                "width": 768,
                "height": 1024,
                "models": [],
                "prompt": "The painting is created in a highly detailed sci-fi fantasy style.  The brushstrokes are smooth and precise, bringing out the sleekness and complexity of the robot.  The colors are vivid and rich, with a blend of metallic hues and neon accents.  The texture is a combination of smooth surfaces and intricate patterns.\nScene Description: In the center of the painting stands a majestic robot, its body a combination of gleaming metal and advanced technology.  The robot's upper body is in a half-portrait view, facing directly forward.  Its face is a transparent reflective visor that shows a complex and magnificent future city.  The city is filled with towering skyscrapers, flying vehicles, and colorful lights.  The robot's body is adorned with intricate designs and symbols, hinting at its advanced capabilities.  The background is a series of strip-like panels that seem like reflective glass, each one showing a different fantastical scene.  Some panels display alien landscapes, others show space battles, and still others show strange technological wonders.\nComposition: The robot is centered in the frame, commanding attention.  The reflective visor draws the viewer's eye, leading them to explore the details of the future city within.  The strip-like panels in the background create a sense of depth and complexity, adding to the overall sci-fi atmosphere.  The composition is balanced and harmonious, with the different elements working together to create a captivating scene.\nColor Palette: The colors are a mix of cool blues, purples, and silvers for the robot's body, with accents of neon pink, green, and orange for the future city and background panels.  The reflective visor has a rainbow of colors, reflecting the vividness of the scenes it shows.\nLight and Shadow: Soft, diffused light bathes the robot and the background, creating a gentle glow.  Shadows are subtle, adding depth without overpowering the colors.  The reflective surfaces of the robot and the panels catch the light, creating a play of light and shadow that enhances the three-dimensional effect.\nDetail: Every aspect of the painting is filled with intricate details.  The robot's body is covered in fine lines and patterns, with every bolt and panel clearly defined.  The reflective visor shows a detailed cityscape with tiny buildings, vehicles, and people.  The background panels are filled with complex scenes, each one with its own unique elements and colors.",
                "denoise": 1,
                "sampler": "Euler",
                "modelIds": [],
                "scheduler": "simple",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": []
            },
            "username": "HS_hi",
            "baseModel": ""
        },
        {
            "id": 32043774,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc20c4aa-608e-42af-b048-58905943652a/width=768/bc20c4aa-608e-42af-b048-58905943652a.jpeg",
            "hash": "UABpIP%L01E3CltQrXNG02Wr~A$zz:I;Xm%1",
            "width": 768,
            "height": 1024,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-30T06:15:47.267Z",
            "postId": 7334064,
            "stats": {
                "cryCount": 37,
                "laughCount": 20,
                "likeCount": 258,
                "dislikeCount": 0,
                "heartCount": 68,
                "commentCount": 0
            },
            "meta": {
                "seed": 267104024639326,
                "vaes": [
                    "ae.safetensors"
                ],
                "comfy": "{\"prompt\": {\"5\": {\"inputs\": {\"width\": 768, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"6\": {\"inputs\": {\"text\": \"An endless desert with strange lights flashing in the sky and broken code and flickering data fragments on the ground, as if the whole world is on the verge of collapse.\", \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"10\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"5\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 50, \"denoise\": 1.0, \"model\": [\"12\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"12\", 0], \"conditioning\": [\"6\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 267104024639326}, \"class_type\": \"RandomNoise\"}}, \"workflow\": {\"last_node_id\": 25, \"last_link_id\": 40, \"nodes\": [{\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": 37, \"1\": 46}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"pinned\": true}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [38, 39], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 40, \"1\": 166}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"pinned\": true}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [10], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 5, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 43, \"1\": 317}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"pinned\": true}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [23], \"slot_index\": 0, \"label\": \"Latent\"}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [768, 1024, 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 381, \"1\": 160}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {\"pinned\": true}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24, \"label\": \"Latent\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12, \"label\": \"VAE\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [9], \"slot_index\": 0, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 48, \"1\": 698}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"pinned\": true}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 38, \"slot_index\": 0, \"label\": \"\\u6a21\\u578b\"}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"shape\": 3, \"label\": \"Sigmas\"}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 50, 1], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 39, \"1\": 597}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {\"pinned\": true}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19], \"shape\": 3, \"label\": \"\\u91c7\\u6837\\u5668\"}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 43, \"1\": 464}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"pinned\": true}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"shape\": 3, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [267104024639326, \"randomize\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 392, \"1\": 476}, \"size\": {\"0\": 416.155029296875, \"1\": 326}, \"flags\": {\"pinned\": true}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 30, \"slot_index\": 1, \"label\": \"\\u5f15\\u5bfc\"}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2, \"label\": \"\\u91c7\\u6837\\u5668\"}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3, \"label\": \"Sigmas\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 23, \"slot_index\": 4, \"label\": \"Latent\"}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u8f93\\u51fa\"}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3, \"label\": \"\\u964d\\u566a\\u8f93\\u51fa\"}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#233\", \"bgcolor\": \"#355\", \"shape\": 1}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 604, \"1\": 161}, \"size\": {\"0\": 202.94503784179688, \"1\": 46}, \"flags\": {\"pinned\": true}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 39, \"slot_index\": 0, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 40, \"slot_index\": 1, \"label\": \"\\u6761\\u4ef6\"}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [30], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u5f15\\u5bfc\"}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 386, \"1\": 55}, \"size\": {\"0\": 422.5250549316406, \"1\": 59.05733871459961}, \"flags\": {\"pinned\": true}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12], \"slot_index\": 0, \"shape\": 3, \"label\": \"VAE\"}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": {\"0\": 836, \"1\": 51}, \"size\": {\"0\": 856.820068359375, \"1\": 895.4721069335938}, \"flags\": {\"pinned\": true}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 9, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\", \"shape\": 1}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 388, \"1\": 263}, \"size\": {\"0\": 422.84503173828125, \"1\": 164.31304931640625}, \"flags\": {\"pinned\": true}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 10, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [40], \"slot_index\": 0, \"label\": \"\\u6761\\u4ef6\"}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"An endless desert with strange lights flashing in the sky and broken code and flickering data fragments on the ground, as if the whole world is on the verge of collapse.\"], \"color\": \"#232\", \"bgcolor\": \"#353\", \"shape\": 1}], \"links\": [[9, 8, 0, 9, 0, \"IMAGE\"], [10, 11, 0, 6, 0, \"CLIP\"], [12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [23, 5, 0, 13, 4, \"LATENT\"], [24, 13, 0, 8, 0, \"LATENT\"], [30, 22, 0, 13, 1, \"GUIDER\"], [37, 25, 0, 13, 0, \"NOISE\"], [38, 12, 0, 17, 0, \"MODEL\"], [39, 12, 0, 22, 0, \"MODEL\"], [40, 6, 0, 22, 1, \"CONDITIONING\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.6830134553650705, \"offset\": [429.31702744735054, 33.1537900664593]}, \"workspace_info\": {\"id\": \"L7ZoSc9K2Yo3rxKB0iBYv\", \"saveLock\": false, \"cloudID\": null, \"coverMediaPath\": null}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}}, \"seed_widgets\": {\"25\": 0}}}",
                "steps": 50,
                "width": 768,
                "height": 1024,
                "models": [],
                "prompt": "An endless desert with strange lights flashing in the sky and broken code and flickering data fragments on the ground, as if the whole world is on the verge of collapse.",
                "denoise": 1,
                "sampler": "Euler",
                "modelIds": [],
                "scheduler": "simple",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": []
            },
            "username": "HS_hi",
            "baseModel": ""
        },
        {
            "id": 31476275,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b18398d7-451b-4d20-9f4e-82ae114c4677/width=896/b18398d7-451b-4d20-9f4e-82ae114c4677.jpeg",
            "hash": "U397U@WU4Tso%hWV00jF~pt7-:V@9GaejIf+",
            "width": 896,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-26T18:30:02.154Z",
            "postId": 7036134,
            "stats": {
                "cryCount": 0,
                "laughCount": 18,
                "likeCount": 298,
                "dislikeCount": 0,
                "heartCount": 67,
                "commentCount": 1
            },
            "meta": {
                "Size": "896x1152",
                "seed": 0,
                "Model": "flux_dev",
                "steps": 20,
                "hashes": {
                    "model": "",
                    "LORA:Mechanical body": "c8ca6a0ec6",
                    "LORA:Ethereal_EasternV2": "b22828a7aa"
                },
                "prompt": "A cyborg Chinese heroine stands before a ancient structure adorned with traditional Chinese machinery. Her mechanical arms have replaced her original limbs, with metallic skin hidden beneath her traditional martial arts attire. A portion of her face is scarred, revealing mechanical components underneath. The overall style is cold and modern yet blended with Chinese elements. Watercolor ink wash technique is used to create a moody atmosphere, incorporating cyberpunk elements. Darker tones dominate the color palette.,,cyborg woman, Chinese heritage, martial arts attire, metallic skin, scarred face, mechanical arms, traditional machinery, ancient structure, cold modern style, cyberpunk elements, watercolor ink wash, moody atmosphere, darker tones,,<lora:Mechanical body:0.6>,<lora:Ethereal_EasternV2:0.6>",
                "Version": "ComfyUI",
                "sampler": "Euler",
                "cfgScale": 1,
                "resources": [
                    {
                        "name": "Ethereal_EasternV2",
                        "type": "lora",
                        "weight": 0.6
                    }
                ],
                "Model hash": "",
                "negativePrompt": "unknown"
            },
            "username": "3years_go_Mars",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 30824976,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f4dba093-4686-43ec-858e-0abfd7476e19/width=832/f4dba093-4686-43ec-858e-0abfd7476e19.jpeg",
            "hash": "UFDlB1[T]N%2?^oH$dxV-=$yZ}k7OWkpRNW9",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-22T22:33:31.663Z",
            "postId": 6893504,
            "stats": {
                "cryCount": 6,
                "laughCount": 57,
                "likeCount": 241,
                "dislikeCount": 0,
                "heartCount": 79,
                "commentCount": 1
            },
            "meta": null,
            "username": "DirtyDetective",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 30372077,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1afa4021-847f-4d14-aa22-968a2562a8db/width=1664/1afa4021-847f-4d14-aa22-968a2562a8db.jpeg",
            "hash": "UBBW[4D*4T?atQtSDjZ~4TM{kXxZMxaJ_Ntm",
            "width": 1664,
            "height": 2432,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-20T06:17:42.570Z",
            "postId": 6795414,
            "stats": {
                "cryCount": 9,
                "laughCount": 21,
                "likeCount": 249,
                "dislikeCount": 0,
                "heartCount": 104,
                "commentCount": 1
            },
            "meta": {
                "seed": 743481148053468,
                "vaes": [
                    "ae.sft"
                ],
                "comfy": "{\"prompt\": {\"4\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp16.safetensors\", \"clip_name2\": \"ViT-L-14-TEXT-detail-improved-hiT-GmP-HF.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"7\": {\"inputs\": {\"styles\": \"Photography | Cinematic\"}, \"class_type\": \"Load Styles CSV\"}, \"8\": {\"inputs\": {\"width\": [\"9\", 0], \"height\": [\"9\", 1], \"batch_size\": 4}, \"class_type\": \"EmptyLatentImage\"}, \"9\": {\"inputs\": {\"resolution\": \"portrait - 832x1216 (2:3)\"}, \"class_type\": \"SDXL Resolutions (JPS)\"}, \"11\": {\"inputs\": {\"vae_name\": \"ae.sft\"}, \"class_type\": \"VAELoader\"}, \"26\": {\"inputs\": {\"prompt1\": [\"131\", 0], \"prompt2\": \"\", \"separator\": \",\"}, \"class_type\": \"easy promptConcat\"}, \"29\": {\"inputs\": {\"samples\": [\"89\", 0], \"vae\": [\"11\", 0]}, \"class_type\": \"VAEDecode\"}, \"32\": {\"inputs\": {\"styles\": \"fooocus_styles\", \"positive\": [\"7\", 0], \"select_styles\": \"sai-digital art,mre-gloomy-art,futuristic-retro futurism,mre-bad-dream\"}, \"class_type\": \"easy stylesSelector\"}, \"51\": {\"inputs\": {\"mode\": \"always\", \"volume\": 0.5, \"file\": \"notify.mp3\", \"any\": [\"89\", 0]}, \"class_type\": \"PlaySound|pysssss\", \"is_changed\": NaN}, \"52\": {\"inputs\": {\"text\": \"Frank Frazetta fantasy oil painting,\", \"generation\": \"off\", \"seed\": 882791830129566, \"speak_and_recognation\": true}, \"class_type\": \"ChinesePrompt_Mix\"}, \"53\": {\"inputs\": {\"text\": \"Frank Frazetta fantasy oil painting,a digital artwork depicting a surreal, sci-fi scene inside a subway train, the setting is dimly lit, with a starry night sky visible through the large window in the background, the interior of the train car is predominantly white with orange seats and metal poles, and the floor is covered in a dark, textured carpet, in the foreground, a humanoid figure wearing a white spacesuit with a full-body suit and a helmet, sitting on a bench in the center of the image, to the left, a blue-skinned creature with a reptilian-like appearance sits on a red bench, facing the viewer, and to the right, an alien figure with a bald head and green skin sits on the bench, reading a book titled How to Talk to Astronomers, the alien figure has a tattoo on its back and appears to be in a state of contemplation, the creature's expression is one of deep thought or contemplation, with its hands clasped together in front of its lap, the overall mood of the artwork is eerie and surreal, with the textures of the metallic surfaces and the softness of the seats rendered in a realistic, almost photorealistic style, the artwork uses a blend of realism and fantasy elements to create a sense of depth and mystery, blending elements of surrealism and space exploration, the textures are meticulously rendered, enhancing the surreal and dreamlike quality of the scene\\n\\n \\\\(creature\\\\), 1girl, breasts, short hair, blue hair, sitting, closed mouth, full body, boots, artist name, indoors, 3boys, book, from side, covered navel, alien, space, star \\\\(sky\\\\), realistic, space theme,,concept art Cinematic photography, movie mood, cinematic light, compelling composition, storytelling elements, conveys emotion, mood, and narrative depth, creating visually striking images that feel like still frames from a film . digital artwork, illustrative, painterly, matte painting, highly detailed, astonishing gloomy art made mainly of shadows and lighting, forming . masterful usage of lighting, shadows and chiaroscuro. made by black-hearted artist, drawing from darkness. best quality, high resolution, retro-futuristic  . vintage sci-fi, 50s and 60s style, atomic age, vibrant, highly detailed, picture from really bad dream about terrifying , true horror. bone-chilling vision. mad world that shouldn't exist. best quality, high resolution\", \"anything\": [\"144\", 0]}, \"class_type\": \"easy showAnything\"}, \"89\": {\"inputs\": {\"add_noise\": \"enable\", \"noise_seed\": 743481148053468, \"steps\": 35, \"cfg\": 1.0, \"sampler_name\": \"dpm_adaptive\", \"scheduler\": \"sgm_uniform\", \"start_at_step\": 0, \"end_at_step\": 10000, \"return_with_leftover_noise\": \"disable\", \"model\": [\"181\", 0], \"positive\": [\"191\", 0], \"negative\": [\"191\", 1], \"latent_image\": [\"8\", 0]}, \"class_type\": \"KSamplerAdvanced\"}, \"101\": {\"inputs\": {\"upscale_by\": 2.0, \"seed\": 611744680965474, \"steps\": 10, \"cfg\": 1.0, \"sampler_name\": \"dpm_adaptive\", \"scheduler\": \"sgm_uniform\", \"denoise\": 0.2, \"mode_type\": \"Linear\", \"tile_width\": 1024, \"tile_height\": 1024, \"mask_blur\": 8, \"tile_padding\": 32, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 8, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"119\", 0], \"model\": [\"147\", 0], \"positive\": [\"191\", 0], \"negative\": [\"191\", 1], \"vae\": [\"11\", 0], \"upscale_model\": [\"103\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"103\": {\"inputs\": {\"model_name\": \"4x_foolhardy_Remacri.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"115\": {\"inputs\": {\"filename_prefix\": \"2024-09-20/_\", \"images\": [\"175\", 0]}, \"class_type\": \"SaveImage\"}, \"119\": {\"inputs\": {\"mode\": \"Always Pause\", \"images\": [\"29\", 0]}, \"class_type\": \"easy imageChooser\", \"is_changed\": NaN}, \"125\": {\"inputs\": {\"image\": \"47c2604cf9d0a7d04fa013dc19a3c750.jpg\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"ae23d47d18c365179d240af558338387d4fb25e06c191e79d82d4d8b8fdf31c8\"]}, \"127\": {\"inputs\": {\"text\": \"a digital artwork depicting a surreal, sci-fi scene inside a subway train, the setting is dimly lit, with a starry night sky visible through the large window in the background, the interior of the train car is predominantly white with orange seats and metal poles, and the floor is covered in a dark, textured carpet, in the foreground, a humanoid figure wearing a white spacesuit with a full-body suit and a helmet, sitting on a bench in the center of the image, to the left, a blue-skinned creature with a reptilian-like appearance sits on a red bench, facing the viewer, and to the right, an alien figure with a bald head and green skin sits on the bench, reading a book titled How to Talk to Astronomers, the alien figure has a tattoo on its back and appears to be in a state of contemplation, the creature's expression is one of deep thought or contemplation, with its hands clasped together in front of its lap, the overall mood of the artwork is eerie and surreal, with the textures of the metallic surfaces and the softness of the seats rendered in a realistic, almost photorealistic style, the artwork uses a blend of realism and fantasy elements to create a sense of depth and mystery, blending elements of surrealism and space exploration, the textures are meticulously rendered, enhancing the surreal and dreamlike quality of the scene\\n\\n \\\\(creature\\\\), 1girl, breasts, short hair, blue hair, sitting, closed mouth, full body, boots, artist name, indoors, 3boys, book, from side, covered navel, alien, space, star \\\\(sky\\\\), realistic, space theme\", \"anything\": [\"189\", 2]}, \"class_type\": \"easy showAnything\"}, \"131\": {\"inputs\": {\"prompt1\": [\"52\", 0], \"prompt2\": [\"189\", 2], \"separator\": \",\"}, \"class_type\": \"easy promptConcat\"}, \"140\": {\"inputs\": {\"unet_name\": \"flux1-dev.sft\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"144\": {\"inputs\": {\"prompt1\": [\"26\", 0], \"prompt2\": [\"32\", 0], \"separator\": \",\"}, \"class_type\": \"easy promptConcat\"}, \"147\": {\"inputs\": {\"lora_name\": \"flux\\\\Hyper-FLUX.1-dev-8steps-lora.safetensors\", \"strength_model\": 0.13, \"model\": [\"181\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"152\": {\"inputs\": {\"rgthree_comparer\": {\"images\": [{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_gndtk_00027_.png&type=temp&subfolder=&rand=0.9008712718621289\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_gndtk_00028_.png&type=temp&subfolder=&rand=0.6622177033332636\"}]}, \"image_a\": [\"176\", 0], \"image_b\": [\"175\", 0]}, \"class_type\": \"Image Comparer (rgthree)\"}, \"163\": {\"inputs\": {\"strength\": 0.4, \"start_percent\": 0.0, \"end_percent\": 0.4, \"positive\": [\"191\", 0], \"negative\": [\"191\", 1], \"control_net\": [\"165\", 0], \"vae\": [\"11\", 0], \"image\": [\"101\", 0]}, \"class_type\": \"ControlNetApplySD3\"}, \"165\": {\"inputs\": {\"type\": \"tile\", \"control_net\": [\"166\", 0]}, \"class_type\": \"SetUnionControlNetType\"}, \"166\": {\"inputs\": {\"control_net_name\": \"flux\\\\FLUX.1-dev-ControlNet-Union-Pro.safetensors\"}, \"class_type\": \"ControlNetLoader\"}, \"170\": {\"inputs\": {\"images\": [\"175\", 0]}, \"class_type\": \"PreviewImage\"}, \"175\": {\"inputs\": {\"upscale_by\": 1.0, \"seed\": 248839888580556, \"steps\": 8, \"cfg\": 1.0, \"sampler_name\": \"ddim\", \"scheduler\": \"sgm_uniform\", \"denoise\": 0.5, \"mode_type\": \"Linear\", \"tile_width\": 1024, \"tile_height\": 1024, \"mask_blur\": 8, \"tile_padding\": 32, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 8, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"176\", 0], \"model\": [\"147\", 0], \"positive\": [\"163\", 0], \"negative\": [\"163\", 1], \"vae\": [\"11\", 0], \"upscale_model\": [\"103\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"176\": {\"inputs\": {\"mode\": \"Always Pause\", \"images\": [\"101\", 0]}, \"class_type\": \"easy imageChooser\", \"is_changed\": NaN}, \"177\": {\"inputs\": {\"q\": 1.2, \"k\": 1.1, \"v\": 0.8, \"out\": 1.25, \"clip\": [\"4\", 0]}, \"class_type\": \"CLIPAttentionMultiply\"}, \"178\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5, \"width\": [\"9\", 0], \"height\": [\"9\", 1], \"model\": [\"140\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"181\": {\"inputs\": {\"lora_name\": \"flux\\\\aidmaMJ6.1-FLUX-V0.2.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"182\", 0], \"clip\": [\"182\", 1]}, \"class_type\": \"LoraLoader\"}, \"182\": {\"inputs\": {\"lora_name\": \"flux\\\\frazetta_flux_v2-000150.safetensors\", \"strength_model\": 0.8, \"strength_clip\": 1.0, \"model\": [\"183\", 0], \"clip\": [\"183\", 1]}, \"class_type\": \"LoraLoader\"}, \"183\": {\"inputs\": {\"lora_name\": \"flux\\\\FluxDFaeTasticDetails.safetensors\", \"strength_model\": 0.3, \"strength_clip\": 1.0, \"model\": [\"184\", 0], \"clip\": [\"184\", 1]}, \"class_type\": \"LoraLoader\"}, \"184\": {\"inputs\": {\"lora_name\": \"flux\\\\Dever_Flux_Enhancer.safetensors\", \"strength_model\": 0.4, \"strength_clip\": 1.0, \"model\": [\"178\", 0], \"clip\": [\"177\", 0]}, \"class_type\": \"LoraLoader\"}, \"189\": {\"inputs\": {\"model\": \"promptgen_large_v1.5\", \"folder_path\": \"Path to your image folder\", \"caption_method\": \"mixed\", \"max_new_tokens\": 1024, \"num_beams\": 4, \"random_prompt\": \"never\", \"prefix_caption\": \"\", \"suffix_caption\": \"\", \"replace_tags\": \"replace_tags eg:search1:replace1;search2:replace2\", \"speak_and_recognation\": true, \"images\": [\"125\", 0]}, \"class_type\": \"Miaoshouai_Tagger\", \"is_changed\": [\"\"]}, \"191\": {\"inputs\": {\"caption\": [\"144\", 0], \"guidance\": 3.5, \"clip\": [\"181\", 1]}, \"class_type\": \"Miaoshouai_Flux_CLIPTextEncode\"}}, \"workflow\": {\"last_node_id\": 192, \"last_link_id\": 370, \"nodes\": [{\"id\": 68, \"type\": \"PreviewImage\", \"pos\": {\"0\": 2380, \"1\": 1250}, \"size\": {\"0\": 350, \"1\": 360}, \"flags\": {}, \"order\": 30, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 107, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 66, \"type\": \"AIO_Preprocessor\", \"pos\": {\"0\": 1970, \"1\": 1790}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 26, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 210, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [100, 107], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"AIO_Preprocessor\"}, \"widgets_values\": [\"DepthAnythingV2Preprocessor\", 1024]}, {\"id\": 122, \"type\": \"ControlNetLoader\", \"pos\": {\"0\": 1970, \"1\": 1650}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 0, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [208], \"shape\": 3, \"label\": \"ControlNet\"}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"flux\\\\FLUX.1-dev-ControlNet-Union-Pro.safetensors\"]}, {\"id\": 121, \"type\": \"SetUnionControlNetType\", \"pos\": {\"0\": 1970, \"1\": 1510}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 16, \"mode\": 4, \"inputs\": [{\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 208, \"label\": \"ControlNet\"}], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [207], \"shape\": 3, \"label\": \"ControlNet\"}], \"properties\": {\"Node name for S&R\": \"SetUnionControlNetType\"}, \"widgets_values\": [\"depth\"]}, {\"id\": 67, \"type\": \"LoadImage\", \"pos\": {\"0\": 1560, \"1\": 1250}, \"size\": [320, 310], \"flags\": {}, \"order\": 1, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [209], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3, \"label\": \"\\u906e\\u7f69\"}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"jaxiewickd3980_Tokusatsu_main_visual_poster_featuring_an_Asian__3d7801cc-147b-4d9f-87d4-8e359322148e.png\", \"image\"]}, {\"id\": 123, \"type\": \"ImageScale\", \"pos\": {\"0\": 1560, \"1\": 1630}, \"size\": {\"0\": 320, \"1\": 130}, \"flags\": {}, \"order\": 22, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 209, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 211, \"widget\": {\"name\": \"width\"}, \"label\": \"\\u5bbd\\u5ea6\"}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 212, \"widget\": {\"name\": \"height\"}, \"label\": \"\\u9ad8\\u5ea6\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [210], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"nearest-exact\", 512, 512, \"center\"]}, {\"id\": 29, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1680, \"1\": 740}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 156, \"label\": \"Latent\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 39, \"label\": \"VAE\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [204], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 8, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 1030, \"1\": 350}, \"size\": {\"0\": 340, \"1\": 80}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 77, \"widget\": {\"name\": \"width\"}, \"label\": \"\\u5bbd\\u5ea6\"}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 8, \"widget\": {\"name\": \"height\"}, \"label\": \"\\u9ad8\\u5ea6\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [155], \"slot_index\": 0, \"shape\": 3, \"label\": \"Latent\"}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [512, 512, 4], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 64, \"type\": \"ControlNetApplySD3\", \"pos\": {\"0\": 1970, \"1\": 1250}, \"size\": {\"0\": 320, \"1\": 190}, \"flags\": {}, \"order\": 40, \"mode\": 4, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 364, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 365, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 207, \"label\": \"ControlNet\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 99, \"label\": \"VAE\"}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 100, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [237, 252, 293, 312], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [192, 249, 294, 313], \"slot_index\": 1, \"shape\": 3, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}], \"properties\": {\"Node name for S&R\": \"ControlNetApplySD3\"}, \"widgets_values\": [0.3, 0, 0.6]}, {\"id\": 106, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2870, \"1\": 2220}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 2, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [186], \"slot_index\": 0, \"shape\": 3, \"label\": \"BBox\\u68c0\\u6d4b\"}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [193], \"slot_index\": 1, \"shape\": 3, \"label\": \"SEGM\\u68c0\\u6d4b\"}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 111, \"type\": \"SAMLoader\", \"pos\": {\"0\": 2870, \"1\": 2370}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 3, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [197], \"slot_index\": 0, \"shape\": 3, \"label\": \"SAM\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_h_4b8939.pth\", \"AUTO\"]}, {\"id\": 107, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 3230, \"1\": 2220}, \"size\": {\"0\": 370, \"1\": 1130}, \"flags\": {\"collapsed\": false}, \"order\": 46, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 187, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 351, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 348, \"label\": \"CLIP\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 190, \"label\": \"VAE\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 252, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 192, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 186, \"label\": \"BBox\\u68c0\\u6d4b\"}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 197, \"label\": \"SAM\\u6a21\\u578b\"}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 193, \"label\": \"Segm\\u68c0\\u6d4b\"}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null, \"label\": \"\\u7ec6\\u5316\\u7ea6\\u675f\"}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null, \"label\": \"scheduler_func_opt\"}, {\"name\": \"seed\", \"type\": \"INT\", \"link\": null, \"widget\": {\"name\": \"seed\"}, \"label\": \"\\u968f\\u673a\\u79cd\"}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [198], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6, \"label\": \"\\u7ec6\\u5316\\u56fe\\u50cf\"}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6, \"label\": \"\\u7ec6\\u5316\\u90e8\\u5206\"}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3, \"label\": \"\\u906e\\u7f69\"}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"slot_index\": 4, \"shape\": 3, \"label\": \"\\u7ec6\\u5316\\u8282\\u70b9\\u675f\"}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6, \"label\": \"ControlNet\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [256, true, 768, 955604052976792, \"fixed\", 4, 1.5, \"euler\", \"simple\", 0.2, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 0, true]}, {\"id\": 112, \"type\": \"PreviewImage\", \"pos\": {\"0\": 3650, \"1\": 2220}, \"size\": {\"0\": 840, \"1\": 690}, \"flags\": {}, \"order\": 49, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 198, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 147, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": 2870, \"1\": 150}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 350, \"label\": \"\\u6a21\\u578b\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [265, 323], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"flux\\\\Hyper-FLUX.1-dev-8steps-lora.safetensors\", 0.13], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 11, \"type\": \"VAELoader\", \"pos\": {\"0\": 610, \"1\": -510}, \"size\": {\"0\": 340, \"1\": 60}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [39, 99, 182, 190, 311, 329], \"slot_index\": 0, \"shape\": 3, \"label\": \"VAE\"}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.sft\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 115, \"type\": \"SaveImage\", \"pos\": {\"0\": 3800, \"1\": 2110}, \"size\": {\"0\": 320, \"1\": 270}, \"flags\": {\"collapsed\": true}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 332, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"%date:yyyy-MM-dd%/_\"]}, {\"id\": 177, \"type\": \"CLIPAttentionMultiply\", \"pos\": {\"0\": 100, \"1\": -580}, \"size\": {\"0\": 340, \"1\": 130}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 333, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [334], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"CLIPAttentionMultiply\"}, \"widgets_values\": [1.2, 1.1, 0.8, 1.25]}, {\"id\": 140, \"type\": \"UNETLoader\", \"pos\": {\"0\": 610, \"1\": -650}, \"size\": {\"0\": 340, \"1\": 80}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [335], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev.sft\", \"fp8_e4m3fn\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 178, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 610, \"1\": -380}, \"size\": {\"0\": 340, \"1\": 130}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 335, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 337, \"widget\": {\"name\": \"width\"}, \"label\": \"\\u5bbd\\u5ea6\"}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 338, \"widget\": {\"name\": \"height\"}, \"label\": \"\\u9ad8\\u5ea6\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [345], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 1024, 1024]}, {\"id\": 103, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2870, \"1\": 300}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [180, 322], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u653e\\u5927\\u6a21\\u578b\"}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3, \"label\": \"\\u6a21\\u578b\\u540d\\u79f0\\u6587\\u672c\"}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_foolhardy_Remacri.pth\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 165, \"type\": \"SetUnionControlNetType\", \"pos\": {\"0\": 2870, \"1\": 1440}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 310, \"label\": \"ControlNet\"}], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [309], \"slot_index\": 0, \"shape\": 3, \"label\": \"ControlNet\"}], \"properties\": {\"Node name for S&R\": \"SetUnionControlNetType\"}, \"widgets_values\": [\"tile\"]}, {\"id\": 166, \"type\": \"ControlNetLoader\", \"pos\": {\"0\": 2870, \"1\": 1560}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [310], \"slot_index\": 0, \"shape\": 3, \"label\": \"ControlNet\"}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"flux\\\\FLUX.1-dev-ControlNet-Union-Pro.safetensors\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 101, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 3250, \"1\": 150}, \"size\": {\"0\": 320, \"1\": 830}, \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 278, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 265, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 312, \"slot_index\": 2, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 313, \"slot_index\": 3, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 182, \"label\": \"VAE\"}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 180, \"slot_index\": 5, \"label\": \"\\u653e\\u5927\\u6a21\\u578b\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [187, 314, 324], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 611744680965474, \"randomize\", 10, 1, \"dpm_adaptive\", \"sgm_uniform\", 0.2, \"Linear\", 1024, 1024, 8, 32, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 34, \"type\": \"OllamaGenerateAdvance\", \"pos\": {\"0\": -190, \"1\": 1340}, \"size\": {\"0\": 430, \"1\": 530}, \"flags\": {}, \"order\": 8, \"mode\": 4, \"inputs\": [{\"name\": \"context\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"context\"}, \"label\": \"context\"}], \"outputs\": [{\"name\": \"response\", \"type\": \"STRING\", \"links\": [46], \"slot_index\": 0, \"shape\": 3, \"label\": \"response\"}, {\"name\": \"context\", \"type\": \"STRING\", \"links\": null, \"shape\": 3, \"label\": \"context\"}], \"properties\": {\"Node name for S&R\": \"OllamaGenerateAdvance\"}, \"widgets_values\": [\"\\u7528\\u82f1\\u8bed\\u620f\\u5267\\u4ee5\\u6700\\u540e\\u7684\\u665a\\u9910\\u7ecf\\u5178\\u6784\\u56fe\\u6765\\u63cf\\u7ed8\\u4e00\\u4e2a\\u8d5b\\u535a\\u670b\\u514b\\u98ce\\u683c\\u7684\\u573a\\u666f\\uff0c\\u4eba\\u7269\\u548c\\u80cc\\u666f\\u89c6\\u89c9\\u9700\\u8981\\u65f6\\u8d5b\\u535a\\u670b\\u514b\\u98ce\\u683c\\uff0c\\u6784\\u56fe\\u662f\\u6700\\u540e\\u7684\\u665a\\u9910\\u7684\\u6784\\u56fe\", false, \"http://127.0.0.1:11434\", \"llama3.1:latest\", \"You are creating a prompt for Stable Diffusion to generate an image. understand the input and generate a text prompt for the input,only respond in English,Just give me the final result without any prefix or suffix\\uff0cNo need to say something like \\\"Here is the generated text prompt:\\\"\\uff0c keep it above 200 tokens.\", 2099367442, \"randomize\", 50, 0.9500000000000001, 0.7000000000000001, -1, 1, 5, false, \"\", true, true]}, {\"id\": 53, \"type\": \"easy showAnything\", \"pos\": {\"0\": 820, \"1\": 1300}, \"size\": {\"0\": 640, \"1\": 590}, \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 245, \"label\": \"\\u8f93\\u5165\\u4efb\\u4f55\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [[\"Frank Frazetta fantasy oil painting,a digital illustration depicting a bustling train station in a fantastical, gothic style, the scene is dominated by a large, ornate clock face hanging from the ceiling, surrounded by intricate, glass-paneled ceilings and ornate, mechanical elements, the clock face is prominently displayed, with roman numerals and a prominent hourglass symbol, and is surrounded by a cloud of steam, indicating a sense of movement and urgency, in the foreground, a steam-powered, black steam locomotive is pulling a passenger train, with numerous passengers, some of whom are dressed in formal attire, including suits and ties, the train's headlights are turned on, casting a warm, golden glow, the platform is bustling with people of various ages and genders, some standing and some walking, adding to the bustling atmosphere, the background features large, arched windows that allow natural light to filter through, illuminating the space and casting a soft glow on the scene, the overall color palette is rich and muted, with shades of blue, green, and gold, enhancing the sense of grandeur and mystery, the illustration is highly detailed, with a focus on intricate textures and lighting effects, giving it a realistic yet fantastical quality, the style is reminiscent of high-end digital art, blending elements of fantasy and realism\\r\\n\\r\\n \\\\(creature\\\\), 1girl, long hair, multiple girls, hat, long sleeves, standing, male focus, outdoors, multiple boys, sky, day, cloud, bag, blurry, artist name, indoors, from side, window, blurry background, train, scenery, clock, train station, steam, scenery around the world, clock face,,concept art Cinematic photography, movie mood, cinematic light, compelling composition, storytelling elements, conveys emotion, mood, and narrative depth, creating visually striking images that feel like still frames from a film . digital artwork, illustrative, painterly, matte painting, highly detailed, astonishing gloomy art made mainly of shadows and lighting, forming . masterful usage of lighting, shadows and chiaroscuro. made by black-hearted artist, drawing from darkness. best quality, high resolution, retro-futuristic  . vintage sci-fi, 50s and 60s style, atomic age, vibrant, highly detailed, picture from really bad dream about terrifying , true horror. bone-chilling vision. mad world that shouldn't exist. best quality, high resolution\"]]}, {\"id\": 7, \"type\": \"Load Styles CSV\", \"pos\": {\"0\": 240, \"1\": 100}, \"size\": {\"0\": 430, \"1\": 80}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"positive prompt\", \"type\": \"STRING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3, \"label\": \"positive prompt\"}, {\"name\": \"negative prompt\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 1, \"shape\": 3, \"label\": \"negative prompt\"}], \"properties\": {\"Node name for S&R\": \"Load Styles CSV\"}, \"widgets_values\": [\"Photography | Cinematic\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 99, \"type\": \"LongCLIPTextEncodeFlux\", \"pos\": {\"0\": 100, \"1\": -370}, \"size\": {\"0\": 340, \"1\": 60}, \"flags\": {}, \"order\": 25, \"mode\": 4, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 334, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [346], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"LongCLIPTextEncodeFlux\"}, \"widgets_values\": [\"longclip-L.pt\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 181, \"type\": \"LoraLoader\", \"pos\": {\"0\": 1030, \"1\": -770}, \"size\": {\"0\": 380, \"1\": 130}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 341, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 344, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [349, 350, 351], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [348, 353], \"slot_index\": 1, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux\\\\aidmaMJ6.1-FLUX-V0.2.safetensors\", 1, 1], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 33, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": 270, \"1\": 1340}, \"size\": {\"0\": 450, \"1\": 350}, \"flags\": {}, \"order\": 18, \"mode\": 4, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 46, \"widget\": {\"name\": \"text\"}, \"label\": \"\\u6587\\u672c\"}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [236], \"slot_index\": 0, \"shape\": 6, \"label\": \"\\u5b57\\u7b26\\u4e32\"}], \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [\"\", \"In a dimly lit, smoke-filled cyberpunk cantina, a group of shady hackers and tech-savvy outlaws gathered around a table for what seemed like the ultimate last supper. The air was thick with tension as they surrounded a steaming plate of synthetically-grown \\\"meat\\\" pies, their eyes fixed on the figure at the head of the table.\\n\\nLeonardo, a brilliant but reclusive hacker, sat with his back to the wall, his piercing green eyes gleaming in the soft light. He wore a black leather jacket adorned with intricate circuit boards and wires, giving him an air of mystery and menace. His long, dark hair was slicked back, revealing a sharp jawline and prominent cheekbones.\\n\\nTo Leonardo's right sat Michelangelo, a burly, imposing figure with a thick beard and a menacing scowl. He was the cantina's enforcer, feared by all who knew him. His massive frame was clad in a black duster coat, and his eyes seemed to bore into the souls of those around him.\\n\\nNext to Michelangelo sat Raphael, a smooth-talking con artist with a quick wit and an even quicker tongue. He wore a flashy silver suit, complete with a diamond-encrusted watch, and had a charming smile that could charm the birds from the trees.\\n\\nFinally, there was Donatello, the group's resident tech expert and Leonardo's closest friend. He sat at the end of the table, his eyes fixed on the holographic display projected in front of him. His wild hair was tied back in a ponytail, revealing a pair of thick-rimmed glasses perched on the end of his nose.\\n\\nAs they dug into their meal, the conversation turned to the topic of the latest hacking exploit: a high-stakes heist that had just gone down at the city's central bank. The group was abuzz with excitement and speculation, each member vying for attention and trying to one-up the others with tales of daring-do.\\n\\nLeonardo listened intently, his eyes never leaving the face of the person speaking. He was a master of manipulation, able to read people like a book and use that knowledge to his advantage. As he sat there, surrounded by his crew, he felt a sense of satisfaction wash over him. This was what it meant to be part of something bigger than himself \\u2013 a family, a team, a machine.\\n\\nAnd yet, as the night wore on and the conversation turned to more serious matters, Leonardo's expression grew increasingly dark. He knew that their world was not without its dangers, and that they were all just one misstep away from being caught in the crosshairs of the authorities. The thought sent a shiver down his spine, but he pushed it aside, focusing instead on the task at hand: protecting his team and pulling off the heist of a lifetime.\\n\\nAs the meal drew to a close and the group began to disperse, Leonardo's eyes locked onto Donatello's, a silent understanding passing between them. It was time to get back to work, to start planning and preparing for the biggest challenge they had ever faced. The game was on, and only one team could emerge victorious.\"]}, {\"id\": 189, \"type\": \"Miaoshouai_Tagger\", \"pos\": {\"0\": -1080, \"1\": 1340}, \"size\": {\"0\": 400, \"1\": 420}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 355, \"label\": \"images\"}, {\"name\": \"filenames\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"filenames\"}, \"label\": \"filenames\"}, {\"name\": \"captions\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"captions\"}, \"label\": \"captions\"}], \"outputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6, \"label\": \"images\"}, {\"name\": \"filenames\", \"type\": \"STRING\", \"links\": null, \"shape\": 6, \"label\": \"filenames\"}, {\"name\": \"captions\", \"type\": \"STRING\", \"links\": [357, 369], \"slot_index\": 2, \"shape\": 6, \"label\": \"captions\"}, {\"name\": \"folder_path\", \"type\": \"STRING\", \"links\": null, \"slot_index\": 3, \"shape\": 3, \"label\": \"folder_path\"}, {\"name\": \"batch_size\", \"type\": \"INT\", \"links\": null, \"shape\": 3, \"label\": \"batch_size\"}], \"properties\": {\"Node name for S&R\": \"Miaoshouai_Tagger\"}, \"widgets_values\": [\"promptgen_large_v1.5\", \"Path to your image folder\", \"mixed\", 1024, 4, \"never\", \"\", \"\", \"\", \"\", \"replace_tags eg:search1:replace1;search2:replace2\", true, true, true]}, {\"id\": 26, \"type\": \"easy promptConcat\", \"pos\": {\"0\": 380, \"1\": 980}, \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"prompt1\", \"type\": \"STRING\", \"link\": 220, \"widget\": {\"name\": \"prompt1\"}, \"label\": \"\\u63d0\\u793a\\u8bcd1\"}, {\"name\": \"prompt2\", \"type\": \"STRING\", \"link\": 236, \"widget\": {\"name\": \"prompt2\"}, \"label\": \"\\u63d0\\u793a\\u8bcd2\"}], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [368], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u63d0\\u793a\\u8bcd\"}], \"properties\": {\"Node name for S&R\": \"easy promptConcat\"}, \"widgets_values\": [\"\", \"\", \",\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 144, \"type\": \"easy promptConcat\", \"pos\": {\"0\": 550, \"1\": 980}, \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"prompt1\", \"type\": \"STRING\", \"link\": 368, \"widget\": {\"name\": \"prompt1\"}, \"label\": \"\\u63d0\\u793a\\u8bcd1\"}, {\"name\": \"prompt2\", \"type\": \"STRING\", \"link\": 367, \"widget\": {\"name\": \"prompt2\"}, \"label\": \"\\u63d0\\u793a\\u8bcd2\"}], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [245, 366], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u63d0\\u793a\\u8bcd\"}], \"properties\": {\"Node name for S&R\": \"easy promptConcat\"}, \"widgets_values\": [\"\", \"\", \",\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 191, \"type\": \"Miaoshouai_Flux_CLIPTextEncode\", \"pos\": {\"0\": 1030, \"1\": 100}, \"size\": {\"0\": 340, \"1\": 140}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 359, \"label\": \"clip\"}, {\"name\": \"caption\", \"type\": \"STRING\", \"link\": 366, \"widget\": {\"name\": \"caption\"}, \"label\": \"caption\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [364], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}, {\"name\": \"EMPTY CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [365], \"slot_index\": 1, \"shape\": 3, \"label\": \"EMPTY CONDITIONING\"}, {\"name\": \"t5xxl\", \"type\": \"STRING\", \"links\": null, \"shape\": 3, \"label\": \"t5xxl\"}, {\"name\": \"clip_l\", \"type\": \"STRING\", \"links\": null, \"shape\": 3, \"label\": \"clip_l\"}], \"properties\": {\"Node name for S&R\": \"Miaoshouai_Flux_CLIPTextEncode\"}, \"widgets_values\": [\"\", 3.5]}, {\"id\": 89, \"type\": \"KSamplerAdvanced\", \"pos\": {\"0\": 1470, \"1\": 100}, \"size\": {\"0\": 320, \"1\": 550}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 349, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 237, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 249, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 155, \"label\": \"Latent\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [156, 158], \"slot_index\": 0, \"shape\": 3, \"label\": \"Latent\"}], \"properties\": {\"Node name for S&R\": \"KSamplerAdvanced\"}, \"widgets_values\": [\"enable\", 743481148053468, \"randomize\", 35, 1, \"dpm_adaptive\", \"sgm_uniform\", 0, 10000, \"disable\"]}, {\"id\": 3, \"type\": \"UnetLoaderGGUF\", \"pos\": {\"0\": 610, \"1\": -770}, \"size\": {\"0\": 340, \"1\": 60}, \"flags\": {}, \"order\": 10, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3, \"label\": \"MODEL\"}], \"properties\": {\"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q8_0.gguf\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 4, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 100, \"1\": -770}, \"size\": {\"0\": 340, \"1\": 110}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [333], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp16.safetensors\", \"ViT-L-14-TEXT-detail-improved-hiT-GmP-HF.safetensors\", \"flux\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 175, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 3250, \"1\": 1190}, \"size\": {\"0\": 320, \"1\": 830}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 325, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 323, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 327, \"slot_index\": 2, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 328, \"slot_index\": 3, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 329, \"label\": \"VAE\"}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 322, \"slot_index\": 5, \"label\": \"\\u653e\\u5927\\u6a21\\u578b\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [326, 330, 332], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1, 248839888580556, \"randomize\", 8, 1, \"ddim\", \"sgm_uniform\", 0.5, \"Linear\", 1024, 1024, 8, 32, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 163, \"type\": \"ControlNetApplySD3\", \"pos\": {\"0\": 2870, \"1\": 1190}, \"size\": {\"0\": 320, \"1\": 190}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 293, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 294, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 309, \"label\": \"ControlNet\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 311, \"label\": \"VAE\"}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 314, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [327], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [328], \"slot_index\": 1, \"shape\": 3, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}], \"properties\": {\"Node name for S&R\": \"ControlNetApplySD3\"}, \"widgets_values\": [0.4, 0, 0.4]}, {\"id\": 131, \"type\": \"easy promptConcat\", \"pos\": {\"0\": 210, \"1\": 980}, \"size\": {\"0\": 430, \"1\": 390}, \"flags\": {\"collapsed\": true}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"prompt1\", \"type\": \"STRING\", \"link\": 370, \"widget\": {\"name\": \"prompt1\"}, \"label\": \"\\u63d0\\u793a\\u8bcd1\"}, {\"name\": \"prompt2\", \"type\": \"STRING\", \"link\": 369, \"widget\": {\"name\": \"prompt2\"}, \"label\": \"\\u63d0\\u793a\\u8bcd2\"}], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [220], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u63d0\\u793a\\u8bcd\"}], \"properties\": {\"Node name for S&R\": \"easy promptConcat\"}, \"widgets_values\": [\"\", \"\", \",\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 51, \"type\": \"PlaySound|pysssss\", \"pos\": {\"0\": 1680, \"1\": 790}, \"size\": {\"0\": 210, \"1\": 110}, \"flags\": {\"collapsed\": true}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"any\", \"type\": \"*\", \"link\": 158, \"label\": \"\\u8f93\\u5165\"}], \"outputs\": [{\"name\": \"*\", \"type\": \"*\", \"links\": null, \"shape\": 6, \"label\": \"*\"}], \"properties\": {\"Node name for S&R\": \"PlaySound|pysssss\"}, \"widgets_values\": [\"always\", 0.5, \"notify.mp3\"]}, {\"id\": 152, \"type\": \"Image Comparer (rgthree)\", \"pos\": {\"0\": 4650, \"1\": 110}, \"size\": {\"0\": 950, \"1\": 880}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"link\": 331, \"label\": \"\\u56fe\\u50cf_A\", \"dir\": 3}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"link\": 330, \"label\": \"\\u56fe\\u50cf_B\", \"dir\": 3}], \"outputs\": [], \"properties\": {\"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_gndtk_00027_.png&type=temp&subfolder=&rand=0.9008712718621289\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_gndtk_00028_.png&type=temp&subfolder=&rand=0.6622177033332636\"}]]}, {\"id\": 35, \"type\": \"Fast Groups Bypasser (rgthree)\", \"pos\": {\"0\": -910, \"1\": 110}, \"size\": {\"0\": 430, \"1\": 200}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null, \"label\": \"\\u53ef\\u9009\\u8fde\\u63a5\"}], \"properties\": {\"matchColors\": \"\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 184, \"type\": \"LoraLoader\", \"pos\": {\"0\": 1030, \"1\": -160}, \"size\": {\"0\": 380, \"1\": 130}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 345, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 346, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [339], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [342], \"slot_index\": 1, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux\\\\Dever_Flux_Enhancer.safetensors\", 0.4, 1], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 183, \"type\": \"LoraLoader\", \"pos\": {\"0\": 1030, \"1\": -370}, \"size\": {\"0\": 380, \"1\": 130}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 339, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 342, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [340], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [343], \"slot_index\": 1, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux\\\\FluxDFaeTasticDetails.safetensors\", 0.3, 1], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 127, \"type\": \"easy showAnything\", \"pos\": {\"0\": -630, \"1\": 1340}, \"size\": {\"0\": 330, \"1\": 450}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 357, \"label\": \"\\u8f93\\u5165\\u4efb\\u4f55\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"easy showAnything\"}, \"widgets_values\": [[\"a digital illustration depicting a bustling train station in a fantastical, gothic style, the scene is dominated by a large, ornate clock face hanging from the ceiling, surrounded by intricate, glass-paneled ceilings and ornate, mechanical elements, the clock face is prominently displayed, with roman numerals and a prominent hourglass symbol, and is surrounded by a cloud of steam, indicating a sense of movement and urgency, in the foreground, a steam-powered, black steam locomotive is pulling a passenger train, with numerous passengers, some of whom are dressed in formal attire, including suits and ties, the train's headlights are turned on, casting a warm, golden glow, the platform is bustling with people of various ages and genders, some standing and some walking, adding to the bustling atmosphere, the background features large, arched windows that allow natural light to filter through, illuminating the space and casting a soft glow on the scene, the overall color palette is rich and muted, with shades of blue, green, and gold, enhancing the sense of grandeur and mystery, the illustration is highly detailed, with a focus on intricate textures and lighting effects, giving it a realistic yet fantastical quality, the style is reminiscent of high-end digital art, blending elements of fantasy and realism\\r\\n\\r\\n \\\\(creature\\\\), 1girl, long hair, multiple girls, hat, long sleeves, standing, male focus, outdoors, multiple boys, sky, day, cloud, bag, blurry, artist name, indoors, from side, window, blurry background, train, scenery, clock, train station, steam, scenery around the world, clock face\"]]}, {\"id\": 9, \"type\": \"SDXL Resolutions (JPS)\", \"pos\": {\"0\": 1030, \"1\": 500}, \"size\": {\"0\": 340, \"1\": 80}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [77, 211, 337], \"slot_index\": 0, \"shape\": 3, \"label\": \"width\"}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [8, 212, 338], \"slot_index\": 1, \"shape\": 3, \"label\": \"height\"}], \"properties\": {\"Node name for S&R\": \"SDXL Resolutions (JPS)\"}, \"widgets_values\": [\"portrait - 832x1216 (2:3)\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 52, \"type\": \"ChinesePrompt_Mix\", \"pos\": {\"0\": -270, \"1\": 100}, \"size\": {\"0\": 430, \"1\": 390}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [370], \"slot_index\": 0, \"shape\": 6, \"label\": \"\\u63d0\\u793a\\u8bcd\"}], \"properties\": {\"Node name for S&R\": \"ChinesePrompt_Mix\"}, \"widgets_values\": [\"Frank Frazetta fantasy oil painting,\", \"off\", 882791830129566, \"randomize\", true], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 182, \"type\": \"LoraLoader\", \"pos\": {\"0\": 1030, \"1\": -570}, \"size\": {\"0\": 380, \"1\": 130}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 340, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 343, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [341], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [344], \"slot_index\": 1, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux\\\\frazetta_flux_v2-000150.safetensors\", 0.8, 1], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 32, \"type\": \"easy stylesSelector\", \"pos\": {\"0\": 240, \"1\": 260}, \"size\": {\"0\": 430, \"1\": 500}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"positive\", \"type\": \"STRING\", \"link\": 42, \"widget\": {\"name\": \"positive\"}, \"label\": \"\\u6b63\\u9762\\u63d0\\u793a\\u8bcd\\uff08\\u53ef\\u9009\\uff09\"}, {\"name\": \"negative\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative\"}, \"label\": \"\\u8d1f\\u9762\\u63d0\\u793a\\u8bcd\\uff08\\u53ef\\u9009\\uff09\"}], \"outputs\": [{\"name\": \"positive\", \"type\": \"STRING\", \"links\": [367], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6b63\\u9762\\u63d0\\u793a\\u8bcd\"}, {\"name\": \"negative\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 1, \"shape\": 3, \"label\": \"\\u8d1f\\u9762\\u63d0\\u793a\\u8bcd\"}], \"properties\": {\"Node name for S&R\": \"easy stylesSelector\", \"values\": [\"sai-digital art\", \"mre-gloomy-art\", \"futuristic-retro futurism\", \"mre-bad-dream\"]}, \"widgets_values\": [\"fooocus_styles\", \"\", \"\", \"sai-digital art,mre-gloomy-art,futuristic-retro futurism,mre-bad-dream\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 187, \"type\": \"FluxAttentionSeeker+\", \"pos\": {\"0\": 740, \"1\": 100}, \"size\": {\"0\": 210, \"1\": 1070}, \"flags\": {}, \"order\": 38, \"mode\": 4, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 353, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [359], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"FluxAttentionSeeker+\"}, \"widgets_values\": [false, true, false, false, 3.12, 3.12, 3.12, 3.12, 3.12, 3.12, 3.12, 3.12, 3.12, 3.12, 3.12, 3.12, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, 2.88, null, null, null]}, {\"id\": 170, \"type\": \"PreviewImage\", \"pos\": {\"0\": 3630, \"1\": 1190}, \"size\": {\"0\": 860, \"1\": 760}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 326, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 119, \"type\": \"easy imageChooser\", \"pos\": {\"0\": 1900, \"1\": 100}, \"size\": {\"0\": 830, \"1\": 790}, \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 204, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [278], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"values\": [3], \"Node name for S&R\": \"easy imageChooser\"}, \"widgets_values\": [\"Always Pause\", \"\", \"\"]}, {\"id\": 176, \"type\": \"easy imageChooser\", \"pos\": {\"0\": 3630, \"1\": 150}, \"size\": {\"0\": 860, \"1\": 830}, \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 324, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [325, 331], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"values\": [0, 1], \"Node name for S&R\": \"easy imageChooser\"}, \"widgets_values\": [\"Always Pause\", \"\", \"\"]}, {\"id\": 125, \"type\": \"LoadImage\", \"pos\": {\"0\": -1450, \"1\": 1340}, \"size\": [320, 310], \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [355], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3, \"label\": \"\\u906e\\u7f69\"}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"47c2604cf9d0a7d04fa013dc19a3c750.jpg\", \"image\"]}], \"links\": [[8, 9, 1, 8, 1, \"INT\"], [39, 11, 0, 29, 1, \"VAE\"], [42, 7, 0, 32, 0, \"STRING\"], [46, 34, 0, 33, 0, \"STRING\"], [77, 9, 0, 8, 0, \"INT\"], [99, 11, 0, 64, 3, \"VAE\"], [100, 66, 0, 64, 4, \"IMAGE\"], [107, 66, 0, 68, 0, \"IMAGE\"], [155, 8, 0, 89, 3, \"LATENT\"], [156, 89, 0, 29, 0, \"LATENT\"], [158, 89, 0, 51, 0, \"*\"], [180, 103, 0, 101, 5, \"UPSCALE_MODEL\"], [182, 11, 0, 101, 4, \"VAE\"], [186, 106, 0, 107, 6, \"BBOX_DETECTOR\"], [187, 101, 0, 107, 0, \"IMAGE\"], [190, 11, 0, 107, 3, \"VAE\"], [192, 64, 1, 107, 5, \"CONDITIONING\"], [193, 106, 1, 107, 8, \"SEGM_DETECTOR\"], [197, 111, 0, 107, 7, \"SAM_MODEL\"], [198, 107, 0, 112, 0, \"IMAGE\"], [204, 29, 0, 119, 0, \"IMAGE\"], [207, 121, 0, 64, 2, \"CONTROL_NET\"], [208, 122, 0, 121, 0, \"CONTROL_NET\"], [209, 67, 0, 123, 0, \"IMAGE\"], [210, 123, 0, 66, 0, \"IMAGE\"], [211, 9, 0, 123, 1, \"INT\"], [212, 9, 1, 123, 2, \"INT\"], [220, 131, 0, 26, 0, \"STRING\"], [236, 33, 0, 26, 1, \"STRING\"], [237, 64, 0, 89, 1, \"CONDITIONING\"], [245, 144, 0, 53, 0, \"*\"], [249, 64, 1, 89, 2, \"CONDITIONING\"], [252, 64, 0, 107, 4, \"CONDITIONING\"], [265, 147, 0, 101, 1, \"MODEL\"], [278, 119, 0, 101, 0, \"IMAGE\"], [293, 64, 0, 163, 0, \"CONDITIONING\"], [294, 64, 1, 163, 1, \"CONDITIONING\"], [309, 165, 0, 163, 2, \"CONTROL_NET\"], [310, 166, 0, 165, 0, \"CONTROL_NET\"], [311, 11, 0, 163, 3, \"VAE\"], [312, 64, 0, 101, 2, \"CONDITIONING\"], [313, 64, 1, 101, 3, \"CONDITIONING\"], [314, 101, 0, 163, 4, \"IMAGE\"], [322, 103, 0, 175, 5, \"UPSCALE_MODEL\"], [323, 147, 0, 175, 1, \"MODEL\"], [324, 101, 0, 176, 0, \"IMAGE\"], [325, 176, 0, 175, 0, \"IMAGE\"], [326, 175, 0, 170, 0, \"IMAGE\"], [327, 163, 0, 175, 2, \"CONDITIONING\"], [328, 163, 1, 175, 3, \"CONDITIONING\"], [329, 11, 0, 175, 4, \"VAE\"], [330, 175, 0, 152, 1, \"IMAGE\"], [331, 176, 0, 152, 0, \"IMAGE\"], [332, 175, 0, 115, 0, \"IMAGE\"], [333, 4, 0, 177, 0, \"CLIP\"], [334, 177, 0, 99, 0, \"CLIP\"], [335, 140, 0, 178, 0, \"MODEL\"], [337, 9, 0, 178, 1, \"INT\"], [338, 9, 1, 178, 2, \"INT\"], [339, 184, 0, 183, 0, \"MODEL\"], [340, 183, 0, 182, 0, \"MODEL\"], [341, 182, 0, 181, 0, \"MODEL\"], [342, 184, 1, 183, 1, \"CLIP\"], [343, 183, 1, 182, 1, \"CLIP\"], [344, 182, 1, 181, 1, \"CLIP\"], [345, 178, 0, 184, 0, \"MODEL\"], [346, 99, 0, 184, 1, \"CLIP\"], [348, 181, 1, 107, 2, \"CLIP\"], [349, 181, 0, 89, 0, \"MODEL\"], [350, 181, 0, 147, 0, \"MODEL\"], [351, 181, 0, 107, 1, \"MODEL\"], [353, 181, 1, 187, 0, \"CLIP\"], [355, 125, 0, 189, 0, \"IMAGE\"], [357, 189, 2, 127, 0, \"*\"], [359, 187, 0, 191, 0, \"CLIP\"], [364, 191, 0, 64, 0, \"CONDITIONING\"], [365, 191, 1, 64, 1, \"CONDITIONING\"], [366, 144, 0, 191, 1, \"STRING\"], [367, 32, 0, 144, 1, \"STRING\"], [368, 26, 0, 144, 0, \"STRING\"], [369, 189, 2, 131, 1, \"STRING\"], [370, 52, 0, 131, 0, \"STRING\"]], \"groups\": [{\"title\": \"Tile detail\", \"bounding\": [2860, 1120, 1640, 914], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"image to text\", \"bounding\": [-1470, 1270, 1180, 594], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"face details\", \"bounding\": [2860, 2150, 1640, 1214], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"llama\", \"bounding\": [-200, 1270, 940, 614], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"controlnet\", \"bounding\": [1550, 1180, 1190, 704], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"SDupscale\", \"bounding\": [2860, 70, 1640, 914], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.8954302432552388, \"offset\": [1580.5138227861175, -887.7807828112054]}}, \"version\": 0.4, \"widget_idx_map\": {\"34\": {\"seed\": 5}, \"52\": {\"seed\": 2}, \"89\": {\"noise_seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"101\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"107\": {\"sampler_name\": 7, \"scheduler\": 8}, \"175\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}}, \"seed_widgets\": {\"34\": 5, \"52\": 2, \"89\": 1, \"101\": 1, \"175\": 1}}}",
                "steps": 35,
                "width": {
                    "inputs": {
                        "resolution": "portrait - 832x1216 (2:3)"
                    },
                    "class_type": "SDXL Resolutions (JPS)"
                },
                "height": {
                    "inputs": {
                        "resolution": "portrait - 832x1216 (2:3)"
                    },
                    "class_type": "SDXL Resolutions (JPS)"
                },
                "models": [],
                "sampler": "DPM adaptive",
                "cfgScale": 1,
                "modelIds": [],
                "scheduler": "sgm_uniform",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [
                    "flux\\FLUX.1-dev-ControlNet-Union-Pro.safetensors"
                ],
                "additionalResources": [
                    {
                        "name": "flux\\Hyper-FLUX.1-dev-8steps-lora.safetensors",
                        "type": "lora",
                        "strength": 0.13
                    },
                    {
                        "name": "flux\\aidmaMJ6.1-FLUX-V0.2.safetensors",
                        "type": "lora",
                        "strength": 1,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux\\frazetta_flux_v2-000150.safetensors",
                        "type": "lora",
                        "strength": 0.8,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux\\FluxDFaeTasticDetails.safetensors",
                        "type": "lora",
                        "strength": 0.3,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux\\Dever_Flux_Enhancer.safetensors",
                        "type": "lora",
                        "strength": 0.4,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "holymoddz",
            "baseModel": ""
        },
        {
            "id": 30356969,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1a6d7dec-4530-4f79-9f39-3b0b5dc7ceca/width=832/1a6d7dec-4530-4f79-9f39-3b0b5dc7ceca.jpeg",
            "hash": "U56b3~UbyDnP~pvLs:spxbv|-ps:xHxB-pog",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-20T04:04:55.823Z",
            "postId": 6792244,
            "stats": {
                "cryCount": 20,
                "laughCount": 50,
                "likeCount": 220,
                "dislikeCount": 0,
                "heartCount": 93,
                "commentCount": 0
            },
            "meta": {
                "seed": 1480,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 30, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 1480}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 4.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": 832, \"height\": 1216, \"model\": [\"51\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"51\": {\"inputs\": {\"lora_name\": \"flux1\\\\sabrina_carpenter.safetensors\", \"strength_model\": 1.2, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.1, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"51\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"71\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.3, \"alpha\": 0.3, \"image\": [\"72\", 0]}, \"class_type\": \"ImageSharpen\"}, \"72\": {\"inputs\": {\"hdr_intensity\": 0.5, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"69\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"73\": {\"inputs\": {\"intensity\": 0.15, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"71\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.35000000000000003, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 25, \"denoise\": 0.15, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"\\nExtremely photorealistic photography of A Gothic woman sabcarp with dark tones and intricate details, dressed in a bohemian crochet dress with voluminous bell sleeves. The outside rustic wooden house setting is illuminated by dramatic, high-contrast lighting, creating a moody, mysterious atmosphere. Black flowers and wilted blooms add to the textured, haunting beauty of the scene.\\n\\nIncorporate subtle rain effects with droplets and reflections for a more dynamic scene.Simulate wet surfaces  on the ground or buildings for added realism, especially under streetlights.\\n\\n\\n\\nShe crosses one arm across her body, resting her hand on her opposite shoulder.\\n\\n\\n\\n\\n\", \"clip\": [\"51\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"109\": {\"inputs\": {\"tile_size\": 512}, \"class_type\": \"VAEEncodeTiled\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"141\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"144\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"147\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"149\": {\"inputs\": {\"scale_method\": \"lanczos\", \"scale_factor\": 1.5, \"use_tiled_vae\": false}, \"class_type\": \"LatentPixelScale\"}}, \"workflow\": {\"last_node_id\": 149, \"last_link_id\": 313, \"nodes\": [{\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1300, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 293, \"1\": -192}, \"size\": [75, 26], \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 153}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 126, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 832, 1216]}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1801, \"1\": 21}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 159}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 355, \"1\": 764}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 112, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 109, \"type\": \"VAEEncodeTiled\", \"pos\": {\"0\": -510, \"1\": 806}, \"size\": {\"0\": 248.89723205566406, \"1\": 78}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncodeTiled\"}, \"widgets_values\": [512]}, {\"id\": 141, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2036, \"1\": 41}, \"size\": {\"0\": 428.9556884765625, \"1\": 78}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1813, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [260, 299], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 117, \"type\": \"SaveImagePlus\", \"pos\": {\"0\": 4366, \"1\": 456}, \"size\": {\"0\": 832.2413940429688, \"1\": 1183.025634765625}, \"flags\": {}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 282}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImagePlus\"}, \"widgets_values\": [\"ComfyUI\", \"JPEG\", true]}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": 2156, \"1\": 435}, \"size\": {\"0\": 504.7402648925781, \"1\": 472.86358642578125}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": 34, \"1\": 42}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [252], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 5, \"1\": 172}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [304], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [294, 305], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [295, 306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [296, 307], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1480, \"1\": 57}, \"size\": {\"0\": 284.1048889160156, \"1\": 619.9912719726562}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 287, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [159, 308], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186, 297, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3079, \"1\": -575}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 311}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 148, \"type\": \"SaveImage\", \"pos\": {\"0\": 3061, \"1\": -483}, \"size\": {\"0\": 281.4468078613281, \"1\": 480.5931091308594}, \"flags\": {}, \"order\": 64, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 313}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 146, \"type\": \"DZ_Face_Detailer\", \"pos\": {\"0\": 2658, \"1\": -843}, \"size\": {\"0\": 309.8262939453125, \"1\": 842.9425659179688}, \"flags\": {}, \"order\": 59, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 305}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 306}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 307}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DZ_Face_Detailer\"}, \"widgets_values\": [1, \"fixed\", 20, 4, \"euler\", \"sgm_uniform\", 0.5, 32, \"face\", \"dilate\", 3, 3]}, {\"id\": 142, \"type\": \"SaveImage\", \"pos\": {\"0\": 3204, \"1\": 556}, \"size\": {\"0\": 813.5270385742188, \"1\": 1236.560546875}, \"flags\": {}, \"order\": 66, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 300}], \"outputs\": [], \"title\": \"FinalPass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 2236, \"1\": 953}, \"size\": {\"0\": 848.405029296875, \"1\": 898.4495849609375}, \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 841, \"1\": 1300}, \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": 8, \"1\": 851}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": 19, \"1\": 1194}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 140, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2769, \"1\": 86}, \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 63, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 294}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 295}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 296}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 297}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 298}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.5, 1, \"fixed\", 25, 3, \"euler\", \"sgm_uniform\", 0.1, \"Linear\", 1344, 768, 24, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 700, \"1\": 54}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 133, \"1\": 321}, \"size\": [214.54766211692385, 58], \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 617, \"1\": 645}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1216, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 374, \"1\": 646}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [112, 115], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [832, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 52, \"type\": \"LoraLoader\", \"pos\": {\"0\": -116, \"1\": 432}, \"size\": {\"0\": 455.3192138671875, \"1\": 131.6434326171875}, \"flags\": {}, \"order\": 23, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 125}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 301}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [126], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [153], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\bustyFC-2.1.safetensors\", 0.5, 1]}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1829, \"1\": 554}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 25, 0.15], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 900, \"1\": 94}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 887, \"1\": 38}, \"size\": [247.96474163161452, 470.6349560288795], \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 892, \"1\": 570}, \"size\": [210, 106], \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 893, \"1\": 720}, \"size\": [210, 178], \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 289], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 879, \"1\": 1133}, \"size\": [210, 82], \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 507, \"1\": 1336}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 289}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 149, \"type\": \"LatentPixelScale\", \"pos\": {\"0\": 465, \"1\": 1483}, \"size\": [243.60000610351562, 146], \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model_opt\", \"type\": \"UPSCALE_MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentPixelScale\"}, \"widgets_values\": [\"lanczos\", 1.5, false]}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1172, \"1\": 43}, \"size\": [243.68327178665822, 82], \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1194, \"1\": 171}, \"size\": [210, 58], \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [287], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1512, \"1\": -35}, \"size\": [140, 46], \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 2061, \"1\": 273}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 260}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.3, 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 474, \"1\": 893}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 486, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 30, 1]}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 403, \"1\": 39}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [4], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 879, \"1\": 949}, \"size\": [210, 130], \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.1, 10, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [1480, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1815, \"1\": 365}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168, 282], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.15, 10, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1244, \"1\": 835}, \"size\": {\"0\": 848.655029296875, \"1\": 899.4495849609375}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 51, \"type\": \"LoraLoader\", \"pos\": {\"0\": -98, \"1\": 604}, \"size\": {\"0\": 462.208251953125, \"1\": 134.61793518066406}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 252}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 304}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [125], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [301], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\sabrina_carpenter.safetensors\", 1.2, 1]}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 379, \"1\": 141}, \"size\": {\"0\": 488.2522277832031, \"1\": 387.7407531738281}, \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\\nExtremely photorealistic photography of A Gothic woman sabcarp with dark tones and intricate details, dressed in a bohemian crochet dress with voluminous bell sleeves. The outside rustic wooden house setting is illuminated by dramatic, high-contrast lighting, creating a moody, mysterious atmosphere. Black flowers and wilted blooms add to the textured, haunting beauty of the scene.\\n\\nIncorporate subtle rain effects with droplets and reflections for a more dynamic scene.Simulate wet surfaces  on the ground or buildings for added realism, especially under streetlights.\\n\\n\\n\\nShe crosses one arm across her body, resting her hand on her opposite shoulder.\\n\\n\\n\\n\\n\"]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [112, 34, 0, 27, 0, \"INT\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [125, 51, 0, 52, 0, \"MODEL\"], [126, 52, 0, 30, 0, \"MODEL\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [153, 52, 1, 49, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [159, 42, 0, 69, 0, \"LATENT\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [252, 12, 0, 51, 0, \"MODEL\"], [260, 72, 0, 71, 0, \"IMAGE\"], [282, 73, 0, 117, 0, \"IMAGE\"], [285, 75, 0, 59, 0, \"IMAGE\"], [287, 134, 0, 42, 2, \"SAMPLER\"], [288, 62, 0, 41, 0, \"IMAGE\"], [289, 61, 0, 77, 1, \"IMAGE\"], [294, 96, 0, 140, 1, \"MODEL\"], [295, 64, 0, 140, 2, \"CONDITIONING\"], [296, 65, 0, 140, 3, \"CONDITIONING\"], [297, 70, 0, 140, 4, \"VAE\"], [298, 141, 0, 140, 5, \"UPSCALE_MODEL\"], [299, 72, 0, 140, 0, \"IMAGE\"], [300, 140, 0, 142, 0, \"IMAGE\"], [301, 51, 1, 52, 1, \"CLIP\"], [304, 11, 0, 51, 1, \"CLIP\"], [305, 96, 0, 146, 0, \"MODEL\"], [306, 64, 0, 146, 1, \"CONDITIONING\"], [307, 65, 0, 146, 2, \"CONDITIONING\"], [308, 42, 0, 146, 3, \"LATENT\"], [310, 70, 0, 146, 4, \"VAE\"], [311, 146, 0, 147, 0, \"LATENT\"], [312, 81, 0, 147, 1, \"VAE\"], [313, 147, 0, 148, 0, \"IMAGE\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.4641000000000006, \"offset\": [55.27012636075994, 121.59617024534208]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}, \"140\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"146\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"140\": 1, \"146\": 0}}}",
                "steps": 30,
                "models": [],
                "prompt": "\nExtremely photorealistic photography of A Gothic woman sabcarp with dark tones and intricate details, dressed in a bohemian crochet dress with voluminous bell sleeves. The outside rustic wooden house setting is illuminated by dramatic, high-contrast lighting, creating a moody, mysterious atmosphere. Black flowers and wilted blooms add to the textured, haunting beauty of the scene.\n\nIncorporate subtle rain effects with droplets and reflections for a more dynamic scene.Simulate wet surfaces  on the ground or buildings for added realism, especially under streetlights.\n\n\n\nShe crosses one arm across her body, resting her hand on her opposite shoulder.\n\n\n\n\n",
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 4,
                "modelIds": [],
                "scheduler": "sgm_uniform",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux1\\sabrina_carpenter.safetensors",
                        "type": "lora",
                        "strength": 1.2,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "salammy",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 30008802,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/60137ece-e9c0-4e9b-a3fa-203b37432906/width=832/60137ece-e9c0-4e9b-a3fa-203b37432906.jpeg",
            "hash": "UfL;d4t7?]xu?aaeRka|Rjj[eobGxufkkCjZ",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-18T04:33:42.171Z",
            "postId": 6714649,
            "stats": {
                "cryCount": 2,
                "laughCount": 23,
                "likeCount": 250,
                "dislikeCount": 0,
                "heartCount": 108,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 207901729,
                "steps": 24,
                "prompt": "furry,by yagi the goat,human girl,Wolf ears,Wolf tail,Grey Tail,Grey ears,grey hair,Human skin,long hair,Short stature,Skinny body,solo,Short stature,Skinny body,score_9,score_8_up,score_7_up,(cute expression, cute face:1.1),simple background,looking at viewer,blush,early teen,print_kimono,furisode,obi,sash,flat chest,<lora:Yagi_the_Goat_ai:1>,fox tail,",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "Yagi_the_Goat_ai",
                        "type": "lora",
                        "weight": 1
                    }
                ],
                "Created Date": "2024-09-17T1256:20.6074485Z",
                "negativePrompt": "text,watermark,artist name,patreon username,patreon logo,english text,web address,signature,monochrome,pregnant,collar,muscular,bad_fingers,easynegative,score_4,score_5,score_6,muscular,traditional media,sketch,border,futa,bad hands,bad anatomy,bad artist,male,1boy,(EasyNegative:1.2),grayscale,worstquality,logo,blurry,low quality,cropped,bad proportions,out of focus,username,sketches,lowres,kneeling,Fennec foxes goire,yellow Fennec foxes girl,yellow ear,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 290640,
                        "modelVersionName": "V6 (start with this one)"
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 808990,
                        "modelVersionName": "V1"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "LRE0v0",
            "baseModel": "Pony"
        },
        {
            "id": 26172944,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/def23e0f-ab1a-4f60-96a0-4aefafc86703/width=864/def23e0f-ab1a-4f60-96a0-4aefafc86703.jpeg",
            "hash": "UJFhO?9bFd%L}mR-Fx$M5=xZtQV[9_kC#mJ9",
            "width": 864,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-26T02:39:39.193Z",
            "postId": 5849913,
            "stats": {
                "cryCount": 10,
                "laughCount": 26,
                "likeCount": 273,
                "dislikeCount": 0,
                "heartCount": 74,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "sdxl_vae.safetensors",
                "Size": "864x1152",
                "seed": 2251513948,
                "Model": "autismmixSDXL_autismmixPony",
                "steps": 30,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "821aa5537f",
                    "lora:bl00mXLP": "020f042f6414"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up,   <lora:bl00mXLP:1> bl00m, 1girl, long hair, solo, blue eyes, wings, orange hair",
                "Version": "v1.10.1",
                "sampler": "Euler a",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "020f042f6414",
                        "name": "bl00mXLP",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "821aa5537f",
                        "name": "autismmixSDXL_autismmixPony",
                        "type": "model"
                    }
                ],
                "Model hash": "821aa5537f",
                "Schedule type": "Automatic",
                "negativePrompt": "watermark, signature, artist name, twitter username,",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.8.0",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "freckledvixon",
            "baseModel": "Pony"
        },
        {
            "id": 25366170,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7b89fac8-b0eb-4f4a-a7a3-f4f97c7b07fe/width=1800/7b89fac8-b0eb-4f4a-a7a3-f4f97c7b07fe.jpeg",
            "hash": "UODb$.[LyZ]p.S:+?GrWFsaHnyI--pRnIus;",
            "width": 2048,
            "height": 2048,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-21T03:15:00.099Z",
            "postId": 5668529,
            "stats": {
                "cryCount": 12,
                "laughCount": 32,
                "likeCount": 257,
                "dislikeCount": 0,
                "heartCount": 82,
                "commentCount": 0
            },
            "meta": {
                "seed": 3477,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"6\": {\"inputs\": {\"text\": \"Photorealistic photography of a stunning beauty, close-up, mouth focus, extremely high detail, intricate textures, extremely dark surrounding, extremely low light, nighttime setting, ultra realistic shadows, ethereal, flowing hair illuminated by glowing butterflies, seductive smile, looking at viewer while playing with her hair,  vibrant colors, dreamlike atmosphere, captivating expression, magical forest background, fiery glow, enchanted lighting, expressive eyes reflecting the glowing light, soft, ethereal glow around the figure, delicate and detailed facial features, golden light, intricate patterns in the background\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", \"clip\": [\"86\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp16.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"default\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"dpm_2\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 40, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 3477}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 3.0, \"conditioning\": [\"6\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5, \"width\": 1024, \"height\": 1024, \"model\": [\"86\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"42\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.4, \"alpha\": 0.4, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"43\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"72\", 0]}, \"class_type\": \"SaveImage\"}, \"70\": {\"inputs\": {\"lora_name\": \"flux1\\\\Madison_Beer_For_Flux.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"72\": {\"inputs\": {\"intensity\": 0.03, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"127\", 0]}, \"class_type\": \"FilmGrain\"}, \"86\": {\"inputs\": {\"lora_name\": \"flux1\\\\flux_realism_lora.safetensors\", \"strength_model\": 0.75, \"strength_clip\": 1.0, \"model\": [\"70\", 0], \"clip\": [\"70\", 1]}, \"class_type\": \"LoraLoader\"}, \"104\": {\"inputs\": {\"text\": \"\", \"clip\": [\"86\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"111\": {\"inputs\": {\"upscale_by\": 2.0, \"seed\": 316, \"steps\": 15, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 0.25, \"mode_type\": \"Linear\", \"tile_width\": 1024, \"tile_height\": 1024, \"mask_blur\": 20, \"tile_padding\": 56, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 16, \"seam_fix_padding\": 32, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"72\", 0], \"model\": [\"30\", 0], \"positive\": [\"6\", 0], \"negative\": [\"104\", 0], \"vae\": [\"10\", 0], \"upscale_model\": [\"112\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"112\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"119\": {\"inputs\": {\"sharpen_radius\": 2, \"sigma\": 0.25, \"alpha\": 0.25, \"image\": [\"111\", 0]}, \"class_type\": \"ImageSharpen\"}, \"120\": {\"inputs\": {\"scale\": 0.25, \"strength\": 0.05, \"saturation\": 0.7, \"toe\": 0.0, \"seed\": 181073080327053, \"image\": [\"125\", 0]}, \"class_type\": \"BetterFilmGrain\"}, \"125\": {\"inputs\": {\"hdr_intensity\": 0.8, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"119\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"127\": {\"inputs\": {\"hdr_intensity\": 0.85, \"shadow_intensity\": 0.45, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.35000000000000003, \"image\": [\"42\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"173\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"120\", 0]}, \"class_type\": \"SaveImage\"}, \"176\": {\"inputs\": {\"guide_size\": 512, \"guide_size_for\": true, \"max_size\": 1024, \"seed\": 700476115409765, \"steps\": 20, \"cfg\": 8, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.5, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.5, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"bbox_detector\": [\"179\", 0], \"sam_model_opt\": [\"178\", 0], \"segm_detector_opt\": [\"181\", 1]}, \"class_type\": \"FaceDetailer\"}, \"177\": {\"inputs\": {\"threshold\": 0.5, \"dilation\": 10, \"crop_factor\": 3, \"drop_size\": 10, \"labels\": \"all\"}, \"class_type\": \"BboxDetectorSEGS\"}, \"178\": {\"inputs\": {\"model_name\": \"mobile_sam.pt\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\"}, \"179\": {\"inputs\": {\"model_name\": null}, \"class_type\": \"ONNXDetectorProvider\"}, \"181\": {\"inputs\": {\"model_name\": \"bbox/face_yolov8m.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"196\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"default\", \"double_blocks_cuda_size\": 7, \"single_blocks_cuda_size\": 7}, \"class_type\": \"MZ_Flux1UnetLoader_cpuDynOffload\"}, \"197\": {\"inputs\": {\"ckpt_name\": \"AuraFlow\\\\aura_flow_0.3.safetensors\", \"double_blocks_cuda_size\": 7, \"single_blocks_cuda_size\": 7}, \"class_type\": \"MZ_Flux1CheckpointLoaderNF4_cpuDynOffload\"}, \"198\": {\"inputs\": {\"anything\": [\"120\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}, \"199\": {\"inputs\": {\"anything\": [\"72\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}, \"201\": {\"inputs\": {\"anything\": [\"27\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}}, \"workflow\": {\"last_node_id\": 203, \"last_link_id\": 337, \"nodes\": [{\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": [359, 149], \"size\": [644.2343679302923, 423.40483577107705], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 162, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [272, 275], \"slot_index\": 0}], \"title\": \"CLIP Text Encode (Positive Prompt)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"Photorealistic photography of a stunning beauty, close-up, mouth focus, extremely high detail, intricate textures, extremely dark surrounding, extremely low light, nighttime setting, ultra realistic shadows, ethereal, flowing hair illuminated by glowing butterflies, seductive smile, looking at viewer while playing with her hair,  vibrant colors, dreamlike atmosphere, captivating expression, magical forest background, fiery glow, enchanted lighting, expressive eyes reflecting the glowing light, soft, ethereal glow around the figure, delicate and detailed facial features, golden light, intricate patterns in the background\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": [825, 48], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 180}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [296], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": [27, 330], \"size\": {\"0\": 311.81634521484375, \"1\": 60.429901123046875}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12, 199], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": [9, 171], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [146], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp16.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": [6, 41], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"default\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": [788, 615], \"size\": {\"0\": 308.62738037109375, \"1\": 567.866943359375}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 30, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 327, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [180], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": [408, 1017], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpm_2\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": [409, 1117], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 55, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 40, 1]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": [349, 39], \"size\": {\"0\": 222.3482666015625, \"1\": 46}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 265, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [30], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": [411, 893], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [3477, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": [591, 42], \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 272}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [265], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": [406, 745], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 140, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [326, 327], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [1024, 1024, 1]}, {\"id\": 28, \"type\": \"Note\", \"pos\": [27, 779], \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": [468, 1286], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 161, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 55, 325], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 1024, 1024]}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": [346, 622], \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 140], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1024, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": [572, 625], \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1024, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 37, \"type\": \"Note\", \"pos\": [35, 1111], \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": [1507, -884], \"size\": {\"0\": 393.98309326171875, \"1\": 1198.8323974609375}, \"flags\": {}, \"order\": 5, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": null}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 42, \"type\": \"ImageSharpen\", \"pos\": [732, -113], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 296, \"slot_index\": 0}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [286], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.4, 0.4]}, {\"id\": 43, \"type\": \"SaveImage\", \"pos\": [1082, -882], \"size\": {\"0\": 396.35198974609375, \"1\": 1194.08154296875}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 318}], \"title\": \"Save Image (sharp and enhance)\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 70, \"type\": \"LoraLoader\", \"pos\": [18, 435], \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 145, \"slot_index\": 0}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 146, \"slot_index\": 1}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [159], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [160], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Madison_Beer_For_Flux.safetensors\", 1, 1]}, {\"id\": 72, \"type\": \"FilmGrain\", \"pos\": [387, -565], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 302, \"slot_index\": 0}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [317, 323, 324], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.03, 10, 0, 0]}, {\"id\": 86, \"type\": \"LoraLoader\", \"pos\": [20, 609], \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 159, \"slot_index\": 0}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 160, \"slot_index\": 1}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [161], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [162, 172], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\flux_realism_lora.safetensors\", 0.75, 1]}, {\"id\": 104, \"type\": \"CLIPTextEncode\", \"pos\": [864, 1096], \"size\": {\"0\": 409.1979064941406, \"1\": 75.99993896484375}, \"flags\": {\"collapsed\": true}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 172, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [191], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 111, \"type\": \"UltimateSDUpscale\", \"pos\": [1116, 550], \"size\": [264.3000183105469, 980.3591918945312], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 324}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 325, \"slot_index\": 1}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 275, \"slot_index\": 2}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 191, \"slot_index\": 3}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 199, \"slot_index\": 4}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 194}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [276], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 316, \"increment\", 15, 1, \"euler\", \"simple\", 0.25, \"Linear\", 1024, 1024, 20, 56, \"None\", 1, 64, 16, 32, true, false], \"locked\": true}, {\"id\": 112, \"type\": \"UpscaleModelLoader\", \"pos\": [1668, 432], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [194], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"]}, {\"id\": 119, \"type\": \"ImageSharpen\", \"pos\": [2512, 894], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 276, \"slot_index\": 0}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [329], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [2, 0.25, 0.25]}, {\"id\": 120, \"type\": \"BetterFilmGrain\", \"pos\": [2518, 1260], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 332}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [309, 335], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BetterFilmGrain\"}, \"widgets_values\": [0.25, 0.05, 0.7, 0, 181073080327053, \"randomize\"]}, {\"id\": 125, \"type\": \"LayerFilter: HDREffects\", \"pos\": [2519, 1042], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 329}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.8, 0.25, 0.75, 0.25, 0.1, 0.25]}, {\"id\": 127, \"type\": \"LayerFilter: HDREffects\", \"pos\": [730, -607], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {\"collapsed\": false}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 298}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [302], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.85, 0.45, 0.75, 0.25, 0.1, 0.35000000000000003]}, {\"id\": 139, \"type\": \"LayerFilter: HDREffects\", \"pos\": [-114, -409], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {\"collapsed\": false}, \"order\": 6, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25]}, {\"id\": 173, \"type\": \"SaveImage\", \"pos\": [1404, 551], \"size\": [557.3127827102903, 897.0792923661102], \"flags\": {\"collapsed\": false}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 337, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"locked\": true}, {\"id\": 174, \"type\": \"CR Aspect Ratio SDXL\", \"pos\": [-415, 850], \"size\": {\"0\": 315, \"1\": 302}, \"flags\": {}, \"order\": 7, \"mode\": 4, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"INT\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"slot_index\": 2, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}, {\"name\": \"INT\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR Aspect Ratio SDXL\"}, \"widgets_values\": [1024, 1024, \"custom\", \"Off\", 1, 1, 1]}, {\"id\": 176, \"type\": \"FaceDetailer\", \"pos\": [3062, -191], \"size\": {\"0\": 519, \"1\": 900}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 282}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 281}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 284}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": null, \"slot_index\": 1, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [512, true, 1024, 700476115409765, \"randomize\", 20, 8, \"euler\", \"normal\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 177, \"type\": \"BboxDetectorSEGS\", \"pos\": [2632, -185], \"size\": {\"0\": 400, \"1\": 212}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": null}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}], \"outputs\": [{\"name\": \"SEGS\", \"type\": \"SEGS\", \"links\": null, \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BboxDetectorSEGS\"}, \"widgets_values\": [0.5, 10, 3, 10, \"all\"]}, {\"id\": 178, \"type\": \"SAMLoader\", \"pos\": [2709, 74], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [281], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"mobile_sam.pt\", \"AUTO\"]}, {\"id\": 179, \"type\": \"ONNXDetectorProvider\", \"pos\": [2705, 218], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [282], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ONNXDetectorProvider\"}, \"widgets_values\": [null]}, {\"id\": 181, \"type\": \"UltralyticsDetectorProvider\", \"pos\": [2281, -122], \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [284], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 182, \"type\": \"EnhanceDetail\", \"pos\": [420, -369], \"size\": {\"0\": 253.6738739013672, \"1\": 130}, \"flags\": {}, \"order\": 33, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 286}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [297], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EnhanceDetail\"}, \"widgets_values\": [2, 0.1, 0.1, 1.5]}, {\"id\": 192, \"type\": \"Image Filter Adjustments\", \"pos\": [721, -382], \"size\": {\"0\": 315, \"1\": 226}, \"flags\": {}, \"order\": 34, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 297}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Filter Adjustments\"}, \"widgets_values\": [0, 1, 1, 1, 0, 0, 0, \"true\"]}, {\"id\": 196, \"type\": \"MZ_Flux1UnetLoader_cpuDynOffload\", \"pos\": [2874, 1406], \"size\": {\"0\": 344.3999938964844, \"1\": 130}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"MZ_Flux1UnetLoader_cpuDynOffload\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"default\", 7, 7]}, {\"id\": 197, \"type\": \"MZ_Flux1CheckpointLoaderNF4_cpuDynOffload\", \"pos\": [3199.2669388355403, 1397.6350680173095], \"size\": {\"0\": 420, \"1\": 146}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": null, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": null, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"MZ_Flux1CheckpointLoaderNF4_cpuDynOffload\"}, \"widgets_values\": [\"AuraFlow\\\\aura_flow_0.3.safetensors\", 7, 7]}, {\"id\": 198, \"type\": \"easy cleanGpuUsed\", \"pos\": [2598, 856], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"collapsed\": true}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 309}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 199, \"type\": \"easy cleanGpuUsed\", \"pos\": [1181, 511], \"size\": [140, 26], \"flags\": {\"collapsed\": true}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 323}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 200, \"type\": \"Reroute\", \"pos\": [785, -778], \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 317}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [318], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 201, \"type\": \"easy cleanGpuUsed\", \"pos\": [876, 1227], \"size\": {\"0\": 140, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 326}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 202, \"type\": \"Reroute\", \"pos\": [2735, 1457], \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 335}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [336], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 203, \"type\": \"Reroute\", \"pos\": [1424, 1457], \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 336}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [337], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}], \"links\": [[12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [30, 22, 0, 13, 1, \"GUIDER\"], [37, 25, 0, 13, 0, \"NOISE\"], [54, 30, 0, 22, 0, \"MODEL\"], [55, 30, 0, 17, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [140, 34, 0, 27, 0, \"INT\"], [145, 12, 0, 70, 0, \"MODEL\"], [146, 11, 0, 70, 1, \"CLIP\"], [159, 70, 0, 86, 0, \"MODEL\"], [160, 70, 1, 86, 1, \"CLIP\"], [161, 86, 0, 30, 0, \"MODEL\"], [162, 86, 1, 6, 0, \"CLIP\"], [172, 86, 1, 104, 0, \"CLIP\"], [180, 13, 0, 8, 0, \"LATENT\"], [191, 104, 0, 111, 3, \"CONDITIONING\"], [194, 112, 0, 111, 5, \"UPSCALE_MODEL\"], [199, 10, 0, 111, 4, \"VAE\"], [265, 26, 0, 22, 1, \"CONDITIONING\"], [272, 6, 0, 26, 0, \"CONDITIONING\"], [275, 6, 0, 111, 2, \"CONDITIONING\"], [276, 111, 0, 119, 0, \"IMAGE\"], [281, 178, 0, 176, 7, \"SAM_MODEL\"], [282, 179, 0, 176, 6, \"BBOX_DETECTOR\"], [284, 181, 1, 176, 8, \"SEGM_DETECTOR\"], [286, 42, 0, 182, 0, \"IMAGE\"], [296, 8, 0, 42, 0, \"IMAGE\"], [297, 182, 0, 192, 0, \"IMAGE\"], [298, 192, 0, 127, 0, \"IMAGE\"], [302, 127, 0, 72, 0, \"IMAGE\"], [309, 120, 0, 198, 0, \"*\"], [317, 72, 0, 200, 0, \"*\"], [318, 200, 0, 43, 0, \"IMAGE\"], [323, 72, 0, 199, 0, \"*\"], [324, 72, 0, 111, 0, \"IMAGE\"], [325, 30, 0, 111, 1, \"MODEL\"], [326, 27, 0, 201, 0, \"*\"], [327, 27, 0, 13, 4, \"LATENT\"], [329, 119, 0, 125, 0, \"IMAGE\"], [332, 125, 0, 120, 0, \"IMAGE\"], [335, 120, 0, 202, 0, \"*\"], [336, 202, 0, 203, 0, \"*\"], [337, 203, 0, 173, 0, \"IMAGE\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.9090909090909091, \"offset\": [-136.51861823690257, 479.4469318606546]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"111\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"120\": {\"seed\": 4}, \"176\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}}, \"seed_widgets\": {\"25\": 0, \"111\": 1, \"120\": 4, \"176\": 3}}}",
                "steps": 40,
                "models": [],
                "prompt": "Photorealistic photography of a stunning beauty, close-up, mouth focus, extremely high detail, intricate textures, extremely dark surrounding, extremely low light, nighttime setting, ultra realistic shadows, ethereal, flowing hair illuminated by glowing butterflies, seductive smile, looking at viewer while playing with her hair,  vibrant colors, dreamlike atmosphere, captivating expression, magical forest background, fiery glow, enchanted lighting, expressive eyes reflecting the glowing light, soft, ethereal glow around the figure, delicate and detailed facial features, golden light, intricate patterns in the background\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
                "denoise": 1,
                "sampler": "DPM2",
                "cfgScale": 3,
                "modelIds": [],
                "scheduler": "simple",
                "upscalers": [
                    "4x-UltraSharp.pth"
                ],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux1\\Madison_Beer_For_Flux.safetensors",
                        "type": "lora",
                        "strength": 1,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux1\\flux_realism_lora.safetensors",
                        "type": "lora",
                        "strength": 0.75,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "salammy",
            "baseModel": null
        },
        {
            "id": 22515477,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9ca9bfd9-16e8-45cc-93bf-9ef8e9cc5282/width=832/9ca9bfd9-16e8-45cc-93bf-9ef8e9cc5282.jpeg",
            "hash": "UCB|7]9ZNe-:~WIvR+xt?GI[WXn~-oWBxZRj",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-03T04:45:30.757Z",
            "postId": 5016989,
            "stats": {
                "cryCount": 4,
                "laughCount": 0,
                "likeCount": 333,
                "dislikeCount": 0,
                "heartCount": 46,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3463770096,
                "steps": 10,
                "prompt": "A captivating night scene illustration featuring Camelot large  hill overlooking a lake in Wales.   Camelot ancient but well maintained and updated and comfortable to live in.  This enchanting artwork captures a serene and peaceful early morning, where the sun is just starting to rise over the beautiful hills and Camelot  which   stands resolute amidst hills of Wales, creating a cinematic experience back to the times of King Arthur and his knights, \n illustration, cinematic\n<lora:DonM3t3rn1tyXL-v1.1:0.7>, DonM3t3rn1tyXL,\nOverallDetailXL  <lora:MJ52:0.3>  <lora:SDXLFaeTastic2400:0.4>  <lora:EpicF4nta5yXL:0.7>",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 2,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "DonM3t3rn1tyXL-v1.1",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "name": "MJ52",
                        "type": "lora",
                        "weight": 0.3
                    },
                    {
                        "name": "SDXLFaeTastic2400",
                        "type": "lora",
                        "weight": 0.4
                    },
                    {
                        "name": "EpicF4nta5yXL",
                        "type": "lora",
                        "weight": 0.7
                    }
                ],
                "Created Date": "2024-08-01T1713:49.4659197Z",
                "negativePrompt": "text, watermark, low quality, medium quality, blurry, censored, wrinkles, deformed, mutated text, watermark, low quality, medium quality, blurry, censored, wrinkles, deformed, mutated, BadDream-SDXL, FastNegativeV2-SDXL",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 128078,
                        "modelVersionName": "v1.0 VAE fix"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 283697,
                        "modelVersionName": "v1.2"
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 293991,
                        "modelVersionName": "v24"
                    },
                    {
                        "type": "lora",
                        "weight": 0.6,
                        "modelVersionId": 312413,
                        "modelVersionName": "SDXL_v1.1"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 560995,
                        "modelVersionName": "SDXL"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "artoriaspendraig",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 22313269,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9a160e6e-ea9a-4381-8931-9c9a34d1ed70/width=960/9a160e6e-ea9a-4381-8931-9c9a34d1ed70.jpeg",
            "hash": "UHEesBJCs+}@55%OIUNFR3RhjCRo%Mwf%4%2",
            "width": 960,
            "height": 1600,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-01T16:33:53.708Z",
            "postId": 4972950,
            "stats": {
                "cryCount": 22,
                "laughCount": 39,
                "likeCount": 214,
                "dislikeCount": 0,
                "heartCount": 108,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "VAE": "fixFP16ErrorsSDXLLowerMemoryUse_v10.safetensors",
                "Size": "768x1280",
                "seed": 4210363654,
                "Model": "realcartoonXL_v7",
                "steps": 40,
                "hashes": {
                    "vae": "3300950725",
                    "model": "d766a0808d"
                },
                "prompt": "Adorable ghost, glowing edges, colorful aura, soft smile, animated appearance, vibrant colors, smooth textures, whimsical ambiance, ultra-high resolution, gentle lighting, dark background, detailed character design, cinematic shot, close-up view, medium shot, wide-angle shot, playful expression, floating particles, ethereal glow, joyful atmosphere, balanced composition, dynamic pose, fluid motion, charming appeal, fantasy setting",
                "Version": "f1.0.2v1.10.1-previous-45-g40dd61ba",
                "sampler": "DPM++ 2M",
                "cfgScale": 9,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "d766a0808d",
                        "name": "realcartoonXL_v7",
                        "type": "model"
                    }
                ],
                "Model hash": "d766a0808d",
                "Extra noise": "0.1",
                "Hires upscale": "1.25",
                "Schedule type": "Karras",
                "Hires upscaler": "4x-UltraSharp",
                "negativePrompt": "Unnatural colors, pixelation, blur, noise, overexposure, harsh shadows, flat lighting, unrealistic textures, poor resolution, unbalanced composition, awkward pose, distorted proportions, distracting background elements, clutter, irrelevant objects, overly saturated colors, harsh contrast, artificial look, static and stiff pose, emotionless expression, lack of detail, unnatural lighting, unrealistic shadows, poorly defined features, inconsistent style, mismatched elements, lack of coherence, low detail, artificial colors, overexposed highlights, poor framing, awkward angle, disproportionate anatomy, irrelevant objects, harsh lighting, static composition, unrealistic appearance, lack of nuance, mismatched style",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.5.1",
                "Denoising strength": "0.5",
                "ADetailer mask blur": "32",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer ControlNet model": "thibaud_xl_openpose [c7b9cadd]",
                "ADetailer ControlNet module": "dw_openpose_full",
                "ADetailer denoising strength": "0.5",
                "ADetailer inpaint only masked": "True"
            },
            "username": "salammy",
            "baseModel": "SDXL 1.0"
        }
    ],
    "metadata": {
        "nextCursor": "12900|1727677502809",
        "nextPage": "https://civitai.com/api/v1/images?sort=Most%20Reactions&nsfw=Soft&cursor=12900%7C1727677502809"
    }
}