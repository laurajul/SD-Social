{
    "items": [
        {
            "id": 14845635,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/08436af0-f078-4f8d-a4e6-d6f79d0ca911/width=896/08436af0-f078-4f8d-a4e6-d6f79d0ca911.jpeg",
            "hash": "UB8|#09GM{xt~p9akBt6t6M{%MWVIUjZ-pM|",
            "width": 896,
            "height": 1152,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-06T17:16:07.686Z",
            "postId": 3293449,
            "stats": {
                "cryCount": 82,
                "laughCount": 95,
                "likeCount": 735,
                "dislikeCount": 0,
                "heartCount": 223,
                "commentCount": 0
            },
            "meta": {
                "Size": "896x1152",
                "seed": 750690149069392,
                "Model": "zavychromaxl_v70",
                "steps": 30,
                "hashes": {
                    "model": "3e0a3274d0"
                },
                "prompt": "unknown",
                "Version": "ComfyUI",
                "sampler": "euler_ancestral_exponential",
                "CFG Scale": "5.0",
                "resources": [
                    {
                        "hash": "3e0a3274d0",
                        "name": "zavychromaxl_v70",
                        "type": "model"
                    }
                ],
                "Model hash": "3e0a3274d0",
                "negativePrompt": "unknown"
            },
            "username": "OceanMadness",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 14655601,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/25dd7149-98ee-4f86-875f-aa3d077deac2/width=896/25dd7149-98ee-4f86-875f-aa3d077deac2.jpeg",
            "hash": "UJL#8[~pt9tT^hw]-=S%%MM{aLxvT0Sh?G%0",
            "width": 896,
            "height": 1584,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-05T04:15:49.736Z",
            "postId": 3253900,
            "stats": {
                "cryCount": 42,
                "laughCount": 65,
                "likeCount": 794,
                "dislikeCount": 0,
                "heartCount": 234,
                "commentCount": 0
            },
            "meta": {
                "VAE": "sdxl_vae.safetensors",
                "Size": "896x1584",
                "seed": 198351883,
                "Model": "colorfulxl_v27",
                "steps": 20,
                "hashes": {
                    "vae": "e9ed949371",
                    "model": "5effeca93b",
                    "lora:zavy-nfrrd-sdxl": "a43f1c1ff50b",
                    "lora:Colorful_Paint_SDXL": "f22e68522022",
                    "lora:artfullyWHIMSICAL_SDXL_V1": "067a2025e85e",
                    "lora:artfullyTREETTREET_SDXL_V1": "abddfe63157e"
                },
                "prompt": "<lora:artfullyWHIMSICAL_SDXL_V1:1>, artwhmscl,surreal painting, Calais from William Turner, snow storm, pastel colors,    <lora:artfullyTREETTREET_SDXL_V1:1.2> Arttrttrt  <lora:Colorful_Paint_SDXL:1> mad-thrdpnt <lora:zavy-nfrrd-sdxl:1> zavy-nffrd",
                "Version": "v1.9.4",
                "sampler": "DPM++ 2M",
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "067a2025e85e",
                        "name": "artfullyWHIMSICAL_SDXL_V1",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "abddfe63157e",
                        "name": "artfullyTREETTREET_SDXL_V1",
                        "type": "lora",
                        "weight": 1.2
                    },
                    {
                        "hash": "f22e68522022",
                        "name": "Colorful_Paint_SDXL",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "a43f1c1ff50b",
                        "name": "zavy-nfrrd-sdxl",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "5effeca93b",
                        "name": "colorfulxl_v27",
                        "type": "model"
                    }
                ],
                "Model hash": "5effeca93b",
                "Schedule type": "Karras"
            },
            "username": "Weak_Examination",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 35392496,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bba4f258-5a5e-4113-bba7-a0bef55fbebe/width=832/bba4f258-5a5e-4113-bba7-a0bef55fbebe.jpeg",
            "hash": "UED]$7^jpf$%JGRjERS%%3WE9uNH%iOsaIxZ",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-19T07:54:02.920Z",
            "postId": 8087996,
            "stats": {
                "cryCount": 67,
                "laughCount": 84,
                "likeCount": 741,
                "dislikeCount": 0,
                "heartCount": 242,
                "commentCount": 7
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3828033918,
                "extra": {
                    "remixOfId": 33622314
                },
                "steps": 28,
                "prompt": "In a hyper-realistic **ne0nfant4sy** vision, the **chrome-clad figure** leans forward, one foot stepping ahead in a stance of quiet readiness. Their right hand grips the brim of the **chrome silver non la**, revealing just a sliver of their face\u2014sharp, angular features accented by **chrome-plated cheekbones and jawline**, giving them a sleek **mechanical-human hybrid** appearance. The **metallic tassels** flow forward, as if caught in motion, partially obscuring the rest of the face beneath the hat, heightening the character's sense of anonymity. The sleeveless **chrome robe**, glossy and reflective, ripples gently in the air, catching vibrant streaks of **neon blue light** from the glowing backdrop. The intricate, **glowing silver tattoo** on the exposed left arm contrasts against the polished chrome surface, its fine details pulsing with an ethereal glow. The figure radiates readiness, their stance poised for imminent action, embodying a fusion of **futuristic technology** and **traditional elegance**, standing out against the surreal neon landscape.\n ((glow_skin,iridescent skin,oily skin,portrait, Detailed hand, Hand, Perfect hand, in the style of Jed-clrfl, surreal photo, iridescent, aesthetic))",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-10-19T0752:45.6900240Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 908156,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 804967,
                        "modelVersionName": "Hand F1D v2.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 827995,
                        "modelVersionName": "V2"
                    },
                    {
                        "type": "lora",
                        "weight": 0.4,
                        "modelVersionId": 813863,
                        "modelVersionName": "v1"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 959406,
                        "modelVersionName": "FLUX V2"
                    }
                ]
            },
            "username": "Nixst3r",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 31955000,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7ca3c462-2827-4eab-885a-8733cda6c905/width=1280/7ca3c462-2827-4eab-885a-8733cda6c905.jpeg",
            "hash": "U59=?O5l0y}s-A1JWA,?vzJ7kqNa#T=dS~I:",
            "width": 1280,
            "height": 2048,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-09-29T17:55:20.056Z",
            "postId": 7275258,
            "stats": {
                "cryCount": 34,
                "laughCount": 89,
                "likeCount": 738,
                "dislikeCount": 0,
                "heartCount": 273,
                "commentCount": 1
            },
            "meta": {
                "seed": 1183585062,
                "steps": 35,
                "prompt": "score_9,score_8_up,score_7_up,\nOverall Detail,(best quality:1.1),(masterpiece:1.2),(detailed:1.1),(highres, best quality:1.2),(ultra HD quality details)(anime_source) (dynamic angle) very aesthetic,rating_questionable,uncensored,\n<lora:YunYingPonyTR:1>,yunying,1girl,solo,\nblack hair,wrapped in bandages,(bare shoulders:1.3),(shoulders:1.5),\nmedium breasts,collarbone visible,\nsweat glistening,navel,(blood:0.2),(injured:0.8),((fire)),flame background,hair,hair between eyes,((blood)),(((too many scars))),\nstraight_hair,(((((very long hair))))),portrait center,wind-blown hair,wind,hair floating free,deadpan,\nthe arm is covered with bandages,((blood on bandages)),scrabbed,complex background details,exaggerated special effects,human  purgatory,(bare arms:1.9),a cold expression,\nscreen burning,(((blood in the chest))),huge filesize,wallpaper,game cg,(((wounding on the face))),(((there is blood on the face))),full of scars,scars and bruises,(bruise:1.4),(injury:1.5),bare legs,(bandaged leg:1.3),\n(barefoot:1.6),full_shot,(standing:1.3),Dynamic Angle,(magnifire:1.1),flame ground,(flame background:1.4),the picture is full of fire,a      woman born of fire,bandage  panties,fighting_stance,a heroic gesture,handsome posture,(gorgeous action:1.2),\nAdd flames on the ground and in the sky,creating a fiery landscape.,fisheye,foreshortening,cinematic_angle,\ncool pose,confident,elegant movement,fluid,dynamic,heroic,confident,graceful,(holding_spear:1.6),\n(fire:1.2),dark,flame wings,undead bird,fire phoenix,",
                "sampler": "Euler a",
                "cfgScale": 5,
                "negativePrompt": "score_6,score_5,score_4,skin blemishes,skin spots,acnes,bad hands,missing fingers,hair_ornament,facial bandage,facial impurities,ugly,mutated,bad action,poorly drawn hands,mutated hands,malformed hands,mutation,wrong hand posture,bad action,not enough gorgeous action,hand-held posture error,bad feet,extra legs,missing limb,floating limbs,disconnected limbs,bad anatomy,low quality,lowres,normal quality,"
            },
            "username": "HS_hi",
            "baseModel": null
        },
        {
            "id": 31186458,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0de7a4ad-f435-455c-a63a-b2b7d9808a46/width=1344/0de7a4ad-f435-455c-a63a-b2b7d9808a46.jpeg",
            "hash": "UBBVFl}s0z0z^6^PxG0}=x-VnO9]}@xGI:WW",
            "width": 1344,
            "height": 1728,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-25T00:10:00.000Z",
            "postId": 6970998,
            "stats": {
                "cryCount": 28,
                "laughCount": 64,
                "likeCount": 823,
                "dislikeCount": 0,
                "heartCount": 218,
                "commentCount": 1
            },
            "meta": {
                "Size": "896x1152",
                "seed": 2423608775,
                "Model": "flux1-dev-bnb-nf4-v2",
                "steps": 35,
                "hashes": {
                    "model": "bea01d51bd",
                    "lora:artisketchyfs-v02": "2097f7b0e740",
                    "lora:dark_fantasy_flux": "6E5F580C0E",
                    "lora:FredFraiStyle-FLUX-Share": "63BFAA1CF9",
                    "lora:flux.1_lora_flyway_Epic-Characters_v1": "B73E077D02BF"
                },
                "Version": "f2.0.1v1.10.1-previous-450-gdb6448df",
                "sampler": "Euler",
                "cfgScale": 1,
                "resources": [
                    {
                        "hash": "B73E077D02BF",
                        "name": "flux.1_lora_flyway_Epic-Characters_v1",
                        "type": "lora"
                    },
                    {
                        "hash": "2097f7b0e740",
                        "name": "artisketchyfs-v02",
                        "type": "lora"
                    },
                    {
                        "hash": "63BFAA1CF9",
                        "name": "FredFraiStyle-FLUX-Share",
                        "type": "lora"
                    },
                    {
                        "hash": "6E5F580C0E",
                        "name": "dark_fantasy_flux",
                        "type": "lora"
                    },
                    {
                        "hash": "bea01d51bd",
                        "name": "flux1-dev-bnb-nf4-v2",
                        "type": "model"
                    }
                ],
                "Model hash": "bea01d51bd",
                "Hires steps": "20",
                "Hires upscale": "1.5",
                "Schedule type": "Normal",
                "Hires upscaler": "4x-UltraSharp",
                "Denoising strength": "0.35",
                "Distilled CFG Scale": "3.5",
                "Diffusion in Low Bits": "Automatic (fp16 LoRA)"
            },
            "username": "ArtifyAI",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 30411384,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1f5071ca-b357-4b1c-aed5-4ce53d816141/width=768/1f5071ca-b357-4b1c-aed5-4ce53d816141.jpeg",
            "hash": "UDGHI,5r0Ov}~oNe^2NH0gjG?FtQ02Ip?Fxt",
            "width": 768,
            "height": 1280,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-20T12:50:00.105Z",
            "postId": 6804326,
            "stats": {
                "cryCount": 33,
                "laughCount": 66,
                "likeCount": 773,
                "dislikeCount": 0,
                "heartCount": 261,
                "commentCount": 4
            },
            "meta": {
                "Size": "768x1280",
                "seed": 299970948807459,
                "Model": "flux1-dev-fp8",
                "steps": 22,
                "hashes": {
                    "model": "",
                    "LORA:flux1-D\\Aura_Flux-000010.safetensors": "f543c903cb",
                    "LORA:flux1-D\\flux.1_lora_flyway_Epic-detail_v2": "df61e68b14"
                },
                "prompt": "Stills from the fantasy film show a sexy woman in a tight white combat suit riding on the back of a white tiger with huge wings, flying in the air, followed by dynamic and dreamy flames, and the whole picture exudes the surreal and dreamlike quality typical of fantasy films.<lora:flux1-D\\flux.1_lora_flyway_Epic-detail_v2:1.0> <lora:flux1-D\\Aura_Flux-000010.safetensors:0.8:0.8>",
                "Version": "ComfyUI",
                "sampler": "Euler",
                "cfgScale": 3.5,
                "resources": [],
                "Model hash": ""
            },
            "username": "flyway",
            "baseModel": null
        },
        {
            "id": 24019882,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/726b41ed-b83b-4e4e-866c-21704d225045/width=1664/726b41ed-b83b-4e4e-866c-21704d225045.jpeg",
            "hash": "USHLMF5Y-;XT_4OZE2oz59OEE2f+9cniw|n#",
            "width": 1664,
            "height": 2496,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-12T23:55:27.329Z",
            "postId": 5359571,
            "stats": {
                "cryCount": 28,
                "laughCount": 63,
                "likeCount": 770,
                "dislikeCount": 0,
                "heartCount": 272,
                "commentCount": 0
            },
            "meta": {
                "RNG": "CPU",
                "VAE": "sdxl_vae.safetensors",
                "Size": "832x1248",
                "seed": 2799752386,
                "Model": "hosekiLustrousmixPony_v10",
                "steps": 28,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "182c96501c",
                    "lora:asiaargento-pdxl-nvwls-v1-000005": "e723fd05852c"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime, 1girl, solo, <lora:asiaargento-pdxl-nvwls-v1-000005:1> dxdaa, blonde hair, very long hair, green eyes, white veil, black dress, long sleeves, big breasts, looking at you, upper body, blue sky, smile, sunset",
                "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
                "sampler": "Euler a",
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "e723fd05852c",
                        "name": "asiaargento-pdxl-nvwls-v1-000005",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "182c96501c",
                        "name": "hosekiLustrousmixPony_v10",
                        "type": "model"
                    }
                ],
                "Model hash": "182c96501c",
                "Hires steps": "10",
                "Hires upscale": "2",
                "Schedule type": "Automatic",
                "Hires upscaler": "4x-AnimeSharp",
                "negativePrompt": "monochrome",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.4.2",
                "Denoising strength": "0.5",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "novowels",
            "baseModel": "Pony"
        },
        {
            "id": 10056105,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/688a5a47-1e18-4ce6-a4e0-616df8e7b46c/width=1216/688a5a47-1e18-4ce6-a4e0-616df8e7b46c.jpeg",
            "hash": "UAFiSw~U0P0M^%-n9c5SKQ-6m+9}yEae-:R*",
            "width": 1216,
            "height": 832,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-04-17T00:54:57.463Z",
            "postId": 2190332,
            "stats": {
                "cryCount": 30,
                "laughCount": 92,
                "likeCount": 714,
                "dislikeCount": 0,
                "heartCount": 297,
                "commentCount": 2
            },
            "meta": {
                "Size": "1216x832",
                "seed": 1388884324,
                "steps": 35,
                "prompt": "carving style artwork, Impasto style painting of a sailing boat in the middle of the ocean, with a Zentangle-style background, high detail, fine brush strokes, traditional art, golden palette, dynamic composition, artstation, 4k resolution, masterpiece",
                "sampler": "DPM++ 2M",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "negativePrompt": "(worst_quality:1.4), watermark, signature, title, text, FastNegativeV2-SDXL,bad body, bad proportions, ugly,2d,flat,bad hands,deform",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 345685
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 344283
                    },
                    {
                        "type": "vae",
                        "weight": 1,
                        "modelVersionId": 177586
                    }
                ]
            },
            "username": "jose9286",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 9062177,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0ffc5fe3-2219-483f-adf4-50f89230d514/width=832/0ffc5fe3-2219-483f-adf4-50f89230d514.jpeg",
            "hash": "UGGh]15#1q}d?1nhEw=gOYOEExwcxGxIwhJ5",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-04-03T08:51:23.319Z",
            "postId": 1957088,
            "stats": {
                "cryCount": 49,
                "laughCount": 67,
                "likeCount": 708,
                "dislikeCount": 0,
                "heartCount": 309,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1530946167,
                "steps": 40,
                "prompt": "1man, katana, neon city, futuristic setting, badass, corpses and blood on the ground, epic, ((cyberpunk)), cataclysmic, absurdres, best quality, digital art style",
                "sampler": "DPM++ 2M",
                "cfgScale": 10,
                "clipSkip": 2,
                "resources": [],
                "negativePrompt": "3d, low quality, worst quality,  mutation, deformed hands, colors, ( three arms or more, three hands or more, three legs or more, three feet or more, comics style:1.6)",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 128078
                    }
                ]
            },
            "username": "GhostGirlLover68",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 6926568,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fc8c7c28-9fab-4c95-a409-1becd80af28f/width=832/fc8c7c28-9fab-4c95-a409-1becd80af28f.jpeg",
            "hash": "UAIO5^0K4mo~$dn#ads.-.^*?HIn~qDh9Z%2",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-21T15:42:36.650Z",
            "postId": 1494450,
            "stats": {
                "cryCount": 25,
                "laughCount": 290,
                "likeCount": 480,
                "dislikeCount": 0,
                "heartCount": 338,
                "commentCount": 5
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1924929587,
                "steps": 47,
                "prompt": "a lot of cats take a selfie, \nphotography very realist",
                "sampler": "Euler a",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "negativePrompt": "ugly, deformed, noisy, blurry, distorted, out of focus, bad anatomy, extra limbs, poorly drawn face, poorly drawn hands, missing fingers,text, logo, signature, letter,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 201514
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 97691
                    }
                ]
            },
            "username": "stephdg453",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 1819613,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f0b1dd0b-f9ff-4546-a96f-2d8e71c15c6b/width=720/f0b1dd0b-f9ff-4546-a96f-2d8e71c15c6b.jpeg",
            "hash": "UDF6Ifks%htS?wNFayo#0KxZMwkCE3%2RPjE",
            "width": 720,
            "height": 1280,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2023-12-23T17:54:59.964Z",
            "postId": 451014,
            "stats": {
                "cryCount": 16,
                "laughCount": 65,
                "likeCount": 605,
                "dislikeCount": 0,
                "heartCount": 447,
                "commentCount": 15
            },
            "meta": null,
            "username": "neiro_nimfa",
            "baseModel": "SD 1.5"
        },
        {
            "id": 34758074,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9974fcb6-cf19-4cf2-8434-22aba9f45d6b/width=1592/9974fcb6-cf19-4cf2-8434-22aba9f45d6b.jpeg",
            "hash": "UA8gTz~BjER*?axani%1t7R*jYxabHWBkCNI",
            "width": 1592,
            "height": 2400,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-15T16:27:45.263Z",
            "postId": 7942837,
            "stats": {
                "cryCount": 48,
                "laughCount": 63,
                "likeCount": 833,
                "dislikeCount": 0,
                "heartCount": 188,
                "commentCount": 1
            },
            "meta": null,
            "username": "Castr0",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 15461101,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7315630e-1d59-4c26-92b3-919fd0efa033/width=1664/7315630e-1d59-4c26-92b3-919fd0efa033.jpeg",
            "hash": "U5CGD40LHa-:0jn602%fv602%d~oNs^%-:NK",
            "width": 1664,
            "height": 2304,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-11T23:39:42.089Z",
            "postId": 3441179,
            "stats": {
                "cryCount": 31,
                "laughCount": 88,
                "likeCount": 717,
                "dislikeCount": 0,
                "heartCount": 296,
                "commentCount": 3
            },
            "meta": {
                "seed": 1028711018009152,
                "steps": 4,
                "prompt": "marketplace, casing,lunar landscape,moss-covered logs,root-like eclipse chaos asian drake-like Coatl,   translucent ,\n,Crochet craft style, versatile and creative, yarn",
                "sampler": "DPM++ SDE Karras",
                "cfgScale": 1
            },
            "username": "green21st",
            "baseModel": "SDXL Lightning"
        },
        {
            "id": 20158546,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d465e643-67c5-4a86-8918-711446708087/width=512/d465e643-67c5-4a86-8918-711446708087.jpeg",
            "hash": "UaI|~}?bM|%0~p?aRkM{ozxuofM{tRfjoLt7",
            "width": 512,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-17T00:25:06.226Z",
            "postId": 4497306,
            "stats": {
                "cryCount": 13,
                "laughCount": 60,
                "likeCount": 767,
                "dislikeCount": 0,
                "heartCount": 291,
                "commentCount": 0
            },
            "meta": null,
            "username": "ryosakasaka619720",
            "baseModel": ""
        },
        {
            "id": 16756146,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8d221068-703f-4739-b11b-071b48de14c3/width=1344/8d221068-703f-4739-b11b-071b48de14c3.jpeg",
            "hash": "UABy{ul:FzF|pyV?off+4,yYn3sCV?bcX8s9",
            "width": 1344,
            "height": 1728,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-22T16:12:24.593Z",
            "postId": 3759253,
            "stats": {
                "cryCount": 29,
                "laughCount": 78,
                "likeCount": 734,
                "dislikeCount": 0,
                "heartCount": 290,
                "commentCount": 2
            },
            "meta": {
                "Size": "1792x2304",
                "seed": 242946139762225,
                "Model": "snowpony_v10",
                "steps": 75,
                "hashes": {
                    "model": "d6f941b46b",
                    "embed:PONY\\zPDXL2-neg": "29dc1b9b1a",
                    "LORA:Style\\BioPunky PDXL.safetensors": "a26e817198",
                    "LORA:Style\\GlowNeon SDXL.safetensors": "4e114aeeff",
                    "LORA:Style\\Neon Noir PDXL.safetensors": "8d207c5aeb",
                    "LORA:Style\\Midjourney Mimic SDXL.safetensors": "e526855052",
                    "LORA:General\\DetailedEyes XL V3.0.safetensors": "2c1c3f889f",
                    "LORA:Style\\Aether Ghost SDXL V1.1.safetensors": "402f8fd4d9",
                    "LORA:General\\Detail Tweaker XL V1.0.safetensors": "0d9bd1b873",
                    "LORA:Style\\Real Mechanical Parts PDXL.safetensors": "4b32cdcdb1",
                    "LORA:General\\Sinfully Stylish SDXL V0.1.safetensors": "033c44dfb8",
                    "LORA:Style\\Vixon's Pony Styles Colour Glow.safetensors": "c9cdc96144",
                    "LORA:Character\\Clothing\\Laser Light Clothes PDXL.safetensors": "b4e62fca84",
                    "LORA:Character\\Archetypes\\Slime Girl Concept PDXL.safetensors": "509a832032",
                    "LORA:Character\\Archetypes\\Wizardslimus Slime Girl PDXL.safetensors": "d8bfd98067",
                    "LORA:Concepts\\Translucent - Subsurface Scattering Test.safetensors": "064a59daeb"
                },
                "Version": "ComfyUI",
                "sampler": "DPM++ 2M SDE",
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "d6f941b46b",
                        "name": "snowpony_v10",
                        "type": "model"
                    }
                ],
                "Model hash": "d6f941b46b"
            },
            "username": "AnimePorn",
            "baseModel": "Pony"
        },
        {
            "id": 40931728,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5ade378d-b498-448e-a20a-1d8e8603a67b/width=832/5ade378d-b498-448e-a20a-1d8e8603a67b.jpeg",
            "hash": "UeN,SYMxpw-p~VM_x^W;NytQoNtS-:ogR*xu",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-19T10:14:14.901Z",
            "postId": 9324979,
            "stats": {
                "cryCount": 42,
                "laughCount": 76,
                "likeCount": 761,
                "dislikeCount": 0,
                "heartCount": 251,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "nsfw": false,
                "seed": 1760073478,
                "draft": false,
                "extra": {
                    "remixOfId": 39926723
                },
                "steps": 30,
                "width": 832,
                "height": 1216,
                "prompt": "1girl,leafa, teeth, lips, thin lips, solo, looking at viewer, open mouth, upper body, masterpiece, best quality, very aesthetic",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 5,
                "clipSkip": 2,
                "quantity": 4,
                "workflow": "txt2img",
                "baseModel": "SDXL",
                "resources": [],
                "Created Date": "2024-11-18T0854:04.1626945Z",
                "negativePrompt": "worst quality, low quality, displeasing, text, watermark, bad anatomy,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 1046043,
                        "modelVersionName": "V-Pred-0.5-Version"
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 1036362,
                        "modelVersionName": "v4_noobEv1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 318562,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 106916,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "ArtomYT",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 38396662,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ae72a520-fc7b-4fd6-a9fa-48decb477dc2/width=832/ae72a520-fc7b-4fd6-a9fa-48decb477dc2.jpeg",
            "hash": "U5FFZ|~q000L+Ht6019GlUX9Q,-UKjozMJIA",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-05T09:00:00.000Z",
            "postId": 8765628,
            "stats": {
                "cryCount": 56,
                "laughCount": 86,
                "likeCount": 748,
                "dislikeCount": 0,
                "heartCount": 240,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2248229830,
                "extra": {
                    "remixOfId": 37815608
                },
                "steps": 4,
                "prompt": "upper body portrait, one pale woman (supermodel) head lowered bt eyes looking at viewer, sultry expression, long white hair, piercing eyes, seductive, charming woman, charmful looking, captivating, minimalist, slender frame, detailed, wool jumper",
                "sampler": "Undefined",
                "cfgScale": 1,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-11-05T0122:57.8119018Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 699279,
                        "modelVersionName": "Schnell"
                    }
                ]
            },
            "username": "Aliciaw90",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 28463292,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/502be540-f59c-4297-bf7d-6310494413a5/width=1800/502be540-f59c-4297-bf7d-6310494413a5.jpeg",
            "hash": "UMB|d4M{00%g~pWB9Gt7Z#ofX9RjMdRjtRoz",
            "width": 2112,
            "height": 4032,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-09T00:56:14.042Z",
            "postId": 6367791,
            "stats": {
                "cryCount": 31,
                "laughCount": 69,
                "likeCount": 759,
                "dislikeCount": 0,
                "heartCount": 271,
                "commentCount": 2
            },
            "meta": {
                "seed": 117,
                "vaes": [
                    "ae-dev.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 1], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"flux-tm/fluxtm_pass1\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"10\": {\"inputs\": {\"vae_name\": \"ae-dev.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp16.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux1-dev.sft\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"149\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"88\", 1], \"latent_image\": [\"32\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 35, \"denoise\": 1.0, \"model\": [\"152\", 0]}, \"class_type\": \"BasicScheduler\"}, \"25\": {\"inputs\": {\"noise_seed\": 117}, \"class_type\": \"RandomNoise\"}, \"32\": {\"inputs\": {\"resolution\": \"704x1344 (0.52)\", \"batch_size\": 1, \"width_override\": 0, \"height_override\": 0}, \"class_type\": \"SDXLEmptyLatentSizePicker+\"}, \"88\": {\"inputs\": {\"step\": 0, \"sigmas\": [\"17\", 0]}, \"class_type\": \"SplitSigmas\"}, \"113\": {\"inputs\": {\"blur_radius\": 2, \"sigma\": 2.0, \"image\": [\"177\", 0]}, \"class_type\": \"ImageBlur\"}, \"114\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.5, \"alpha\": 0.39999999999999997, \"image\": [\"177\", 0]}, \"class_type\": \"ImageSharpen\"}, \"115\": {\"inputs\": {\"blend_factor\": 0.39999999999999997, \"blend_mode\": \"normal\", \"image1\": [\"113\", 0], \"image2\": [\"114\", 0]}, \"class_type\": \"ImageBlend\"}, \"123\": {\"inputs\": {\"images\": [\"129\", 0]}, \"class_type\": \"PreviewImage\"}, \"129\": {\"inputs\": {\"blend_factor\": 0.5, \"blend_mode\": \"overlay\", \"image1\": [\"115\", 0], \"image2\": [\"130\", 0]}, \"class_type\": \"ImageBlend\"}, \"130\": {\"inputs\": {\"image\": \"noise_1.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"99e01496bc4d77d83110b432080d06ba6c2b4c47506185d5e017ecd823f26712\"]}, \"131\": {\"inputs\": {\"width\": 2048, \"height\": 2048, \"interpolation\": \"bilinear\", \"method\": \"keep proportion\", \"condition\": \"always\", \"multiple_of\": 16}, \"class_type\": \"ImageResize+\"}, \"133\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"interpolation\": \"bicubic\", \"method\": \"keep proportion\", \"condition\": \"always\", \"multiple_of\": 16, \"image\": [\"145\", 0]}, \"class_type\": \"ImageResize+\"}, \"135\": {\"inputs\": {\"pixels\": [\"133\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"145\": {\"inputs\": {\"image\": \"2024-09-08_20-40-38_6586.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"2da0658ab5ff44b0775c5183ebd06aeb86ebe0a796f32d976033229692fd4ad1\"]}, \"149\": {\"inputs\": {\"model\": [\"152\", 0], \"conditioning\": [\"241\", 0]}, \"class_type\": \"BasicGuider\"}, \"152\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": [\"32\", 1], \"height\": [\"32\", 2], \"model\": [\"249\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"159\": {\"inputs\": {\"filename_prefix\": \"flux-tm/fluxtm_pass2\", \"images\": [\"177\", 0]}, \"class_type\": \"SaveImage\"}, \"162\": {\"inputs\": {\"max_shift\": 0.9349999999999999, \"base_shift\": 0.96, \"width\": [\"169\", 0], \"height\": [\"170\", 0], \"model\": [\"249\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"168\": {\"inputs\": {\"image\": [\"8\", 0]}, \"class_type\": \"GetImageSize+\"}, \"169\": {\"inputs\": {\"value\": \"a*b\", \"a\": [\"168\", 0], \"b\": [\"206\", 0]}, \"class_type\": \"SimpleMath+\"}, \"170\": {\"inputs\": {\"value\": \"a*b\", \"a\": [\"168\", 1], \"b\": [\"206\", 0]}, \"class_type\": \"SimpleMath+\"}, \"171\": {\"inputs\": {\"noise\": [\"175\", 0], \"guider\": [\"176\", 0], \"sampler\": [\"247\", 0], \"sigmas\": [\"174\", 1], \"latent_image\": [\"179\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"172\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"173\": {\"inputs\": {\"scheduler\": \"beta\", \"steps\": 20, \"denoise\": 0.52, \"model\": [\"162\", 0]}, \"class_type\": \"BasicScheduler\"}, \"174\": {\"inputs\": {\"step\": 0, \"sigmas\": [\"173\", 0]}, \"class_type\": \"SplitSigmas\"}, \"175\": {\"inputs\": {\"noise_seed\": 4390}, \"class_type\": \"RandomNoise\"}, \"176\": {\"inputs\": {\"model\": [\"162\", 0], \"conditioning\": [\"241\", 0]}, \"class_type\": \"BasicGuider\"}, \"177\": {\"inputs\": {\"samples\": [\"171\", 1], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"179\": {\"inputs\": {\"upscale_method\": \"bicubic\", \"scale_by\": [\"206\", 0], \"samples\": [\"13\", 1]}, \"class_type\": \"LatentUpscaleBy\"}, \"180\": {\"inputs\": {\"text\": \"hyper-detailed, 4k, High-contrast fantasy illustration, sharp details, showing a majestic white fox with multiple flowing tails perched gracefully on a twisted rock. The fox's glowing amber eyes reflect the eerie light of the full moon, which dominates the misty, night sky. Surrounding the scene are ancient, gnarled trees adorned with fiery red leaves that flutter delicately in the breeze. The moonlight casts a soft glow, highlighting the fox's ethereal fur, while the dark branches and vibrant leaves create a striking contrast, framing the mystical creature in a hauntingly beautiful forest.\\n\\n\\n\\n\\n\\n\"}, \"class_type\": \"Text Multiline\"}, \"182\": {\"inputs\": {\"upscale_model\": [\"183\", 0], \"image\": [\"177\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"183\": {\"inputs\": {\"model_name\": \"002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"190\": {\"inputs\": {\"image\": \"noise_1.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"99e01496bc4d77d83110b432080d06ba6c2b4c47506185d5e017ecd823f26712\"]}, \"193\": {\"inputs\": {\"blend_factor\": 0.585, \"blend_mode\": \"overlay\", \"image1\": [\"201\", 0], \"image2\": [\"190\", 0]}, \"class_type\": \"ImageBlend\"}, \"195\": {\"inputs\": {\"red_offset\": 2, \"green_offset\": -1, \"blue_offset\": 1, \"intensity\": 0.145, \"fade_radius\": 12, \"image\": [\"197\", 0]}, \"class_type\": \"Image Chromatic Aberration\"}, \"197\": {\"inputs\": {\"radius\": 7.5, \"intensity\": 0.15, \"image\": [\"182\", 0]}, \"class_type\": \"Image Bloom Filter\"}, \"200\": {\"inputs\": {\"vignette_shape\": \"oval\", \"feather_amount\": 290, \"x_offset\": 0, \"y_offset\": 0, \"zoom\": 1.4000000000000001, \"reverse\": \"no\", \"image\": [\"232\", 0]}, \"class_type\": \"CR Vignette Filter\"}, \"201\": {\"inputs\": {\"lens_shape\": \"circle\", \"lens_edge\": \"around\", \"lens_curvy\": 8.0, \"lens_zoom\": 2.0, \"lens_aperture\": 0.3, \"blur_intensity\": 20, \"images\": [\"203\", 0]}, \"class_type\": \"MX_LensOpticAxis\"}, \"202\": {\"inputs\": {\"blades_shape\": 5, \"blades_radius\": 5, \"blades_rotation\": 0.0, \"blur_size\": 21, \"blur_type\": \"bilateral\", \"method\": \"dilate\", \"images\": [\"200\", 0]}, \"class_type\": \"MX_LensBokeh\"}, \"203\": {\"inputs\": {\"blend_factor\": 0.25, \"blend_mode\": \"overlay\", \"image1\": [\"200\", 0], \"image2\": [\"202\", 0]}, \"class_type\": \"ImageBlend\"}, \"206\": {\"inputs\": {\"Number\": \"1.5\"}, \"class_type\": \"Float\"}, \"213\": {\"inputs\": {\"filename_prefix\": \"flux-tm/fluxtm_pass3\", \"images\": [\"233\", 0]}, \"class_type\": \"SaveImage\"}, \"214\": {\"inputs\": {\"upscale_model\": [\"215\", 0], \"image\": [\"8\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"215\": {\"inputs\": {\"model_name\": \"002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"216\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.75, \"image\": [\"214\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"217\": {\"inputs\": {\"pixels\": [\"216\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"229\": {\"inputs\": {\"images\": [\"235\", 0]}, \"class_type\": \"PreviewImage\"}, \"232\": {\"inputs\": {\"brightness\": 0.0, \"contrast\": 1.0, \"saturation\": 0.8999999999999999, \"sharpness\": 1.0, \"blur\": 0, \"gaussian_blur\": 0.5, \"edge_enhance\": 0.0, \"detail_enhance\": \"false\", \"image\": [\"195\", 0]}, \"class_type\": \"Image Filter Adjustments\"}, \"233\": {\"inputs\": {\"noise_radius\": 7, \"preserve_edges\": 0.6, \"sharpen\": 4.0, \"ratio\": 0.3, \"image\": [\"193\", 0]}, \"class_type\": \"ImageSmartSharpen+\"}, \"235\": {\"inputs\": {\"noise_radius\": 7, \"preserve_edges\": 0.09999999999999999, \"sharpen\": 5.0, \"ratio\": 0.3, \"image\": [\"177\", 0]}, \"class_type\": \"ImageSmartSharpen+\"}, \"241\": {\"inputs\": {\"clip_l\": \" hyper-detailed, 4k, Fantasy illustration, white fox with glowing eyes, full moon, red leaves, gnarled trees, ethereal night forest.\", \"t5xxl\": [\"180\", 0], \"guidance\": 3.0, \"clip\": [\"249\", 1]}, \"class_type\": \"CLIPTextEncodeFlux\"}, \"245\": {\"inputs\": {\"lora_name\": \"flux\\\\FluxDFaeTasticDetails.safetensors\", \"strength_model\": 0.75, \"model\": [\"12\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"246\": {\"inputs\": {\"red_shift\": 0, \"red_direction\": \"horizontal\", \"green_shift\": 0, \"green_direction\": \"horizontal\", \"blue_shift\": 0, \"blue_direction\": \"horizontal\"}, \"class_type\": \"ChromaticAberration\"}, \"247\": {\"inputs\": {\"solver\": \"bosh3\", \"log_relative_tolerance\": -2.5, \"log_absolute_tolerance\": -3.5, \"max_steps\": 30}, \"class_type\": \"ODESamplerSelect\"}, \"249\": {\"inputs\": {\"lora_01\": \"flux\\\\Wraith_BW_Flux.safetensors\", \"strength_01\": 0.5, \"lora_02\": \"flux\\\\FluxDFaeTasticDetails.safetensors\", \"strength_02\": 0.7000000000000001, \"lora_03\": \"None\", \"strength_03\": 0.7000000000000001, \"lora_04\": \"None\", \"strength_04\": 1.0, \"model\": [\"250\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"Lora Loader Stack (rgthree)\"}, \"250\": {\"inputs\": {\"unet_name\": \"flux1-dev-Q8_0.gguf\"}, \"class_type\": \"UnetLoaderGGUF\"}}, \"workflow\": {\"last_node_id\": 263, \"last_link_id\": 738, \"nodes\": [{\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1062, \"1\": 25}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 649}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [270, 357, 461], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": -80, \"1\": 130}, \"size\": {\"0\": 210, \"1\": 60}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12, 273, 377, 465], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae-dev.sft\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 88, \"type\": \"SplitSigmas\", \"pos\": {\"0\": 550, \"1\": 570}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 201}], \"outputs\": [{\"name\": \"high_sigmas\", \"type\": \"SIGMAS\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"low_sigmas\", \"type\": \"SIGMAS\", \"links\": [574], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SplitSigmas\"}, \"widgets_values\": [0], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 113, \"type\": \"ImageBlur\", \"pos\": {\"0\": 5344.82470703125, \"1\": 863.5073852539062}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 379}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlur\"}, \"widgets_values\": [2, 2]}, {\"id\": 114, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 5344.82470703125, \"1\": 993.5073852539062}, \"size\": {\"0\": 210, \"1\": 110}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 380}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [245], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.5, 0.39999999999999997]}, {\"id\": 115, \"type\": \"ImageBlend\", \"pos\": {\"0\": 5644.82470703125, \"1\": 873.5073852539062}, \"size\": {\"0\": 210, \"1\": 102}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"image1\", \"type\": \"IMAGE\", \"link\": 244}, {\"name\": \"image2\", \"type\": \"IMAGE\", \"link\": 245}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [264], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlend\"}, \"widgets_values\": [0.39999999999999997, \"normal\"]}, {\"id\": 122, \"type\": \"ImageApplyLUT+\", \"pos\": {\"0\": 5644.82470703125, \"1\": 1023.5073852539062}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 59, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 264}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [441], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageApplyLUT+\"}, \"widgets_values\": [\"FGCineBasic.cube\", true, false, 0.25]}, {\"id\": 123, \"type\": \"PreviewImage\", \"pos\": {\"0\": 6410, \"1\": -1010}, \"size\": {\"0\": 940, \"1\": 1410}, \"flags\": {}, \"order\": 63, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 437}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 129, \"type\": \"ImageBlend\", \"pos\": {\"0\": 5964.82470703125, \"1\": 563.5073852539062}, \"size\": {\"0\": 310, \"1\": 102}, \"flags\": {\"pinned\": false}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"image1\", \"type\": \"IMAGE\", \"link\": 441}, {\"name\": \"image2\", \"type\": \"IMAGE\", \"link\": 269, \"label\": \"grain\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [437], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlend\"}, \"widgets_values\": [0.5, \"overlay\"]}, {\"id\": 131, \"type\": \"ImageResize+\", \"pos\": {\"0\": 5377, \"1\": 585}, \"size\": {\"0\": 210, \"1\": 220}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"width\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageResize+\"}, \"widgets_values\": [2048, 2048, \"bilinear\", \"keep proportion\", \"always\", 16]}, {\"id\": 133, \"type\": \"ImageResize+\", \"pos\": {\"0\": 660, \"1\": 1150}, \"size\": {\"0\": 210, \"1\": 220}, \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [275], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"width\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageResize+\"}, \"widgets_values\": [1024, 1024, \"bicubic\", \"keep proportion\", \"always\", 16]}, {\"id\": 149, \"type\": \"BasicGuider\", \"pos\": {\"0\": 650, \"1\": 160}, \"size\": {\"0\": 220, \"1\": 50}, \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 701, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 655, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [306], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 168, \"type\": \"GetImageSize+\", \"pos\": {\"0\": 2810, \"1\": 570}, \"size\": {\"0\": 210, \"1\": 70}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 357}], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [358], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [359], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"count\", \"type\": \"INT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"GetImageSize+\"}, \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 169, \"type\": \"SimpleMath+\", \"pos\": {\"0\": 3090, \"1\": 510}, \"size\": {\"0\": 210, \"1\": 98}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"a\", \"type\": \"INT,FLOAT\", \"link\": 358}, {\"name\": \"b\", \"type\": \"INT,FLOAT\", \"link\": 435}, {\"name\": \"c\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [360], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SimpleMath+\"}, \"widgets_values\": [\"a*b\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 170, \"type\": \"SimpleMath+\", \"pos\": {\"0\": 3090, \"1\": 670}, \"size\": {\"0\": 210, \"1\": 98}, \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"a\", \"type\": \"INT,FLOAT\", \"link\": 359}, {\"name\": \"b\", \"type\": \"INT,FLOAT\", \"link\": 434}, {\"name\": \"c\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [361], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SimpleMath+\"}, \"widgets_values\": [\"a*b\"], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 171, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 3780, \"1\": 470}, \"size\": {\"0\": 360, \"1\": 510}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 370, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 373, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 735, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 366, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 708, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [651], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 175, \"type\": \"RandomNoise\", \"pos\": {\"0\": 3370, \"1\": 240}, \"size\": {\"0\": 240, \"1\": 82}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [370], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4390, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 176, \"type\": \"BasicGuider\", \"pos\": {\"0\": 3390, \"1\": 390}, \"size\": {\"0\": 220, \"1\": 50}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 702, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 656, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [373], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 177, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3920, \"1\": 360}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 651}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 377}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [379, 380, 382, 450, 549], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 183, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 6460, \"1\": 550}, \"size\": {\"0\": 220, \"1\": 60}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [522], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 195, \"type\": \"Image Chromatic Aberration\", \"pos\": {\"0\": 6480, \"1\": 1070}, \"size\": {\"0\": 290, \"1\": 154}, \"flags\": {\"pinned\": false}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 413}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [545], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Chromatic Aberration\"}, \"widgets_values\": [2, -1, 1, 0.145, 12]}, {\"id\": 197, \"type\": \"Image Bloom Filter\", \"pos\": {\"0\": 6480, \"1\": 930}, \"size\": {\"0\": 290, \"1\": 82}, \"flags\": {\"pinned\": false}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 542}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [413], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Bloom Filter\"}, \"widgets_values\": [7.5, 0.15]}, {\"id\": 200, \"type\": \"CR Vignette Filter\", \"pos\": {\"0\": 6480, \"1\": 1270}, \"size\": {\"0\": 290, \"1\": 220}, \"flags\": {\"pinned\": false}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 546}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [419, 554], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR Vignette Filter\"}, \"widgets_values\": [\"oval\", 290, 0, 0, 1.4000000000000001, \"no\"]}, {\"id\": 201, \"type\": \"MX_LensOpticAxis\", \"pos\": {\"0\": 6480, \"1\": 1770}, \"size\": {\"0\": 300, \"1\": 200}, \"flags\": {\"pinned\": false}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 418}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [427], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"MX_LensOpticAxis\"}, \"widgets_values\": [\"circle\", \"around\", 8, 2, 0.3, 20]}, {\"id\": 202, \"type\": \"MX_LensBokeh\", \"pos\": {\"0\": 6480, \"1\": 1540}, \"size\": {\"0\": 290, \"1\": 180}, \"flags\": {\"pinned\": false}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 419}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [555], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"MX_LensBokeh\"}, \"widgets_values\": [5, 5, 0, 21, \"bilateral\", \"dilate\"]}, {\"id\": 203, \"type\": \"ImageBlend\", \"pos\": {\"0\": 7010, \"1\": 920}, \"size\": {\"0\": 210, \"1\": 102}, \"flags\": {\"pinned\": false}, \"order\": 66, \"mode\": 0, \"inputs\": [{\"name\": \"image1\", \"type\": \"IMAGE\", \"link\": 554}, {\"name\": \"image2\", \"type\": \"IMAGE\", \"link\": 555}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [418], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlend\"}, \"widgets_values\": [0.25, \"overlay\"]}, {\"id\": 210, \"type\": \"ImageApplyLUT+\", \"pos\": {\"0\": 7120, \"1\": 580}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 70, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 548}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [460], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageApplyLUT+\"}, \"widgets_values\": [\"FGCineBasic.cube\", true, false, 0.15]}, {\"id\": 214, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 2890, \"1\": 1220}, \"size\": {\"0\": 240, \"1\": 50}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 497, \"slot_index\": 0}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 461}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [463], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}}, {\"id\": 215, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 2810, \"1\": 1110}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [497], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth\"]}, {\"id\": 216, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 2810, \"1\": 1320}, \"size\": {\"0\": 320, \"1\": 82}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 463}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [559], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.75]}, {\"id\": 217, \"type\": \"VAEEncode\", \"pos\": {\"0\": 3200, \"1\": 1230}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 559}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 465}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}}, {\"id\": 229, \"type\": \"PreviewImage\", \"pos\": {\"0\": 5330, \"1\": -1020}, \"size\": {\"0\": 1000, \"1\": 1420}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 550}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 235, \"type\": \"ImageSmartSharpen+\", \"pos\": {\"0\": 4920, \"1\": -350}, \"size\": {\"0\": 320, \"1\": 150}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 549}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [550], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSmartSharpen+\"}, \"widgets_values\": [7, 0.09999999999999999, 5, 0.3]}, {\"id\": 246, \"type\": \"ChromaticAberration\", \"pos\": {\"0\": 5119.1083984375, \"1\": 1447.414794921875}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ChromaticAberration\"}, \"widgets_values\": [0, \"horizontal\", 0, \"horizontal\", 0, \"horizontal\"]}, {\"id\": 174, \"type\": \"SplitSigmas\", \"pos\": {\"0\": 3390, \"1\": 630}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 369}], \"outputs\": [{\"name\": \"high_sigmas\", \"type\": \"SIGMAS\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"low_sigmas\", \"type\": \"SIGMAS\", \"links\": [366], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SplitSigmas\"}, \"widgets_values\": [0], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 173, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 2980, \"1\": 820}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 509, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [369], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"beta\", 20, 0.52], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 162, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 2830, \"1\": 240}, \"size\": {\"0\": 210, \"1\": 122}, \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 705}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 360, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 361, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [509, 702], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [0.9349999999999999, 0.96, 1024, 1024], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -80, \"1\": 260}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [706], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp16.safetensors\", \"clip_l.safetensors\", \"flux\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 179, \"type\": \"LatentUpscaleBy\", \"pos\": {\"0\": 3390, \"1\": 780}, \"size\": {\"0\": 230, \"1\": 290}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 674}, {\"name\": \"scale_by\", \"type\": \"FLOAT\", \"link\": 433, \"widget\": {\"name\": \"scale_by\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [708], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentUpscaleBy\"}, \"widgets_values\": [\"bicubic\", 1.5], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 206, \"type\": \"Float\", \"pos\": {\"0\": 3130, \"1\": 1000}, \"size\": {\"0\": 234.21751403808594, \"1\": 71.93257141113281}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": [433, 434, 435], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Upscale Amount\", \"properties\": {\"Node name for S&R\": \"Float\"}, \"widgets_values\": [\"1.5\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 245, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": -148, \"1\": -288}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 671}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"flux\\\\FluxDFaeTasticDetails.safetensors\", 0.75]}, {\"id\": 172, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 3390, \"1\": 510}, \"size\": {\"0\": 240, \"1\": 270}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 213, \"type\": \"SaveImage\", \"pos\": {\"0\": 7479, \"1\": 159}, \"size\": {\"0\": 1920, \"1\": 3420}, \"flags\": {}, \"order\": 71, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 460}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux-tm/fluxtm_pass3\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -80, \"1\": 0}, \"size\": {\"0\": 250, \"1\": 82}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [671], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev.sft\", \"fp8_e4m3fn\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 233, \"type\": \"ImageSmartSharpen+\", \"pos\": {\"0\": 6740, \"1\": 570}, \"size\": {\"0\": 320, \"1\": 150}, \"flags\": {}, \"order\": 69, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 716}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [548], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSmartSharpen+\"}, \"widgets_values\": [7, 0.6, 4, 0.3], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 182, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 6409, \"1\": 678}, \"size\": {\"0\": 230, \"1\": 50}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 522, \"slot_index\": 0}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 450}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [542], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 232, \"type\": \"Image Filter Adjustments\", \"pos\": {\"0\": 6978, \"1\": 1071}, \"size\": {\"0\": 290, \"1\": 230}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 545}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [546], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Filter Adjustments\"}, \"widgets_values\": [0, 1, 0.8999999999999999, 1, 0, 0.5, 0, \"false\"]}, {\"id\": 193, \"type\": \"ImageBlend\", \"pos\": {\"0\": 6990, \"1\": 1350}, \"size\": {\"0\": 300, \"1\": 102}, \"flags\": {\"pinned\": false}, \"order\": 68, \"mode\": 0, \"inputs\": [{\"name\": \"image1\", \"type\": \"IMAGE\", \"link\": 427}, {\"name\": \"image2\", \"type\": \"IMAGE\", \"link\": 426, \"label\": \"grain\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [716], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageBlend\"}, \"widgets_values\": [0.585, \"overlay\"]}, {\"id\": 152, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 270, \"1\": -10}, \"size\": {\"0\": 210, \"1\": 122}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 704}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 318, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 319, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [512, 701], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 1024, 1024], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 159, \"type\": \"SaveImage\", \"pos\": {\"0\": 4319, \"1\": -135}, \"size\": {\"0\": 960, \"1\": 1390}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 382}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux-tm/fluxtm_pass2\"]}, {\"id\": 250, \"type\": \"UnetLoaderGGUF\", \"pos\": {\"0\": -144, \"1\": -136}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [723], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q8_0.gguf\"]}, {\"id\": 258, \"type\": \"AdvPromptEnhancer\", \"pos\": {\"0\": -1008.6853637695312, \"1\": 107.03500366210938}, \"size\": {\"0\": 340, \"1\": 400}, \"flags\": {}, \"order\": 25, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 732}, {\"name\": \"Instruction\", \"type\": \"STRING\", \"link\": 726, \"widget\": {\"name\": \"Instruction\"}}, {\"name\": \"Examples\", \"type\": \"STRING\", \"link\": 727, \"widget\": {\"name\": \"Examples\"}}, {\"name\": \"Prompt\", \"type\": \"STRING\", \"link\": 728, \"widget\": {\"name\": \"Prompt\"}}], \"outputs\": [{\"name\": \"LLMprompt\", \"type\": \"STRING\", \"links\": [725], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Help\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"Troubleshooting\", \"type\": \"STRING\", \"links\": [729], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"AdvPromptEnhancer\"}, \"widgets_values\": [\"ChatGPT\", \"chatgpt-4o-latest\", \"none\", \"none\", \"none\", 0.7, 100, 1234, \"fixed\", \"Two newlines\", \"\", \"\", \"\", \"\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 261, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1465.684814453125, \"1\": 57.035011291503906}, \"size\": {\"0\": 390, \"1\": 180}, \"flags\": {}, \"order\": 11, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [726], \"slot_index\": 0, \"shape\": 3}], \"title\": \"System: Instructions\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Act as a creative agent who generates a terse but highly creative written image prompt. Include descriptive visual elements of the subject, pose, facing relative to the viewer, lighting and surroundings. Choose an artistic style (eg. photograph, oil painting, etc.) and use descriptive elements that depict and pertain to this artistic style. Include no more than 10 elements presented as one long extremely visually descriptive sentence. Put the most important descriptive elements at the beginning of the sentence.\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 262, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1482, \"1\": 292}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 12, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [728], \"slot_index\": 0, \"shape\": 3}], \"title\": \"User: Prompt\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Create an image prompt from the image provided, be sure to include all details\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 260, \"type\": \"Text Multiline\", \"pos\": {\"0\": -1465.684814453125, \"1\": 447.0350036621094}, \"size\": {\"0\": 390, \"1\": 220}, \"flags\": {}, \"order\": 13, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [727], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Examples\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"In the center of a vibrant and otherworldly scene, a group of people, dressed in vibrant and energetic clothing, engage in a symphony of movement and otherworldly energy. The ground beneath them is a deep, ethereal blue, surrounded by bold red accents that seem to pulse and throb with energy.\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 257, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -595, \"1\": 76}, \"size\": {\"0\": 330, \"1\": 180}, \"flags\": {}, \"order\": 29, \"mode\": 4, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 725, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 6}], \"title\": \"LLM Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"A fierce, demon-like woman named Lucy emerges from glowing molten lava, her body illuminated by the fiery, hellish landscape; towering black horns curl inward from her head, her piercing red eyes glowing menacingly as her long, flowing black hair cascades over her shoulders, with volcanic embers flying around her; the intense heat radiates off the glowing red-orange lava cracks beneath her feet, while blackened rocks line the path she strides through, creating a surreal and dangerous atmosphere in this hyper-real\"], \"A grotesque, weathered clown with pale, cracked skin and deep-set, tired green eyes stares directly at the viewer, wearing a tattered, faded red top hat and matching bow tie, the expression on his face a disturbing mix of a grin and melancholy; the lighting is dim and soft, casting an eerie glow on his wrinkled face, while the background blends muted earthy tones, with a textured, worn wall that adds to the unsettling, vintage atmosphere of the scene, depicted in\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 259, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -594, \"1\": 347}, \"size\": {\"0\": 330, \"1\": 240}, \"flags\": {}, \"order\": 30, \"mode\": 4, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 729, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"title\": \"Troubleshooting\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"\\n\\u27a4 Begin Log for: Advanced Prompt Enhancer, Node #143:\\n\\u2726 INFO: Converting Torch Tensor image to b64 Image file\\n\\u2726 INFO: Setting client to OpenAI ChatGPT object\\n\\u2726 INFO: Using LLM: chatgpt-4o-latest\\n\\u2726 INFO: Tokens Used: CompletionUsage(completion_tokens=100, prompt_tokens=966, total_tokens=1066)\\n\"], \"\\n\\u27a4 Begin Log for: Advanced Prompt Enhancer, Node #258:\\n\\u2726 INFO: Converting Torch Tensor image to b64 Image file\\n\\u2726 INFO: Setting client to OpenAI ChatGPT object\\n\\u2726 INFO: Using LLM: chatgpt-4o-latest\\n\\u2726 INFO: Tokens Used: CompletionUsage(completion_tokens=100, prompt_tokens=1292, total_tokens=1392)\\n\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 263, \"type\": \"LoadImage\", \"pos\": {\"0\": -995, \"1\": 613}, \"size\": {\"0\": 320, \"1\": 314}, \"flags\": {}, \"order\": 14, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [732], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"the_guardian_of_the_forest__the_mystery_behind_the_by_sharadegra_di46whu-pre.png\", \"image\"], \"color\": \"#155588\", \"bgcolor\": \"#29699c\"}, {\"id\": 247, \"type\": \"ODESamplerSelect\", \"pos\": {\"0\": 988, \"1\": 797}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [735], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ODESamplerSelect\"}, \"widgets_values\": [\"bosh3\", -2.5, -3.5, 30]}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": {\"0\": 1459, \"1\": -328}, \"size\": {\"0\": 1142.044189453125, \"1\": 846.9581909179688}, \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 270}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux-tm/fluxtm_pass1\"]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 550, \"1\": 280}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [736], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 945, \"1\": 187}, \"size\": {\"0\": 410, \"1\": 530}, \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 306, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 736, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 574, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 738, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [649, 674], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 130, \"type\": \"LoadImage\", \"pos\": {\"0\": 5959, \"1\": 729}, \"size\": {\"0\": 350, \"1\": 430}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [269], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"title\": \"Load Grain\", \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"noise_1.png\", \"image\"]}, {\"id\": 190, \"type\": \"LoadImage\", \"pos\": {\"0\": 6950, \"1\": 1510}, \"size\": {\"0\": 380, \"1\": 470}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [426], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"title\": \"Load Grain\", \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"noise_1.png\", \"image\"]}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 590, \"1\": 0}, \"size\": {\"0\": 280, \"1\": 82}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [117, \"increment\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 135, \"type\": \"VAEEncode\", \"pos\": {\"0\": 940, \"1\": 1140}, \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 275}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 273}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}}, {\"id\": 180, \"type\": \"Text Multiline\", \"pos\": {\"0\": -80, \"1\": 710}, \"size\": {\"0\": 530, \"1\": 220}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [733], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"hyper-detailed, 4k, High-contrast fantasy illustration, sharp details, showing a majestic white fox with multiple flowing tails perched gracefully on a twisted rock. The fox's glowing amber eyes reflect the eerie light of the full moon, which dominates the misty, night sky. Surrounding the scene are ancient, gnarled trees adorned with fiery red leaves that flutter delicately in the breeze. The moonlight casts a soft glow, highlighting the fox's ethereal fur, while the dark branches and vibrant leaves create a striking contrast, framing the mystical creature in a hauntingly beautiful forest.\\n\\n\\n\\n\\n\\n\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 241, \"type\": \"CLIPTextEncodeFlux\", \"pos\": {\"0\": -80, \"1\": 440}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 707}, {\"name\": \"t5xxl\", \"type\": \"STRING\", \"link\": 733, \"widget\": {\"name\": \"t5xxl\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [655, 656], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncodeFlux\"}, \"widgets_values\": [\" hyper-detailed, 4k, Fantasy illustration, white fox with glowing eyes, full moon, red leaves, gnarled trees, ethereal night forest.\", \"\", 3]}, {\"id\": 249, \"type\": \"Lora Loader Stack (rgthree)\", \"pos\": {\"0\": 321, \"1\": -365}, \"size\": {\"0\": 315, \"1\": 246}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 723}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 706}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [704, 705], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [707], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Lora Loader Stack (rgthree)\"}, \"widgets_values\": [\"flux\\\\Wraith_BW_Flux.safetensors\", 0.5, \"flux\\\\FluxDFaeTasticDetails.safetensors\", 0.7000000000000001, \"None\", 0.7000000000000001, \"None\", 1]}, {\"id\": 145, \"type\": \"LoadImage\", \"pos\": {\"0\": 120, \"1\": 1120}, \"size\": {\"0\": 500, \"1\": 480}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [299], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"2024-09-08_20-40-38_6586.png\", \"image\"]}, {\"id\": 32, \"type\": \"SDXLEmptyLatentSizePicker+\", \"pos\": {\"0\": 590, \"1\": 730}, \"size\": {\"0\": 270, \"1\": 170}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [738], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"width\", \"type\": \"INT\", \"links\": [318], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [319], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SDXLEmptyLatentSizePicker+\"}, \"widgets_values\": [\"704x1344 (0.52)\", 1, 0, 0], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 550, \"1\": 400}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 512, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [201], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 35, 1], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}], \"links\": [[12, 10, 0, 8, 1, \"VAE\"], [37, 25, 0, 13, 0, \"NOISE\"], [201, 17, 0, 88, 0, \"SIGMAS\"], [244, 113, 0, 115, 0, \"IMAGE\"], [245, 114, 0, 115, 1, \"IMAGE\"], [264, 115, 0, 122, 0, \"IMAGE\"], [269, 130, 0, 129, 1, \"IMAGE\"], [270, 8, 0, 9, 0, \"IMAGE\"], [273, 10, 0, 135, 1, \"VAE\"], [275, 133, 0, 135, 0, \"IMAGE\"], [299, 145, 0, 133, 0, \"IMAGE\"], [306, 149, 0, 13, 1, \"GUIDER\"], [318, 32, 1, 152, 1, \"INT\"], [319, 32, 2, 152, 2, \"INT\"], [357, 8, 0, 168, 0, \"IMAGE\"], [358, 168, 0, 169, 0, \"INT,FLOAT\"], [359, 168, 1, 170, 0, \"INT,FLOAT\"], [360, 169, 0, 162, 1, \"INT\"], [361, 170, 0, 162, 2, \"INT\"], [366, 174, 1, 171, 3, \"SIGMAS\"], [369, 173, 0, 174, 0, \"SIGMAS\"], [370, 175, 0, 171, 0, \"NOISE\"], [373, 176, 0, 171, 1, \"GUIDER\"], [377, 10, 0, 177, 1, \"VAE\"], [379, 177, 0, 113, 0, \"IMAGE\"], [380, 177, 0, 114, 0, \"IMAGE\"], [382, 177, 0, 159, 0, \"IMAGE\"], [413, 197, 0, 195, 0, \"IMAGE\"], [418, 203, 0, 201, 0, \"IMAGE\"], [419, 200, 0, 202, 0, \"IMAGE\"], [426, 190, 0, 193, 1, \"IMAGE\"], [427, 201, 0, 193, 0, \"IMAGE\"], [433, 206, 0, 179, 1, \"FLOAT\"], [434, 206, 0, 170, 1, \"INT,FLOAT\"], [435, 206, 0, 169, 1, \"INT,FLOAT\"], [437, 129, 0, 123, 0, \"IMAGE\"], [441, 122, 0, 129, 0, \"IMAGE\"], [450, 177, 0, 182, 1, \"IMAGE\"], [460, 210, 0, 213, 0, \"IMAGE\"], [461, 8, 0, 214, 1, \"IMAGE\"], [463, 214, 0, 216, 0, \"IMAGE\"], [465, 10, 0, 217, 1, \"VAE\"], [497, 215, 0, 214, 0, \"UPSCALE_MODEL\"], [509, 162, 0, 173, 0, \"MODEL\"], [512, 152, 0, 17, 0, \"MODEL\"], [522, 183, 0, 182, 0, \"UPSCALE_MODEL\"], [542, 182, 0, 197, 0, \"IMAGE\"], [545, 195, 0, 232, 0, \"IMAGE\"], [546, 232, 0, 200, 0, \"IMAGE\"], [548, 233, 0, 210, 0, \"IMAGE\"], [549, 177, 0, 235, 0, \"IMAGE\"], [550, 235, 0, 229, 0, \"IMAGE\"], [554, 200, 0, 203, 0, \"IMAGE\"], [555, 202, 0, 203, 1, \"IMAGE\"], [559, 216, 0, 217, 0, \"IMAGE\"], [574, 88, 1, 13, 3, \"SIGMAS\"], [649, 13, 1, 8, 0, \"LATENT\"], [651, 171, 1, 177, 0, \"LATENT\"], [655, 241, 0, 149, 1, \"CONDITIONING\"], [656, 241, 0, 176, 1, \"CONDITIONING\"], [671, 12, 0, 245, 0, \"MODEL\"], [674, 13, 1, 179, 0, \"LATENT\"], [701, 152, 0, 149, 0, \"MODEL\"], [702, 162, 0, 176, 0, \"MODEL\"], [704, 249, 0, 152, 0, \"MODEL\"], [705, 249, 0, 162, 0, \"MODEL\"], [706, 11, 0, 249, 1, \"CLIP\"], [707, 249, 1, 241, 0, \"CLIP\"], [708, 179, 0, 171, 4, \"LATENT\"], [716, 193, 0, 233, 0, \"IMAGE\"], [723, 250, 0, 249, 0, \"MODEL\"], [725, 258, 0, 257, 0, \"STRING\"], [726, 261, 0, 258, 1, \"STRING\"], [727, 260, 0, 258, 2, \"STRING\"], [728, 262, 0, 258, 3, \"STRING\"], [729, 258, 2, 259, 0, \"STRING\"], [732, 263, 0, 258, 0, \"IMAGE\"], [733, 180, 0, 241, 1, \"STRING\"], [735, 247, 0, 171, 2, \"SAMPLER\"], [736, 16, 0, 13, 2, \"SAMPLER\"], [738, 32, 0, 13, 4, \"LATENT\"]], \"groups\": [{\"title\": \"Post - Less Favourable\", \"bounding\": [6400, 820, 450, 1190], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Pixel Upscale\", \"bounding\": [6400, 430, 980, 330], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Pixel Upscale Post Processing\", \"bounding\": [6900, 820, 490, 1190], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Post Processing\", \"bounding\": [5335, 494, 990, 674], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"1st Pass\", \"bounding\": [-120, -110, 1519, 1054], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Upscale\", \"bounding\": [2790, 150, 1380, 860], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"img2img\", \"bounding\": [90, 1030, 1030, 600], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"LLM captioning\", \"bounding\": [-1499, -25, 1320, 1006], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.5445000000000018, \"offset\": [661.2621653357219, 305.42047626757835]}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"172\": {\"sampler_name\": 0}, \"173\": {\"scheduler\": 0}, \"175\": {\"noise_seed\": 0}, \"258\": {\"seed\": 7}}, \"seed_widgets\": {\"25\": 0, \"175\": 0, \"258\": 7}}}",
                "models": [],
                "sampler": "Euler",
                "modelIds": [],
                "upscalers": [
                    "002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth",
                    "002_lightweightSR_DIV2K_s64w8_SwinIR-S_x2.pth"
                ],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux\\FluxDFaeTasticDetails.safetensors",
                        "type": "lora",
                        "strength": 0.75
                    }
                ]
            },
            "username": "NaomiVK",
            "baseModel": null
        },
        {
            "id": 13966026,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/196c2987-f586-43ba-b0af-5deecdd6f187/width=512/196c2987-f586-43ba-b0af-5deecdd6f187.jpeg",
            "hash": "UG9av[%NDNMwIAoeWARjDNRjtStR.TogaKoe",
            "width": 512,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-05-29T18:59:18.997Z",
            "postId": 3097412,
            "stats": {
                "cryCount": 40,
                "laughCount": 96,
                "likeCount": 743,
                "dislikeCount": 0,
                "heartCount": 251,
                "commentCount": 1
            },
            "meta": {
                "Size": "512x768",
                "seed": 1798589767,
                "steps": 28,
                "prompt": "dark background, smoke generated buddha image, sitting on a lotus, shining stars, lightning, fire flame, glowing,",
                "sampler": "DDIM",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-05-29T1858:38.0816211Z",
                "negativePrompt": "disfigured, blurred, bad anatomy, old",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 76907,
                        "modelVersionName": "v2.0-BakedVAE"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 536893,
                        "modelVersionName": "v1.0"
                    }
                ]
            },
            "username": "wokankan333",
            "baseModel": "SD 1.5"
        },
        {
            "id": 13921437,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3c1fd352-8034-4ada-990f-6e9081990103/width=832/3c1fd352-8034-4ada-990f-6e9081990103.jpeg",
            "hash": "ULDd?k-,9EI:KUWBrBn$TMR9s%xC$*VvIWob",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-05-29T08:32:32.314Z",
            "postId": 3085951,
            "stats": {
                "cryCount": 41,
                "laughCount": 94,
                "likeCount": 788,
                "dislikeCount": 0,
                "heartCount": 207,
                "commentCount": 2
            },
            "meta": {
                "Size": "832x1216",
                "seed": 2067392855,
                "steps": 30,
                "prompt": "Full body illustration of ultra realistic very detailed cute neon vibrant yellow banana  very detailed dreamy cosmic eyes hiding in a very realistic very detailed colorful field of banana flowers in a realistic very detailed meadow, realistic very detailed jungle grass, realistic very detailed trees, highest contrast, masterpiece, 32k, high contrast, vibrant colors, vivid colors, high resolution textures, crisp colors, ultra sharp, sharp focus, <lora:xl_more_art-full_v1:0.28>,\n <lora:add-detail-xl:1>,\n <lora:WildcardX-XL-Detail-Enhancer:0.7>  ,\n <lora:ral-vltne:0.8>",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "xl_more_art-full_v1",
                        "type": "lora",
                        "weight": 0.28
                    },
                    {
                        "name": "add-detail-xl",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "name": "WildcardX-XL-Detail-Enhancer",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "name": "ral-vltne",
                        "type": "lora",
                        "weight": 0.8
                    }
                ],
                "Created Date": "2024-05-29T0829:48.4689168Z",
                "negativePrompt": "(CyberRealistic_Negative-neg:0.8), mature, curvy, big tits, (deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, amputation",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 345685,
                        "modelVersionName": "FUSION OG"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 285837,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 532216,
                        "modelVersionName": "TQ - Origami Style XL"
                    },
                    {
                        "type": "vae",
                        "weight": 1,
                        "modelVersionId": 333245,
                        "modelVersionName": "SDXL-VAE"
                    }
                ]
            },
            "username": "crazybananaplush",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 37872234,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ce1fe6e6-05d5-4e55-9a1a-429045285dbe/width=832/ce1fe6e6-05d5-4e55-9a1a-429045285dbe.jpeg",
            "hash": "UNFEva^,ImR%~Dj[V[og-qf,s;oJ^,-;xut7",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-02T06:08:12.461Z",
            "postId": 8649199,
            "stats": {
                "cryCount": 53,
                "laughCount": 90,
                "likeCount": 735,
                "dislikeCount": 0,
                "heartCount": 251,
                "commentCount": 0
            },
            "meta": {
                "seed": 1026328853481948,
                "vaes": [],
                "Model": "ponyDiffusionV6XL_v6StartWithThisOne",
                "comfy": "{\"prompt\": {\"10\": {\"inputs\": {\"ckpt_name\": \"ponyDiffusionV6XL_v6StartWithThisOne.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"11\": {\"inputs\": {\"text\": \"score_9, score_8_up, score_7_up, score_6_up, prsnl3, 1girl, flower, solo, glowing, mole under eye, parted lips, looking at viewer, purple theme, glowing eyes, white eyes, short hair, lying in a field with roses with roses, ((lens flares)), highlights, rays, detailed, masterpiece, close-up, depth of field, lying pn stomach\", \"clip\": [\"10\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"12\": {\"inputs\": {\"CONDITIONING\": [\"13\", 0]}, \"class_type\": \"Prompts Everywhere\"}, \"13\": {\"inputs\": {\"text\": \"score_5, score_4, score_3, ugly, fat\", \"clip\": [\"10\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"22\": {\"inputs\": {\"VAE\": [\"10\", 2]}, \"class_type\": \"Anything Everywhere\"}, \"23\": {\"inputs\": {\"CLIP\": [\"10\", 1]}, \"class_type\": \"Anything Everywhere\"}, \"29\": {\"inputs\": {\"samples\": [\"64\", 0], \"vae\": [\"10\", 2]}, \"class_type\": \"VAEDecode\"}, \"32\": {\"inputs\": {\"filename_prefix\": \"BSS\", \"images\": [\"29\", 0]}, \"class_type\": \"SaveImage\"}, \"33\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"34\": {\"inputs\": {\"LATENT\": [\"33\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"53\": {\"inputs\": {\"MODEL\": [\"55\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"55\": {\"inputs\": {\"lora_name\": \"MyLoRas\\\\PRSNL3.safetensors\", \"strength_model\": 0.8, \"model\": [\"10\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"62\": {\"inputs\": {\"IMAGE\": [\"29\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"64\": {\"inputs\": {\"seed\": 1026328853481948, \"steps\": 26, \"cfg\": 7.0, \"sampler_name\": \"euler_ancestral\", \"scheduler\": \"karras\", \"denoise\": 1.0, \"model\": [\"55\", 0], \"positive\": [\"11\", 0], \"negative\": [\"13\", 0], \"latent_image\": [\"33\", 0]}, \"class_type\": \"KSampler\"}}, \"workflow\": {\"last_node_id\": 64, \"last_link_id\": 71, \"nodes\": [{\"id\": 12, \"type\": \"Prompts Everywhere\", \"pos\": [360, 470], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"CONDITIONING\", \"type\": \"*\", \"link\": 10, \"color_on\": \"#cf876f\"}, {\"name\": \"CONDITIONING\", \"type\": \"*\", \"link\": 11, \"color_on\": \"#cf876f\"}], \"properties\": {\"Node name for S&R\": \"Prompts Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 54, \"type\": \"LoraLoaderModelOnly\", \"pos\": [430, 210], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 15, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 47}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [49], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"MyLoRas\\\\SLVTK.safetensors\", 0.8], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 53, \"type\": \"Anything Everywhere\", \"pos\": [650, 240], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"MODEL\", \"type\": \"*\", \"link\": 50, \"color_on\": \"#8978a7\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 29, \"type\": \"VAEDecode\", \"pos\": [690, 450], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 63}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [53], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 55, \"type\": \"LoraLoaderModelOnly\", \"pos\": [650, 210], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 49}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [50], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"MyLoRas\\\\PRSNL3.safetensors\", 0.8], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 59, \"type\": \"UpscaleModelLoader\", \"pos\": [1270, 130], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": true}, \"order\": 0, \"mode\": 2, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [52], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x_NMKD-Superscale-SP178000_G.pth\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 61, \"type\": \"ImageUpscaleWithModel\", \"pos\": [1270, 170], \"size\": {\"0\": 240, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 7, \"mode\": 2, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 52}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [54], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}}, {\"id\": 46, \"type\": \"LoraLoaderModelOnly\", \"pos\": [210, 210], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 8, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 46}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [47], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"MyLoRas\\\\SLVTK-2.safetensors\", 0.8], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 10, \"type\": \"CheckpointLoaderSimple\", \"pos\": [210, 170], \"size\": {\"0\": 320, \"1\": 100}, \"flags\": {\"collapsed\": true}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [46], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [43], \"shape\": 3, \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [44], \"shape\": 3, \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"ponyDiffusionV6XL_v6StartWithThisOne.safetensors\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 34, \"type\": \"Anything Everywhere\", \"pos\": [390, 130], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"LATENT\", \"type\": \"*\", \"link\": 38, \"color_on\": \"#b38ead\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 33, \"type\": \"EmptyLatentImage\", \"pos\": [210, 130], \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {\"collapsed\": true}, \"order\": 2, \"mode\": 0, \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [38], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [832, 1216, 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 23, \"type\": \"Anything Everywhere\", \"pos\": [370, 170], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"CLIP\", \"type\": \"*\", \"link\": 43, \"color_on\": \"#eacb8b\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 22, \"type\": \"Anything Everywhere\", \"pos\": [560, 170], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"VAE\", \"type\": \"*\", \"link\": 44, \"color_on\": \"#be616b\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 62, \"type\": \"Anything Everywhere\", \"pos\": [690, 490], \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"IMAGE\", \"type\": \"*\", \"link\": 53, \"color_on\": \"#80a1c0\"}], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": [], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 63, \"type\": \"SaveImage\", \"pos\": [1270, 210], \"size\": [370, 590], \"flags\": {}, \"order\": 14, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 54}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"BSS_upscale\"]}, {\"id\": 64, \"type\": \"KSampler\", \"pos\": [650, 330], \"size\": [210, 470], \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [63], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1026328853481948, \"randomize\", 26, 7, \"euler_ancestral\", \"karras\", 1], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 32, \"type\": \"SaveImage\", \"pos\": [870, 210], \"size\": [370, 590], \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": null}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"BSS\"]}, {\"id\": 13, \"type\": \"CLIPTextEncode\", \"pos\": [210, 600], \"size\": [430, 200], \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [11], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_5, score_4, score_3, ugly, fat\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 11, \"type\": \"CLIPTextEncode\", \"pos\": [210, 330], \"size\": [430, 230], \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [10], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_9, score_8_up, score_7_up, score_6_up, prsnl3, 1girl, flower, solo, glowing, mole under eye, parted lips, looking at viewer, purple theme, glowing eyes, white eyes, short hair, lying in a field with roses with roses, ((lens flares)), highlights, rays, detailed, masterpiece, close-up, depth of field, lying pn stomach\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}], \"links\": [[10, 11, 0, 12, 0, \"CONDITIONING\"], [11, 13, 0, 12, 1, \"CONDITIONING\"], [38, 33, 0, 34, 0, \"LATENT\"], [43, 10, 1, 23, 0, \"CLIP\"], [44, 10, 2, 22, 0, \"VAE\"], [46, 10, 0, 46, 0, \"MODEL\"], [47, 46, 0, 54, 0, \"MODEL\"], [49, 54, 0, 55, 0, \"MODEL\"], [50, 55, 0, 53, 0, \"MODEL\"], [52, 59, 0, 61, 0, \"UPSCALE_MODEL\"], [53, 29, 0, 62, 0, \"IMAGE\"], [54, 61, 0, 63, 0, \"IMAGE\"], [55, 10, 2, 29, 1, \"VAE\"], [56, 29, 0, 32, 0, \"IMAGE\"], [57, 10, 1, 13, 0, \"CLIP\"], [58, 10, 1, 11, 0, \"CLIP\"], [59, 55, 0, 52, 0, \"MODEL\"], [60, 11, 0, 52, 1, \"CONDITIONING\"], [61, 13, 0, 52, 2, \"CONDITIONING\"], [62, 33, 0, 52, 3, \"LATENT\"], [63, 64, 0, 29, 0, \"LATENT\"], [64, 10, 2, 29, 1, \"VAE\"], [65, 55, 0, 64, 0, \"MODEL\"], [66, 11, 0, 64, 1, \"CONDITIONING\"], [67, 13, 0, 64, 2, \"CONDITIONING\"], [68, 33, 0, 64, 3, \"LATENT\"], [69, 29, 0, 32, 0, \"IMAGE\"], [70, 10, 1, 13, 0, \"CLIP\"], [71, 10, 1, 11, 0, \"CLIP\"]], \"groups\": [{\"title\": \"Upscale\", \"bounding\": [1260, 50, 390, 760], \"color\": \"#b19139\", \"font_size\": 24, \"locked\": false}, {\"title\": \"Generate\", \"bounding\": [200, 50, 1050, 760], \"color\": \"#8A8\", \"font_size\": 24, \"locked\": false}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.7088742511246109, \"offset\": [64.44392825053288, -198.4087608224517]}}, \"version\": 0.4, \"widget_idx_map\": {\"64\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"64\": 0}}}",
                "steps": 26,
                "width": 832,
                "height": 1216,
                "models": [
                    "ponyDiffusionV6XL_v6StartWithThisOne.safetensors"
                ],
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, prsnl3, 1girl, flower, solo, glowing, mole under eye, parted lips, looking at viewer, purple theme, glowing eyes, white eyes, short hair, lying in a field with roses with roses, ((lens flares)), highlights, rays, detailed, masterpiece, close-up, depth of field, lying pn stomach",
                "denoise": 1,
                "sampler": "Euler a",
                "cfgScale": 7,
                "modelIds": [],
                "scheduler": "karras",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "score_5, score_4, score_3, ugly, fat",
                "additionalResources": [
                    {
                        "name": "MyLoRas\\PRSNL3.safetensors",
                        "type": "lora",
                        "strength": 0.8
                    }
                ]
            },
            "username": "blacksnowskill",
            "baseModel": null
        },
        {
            "id": 35047611,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1aeab31a-bdf3-4a18-a605-c9b4de16605e/width=832/1aeab31a-bdf3-4a18-a605-c9b4de16605e.jpeg",
            "hash": "U2Amq=t:00O,%iNFfyN40_-.}]^$Oa-;~TIW",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-17T08:42:43.117Z",
            "postId": 8010328,
            "stats": {
                "cryCount": 71,
                "laughCount": 131,
                "likeCount": 725,
                "dislikeCount": 0,
                "heartCount": 202,
                "commentCount": 2
            },
            "meta": null,
            "username": "Lady_Luminous",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 27520765,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/eefebbb8-8ca9-45db-8863-c36530c7f414/width=832/eefebbb8-8ca9-45db-8863-c36530c7f414.jpeg",
            "hash": "U97yb$D4O:tjHXXetkMJPVf3Ql*0mPbTXUn.",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-03T06:46:03.317Z",
            "postId": 6153859,
            "stats": {
                "cryCount": 35,
                "laughCount": 45,
                "likeCount": 761,
                "dislikeCount": 0,
                "heartCount": 288,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 542271050,
                "extra": {
                    "remixOfId": 26650264
                },
                "steps": 24,
                "prompt": "Create a close-up image of a fantasy maidens face. Her skin glows with a soft,ethereal light and is adorned with neon tattoos that cover her face in intricate patterns. The tattoos emit a magical glow that illuminates her delicate features. Her eyes are large and bright,subtly changing between shades of blue and white,as if holding an ocean within them. Her long,silver hair frames her face,adding a splash of magic to the scene. The background features a starry sky that enhances the dreamy atmosphere,fantasy art,<lora:ImageUpgraderV2:1>,",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [
                    {
                        "name": "ImageUpgraderV2",
                        "type": "lora",
                        "weight": 1
                    }
                ],
                "Created Date": "2024-09-03T0644:29.9538612Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 735063,
                        "modelVersionName": "FLUX"
                    }
                ]
            },
            "username": "Ankiipankii",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 24656073,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/66ec106e-097d-4eee-bcd1-46a5bc4b1555/width=832/66ec106e-097d-4eee-bcd1-46a5bc4b1555.jpeg",
            "hash": "UrNKCftQ_4ajtSRkn$oe?bj]M_t6-UoeNbR+",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-08-16T23:05:40.032Z",
            "postId": 5509489,
            "stats": {
                "cryCount": 35,
                "laughCount": 201,
                "likeCount": 698,
                "dislikeCount": 0,
                "heartCount": 195,
                "commentCount": 1
            },
            "meta": {
                "Size": "832x1216",
                "seed": 156784723,
                "steps": 25,
                "prompt": "A wide big green can labelled \"Uncle Bob's Genuine Albanian Goat Smegma\", text at bottom of the can says \"With Naturally Formed Crust\", on bottom left of label it says \"300g nett\"",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-16T2242:11.6944135Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    }
                ]
            },
            "username": "UnstableGen",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 22013605,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d5354b48-5716-4756-9449-0e15bd30aeed/width=832/d5354b48-5716-4756-9449-0e15bd30aeed.jpeg",
            "hash": "UCI4t{-oGcRQBsxt?dSh0jENZ#Nd~CRP^h=|",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-08-25T16:00:00.000Z",
            "postId": 4907200,
            "stats": {
                "cryCount": 67,
                "laughCount": 166,
                "likeCount": 650,
                "dislikeCount": 0,
                "heartCount": 246,
                "commentCount": 1
            },
            "meta": {
                "RNG": "NV",
                "VAE": "fixFP16ErrorsSDXLLowerMemoryUse_v10.safetensors",
                "Size": "832x1216",
                "seed": 1620852199,
                "Model": "mfcgPaintjob_v40",
                "steps": 24,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "da7a42748f",
                    "lora:JokersForcedSmile_pdxl_Incrs_v1": "1c50ad0197e0"
                },
                "prompt": "score_9, score_8_up, score_7_up, forced smile, mouth pull, fingersmile, <lora:JokersForcedSmile_pdxl_Incrs_v1:1>, makeup, clown nose, runny makeup, 1girl, higashiyama kobeni,",
                "Version": "f0.0.17v1.8.0rc-latest-287-g77bdb920",
                "sampler": "Euler a",
                "cfgScale": 6,
                "resources": [
                    {
                        "hash": "1c50ad0197e0",
                        "name": "JokersForcedSmile_pdxl_Incrs_v1",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "da7a42748f",
                        "name": "mfcgPaintjob_v40",
                        "type": "model"
                    }
                ],
                "Model hash": "da7a42748f",
                "negativePrompt": "monochrome",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.6.0",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer negative prompt": "3d",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "FallenIncursio",
            "baseModel": "Pony"
        },
        {
            "id": 13603530,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/18733c0d-f0c0-451e-95f9-949c00477a80/width=1040/18733c0d-f0c0-451e-95f9-949c00477a80.jpeg",
            "hash": "UMAnJpaeD%xu_MV[IVxt%LWBoft7x]ofjZn%",
            "width": 1040,
            "height": 1520,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-05-26T05:13:06.205Z",
            "postId": 3012644,
            "stats": {
                "cryCount": 47,
                "laughCount": 83,
                "likeCount": 717,
                "dislikeCount": 0,
                "heartCount": 282,
                "commentCount": 1
            },
            "meta": null,
            "username": "Rom4rio",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 2003302,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a3fbc5dd-d21a-4886-a230-d4e3427af233/width=1152/a3fbc5dd-d21a-4886-a230-d4e3427af233.jpeg",
            "hash": "UCJ?jKI:r=xu}_16o|bbxy-U$yET-r$,bIrY",
            "width": 1152,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-02-12T19:17:03.381Z",
            "postId": 492745,
            "stats": {
                "cryCount": 11,
                "laughCount": 59,
                "likeCount": 754,
                "dislikeCount": 0,
                "heartCount": 305,
                "commentCount": 0
            },
            "meta": {
                "vaes": [],
                "Model": "talmendoxlSDXL_v11Beta",
                "comfy": {
                    "prompt": {
                        "4": {
                            "inputs": {
                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                            },
                            "class_type": "CheckpointLoaderSimple"
                        },
                        "5": {
                            "inputs": {
                                "width": 1152,
                                "height": 768,
                                "batch_size": 1
                            },
                            "class_type": "EmptyLatentImage"
                        },
                        "6": {
                            "inputs": {
                                "clip": {
                                    "inputs": {
                                        "clip": {
                                            "inputs": {
                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "model": {
                                            "inputs": {
                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "lora_name": "impressionism.safetensors",
                                        "strength_clip": 1,
                                        "strength_model": 1
                                    },
                                    "class_type": "LoraLoader"
                                },
                                "text": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                            },
                            "class_type": "CLIPTextEncode"
                        },
                        "7": {
                            "inputs": {
                                "clip": {
                                    "inputs": {
                                        "clip": {
                                            "inputs": {
                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "model": {
                                            "inputs": {
                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "lora_name": "impressionism.safetensors",
                                        "strength_clip": 1,
                                        "strength_model": 1
                                    },
                                    "class_type": "LoraLoader"
                                },
                                "text": "low quality, medium quality, \ntext, signature, watermark, \n"
                            },
                            "class_type": "CLIPTextEncode"
                        },
                        "10": {
                            "inputs": {
                                "cfg": 7,
                                "model": {
                                    "inputs": {
                                        "clip": {
                                            "inputs": {
                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "model": {
                                            "inputs": {
                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "lora_name": "impressionism.safetensors",
                                        "strength_clip": 1,
                                        "strength_model": 1
                                    },
                                    "class_type": "LoraLoader"
                                },
                                "steps": 30,
                                "negative": {
                                    "inputs": {
                                        "clip": {
                                            "inputs": {
                                                "clip": {
                                                    "inputs": {
                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                    },
                                                    "class_type": "CheckpointLoaderSimple"
                                                },
                                                "model": {
                                                    "inputs": {
                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                    },
                                                    "class_type": "CheckpointLoaderSimple"
                                                },
                                                "lora_name": "impressionism.safetensors",
                                                "strength_clip": 1,
                                                "strength_model": 1
                                            },
                                            "class_type": "LoraLoader"
                                        },
                                        "text": "low quality, medium quality, \ntext, signature, watermark, \n"
                                    },
                                    "class_type": "CLIPTextEncode"
                                },
                                "positive": {
                                    "inputs": {
                                        "clip": {
                                            "inputs": {
                                                "clip": {
                                                    "inputs": {
                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                    },
                                                    "class_type": "CheckpointLoaderSimple"
                                                },
                                                "model": {
                                                    "inputs": {
                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                    },
                                                    "class_type": "CheckpointLoaderSimple"
                                                },
                                                "lora_name": "impressionism.safetensors",
                                                "strength_clip": 1,
                                                "strength_model": 1
                                            },
                                            "class_type": "LoraLoader"
                                        },
                                        "text": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                    },
                                    "class_type": "CLIPTextEncode"
                                },
                                "add_noise": "enable",
                                "scheduler": "karras",
                                "noise_seed": 529518536884765,
                                "end_at_step": 20,
                                "latent_image": {
                                    "inputs": {
                                        "width": 1152,
                                        "height": 768,
                                        "batch_size": 1
                                    },
                                    "class_type": "EmptyLatentImage"
                                },
                                "sampler_name": "dpmpp_2m",
                                "start_at_step": 0,
                                "return_with_leftover_noise": "enable"
                            },
                            "class_type": "KSamplerAdvanced"
                        },
                        "11": {
                            "inputs": {
                                "cfg": 3,
                                "model": {
                                    "inputs": {
                                        "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                    },
                                    "class_type": "CheckpointLoaderSimple"
                                },
                                "steps": 30,
                                "negative": {
                                    "inputs": {
                                        "clip": {
                                            "inputs": {
                                                "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "text": "low quality, medium quality, \ntext, signature, watermark, \n"
                                    },
                                    "class_type": "CLIPTextEncode"
                                },
                                "positive": {
                                    "inputs": {
                                        "clip": {
                                            "inputs": {
                                                "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "text": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                    },
                                    "class_type": "CLIPTextEncode"
                                },
                                "add_noise": "disable",
                                "scheduler": "karras",
                                "noise_seed": 0,
                                "end_at_step": 10000,
                                "latent_image": {
                                    "inputs": {
                                        "cfg": 7,
                                        "model": {
                                            "inputs": {
                                                "clip": {
                                                    "inputs": {
                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                    },
                                                    "class_type": "CheckpointLoaderSimple"
                                                },
                                                "model": {
                                                    "inputs": {
                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                    },
                                                    "class_type": "CheckpointLoaderSimple"
                                                },
                                                "lora_name": "impressionism.safetensors",
                                                "strength_clip": 1,
                                                "strength_model": 1
                                            },
                                            "class_type": "LoraLoader"
                                        },
                                        "steps": 30,
                                        "negative": {
                                            "inputs": {
                                                "clip": {
                                                    "inputs": {
                                                        "clip": {
                                                            "inputs": {
                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                            },
                                                            "class_type": "CheckpointLoaderSimple"
                                                        },
                                                        "model": {
                                                            "inputs": {
                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                            },
                                                            "class_type": "CheckpointLoaderSimple"
                                                        },
                                                        "lora_name": "impressionism.safetensors",
                                                        "strength_clip": 1,
                                                        "strength_model": 1
                                                    },
                                                    "class_type": "LoraLoader"
                                                },
                                                "text": "low quality, medium quality, \ntext, signature, watermark, \n"
                                            },
                                            "class_type": "CLIPTextEncode"
                                        },
                                        "positive": {
                                            "inputs": {
                                                "clip": {
                                                    "inputs": {
                                                        "clip": {
                                                            "inputs": {
                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                            },
                                                            "class_type": "CheckpointLoaderSimple"
                                                        },
                                                        "model": {
                                                            "inputs": {
                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                            },
                                                            "class_type": "CheckpointLoaderSimple"
                                                        },
                                                        "lora_name": "impressionism.safetensors",
                                                        "strength_clip": 1,
                                                        "strength_model": 1
                                                    },
                                                    "class_type": "LoraLoader"
                                                },
                                                "text": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                            },
                                            "class_type": "CLIPTextEncode"
                                        },
                                        "add_noise": "enable",
                                        "scheduler": "karras",
                                        "noise_seed": 529518536884765,
                                        "end_at_step": 20,
                                        "latent_image": {
                                            "inputs": {
                                                "width": 1152,
                                                "height": 768,
                                                "batch_size": 1
                                            },
                                            "class_type": "EmptyLatentImage"
                                        },
                                        "sampler_name": "dpmpp_2m",
                                        "start_at_step": 0,
                                        "return_with_leftover_noise": "enable"
                                    },
                                    "class_type": "KSamplerAdvanced"
                                },
                                "sampler_name": "dpmpp_2m",
                                "start_at_step": 20,
                                "return_with_leftover_noise": "disable"
                            },
                            "class_type": "KSamplerAdvanced"
                        },
                        "12": {
                            "inputs": {
                                "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                            },
                            "class_type": "CheckpointLoaderSimple"
                        },
                        "15": {
                            "inputs": {
                                "clip": {
                                    "inputs": {
                                        "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                    },
                                    "class_type": "CheckpointLoaderSimple"
                                },
                                "text": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                            },
                            "class_type": "CLIPTextEncode"
                        },
                        "16": {
                            "inputs": {
                                "clip": {
                                    "inputs": {
                                        "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                    },
                                    "class_type": "CheckpointLoaderSimple"
                                },
                                "text": "low quality, medium quality, \ntext, signature, watermark, \n"
                            },
                            "class_type": "CLIPTextEncode"
                        },
                        "17": {
                            "inputs": {
                                "vae": {
                                    "inputs": {
                                        "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                    },
                                    "class_type": "CheckpointLoaderSimple"
                                },
                                "samples": {
                                    "inputs": {
                                        "cfg": 3,
                                        "model": {
                                            "inputs": {
                                                "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "steps": 30,
                                        "negative": {
                                            "inputs": {
                                                "clip": {
                                                    "inputs": {
                                                        "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                                    },
                                                    "class_type": "CheckpointLoaderSimple"
                                                },
                                                "text": "low quality, medium quality, \ntext, signature, watermark, \n"
                                            },
                                            "class_type": "CLIPTextEncode"
                                        },
                                        "positive": {
                                            "inputs": {
                                                "clip": {
                                                    "inputs": {
                                                        "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                                    },
                                                    "class_type": "CheckpointLoaderSimple"
                                                },
                                                "text": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                            },
                                            "class_type": "CLIPTextEncode"
                                        },
                                        "add_noise": "disable",
                                        "scheduler": "karras",
                                        "noise_seed": 0,
                                        "end_at_step": 10000,
                                        "latent_image": {
                                            "inputs": {
                                                "cfg": 7,
                                                "model": {
                                                    "inputs": {
                                                        "clip": {
                                                            "inputs": {
                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                            },
                                                            "class_type": "CheckpointLoaderSimple"
                                                        },
                                                        "model": {
                                                            "inputs": {
                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                            },
                                                            "class_type": "CheckpointLoaderSimple"
                                                        },
                                                        "lora_name": "impressionism.safetensors",
                                                        "strength_clip": 1,
                                                        "strength_model": 1
                                                    },
                                                    "class_type": "LoraLoader"
                                                },
                                                "steps": 30,
                                                "negative": {
                                                    "inputs": {
                                                        "clip": {
                                                            "inputs": {
                                                                "clip": {
                                                                    "inputs": {
                                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                    },
                                                                    "class_type": "CheckpointLoaderSimple"
                                                                },
                                                                "model": {
                                                                    "inputs": {
                                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                    },
                                                                    "class_type": "CheckpointLoaderSimple"
                                                                },
                                                                "lora_name": "impressionism.safetensors",
                                                                "strength_clip": 1,
                                                                "strength_model": 1
                                                            },
                                                            "class_type": "LoraLoader"
                                                        },
                                                        "text": "low quality, medium quality, \ntext, signature, watermark, \n"
                                                    },
                                                    "class_type": "CLIPTextEncode"
                                                },
                                                "positive": {
                                                    "inputs": {
                                                        "clip": {
                                                            "inputs": {
                                                                "clip": {
                                                                    "inputs": {
                                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                    },
                                                                    "class_type": "CheckpointLoaderSimple"
                                                                },
                                                                "model": {
                                                                    "inputs": {
                                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                    },
                                                                    "class_type": "CheckpointLoaderSimple"
                                                                },
                                                                "lora_name": "impressionism.safetensors",
                                                                "strength_clip": 1,
                                                                "strength_model": 1
                                                            },
                                                            "class_type": "LoraLoader"
                                                        },
                                                        "text": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                                    },
                                                    "class_type": "CLIPTextEncode"
                                                },
                                                "add_noise": "enable",
                                                "scheduler": "karras",
                                                "noise_seed": 529518536884765,
                                                "end_at_step": 20,
                                                "latent_image": {
                                                    "inputs": {
                                                        "width": 1152,
                                                        "height": 768,
                                                        "batch_size": 1
                                                    },
                                                    "class_type": "EmptyLatentImage"
                                                },
                                                "sampler_name": "dpmpp_2m",
                                                "start_at_step": 0,
                                                "return_with_leftover_noise": "enable"
                                            },
                                            "class_type": "KSamplerAdvanced"
                                        },
                                        "sampler_name": "dpmpp_2m",
                                        "start_at_step": 20,
                                        "return_with_leftover_noise": "disable"
                                    },
                                    "class_type": "KSamplerAdvanced"
                                }
                            },
                            "class_type": "VAEDecode"
                        },
                        "62": {
                            "inputs": {
                                "images": {
                                    "inputs": {
                                        "vae": {
                                            "inputs": {
                                                "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                            },
                                            "class_type": "CheckpointLoaderSimple"
                                        },
                                        "samples": {
                                            "inputs": {
                                                "cfg": 3,
                                                "model": {
                                                    "inputs": {
                                                        "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                                    },
                                                    "class_type": "CheckpointLoaderSimple"
                                                },
                                                "steps": 30,
                                                "negative": {
                                                    "inputs": {
                                                        "clip": {
                                                            "inputs": {
                                                                "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                                            },
                                                            "class_type": "CheckpointLoaderSimple"
                                                        },
                                                        "text": "low quality, medium quality, \ntext, signature, watermark, \n"
                                                    },
                                                    "class_type": "CLIPTextEncode"
                                                },
                                                "positive": {
                                                    "inputs": {
                                                        "clip": {
                                                            "inputs": {
                                                                "ckpt_name": "sd_xl_refiner_1.0_0.9vae.safetensors"
                                                            },
                                                            "class_type": "CheckpointLoaderSimple"
                                                        },
                                                        "text": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                                    },
                                                    "class_type": "CLIPTextEncode"
                                                },
                                                "add_noise": "disable",
                                                "scheduler": "karras",
                                                "noise_seed": 0,
                                                "end_at_step": 10000,
                                                "latent_image": {
                                                    "inputs": {
                                                        "cfg": 7,
                                                        "model": {
                                                            "inputs": {
                                                                "clip": {
                                                                    "inputs": {
                                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                    },
                                                                    "class_type": "CheckpointLoaderSimple"
                                                                },
                                                                "model": {
                                                                    "inputs": {
                                                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                    },
                                                                    "class_type": "CheckpointLoaderSimple"
                                                                },
                                                                "lora_name": "impressionism.safetensors",
                                                                "strength_clip": 1,
                                                                "strength_model": 1
                                                            },
                                                            "class_type": "LoraLoader"
                                                        },
                                                        "steps": 30,
                                                        "negative": {
                                                            "inputs": {
                                                                "clip": {
                                                                    "inputs": {
                                                                        "clip": {
                                                                            "inputs": {
                                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                            },
                                                                            "class_type": "CheckpointLoaderSimple"
                                                                        },
                                                                        "model": {
                                                                            "inputs": {
                                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                            },
                                                                            "class_type": "CheckpointLoaderSimple"
                                                                        },
                                                                        "lora_name": "impressionism.safetensors",
                                                                        "strength_clip": 1,
                                                                        "strength_model": 1
                                                                    },
                                                                    "class_type": "LoraLoader"
                                                                },
                                                                "text": "low quality, medium quality, \ntext, signature, watermark, \n"
                                                            },
                                                            "class_type": "CLIPTextEncode"
                                                        },
                                                        "positive": {
                                                            "inputs": {
                                                                "clip": {
                                                                    "inputs": {
                                                                        "clip": {
                                                                            "inputs": {
                                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                            },
                                                                            "class_type": "CheckpointLoaderSimple"
                                                                        },
                                                                        "model": {
                                                                            "inputs": {
                                                                                "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                                                            },
                                                                            "class_type": "CheckpointLoaderSimple"
                                                                        },
                                                                        "lora_name": "impressionism.safetensors",
                                                                        "strength_clip": 1,
                                                                        "strength_model": 1
                                                                    },
                                                                    "class_type": "LoraLoader"
                                                                },
                                                                "text": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                                            },
                                                            "class_type": "CLIPTextEncode"
                                                        },
                                                        "add_noise": "enable",
                                                        "scheduler": "karras",
                                                        "noise_seed": 529518536884765,
                                                        "end_at_step": 20,
                                                        "latent_image": {
                                                            "inputs": {
                                                                "width": 1152,
                                                                "height": 768,
                                                                "batch_size": 1
                                                            },
                                                            "class_type": "EmptyLatentImage"
                                                        },
                                                        "sampler_name": "dpmpp_2m",
                                                        "start_at_step": 0,
                                                        "return_with_leftover_noise": "enable"
                                                    },
                                                    "class_type": "KSamplerAdvanced"
                                                },
                                                "sampler_name": "dpmpp_2m",
                                                "start_at_step": 20,
                                                "return_with_leftover_noise": "disable"
                                            },
                                            "class_type": "KSamplerAdvanced"
                                        }
                                    },
                                    "class_type": "VAEDecode"
                                },
                                "filename_prefix": "ComfyUI"
                            },
                            "class_type": "SaveImage"
                        },
                        "78": {
                            "inputs": {
                                "clip": {
                                    "inputs": {
                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                    },
                                    "class_type": "CheckpointLoaderSimple"
                                },
                                "model": {
                                    "inputs": {
                                        "ckpt_name": "talmendoxlSDXL_v11Beta.safetensors"
                                    },
                                    "class_type": "CheckpointLoaderSimple"
                                },
                                "lora_name": "impressionism.safetensors",
                                "strength_clip": 1,
                                "strength_model": 1
                            },
                            "class_type": "LoraLoader"
                        }
                    },
                    "workflow": {
                        "extra": {},
                        "links": [
                            [
                                11,
                                6,
                                0,
                                10,
                                1,
                                "CONDITIONING"
                            ],
                            [
                                12,
                                7,
                                0,
                                10,
                                2,
                                "CONDITIONING"
                            ],
                            [
                                14,
                                12,
                                0,
                                11,
                                0,
                                "MODEL"
                            ],
                            [
                                16,
                                13,
                                0,
                                6,
                                1,
                                "STRING"
                            ],
                            [
                                18,
                                14,
                                0,
                                7,
                                1,
                                "STRING"
                            ],
                            [
                                19,
                                12,
                                1,
                                15,
                                0,
                                "CLIP"
                            ],
                            [
                                20,
                                12,
                                1,
                                16,
                                0,
                                "CLIP"
                            ],
                            [
                                21,
                                13,
                                0,
                                15,
                                1,
                                "STRING"
                            ],
                            [
                                22,
                                14,
                                0,
                                16,
                                1,
                                "STRING"
                            ],
                            [
                                23,
                                15,
                                0,
                                11,
                                1,
                                "CONDITIONING"
                            ],
                            [
                                24,
                                16,
                                0,
                                11,
                                2,
                                "CONDITIONING"
                            ],
                            [
                                25,
                                11,
                                0,
                                17,
                                0,
                                "LATENT"
                            ],
                            [
                                27,
                                5,
                                0,
                                10,
                                3,
                                "LATENT"
                            ],
                            [
                                34,
                                12,
                                2,
                                17,
                                1,
                                "VAE"
                            ],
                            [
                                38,
                                45,
                                0,
                                11,
                                4,
                                "INT"
                            ],
                            [
                                41,
                                45,
                                0,
                                10,
                                4,
                                "INT"
                            ],
                            [
                                43,
                                47,
                                0,
                                10,
                                5,
                                "INT"
                            ],
                            [
                                44,
                                47,
                                0,
                                11,
                                5,
                                "INT"
                            ],
                            [
                                52,
                                10,
                                0,
                                11,
                                3,
                                "LATENT"
                            ],
                            [
                                116,
                                17,
                                0,
                                62,
                                0,
                                "IMAGE"
                            ],
                            [
                                134,
                                78,
                                1,
                                6,
                                0,
                                "CLIP"
                            ],
                            [
                                135,
                                78,
                                1,
                                7,
                                0,
                                "CLIP"
                            ],
                            [
                                136,
                                78,
                                0,
                                10,
                                0,
                                "MODEL"
                            ],
                            [
                                137,
                                4,
                                0,
                                78,
                                0,
                                "MODEL"
                            ],
                            [
                                138,
                                4,
                                1,
                                78,
                                1,
                                "CLIP"
                            ]
                        ],
                        "nodes": [
                            {
                                "id": 15,
                                "pos": [
                                    1139.1103087741085,
                                    -121.78948886648053
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 54
                                },
                                "type": "CLIPTextEncode",
                                "color": "#232",
                                "flags": {},
                                "order": 16,
                                "inputs": [
                                    {
                                        "link": 19,
                                        "name": "clip",
                                        "type": "CLIP"
                                    },
                                    {
                                        "link": 21,
                                        "name": "text",
                                        "type": "STRING",
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 1
                                    }
                                ],
                                "bgcolor": "#353",
                                "outputs": [
                                    {
                                        "name": "CONDITIONING",
                                        "type": "CONDITIONING",
                                        "links": [
                                            23
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CLIPTextEncode"
                                },
                                "widgets_values": [
                                    "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                ]
                            },
                            {
                                "id": 16,
                                "pos": [
                                    1139.1103087741085,
                                    -31.789488866480543
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 54
                                },
                                "type": "CLIPTextEncode",
                                "color": "#322",
                                "flags": {},
                                "order": 17,
                                "inputs": [
                                    {
                                        "link": 20,
                                        "name": "clip",
                                        "type": "CLIP"
                                    },
                                    {
                                        "link": 22,
                                        "name": "text",
                                        "type": "STRING",
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 1
                                    }
                                ],
                                "bgcolor": "#533",
                                "outputs": [
                                    {
                                        "name": "CONDITIONING",
                                        "type": "CONDITIONING",
                                        "links": [
                                            24
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CLIPTextEncode"
                                },
                                "widgets_values": [
                                    "low quality, medium quality, \ntext, signature, watermark, \n"
                                ]
                            },
                            {
                                "id": 36,
                                "pos": [
                                    62.56920039310091,
                                    -864.9818597222632
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 315.70074462890625,
                                    "1": 147.9551239013672
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 0,
                                "title": "Note - Load Checkpoint BASE",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "This is a checkpoint model loader. \n - This is set up automatically with the optimal settings for whatever SD model version you choose to use.\n - In this example, it is for the Base SDXL model\n - This node is also used for SD1.5 and SD2.x models\n \nNOTE: When loading in another person's workflow, be sure to manually choose your own *local* model. This also applies to LoRas and all their deviations"
                                ]
                            },
                            {
                                "id": 37,
                                "pos": [
                                    610,
                                    -460
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 330,
                                    "1": 140
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 1,
                                "title": "Note - Load Checkpoint REFINER",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "This is a checkpoint model loader. \n - This is set up automatically with the optimal settings for whatever SD model version you choose to use.\n - In this example, it is for the Refiner SDXL model\n\nNOTE: When loading in another person's workflow, be sure to manually choose your own *local* model. This also applies to LoRas and all their deviations."
                                ]
                            },
                            {
                                "id": 38,
                                "pos": [
                                    85.14067680358886,
                                    647.7798582458481
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 284.3257141113281,
                                    "1": 123.88604736328125
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 2,
                                "title": "Note - Text Prompts",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "These nodes are where you include the text for:\n - what you want in the picture (Positive Prompt, Green)\n - or what you don't want in the picture (Negative Prompt, Red)\n\nThis node type is called a \"PrimitiveNode\" if you are searching for the node type."
                                ]
                            },
                            {
                                "id": 41,
                                "pos": [
                                    2160.7710413363047,
                                    229.60259386016995
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 320,
                                    "1": 120
                                },
                                "type": "Note",
                                "color": "#332922",
                                "flags": {},
                                "order": 3,
                                "title": "Note - VAE Decoder",
                                "bgcolor": "#593930",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "This node will take the latent data from the KSampler and, using the VAE, it will decode it into visible data\n\nVAE = Latent --> Visible\n\nThis can then be sent to the Save Image node to be saved as a PNG."
                                ]
                            },
                            {
                                "id": 42,
                                "pos": [
                                    564.5041024540307,
                                    801.1200708259006
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 260,
                                    "1": 210
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 4,
                                "title": "Note - Empty Latent Image",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "This node sets the image's resolution in Width and Height.\n\nNOTE: For SDXL, it is recommended to use trained values listed below:\n - 1024 x 1024\n - 1152 x 896\n - 896  x 1152\n - 1216 x 832\n - 832  x 1216\n - 1344 x 768\n - 768  x 1344\n - 1536 x 640\n - 640  x 1536"
                                ]
                            },
                            {
                                "id": 43,
                                "pos": [
                                    1125,
                                    70
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 240,
                                    "1": 80
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 5,
                                "title": "Note - CLIP Encode (REFINER)",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "These nodes receive the text from the prompt and use the optimal CLIP settings for the specified checkpoint model (in this case: SDXL Refiner)"
                                ]
                            },
                            {
                                "id": 39,
                                "pos": [
                                    599.4967909953033,
                                    449.4780241240287
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 80
                                },
                                "type": "Note",
                                "color": "#323",
                                "flags": {},
                                "order": 6,
                                "title": "Note - CLIP Encode (BASE)",
                                "bgcolor": "#535",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "These nodes receive the text from the prompt and use the optimal CLIP settings for the specified checkpoint model (in this case: SDXL Base)"
                                ]
                            },
                            {
                                "id": 48,
                                "pos": [
                                    1036,
                                    1018
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 213.90769958496094,
                                    "1": 110.17156982421875
                                },
                                "type": "Note",
                                "color": "#432",
                                "flags": {},
                                "order": 7,
                                "bgcolor": "#653",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "These can be used to control the total sampling steps and the step at which the sampling switches to the refiner."
                                ]
                            },
                            {
                                "id": 47,
                                "pos": [
                                    1037.5286840013239,
                                    881.6113881513106
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 82
                                },
                                "type": "PrimitiveNode",
                                "color": "#432",
                                "flags": {},
                                "order": 8,
                                "title": "end_at_step",
                                "bgcolor": "#653",
                                "outputs": [
                                    {
                                        "name": "INT",
                                        "type": "INT",
                                        "links": [
                                            43,
                                            44
                                        ],
                                        "widget": {
                                            "name": "end_at_step",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 0,
                                                    "default": 10000
                                                }
                                            ]
                                        },
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    20,
                                    "fixed"
                                ]
                            },
                            {
                                "id": 45,
                                "pos": [
                                    1040,
                                    735
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 82
                                },
                                "type": "PrimitiveNode",
                                "color": "#432",
                                "flags": {},
                                "order": 9,
                                "title": "steps",
                                "bgcolor": "#653",
                                "outputs": [
                                    {
                                        "name": "INT",
                                        "type": "INT",
                                        "links": [
                                            38,
                                            41
                                        ],
                                        "widget": {
                                            "name": "steps",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 1,
                                                    "default": 20
                                                }
                                            ]
                                        }
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    30,
                                    "fixed"
                                ]
                            },
                            {
                                "id": 13,
                                "pos": [
                                    80,
                                    250
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 160
                                },
                                "type": "PrimitiveNode",
                                "color": "#232",
                                "flags": {},
                                "order": 10,
                                "title": "Positive Prompt (Text)",
                                "bgcolor": "#353",
                                "outputs": [
                                    {
                                        "name": "STRING",
                                        "type": "STRING",
                                        "links": [
                                            16,
                                            21
                                        ],
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                ]
                            },
                            {
                                "id": 6,
                                "pos": [
                                    600,
                                    270
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 54
                                },
                                "type": "CLIPTextEncode",
                                "color": "#232",
                                "flags": {},
                                "order": 19,
                                "inputs": [
                                    {
                                        "link": 134,
                                        "name": "clip",
                                        "type": "CLIP"
                                    },
                                    {
                                        "link": 16,
                                        "name": "text",
                                        "type": "STRING",
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 1
                                    }
                                ],
                                "bgcolor": "#353",
                                "outputs": [
                                    {
                                        "name": "CONDITIONING",
                                        "type": "CONDITIONING",
                                        "links": [
                                            11
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CLIPTextEncode"
                                },
                                "widgets_values": [
                                    "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist"
                                ]
                            },
                            {
                                "id": 7,
                                "pos": [
                                    600,
                                    360
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 210,
                                    "1": 54
                                },
                                "type": "CLIPTextEncode",
                                "color": "#322",
                                "flags": {},
                                "order": 20,
                                "inputs": [
                                    {
                                        "link": 135,
                                        "name": "clip",
                                        "type": "CLIP"
                                    },
                                    {
                                        "link": 18,
                                        "name": "text",
                                        "type": "STRING",
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 1
                                    }
                                ],
                                "bgcolor": "#533",
                                "outputs": [
                                    {
                                        "name": "CONDITIONING",
                                        "type": "CONDITIONING",
                                        "links": [
                                            12
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CLIPTextEncode"
                                },
                                "widgets_values": [
                                    "low quality, medium quality, \ntext, signature, watermark, \n"
                                ]
                            },
                            {
                                "id": 12,
                                "pos": [
                                    600,
                                    -611
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 350,
                                    "1": 100
                                },
                                "type": "CheckpointLoaderSimple",
                                "color": "#323",
                                "flags": {},
                                "order": 11,
                                "title": "Load Checkpoint - REFINER",
                                "bgcolor": "#535",
                                "outputs": [
                                    {
                                        "name": "MODEL",
                                        "type": "MODEL",
                                        "links": [
                                            14
                                        ],
                                        "shape": 3,
                                        "slot_index": 0
                                    },
                                    {
                                        "name": "CLIP",
                                        "type": "CLIP",
                                        "links": [
                                            19,
                                            20
                                        ],
                                        "shape": 3,
                                        "slot_index": 1
                                    },
                                    {
                                        "name": "VAE",
                                        "type": "VAE",
                                        "links": [
                                            34
                                        ],
                                        "shape": 3,
                                        "slot_index": 2
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CheckpointLoaderSimple"
                                },
                                "widgets_values": [
                                    "sd_xl_refiner_1.0_0.9vae.safetensors"
                                ]
                            },
                            {
                                "id": 17,
                                "pos": [
                                    2214,
                                    108
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 200,
                                    "1": 50
                                },
                                "type": "VAEDecode",
                                "color": "#332922",
                                "flags": {},
                                "order": 23,
                                "inputs": [
                                    {
                                        "link": 25,
                                        "name": "samples",
                                        "type": "LATENT"
                                    },
                                    {
                                        "link": 34,
                                        "name": "vae",
                                        "type": "VAE"
                                    }
                                ],
                                "bgcolor": "#593930",
                                "outputs": [
                                    {
                                        "name": "IMAGE",
                                        "type": "IMAGE",
                                        "links": [
                                            116
                                        ],
                                        "shape": 3,
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "VAEDecode"
                                }
                            },
                            {
                                "id": 14,
                                "pos": [
                                    80,
                                    450
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 160
                                },
                                "type": "PrimitiveNode",
                                "color": "#322",
                                "flags": {},
                                "order": 12,
                                "title": "Negative Prompt (Text)",
                                "bgcolor": "#533",
                                "outputs": [
                                    {
                                        "name": "STRING",
                                        "type": "STRING",
                                        "links": [
                                            18,
                                            22
                                        ],
                                        "widget": {
                                            "name": "text",
                                            "config": [
                                                "STRING",
                                                {
                                                    "multiline": true
                                                }
                                            ]
                                        },
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    "low quality, medium quality, \ntext, signature, watermark, \n"
                                ]
                            },
                            {
                                "id": 40,
                                "pos": [
                                    1325,
                                    234
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 451.5049743652344,
                                    "1": 424.4164123535156
                                },
                                "type": "Note",
                                "color": "#223",
                                "flags": {},
                                "order": 13,
                                "title": "Note - KSampler  ADVANCED General Information",
                                "bgcolor": "#335",
                                "properties": {
                                    "text": ""
                                },
                                "widgets_values": [
                                    "Here are the settings that SHOULD stay in place if you want this workflow to work correctly:\n - add_noise: enable = This adds random noise into the picture so the model can denoise it\n\n - return_with_leftover_noise: enable = This sends the latent image data and all it's leftover noise to the next KSampler node.\n\nThe settings to pay attention to:\n - control_after_generate = generates a new random seed after each workflow job completed.\n - steps = This is the amount of iterations you would like to run the positive and negative CLIP prompts through. Each Step will add (positive) or remove (negative) pixels based on what stable diffusion \"thinks\" should be there according to the model's training\n - cfg = This is how much you want SDXL to adhere to the prompt. Lower CFG gives you more creative but often blurrier results. Higher CFG (recommended max 10) gives you stricter results according to the CLIP prompt. If the CFG value is too high, it can also result in \"burn-in\" where the edges of the picture become even stronger, often highlighting details in unnatural ways.\n - sampler_name = This is the sampler type, and unfortunately different samplers and schedulers have better results with fewer steps, while others have better success with higher steps. This will require experimentation on your part!\n - scheduler = The algorithm/method used to choose the timesteps to denoise the picture.\n - start_at_step = This is the step number the KSampler will start out it's process of de-noising the picture or \"removing the random noise to reveal the picture within\". The first KSampler usually starts with Step 0. Starting at step 0 is the same as setting denoise to 1.0 in the regular Sampler node.\n - end_at_step = This is the step number the KSampler will stop it's process of de-noising the picture. If there is any remaining leftover noise and return_with_leftover_noise is enabled, then it will pass on the left over noise to the next KSampler (assuming there is another one)."
                                ]
                            },
                            {
                                "id": 11,
                                "pos": [
                                    1800,
                                    130
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 340
                                },
                                "type": "KSamplerAdvanced",
                                "color": "#223",
                                "flags": {},
                                "order": 22,
                                "title": "KSampler (Advanced) - REFINER",
                                "inputs": [
                                    {
                                        "link": 14,
                                        "name": "model",
                                        "type": "MODEL",
                                        "slot_index": 0
                                    },
                                    {
                                        "link": 23,
                                        "name": "positive",
                                        "type": "CONDITIONING"
                                    },
                                    {
                                        "link": 24,
                                        "name": "negative",
                                        "type": "CONDITIONING"
                                    },
                                    {
                                        "link": 52,
                                        "name": "latent_image",
                                        "type": "LATENT"
                                    },
                                    {
                                        "link": 38,
                                        "name": "steps",
                                        "type": "INT",
                                        "widget": {
                                            "name": "steps",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 1,
                                                    "default": 20
                                                }
                                            ]
                                        },
                                        "slot_index": 4
                                    },
                                    {
                                        "link": 44,
                                        "name": "start_at_step",
                                        "type": "INT",
                                        "widget": {
                                            "name": "start_at_step",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 0,
                                                    "default": 0
                                                }
                                            ]
                                        }
                                    }
                                ],
                                "bgcolor": "#335",
                                "outputs": [
                                    {
                                        "name": "LATENT",
                                        "type": "LATENT",
                                        "links": [
                                            25
                                        ],
                                        "shape": 3,
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "KSamplerAdvanced"
                                },
                                "widgets_values": [
                                    "disable",
                                    0,
                                    "fixed",
                                    30,
                                    3,
                                    "dpmpp_2m",
                                    "karras",
                                    20,
                                    10000,
                                    "disable"
                                ]
                            },
                            {
                                "id": 10,
                                "pos": [
                                    1000,
                                    230
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 334
                                },
                                "type": "KSamplerAdvanced",
                                "color": "#223",
                                "flags": {},
                                "order": 21,
                                "title": "KSampler (Advanced) - BASE",
                                "inputs": [
                                    {
                                        "link": 136,
                                        "name": "model",
                                        "type": "MODEL"
                                    },
                                    {
                                        "link": 11,
                                        "name": "positive",
                                        "type": "CONDITIONING"
                                    },
                                    {
                                        "link": 12,
                                        "name": "negative",
                                        "type": "CONDITIONING"
                                    },
                                    {
                                        "link": 27,
                                        "name": "latent_image",
                                        "type": "LATENT"
                                    },
                                    {
                                        "link": 41,
                                        "name": "steps",
                                        "type": "INT",
                                        "widget": {
                                            "name": "steps",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 1,
                                                    "default": 20
                                                }
                                            ]
                                        },
                                        "slot_index": 4
                                    },
                                    {
                                        "link": 43,
                                        "name": "end_at_step",
                                        "type": "INT",
                                        "widget": {
                                            "name": "end_at_step",
                                            "config": [
                                                "INT",
                                                {
                                                    "max": 10000,
                                                    "min": 0,
                                                    "default": 10000
                                                }
                                            ]
                                        },
                                        "slot_index": 5
                                    }
                                ],
                                "bgcolor": "#335",
                                "outputs": [
                                    {
                                        "name": "LATENT",
                                        "type": "LATENT",
                                        "links": [
                                            52
                                        ],
                                        "shape": 3,
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "KSamplerAdvanced"
                                },
                                "widgets_values": [
                                    "enable",
                                    529518536884765,
                                    "randomize",
                                    30,
                                    7,
                                    "dpmpp_2m",
                                    "karras",
                                    0,
                                    20,
                                    "enable"
                                ]
                            },
                            {
                                "id": 78,
                                "pos": [
                                    50,
                                    -157
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 315,
                                    "1": 126
                                },
                                "type": "LoraLoader",
                                "flags": {},
                                "order": 18,
                                "inputs": [
                                    {
                                        "link": 137,
                                        "name": "model",
                                        "type": "MODEL"
                                    },
                                    {
                                        "link": 138,
                                        "name": "clip",
                                        "type": "CLIP"
                                    }
                                ],
                                "outputs": [
                                    {
                                        "name": "MODEL",
                                        "type": "MODEL",
                                        "links": [
                                            136
                                        ],
                                        "shape": 3,
                                        "slot_index": 0
                                    },
                                    {
                                        "name": "CLIP",
                                        "type": "CLIP",
                                        "links": [
                                            134,
                                            135
                                        ],
                                        "shape": 3,
                                        "slot_index": 1
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "LoraLoader"
                                },
                                "widgets_values": [
                                    "impressionism.safetensors",
                                    1,
                                    1
                                ]
                            },
                            {
                                "id": 4,
                                "pos": [
                                    46.56920039310091,
                                    -1014.9818597222632
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 350,
                                    "1": 100
                                },
                                "type": "CheckpointLoaderSimple",
                                "color": "#323",
                                "flags": {},
                                "order": 14,
                                "title": "Load Checkpoint - BASE",
                                "bgcolor": "#535",
                                "outputs": [
                                    {
                                        "name": "MODEL",
                                        "type": "MODEL",
                                        "links": [
                                            137
                                        ],
                                        "slot_index": 0
                                    },
                                    {
                                        "name": "CLIP",
                                        "type": "CLIP",
                                        "links": [
                                            138
                                        ],
                                        "slot_index": 1
                                    },
                                    {
                                        "name": "VAE",
                                        "type": "VAE",
                                        "links": [],
                                        "slot_index": 2
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "CheckpointLoaderSimple"
                                },
                                "widgets_values": [
                                    "talmendoxlSDXL_v11Beta.safetensors"
                                ]
                            },
                            {
                                "id": 5,
                                "pos": [
                                    544.5041024540301,
                                    651.1200708259006
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 300,
                                    "1": 110
                                },
                                "type": "EmptyLatentImage",
                                "color": "#323",
                                "flags": {},
                                "order": 15,
                                "bgcolor": "#535",
                                "outputs": [
                                    {
                                        "name": "LATENT",
                                        "type": "LATENT",
                                        "links": [
                                            27
                                        ],
                                        "slot_index": 0
                                    }
                                ],
                                "properties": {
                                    "Node name for S&R": "EmptyLatentImage"
                                },
                                "widgets_values": [
                                    1152,
                                    768,
                                    1
                                ]
                            },
                            {
                                "id": 62,
                                "pos": [
                                    2569,
                                    -298
                                ],
                                "mode": 0,
                                "size": {
                                    "0": 315,
                                    "1": 270
                                },
                                "type": "SaveImage",
                                "flags": {},
                                "order": 24,
                                "inputs": [
                                    {
                                        "link": 116,
                                        "name": "images",
                                        "type": "IMAGE"
                                    }
                                ],
                                "properties": {},
                                "widgets_values": [
                                    "ComfyUI"
                                ]
                            }
                        ],
                        "config": {},
                        "groups": [
                            {
                                "color": "#3f789e",
                                "title": "Base Prompt",
                                "bounding": [
                                    579,
                                    189,
                                    252,
                                    361
                                ]
                            },
                            {
                                "color": "#3f789e",
                                "title": "Refiner Prompt",
                                "bounding": [
                                    1102,
                                    -201,
                                    282,
                                    372
                                ]
                            },
                            {
                                "color": "#3f789e",
                                "title": "Text Prompts",
                                "bounding": [
                                    56,
                                    166,
                                    339,
                                    622
                                ]
                            },
                            {
                                "color": "#a1309b",
                                "title": "Load in BASE SDXL Model",
                                "bounding": [
                                    36,
                                    -1095,
                                    369,
                                    399
                                ]
                            },
                            {
                                "color": "#a1309b",
                                "title": "Load in REFINER SDXL Model",
                                "bounding": [
                                    581,
                                    -700,
                                    391,
                                    400
                                ]
                            },
                            {
                                "color": "#a1309b",
                                "title": "Empty Latent Image",
                                "bounding": [
                                    524,
                                    577,
                                    339,
                                    443
                                ]
                            },
                            {
                                "color": "#b06634",
                                "title": "VAE Decoder",
                                "bounding": [
                                    2142,
                                    51,
                                    360,
                                    350
                                ]
                            },
                            {
                                "color": "#3f789e",
                                "title": "Step Control",
                                "bounding": [
                                    1005,
                                    623,
                                    284,
                                    524
                                ]
                            }
                        ],
                        "version": 0.4,
                        "last_link_id": 138,
                        "last_node_id": 78
                    }
                },
                "steps": 30,
                "width": 1152,
                "height": 768,
                "models": [
                    "talmendoxlSDXL_v11Beta.safetensors",
                    "sd_xl_refiner_1.0_0.9vae.safetensors"
                ],
                "prompt": "A vast scene of Dream Weavers from Spyro in the style of Renoir, videogame, impressionist",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "modelIds": [],
                "scheduler": "karras",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "low quality, medium quality, \ntext, signature, watermark, \n",
                "additionalResources": [
                    {
                        "name": "impressionism.safetensors",
                        "type": "lora",
                        "strength": 1,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "ratchancellor",
            "baseModel": ""
        },
        {
            "id": 39429563,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2715ab1d-5d9f-4560-9de8-1b2fcd41ccbb/width=1248/2715ab1d-5d9f-4560-9de8-1b2fcd41ccbb.jpeg",
            "hash": "UeLW@hD%kpIA~VRPX8RjbcRjM{oztRjaniRk",
            "width": 1248,
            "height": 1824,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-10T21:14:23.723Z",
            "postId": 8994717,
            "stats": {
                "cryCount": 39,
                "laughCount": 74,
                "likeCount": 788,
                "dislikeCount": 0,
                "heartCount": 228,
                "commentCount": 1
            },
            "meta": {
                "": {},
                "VAE": "sdxl_vae_fixed.safetensors",
                "Size": "1248x1824",
                "seed": 16215382,
                "Model": "prefect_pony_xl_v4.fp16",
                "steps": 20,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "95ded7d685",
                    "lora:kiyosumi_akira_blue_archive_pdxl_goofy": "5bb40b097675"
                },
                "prompt": "score_9,score_8_up,score_7_up,<lora:kiyosumi_akira_blue_archive_pdxl_goofy:1>akiraBa, 1girl, black choker, smile, white gloves, halo, black bow, white shirt, holding mask, eye mask, colored eyelashes, looking at viewer, black bowtie, brooch, long sleeves, grin, white cape, upper body, blush, white coat, jewelry, cat girl,white hair,",
                "Version": "v1.10.1",
                "sampler": "DPM++ 2M",
                "{Method": {},
                "Upscaler": {},
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "5bb40b097675",
                        "name": "kiyosumi_akira_blue_archive_pdxl_goofy",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "95ded7d685",
                        "name": "prefect_pony_xl_v4.fp16",
                        "type": "model"
                    }
                ],
                "Model hash": "95ded7d685",
                "Tile Overlap": "48",
                "Schedule type": "Karras",
                "Upscale factor": "1.5",
                "negativePrompt": "realistic,monochrome,greyscale, artist name, signature, watermark,",
                "ADetailer model": "face_yolov8n.pt",
                "Keep input size": "true}",
                "Tile batch size": "6",
                "Tile tile width": "160",
                "Tiled Diffusion": {},
                "Tile tile height": "160",
                "ADetailer version": "24.8.0",
                "Denoising strength": "0.25",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "Tiled Diffusion upscaler": "4x-UltraSharp",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "Tiled Diffusion scale factor": "1.5",
                "ADetailer inpaint only masked": "True"
            },
            "username": "Goofy_Ai",
            "baseModel": "Pony"
        },
        {
            "id": 32126643,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/866e9ad2-ff75-4a9b-ab9a-8282718d25ed/width=832/866e9ad2-ff75-4a9b-ab9a-8282718d25ed.jpeg",
            "hash": "UL8E_An3.Ts.yFofbdtRM|RlM{R,RPofemjF",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-30T19:00:00.000Z",
            "postId": 7352655,
            "stats": {
                "cryCount": 24,
                "laughCount": 72,
                "likeCount": 774,
                "dislikeCount": 0,
                "heartCount": 258,
                "commentCount": 1
            },
            "meta": null,
            "username": "DoreenAI",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 26688729,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c3ed41da-8d15-47b1-8bef-80be975ef001/width=832/c3ed41da-8d15-47b1-8bef-80be975ef001.jpeg",
            "hash": "U5D+h]M{yr?G~UNdWoxt00%10LNGl9Rj^ks:",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-08-29T06:40:41.878Z",
            "postId": 5966700,
            "stats": {
                "cryCount": 17,
                "laughCount": 43,
                "likeCount": 793,
                "dislikeCount": 0,
                "heartCount": 275,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 3927923738,
                "extra": {
                    "remixOfId": 26519196
                },
                "steps": 15,
                "prompt": "score_9, score_8_up, \n1girl, female, 20 year old, pale skin, blue eyes, perfect round breasts, shiny skin, long hair, \noffice skirt, glasses, mini skirt, tight skirt, black blouse, top button unbuttoned, cleavage, standing with her arms crossed amplifying her cleavage, angry look on face, inside an office, long legs, sexy thighs, \ndepth of field, Breathtaking, highly detailed, sharp focus,",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-08-29T0639:16.2326781Z",
                "negativePrompt": "easynegative, teeth, worst quality, greyscale, artifacts,  unsharp, ugly, 3d, cartoon",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 578496,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 9208,
                        "modelVersionName": "EasyNegative"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 135867,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 382152,
                        "modelVersionName": "ExpressiveH"
                    },
                    {
                        "type": "lora",
                        "weight": 0.3,
                        "modelVersionId": 438481,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 522995,
                        "modelVersionName": "Pony"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250708,
                        "modelVersionName": "safe_pos"
                    },
                    {
                        "type": "embed",
                        "modelVersionId": 250712,
                        "modelVersionName": "safe_neg"
                    }
                ]
            },
            "username": "jon1992doe1992",
            "baseModel": "Pony"
        },
        {
            "id": 19638125,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c6ead0d8-a820-4a94-8839-6bb4aad664fa/width=1800/c6ead0d8-a820-4a94-8839-6bb4aad664fa.jpeg",
            "hash": "UDCPt~M^00bK~Bbv9ur^9DSyxb-B$LwfNGtQ",
            "width": 3192,
            "height": 4096,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-13T11:40:29.328Z",
            "postId": 4385403,
            "stats": {
                "cryCount": 24,
                "laughCount": 79,
                "likeCount": 748,
                "dislikeCount": 0,
                "heartCount": 277,
                "commentCount": 1
            },
            "meta": null,
            "username": "Zavy",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 34289125,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9850eb9a-d034-44ef-aae8-2984c6719733/width=1024/9850eb9a-d034-44ef-aae8-2984c6719733.jpeg",
            "hash": "UJDkKi-E0voa=*NEEb$-In$,-VR%9;NZSINY",
            "width": 1024,
            "height": 1024,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-13T01:42:01.124Z",
            "postId": 7835780,
            "stats": {
                "cryCount": 48,
                "laughCount": 79,
                "likeCount": 766,
                "dislikeCount": 0,
                "heartCount": 234,
                "commentCount": 0
            },
            "meta": {
                "seed": 863775656970498,
                "vaes": [],
                "Model": "BSSPonyXL_v1",
                "comfy": "{\"prompt\": {\"3\": {\"inputs\": {\"seed\": 863775656970498, \"steps\": 25, \"cfg\": 7.0, \"sampler_name\": \"euler_ancestral\", \"scheduler\": \"karras\", \"denoise\": 1.0, \"model\": [\"4\", 0], \"positive\": [\"6\", 0], \"negative\": [\"7\", 0], \"latent_image\": [\"5\", 0]}, \"class_type\": \"KSampler\"}, \"4\": {\"inputs\": {\"ckpt_name\": \"BSSPonyXL_v1.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"5\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"6\": {\"inputs\": {\"text\": \"score_9, score_8_up, score_7_up, score_6_up, glshs, 1girl, flower, mole, solo, portrait, rose, glowing, mole under eye, parted lips, looking at viewer, simple background, black background, purple theme, glowing eyes, white eyes, short hair\", \"clip\": [\"4\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"7\": {\"inputs\": {\"text\": \"score_5, score_4, score_3, ugly, fat\", \"clip\": [\"4\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"3\", 0], \"vae\": [\"4\", 2]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"BSS\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}}, \"workflow\": {\"last_node_id\": 11, \"last_link_id\": 9, \"nodes\": [{\"id\": 8, \"type\": \"VAEDecode\", \"pos\": [1209, 188], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 7}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 8}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [9], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 5, \"type\": \"EmptyLatentImage\", \"pos\": [473, 609], \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [2], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [1024, 1024, 1]}, {\"id\": 7, \"type\": \"CLIPTextEncode\", \"pos\": [413, 389], \"size\": {\"0\": 430, \"1\": 180}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 5}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [6], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_5, score_4, score_3, ugly, fat\"]}, {\"id\": 3, \"type\": \"KSampler\", \"pos\": [863, 186], \"size\": [320, 470], \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 1}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 4}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 6}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 2}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [7], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [863775656970498, \"randomize\", 25, 7, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 4, \"type\": \"CheckpointLoaderSimple\", \"pos\": [26, 474], \"size\": {\"0\": 320, \"1\": 100}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [1], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [3, 5], \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [8], \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"BSSPonyXL_v1.safetensors\"]}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": [1451, 189], \"size\": [420, 470], \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 9}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"BSS\"]}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": [415, 186], \"size\": {\"0\": 420, \"1\": 160}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 3}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [4], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_9, score_8_up, score_7_up, score_6_up, glshs, 1girl, flower, mole, solo, portrait, rose, glowing, mole under eye, parted lips, looking at viewer, simple background, black background, purple theme, glowing eyes, white eyes, short hair\"]}], \"links\": [[1, 4, 0, 3, 0, \"MODEL\"], [2, 5, 0, 3, 3, \"LATENT\"], [3, 4, 1, 6, 0, \"CLIP\"], [4, 6, 0, 3, 1, \"CONDITIONING\"], [5, 4, 1, 7, 0, \"CLIP\"], [6, 7, 0, 3, 2, \"CONDITIONING\"], [7, 3, 0, 8, 0, \"LATENT\"], [8, 4, 2, 8, 1, \"VAE\"], [9, 8, 0, 9, 0, \"IMAGE\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.7088742511245874, \"offset\": [-435.75139109749756, -115.50986396135218]}}, \"version\": 0.4, \"widget_idx_map\": {\"3\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"3\": 0}}}",
                "steps": 25,
                "width": 1024,
                "height": 1024,
                "models": [
                    "BSSPonyXL_v1.safetensors"
                ],
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, glshs, 1girl, flower, mole, solo, portrait, rose, glowing, mole under eye, parted lips, looking at viewer, simple background, black background, purple theme, glowing eyes, white eyes, short hair",
                "denoise": 1,
                "sampler": "Euler a",
                "cfgScale": 7,
                "modelIds": [],
                "scheduler": "karras",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "negativePrompt": "score_5, score_4, score_3, ugly, fat",
                "additionalResources": []
            },
            "username": "blacksnowskill",
            "baseModel": null
        },
        {
            "id": 30659396,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c86f99b5-c117-4b65-9bf4-c6f713584ed3/width=1160/c86f99b5-c117-4b65-9bf4-c6f713584ed3.jpeg",
            "hash": "UAC@ja9FF3^jVsMcD%R3E1%0RjI9.94nIA?w",
            "width": 1160,
            "height": 1696,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-22T01:03:34.584Z",
            "postId": 6859220,
            "stats": {
                "cryCount": 50,
                "laughCount": 117,
                "likeCount": 701,
                "dislikeCount": 0,
                "heartCount": 259,
                "commentCount": 0
            },
            "meta": {
                "seed": 603,
                "vaes": [
                    "FLUX1\\ae.sft"
                ],
                "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux_dev.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 50, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 603}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 3.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": 832, \"height\": 1216, \"model\": [\"156\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.5, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.05, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"156\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"73\": {\"inputs\": {\"intensity\": 0.07, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"69\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.35000000000000003, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 25, \"denoise\": 0.3, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"anime artwork and fantasy art of a female cyborg in a pristine, high-tech laboratory, surrounded by futuristic equipment and glowing monitors displaying complex data. She is in the process of having her mechanical components examined or upgraded, with robotic arms and tools delicately interacting with her. Her serene expression and calm demeanor contrast with the precision and complexity of the machinery around her. Focus on the detailed mechanical components of her body, intricate robotic hands, the clinical, high-tech environment, and the subtle interplay of human and machine elements.\\n\\na subtle, integrated communication system in her head or neck, with tiny speakers and microphones for direct interaction.a form-fitting, adaptive fabric bodysuit that covers parts of her body, adjusting its texture and rigidity based on her needs.Introduce subtle, bioluminescent vein-like structures that run through her mechanical components, pulsing gently with a soft glow.Integrate glowing, circuitry-like patterns onto her metallic parts, that light up and pulse.\\n\\n\", \"clip\": [\"156\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"117\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"file_type\": \"JPEG\", \"remove_metadata\": true, \"images\": [\"73\", 0]}, \"class_type\": \"SaveImagePlus\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"141\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"144\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"147\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"149\": {\"inputs\": {\"scale_method\": \"nearest-exact\", \"scale_factor\": 1.5, \"use_tiled_vae\": false}, \"class_type\": \"LatentPixelScale\"}, \"155\": {\"inputs\": {\"lora_name\": \"flux1\\\\detailed_skin_portraits-000005.safetensors\", \"strength_model\": 0.2, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"156\": {\"inputs\": {\"lora_name\": \"flux1\\\\Sakimi_chan_-_FLUX.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"155\", 0], \"clip\": [\"155\", 1]}, \"class_type\": \"LoraLoader\"}}, \"workflow\": {\"last_node_id\": 159, \"last_link_id\": 342, \"nodes\": [{\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1300, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 892, \"1\": 13}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1801, \"1\": 21}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 159}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 450, \"1\": 1353}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 289}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 503, \"1\": 18}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 141, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2036, \"1\": 41}, \"size\": {\"0\": 428.9556884765625, \"1\": 78}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": 2156, \"1\": 435}, \"size\": {\"0\": 504.7402648925781, \"1\": 472.86358642578125}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [294, 305], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [295, 306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [296, 307], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186, 297, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3079, \"1\": -575}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 311}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 148, \"type\": \"SaveImage\", \"pos\": {\"0\": 3061, \"1\": -483}, \"size\": {\"0\": 281.4468078613281, \"1\": 480.5931091308594}, \"flags\": {}, \"order\": 65, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 313}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 149, \"type\": \"LatentPixelScale\", \"pos\": {\"0\": 445.9807434082031, \"1\": 1519.1585693359375}, \"size\": {\"0\": 365.4000244140625, \"1\": 146}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model_opt\", \"type\": \"UPSCALE_MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentPixelScale\"}, \"widgets_values\": [\"nearest-exact\", 1.5, false]}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 883, \"1\": 1143}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 146, \"type\": \"DZ_Face_Detailer\", \"pos\": {\"0\": 2658, \"1\": -843}, \"size\": {\"0\": 309.8262939453125, \"1\": 842.9425659179688}, \"flags\": {}, \"order\": 60, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 305}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 306}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 307}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DZ_Face_Detailer\"}, \"widgets_values\": [1, \"fixed\", 20, 4, \"euler\", \"sgm_uniform\", 0.25, 32, \"face\", \"dilate\", 3, 3]}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": 14, \"1\": 1284}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 301, \"1\": -171}, \"size\": [75, 26], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 325}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 324, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 832, 1216]}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 28, \"1\": 303}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -29, \"1\": 159}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [333], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1303, \"1\": 949}, \"size\": {\"0\": 848.655029296875, \"1\": 899.4495849609375}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1505, \"1\": 40}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -37, \"1\": 33}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux_dev.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1454, \"1\": 131}, \"size\": [334.89553917655417, 535.3447223757851], \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 287, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [159, 308], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [603, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1813, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 61, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [260, 299], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.75, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 474, \"1\": 893}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 884, \"1\": 975}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 10, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 883, \"1\": 758}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 289], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 882, \"1\": 615}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 837, \"1\": 1291}, \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 142, \"type\": \"SaveImage\", \"pos\": {\"0\": 3181, \"1\": 87}, \"size\": {\"0\": 813.5270385742188, \"1\": 1236.560546875}, \"flags\": {}, \"order\": 67, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 300}], \"outputs\": [], \"title\": \"FinalPass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 140, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2769, \"1\": 86}, \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 64, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 294}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 295}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 296}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 297}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 298}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.25, 1, \"fixed\", 25, 3, \"euler\", \"sgm_uniform\", 0.2, \"Linear\", 832, 1216, 24, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 2233, \"1\": 955}, \"size\": {\"0\": 848.405029296875, \"1\": 898.4495849609375}, \"flags\": {}, \"order\": 68, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1819, \"1\": 370}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 66, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168, 282], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.07, 10, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 117, \"type\": \"SaveImagePlus\", \"pos\": {\"0\": 4366, \"1\": 456}, \"size\": {\"0\": 832.2413940429688, \"1\": 1183.025634765625}, \"flags\": {}, \"order\": 69, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 282}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImagePlus\"}, \"widgets_values\": [\"ComfyUI\", \"JPEG\", true]}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": -306, \"1\": 824}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 153, \"type\": \"LoraLoader\", \"pos\": {\"0\": -36, \"1\": 410}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 29, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 326}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 327}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [324], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [325], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\sabrina_carpenter.safetensors\", 1, 1]}, {\"id\": 154, \"type\": \"LoraLoader\", \"pos\": {\"0\": -401, \"1\": 405}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 26, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 338}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 339}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [326], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [327], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\TransparentDress_v1.safetensors\", 1, 1]}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 2061, \"1\": 273}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 63, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 260}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.3, 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1195, \"1\": 46}, \"size\": {\"0\": 245.11636352539062, \"1\": 82}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1214, \"1\": 174}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [287], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 487, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 50, 1]}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 258, \"1\": 793}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 342, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 155, \"type\": \"LoraLoader\", \"pos\": {\"0\": -23, \"1\": 601}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 332}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 333}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [330], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [331], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\detailed_skin_portraits-000005.safetensors\", 0.2, 1]}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 478, \"1\": 102}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1829, \"1\": 554}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 25, 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 862, \"1\": 2}, \"size\": [318.1961990975087, 569.048067717326], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 347, \"1\": 206}, \"size\": {\"0\": 488.2522277832031, \"1\": 387.7407531738281}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"anime artwork and fantasy art of a female cyborg in a pristine, high-tech laboratory, surrounded by futuristic equipment and glowing monitors displaying complex data. She is in the process of having her mechanical components examined or upgraded, with robotic arms and tools delicately interacting with her. Her serene expression and calm demeanor contrast with the precision and complexity of the machinery around her. Focus on the detailed mechanical components of her body, intricate robotic hands, the clinical, high-tech environment, and the subtle interplay of human and machine elements.\\n\\na subtle, integrated communication system in her head or neck, with tiny speakers and microphones for direct interaction.a form-fitting, adaptive fabric bodysuit that covers parts of her body, adjusting its texture and rigidity based on her needs.Introduce subtle, bioluminescent vein-like structures that run through her mechanical components, pulsing gently with a soft glow.Integrate glowing, circuitry-like patterns onto her metallic parts, that light up and pulse.\\n\\n\"]}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 617, \"1\": 645}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1216, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 386, \"1\": 646}, \"size\": [210, 82], \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 342], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [832, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 156, \"type\": \"LoraLoader\", \"pos\": {\"0\": -399, \"1\": 593}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 330}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 331}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [338], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [339], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Sakimi_chan_-_FLUX.safetensors\", 1, 1]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [159, 42, 0, 69, 0, \"LATENT\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [260, 72, 0, 71, 0, \"IMAGE\"], [282, 73, 0, 117, 0, \"IMAGE\"], [285, 75, 0, 59, 0, \"IMAGE\"], [287, 134, 0, 42, 2, \"SAMPLER\"], [288, 62, 0, 41, 0, \"IMAGE\"], [289, 61, 0, 77, 1, \"IMAGE\"], [294, 96, 0, 140, 1, \"MODEL\"], [295, 64, 0, 140, 2, \"CONDITIONING\"], [296, 65, 0, 140, 3, \"CONDITIONING\"], [297, 70, 0, 140, 4, \"VAE\"], [298, 141, 0, 140, 5, \"UPSCALE_MODEL\"], [299, 72, 0, 140, 0, \"IMAGE\"], [300, 140, 0, 142, 0, \"IMAGE\"], [305, 96, 0, 146, 0, \"MODEL\"], [306, 64, 0, 146, 1, \"CONDITIONING\"], [307, 65, 0, 146, 2, \"CONDITIONING\"], [308, 42, 0, 146, 3, \"LATENT\"], [310, 70, 0, 146, 4, \"VAE\"], [311, 146, 0, 147, 0, \"LATENT\"], [312, 81, 0, 147, 1, \"VAE\"], [313, 147, 0, 148, 0, \"IMAGE\"], [324, 153, 0, 30, 0, \"MODEL\"], [325, 153, 1, 49, 0, \"*\"], [326, 154, 0, 153, 0, \"MODEL\"], [327, 154, 1, 153, 1, \"CLIP\"], [330, 155, 0, 156, 0, \"MODEL\"], [331, 155, 1, 156, 1, \"CLIP\"], [332, 12, 0, 155, 0, \"MODEL\"], [333, 11, 0, 155, 1, \"CLIP\"], [338, 156, 0, 154, 0, \"MODEL\"], [339, 156, 1, 154, 1, \"CLIP\"], [342, 34, 0, 27, 0, \"INT\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.8264462809917354, \"offset\": [-353.1001006227467, 400.017171622672]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}, \"140\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"146\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"140\": 1, \"146\": 0}}}",
                "steps": 50,
                "models": [],
                "prompt": "anime artwork and fantasy art of a female cyborg in a pristine, high-tech laboratory, surrounded by futuristic equipment and glowing monitors displaying complex data. She is in the process of having her mechanical components examined or upgraded, with robotic arms and tools delicately interacting with her. Her serene expression and calm demeanor contrast with the precision and complexity of the machinery around her. Focus on the detailed mechanical components of her body, intricate robotic hands, the clinical, high-tech environment, and the subtle interplay of human and machine elements.\n\na subtle, integrated communication system in her head or neck, with tiny speakers and microphones for direct interaction.a form-fitting, adaptive fabric bodysuit that covers parts of her body, adjusting its texture and rigidity based on her needs.Introduce subtle, bioluminescent vein-like structures that run through her mechanical components, pulsing gently with a soft glow.Integrate glowing, circuitry-like patterns onto her metallic parts, that light up and pulse.\n\n",
                "denoise": 1,
                "sampler": "Euler",
                "cfgScale": 3,
                "modelIds": [],
                "scheduler": "sgm_uniform",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "flux1\\detailed_skin_portraits-000005.safetensors",
                        "type": "lora",
                        "strength": 0.2,
                        "strengthClip": 1
                    },
                    {
                        "name": "flux1\\Sakimi_chan_-_FLUX.safetensors",
                        "type": "lora",
                        "strength": 1,
                        "strengthClip": 1
                    }
                ]
            },
            "username": "salammy",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 30561473,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8b50e056-dfa3-440b-b8a1-87e9fe0b5631/width=1248/8b50e056-dfa3-440b-b8a1-87e9fe0b5631.jpeg",
            "hash": "UQFr6N^*?ax]~V?bT0-p-otRXTNHI;oKM{WE",
            "width": 1248,
            "height": 1824,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-21T10:10:05.413Z",
            "postId": 6837480,
            "stats": {
                "cryCount": 37,
                "laughCount": 58,
                "likeCount": 742,
                "dislikeCount": 0,
                "heartCount": 290,
                "commentCount": 0
            },
            "meta": {
                "": {},
                "VAE": "sdxl_vae_fixed.safetensors",
                "Size": "1248x1824",
                "seed": 960219572,
                "Model": "prefect_pony_xl_v3.fp16",
                "steps": 20,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "e31a2563f0",
                    "lora:skin_color_slider_pdxl_goofy": "f78fa120cdb6"
                },
                "prompt": "score_9,score_8_up,score_7_up, <lora:skin_color_slider_pdxl_goofy:-6>1girl, belt, black gloves, blonde hair, blue eyes, breasts, closed mouth, earrings, eyelashes, gloves, high collar, jewelry, light blush, long hair, looking at viewer, necklace, smile, solo, v",
                "Version": "v1.10.1",
                "sampler": "DPM++ 2M",
                "{Method": {},
                "Upscaler": {},
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "f78fa120cdb6",
                        "name": "skin_color_slider_pdxl_goofy",
                        "type": "lora"
                    },
                    {
                        "hash": "e31a2563f0",
                        "name": "prefect_pony_xl_v3.fp16",
                        "type": "model"
                    }
                ],
                "Model hash": "e31a2563f0",
                "Tile Overlap": "48",
                "Schedule type": "Karras",
                "Upscale factor": "1.5",
                "negativePrompt": "realistic,monochrome,greyscale, artist name, signature, watermark,",
                "ADetailer model": "face_yolov8n.pt",
                "Keep input size": "true}",
                "Tile batch size": "6",
                "Tile tile width": "160",
                "Tiled Diffusion": {},
                "Tile tile height": "160",
                "ADetailer version": "24.8.0",
                "Denoising strength": "0.3",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "Tiled Diffusion upscaler": "4x-UltraSharp",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "Tiled Diffusion scale factor": "1.5",
                "ADetailer inpaint only masked": "True"
            },
            "username": "Goofy_Ai",
            "baseModel": "Pony"
        },
        {
            "id": 38739942,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cccb684b-cf7f-493f-b0c3-7c7be901acbf/width=1800/cccb684b-cf7f-493f-b0c3-7c7be901acbf.jpeg",
            "hash": "UTL;4=4o~p^*_3s+NLo#.SxCxCX9x_t7WBWY",
            "width": 2128,
            "height": 1456,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-06T23:44:25.980Z",
            "postId": 8842661,
            "stats": {
                "cryCount": 55,
                "laughCount": 135,
                "likeCount": 718,
                "dislikeCount": 0,
                "heartCount": 218,
                "commentCount": 0
            },
            "meta": {
                "RNG": "NV",
                "Size": "1216x832",
                "seed": 3157406149,
                "Model": "morgymix_v40AAAAAAAAA_935993",
                "steps": 18,
                "hashes": {
                    "model": "0425a621ea",
                    "lora:JebWinsMeme_illusXL_Incrs_v1": "5b21d2a5ac02"
                },
                "prompt": "masterpiece, best quality, map, united states, outstretched arms, upper body, yellow background, white background, english text, <lora:JebWinsMeme_illusXL_Incrs_v1:1>, 1girl, looking to the side, seductive smile, tifa lockhart,",
                "Version": "f2.0.1v1.10.1-previous-584-g9a698e26",
                "sampler": "Restart",
                "Module 1": "sdxl_vae",
                "cfgScale": 6,
                "resources": [
                    {
                        "hash": "5b21d2a5ac02",
                        "name": "JebWinsMeme_illusXL_Incrs_v1",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "0425a621ea",
                        "name": "morgymix_v40AAAAAAAAA_935993",
                        "type": "model"
                    }
                ],
                "Model hash": "0425a621ea",
                "Hires steps": "10",
                "Hires sampler": "Euler a",
                "Hires upscale": "1.75",
                "Schedule type": "SGM Uniform",
                "Hires Module 1": "Use same choices",
                "Hires upscaler": "2x-AnimeSharpV3",
                "negativePrompt": "lowres, worst quality, low quality, bad anatomy, bad proportions, extra limbs, extra digit, extra legs, extra legs and arms, disfigured, missing arms, too many fingers, fused fingers, missing fingers, unclear eyes, username, simple background, 4koma, perineum, realistic, covered nipples,",
                "ADetailer model": "face_yolov8n.pt",
                "Hires CFG Scale": "6",
                "ADetailer version": "24.9.0",
                "Denoising strength": "0.4",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.3",
                "ADetailer inpaint only masked": "True"
            },
            "username": "FallenIncursio",
            "baseModel": "Illustrious"
        },
        {
            "id": 27448712,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e65c9849-ee2b-4b14-a4ab-af6c74d4bd21/width=832/e65c9849-ee2b-4b14-a4ab-af6c74d4bd21.jpeg",
            "hash": "U8C~SR~C0N4=-*Nt9ZIU9[Sv~3-iIDWFoNxI",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-09-02T21:07:56.683Z",
            "postId": 6138273,
            "stats": {
                "cryCount": 30,
                "laughCount": 211,
                "likeCount": 684,
                "dislikeCount": 0,
                "heartCount": 201,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1568400242,
                "steps": 25,
                "prompt": "First - at the top of the image golden letters spelling out \"Pimpin ain't easy\"\nSecond - A photorealistic image of a Minion from Despicable Me, dressed as a pimp. The Minion is wearing a luxurious purple fur coat, a wide-brimmed hat with a feather and leopard pattern band, and holding a silver-tipped cane. He\u2019s adorned with diamond rings and a golden dollar sign necklace, all reflecting light in a dazzling display. The Minion's expression is smug, full of attitude, as he strikes a confident pose. The background is minimal, ensuring the focus remains on the hilarious and over-the-top ensemble. Masterpiece quality, highly detailed, capturing the absurdity of the scene",
                "sampler": "Undefined",
                "cfgScale": 3.5,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-09-02T1245:24.3718075Z",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    }
                ]
            },
            "username": "UnstableGen",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 25343760,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8f31b8e3-3db4-4819-9532-bd2c08a21dfb/width=1248/8f31b8e3-3db4-4819-9532-bd2c08a21dfb.jpeg",
            "hash": "UUG*{Vw1Kln3lVOYtns+N|x]tlIob_kXsns:",
            "width": 1248,
            "height": 1872,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-08-21T00:35:50.297Z",
            "postId": 5663533,
            "stats": {
                "cryCount": 42,
                "laughCount": 62,
                "likeCount": 754,
                "dislikeCount": 0,
                "heartCount": 268,
                "commentCount": 0
            },
            "meta": {
                "RNG": "CPU",
                "VAE": "sdxl_vae.safetensors",
                "Size": "832x1248",
                "seed": 2984265773,
                "Model": "hosekiLustrousmixPony_v10",
                "steps": 28,
                "hashes": {
                    "vae": "63aeecb90f",
                    "model": "182c96501c",
                    "lora:eriko-pdxl-nvwls-v1-000005": "b6b129dece8c"
                },
                "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime, 1girl, solo  <lora:eriko-pdxl-nvwls-v1-000005:1> defEko, brown hair, short hair, bob cut, broken horn, demon horns, purple eyes, fur collar, red capelet, white dress, cleavage, fur trim, red skirt, fur-trimmed skirt, sleeveless, gauntlets, armored boots, spiked tail, purple tail, huge breasts, looking at you, smirk, blue sky, mountains, upper body",
                "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
                "sampler": "Euler a",
                "cfgScale": 7,
                "resources": [
                    {
                        "hash": "b6b129dece8c",
                        "name": "eriko-pdxl-nvwls-v1-000005",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "182c96501c",
                        "name": "hosekiLustrousmixPony_v10",
                        "type": "model"
                    }
                ],
                "Model hash": "182c96501c",
                "Hires steps": "10",
                "Hires upscale": "1.5",
                "Schedule type": "Automatic",
                "Hires upscaler": "4x-AnimeSharp",
                "negativePrompt": "monochrome",
                "ADetailer model": "face_yolov8n.pt",
                "ADetailer version": "24.4.2",
                "Denoising strength": "0.5",
                "ADetailer mask blur": "4",
                "ADetailer confidence": "0.3",
                "ADetailer dilate erode": "4",
                "ADetailer inpaint padding": "32",
                "ADetailer denoising strength": "0.4",
                "ADetailer inpaint only masked": "True"
            },
            "username": "novowels",
            "baseModel": "Pony"
        },
        {
            "id": 18287363,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/db4b70e0-3e76-4e4b-ab3b-8764295603d0/width=832/db4b70e0-3e76-4e4b-ab3b-8764295603d0.jpeg",
            "hash": "UeI}^Vs.R6Rk_3t6NFWW~qkCt6bHtQW=V[oL",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-07-03T16:30:00.000Z",
            "postId": 4086248,
            "stats": {
                "cryCount": 33,
                "laughCount": 66,
                "likeCount": 739,
                "dislikeCount": 0,
                "heartCount": 288,
                "commentCount": 1
            },
            "meta": {
                "RNG": "CPU",
                "VAE": "fixFP16ErrorsSDXLLowerMemoryUse_v10.safetensors",
                "ENSD": "31337",
                "Size": "832x1216",
                "seed": 1371370708,
                "Model": "autismmixSDXL_autismmixConfetti",
                "steps": 20,
                "hashes": {
                    "vae": "235745af8d",
                    "model": "ac006fdd7e",
                    "lora:wrnchexpwhimsicalvisions": "afe824a6c694"
                },
                "prompt": "score_9, score_8_up, score_7_up, source_anime, <lora:wrnchexpwhimsicalvisions:1>, wrnchexpwhimsicalvisions, silhouette, double exposure, white background, solo, 1boy, humanoid pointy ears, waterfall, tree,",
                "Version": "f0.0.17v1.8.0rc-latest-287-g77bdb920",
                "sampler": "Euler a",
                "cfgScale": 6,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "afe824a6c694",
                        "name": "wrnchexpwhimsicalvisions",
                        "type": "lora",
                        "weight": 1
                    },
                    {
                        "hash": "ac006fdd7e",
                        "name": "autismmixSDXL_autismmixConfetti",
                        "type": "model"
                    }
                ],
                "Model hash": "ac006fdd7e",
                "negativePrompt": "3d, greyscale, monochrome,"
            },
            "username": "wrench1815",
            "baseModel": "Pony"
        },
        {
            "id": 16058450,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d97d096f-8cd0-44d1-9a93-8d0fcb2d9a03/width=1216/d97d096f-8cd0-44d1-9a93-8d0fcb2d9a03.jpeg",
            "hash": "UBC6_WDkm6K5v~OrwJMdIowuD*S%~Tt8DQW-",
            "width": 1216,
            "height": 832,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-06-16T22:59:38.881Z",
            "postId": 3587478,
            "stats": {
                "cryCount": 27,
                "laughCount": 81,
                "likeCount": 715,
                "dislikeCount": 0,
                "heartCount": 303,
                "commentCount": 3
            },
            "meta": {
                "Size": "1216x832",
                "seed": 1446682423,
                "steps": 34,
                "prompt": "(award winning photo)of  a cave surrounded by gemstones in the distance you can see a water basin with a waterfall blue roses grow by the basin the light from the gemstones with which the wall is decorated falls on the water and casts shadows on the rose petals the atmosphere of the picture is magical and warm,(masterpiece, best quality),(sharp focus:1.2),(photorealistic),(intricate details),unity 8k wallpaper,ultra detailed,glow particle, ultra detailed face,ultra detailed eyes",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 4,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-06-16T2256:23.2225008Z",
                "negativePrompt": "low quality, worst quality, bad hands,",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 291443,
                        "modelVersionName": "v24"
                    },
                    {
                        "type": "lora",
                        "weight": 1,
                        "modelVersionId": 293991,
                        "modelVersionName": "v24"
                    },
                    {
                        "type": "embed",
                        "weight": 1,
                        "modelVersionId": 7440,
                        "modelVersionName": "Nebula Magic"
                    }
                ]
            },
            "username": "Jedas",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 13180695,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/49d8a281-9d53-4ea5-aa90-7e03e2334079/width=832/49d8a281-9d53-4ea5-aa90-7e03e2334079.jpeg",
            "hash": "U9A]$u4U9w_1y=0LWC^%O[+tRno}^*rqENS$",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-05-21T20:19:00.067Z",
            "postId": 2914522,
            "stats": {
                "cryCount": 44,
                "laughCount": 81,
                "likeCount": 714,
                "dislikeCount": 0,
                "heartCount": 287,
                "commentCount": 7
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1598982299,
                "Model": "paradox3SDXL10_paradox3SDXL10.safetensors",
                "steps": 20,
                "hashes": {
                    "model": "A32D1921A6770D1263FF8C2599A31C84095ADB7F182CE885C5F2208C5F714467"
                },
                "prompt": "singular intricately flowing light strands against a black background\r\n<lora:artfullyECHELIER_SDXL_V1:0.7>\r\n<lora:xl_more_art-full_v1:0.5>\r\n<lora:MJ52:0.5>\r\n<lora:detailed_notrigger:0.5>\r\n<lora:extremely_detailed:0.5>\r\n<lora:add-detail-xl:0.5>",
                "sampler": "DPM++ 2M SDE Karras",
                "cfgScale": 3,
                "resources": [
                    {
                        "name": "artfullyECHELIER_SDXL_V1",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "name": "xl_more_art-full_v1",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "name": "MJ52",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "name": "detailed_notrigger",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "name": "extremely_detailed",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "name": "add-detail-xl",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "hash": "A32D1921A6770D1263FF8C2599A31C84095ADB7F182CE885C5F2208C5F714467",
                        "name": "paradox3SDXL10_paradox3SDXL10.safetensors",
                        "type": "model"
                    }
                ],
                "Model hash": "A32D1921A6770D1263FF8C2599A31C84095ADB7F182CE885C5F2208C5F714467",
                "negativePrompt": "Worst quality, art, drawing, painting,"
            },
            "username": "Carcamagnu",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 10957242,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f57cebff-8409-40c1-9d86-28d03afd46b7/width=768/f57cebff-8409-40c1-9d86-28d03afd46b7.jpeg",
            "hash": "U19jcQ?b0000_N%M004oICoKs,oJE2WCemxu",
            "width": 768,
            "height": 768,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-04-28T04:24:16.601Z",
            "postId": 2402442,
            "stats": {
                "cryCount": 32,
                "laughCount": 287,
                "likeCount": 571,
                "dislikeCount": 0,
                "heartCount": 236,
                "commentCount": 4
            },
            "meta": {
                "seed": 564001504600105,
                "vaes": [],
                "Model": "SDXL\\dreamshaperXL_v2TurboDpmppSDE",
                "comfy": "{\"prompt\": {\"1\": {\"inputs\": {\"ckpt_name\": \"SDXL\\\\dreamshaperXL_v2TurboDpmppSDE.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"2\": {\"inputs\": {\"lora_name\": \"SDXL\\\\custom\\\\withlegs06.safetensors\", \"strength_model\": 1.5, \"strength_clip\": 1.5, \"model\": [\"1\", 0], \"clip\": [\"86\", 0]}, \"class_type\": \"LoraLoader\"}, \"45\": {\"inputs\": {\"samples\": [\"219\", 0], \"vae\": [\"1\", 2]}, \"class_type\": \"VAEDecode\"}, \"86\": {\"inputs\": {\"stop_at_clip_layer\": -1, \"clip\": [\"1\", 1]}, \"class_type\": \"CLIPSetLastLayer\"}, \"187\": {\"inputs\": {\"width\": 768, \"height\": 768, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"216\": {\"inputs\": {\"text\": \"skull with legs, standing\", \"clip\": [\"2\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"217\": {\"inputs\": {\"text\": \"\", \"clip\": [\"2\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"218\": {\"inputs\": {\"filename_prefix\": \"WithLegsV04\", \"images\": [\"45\", 0]}, \"class_type\": \"SaveImage\"}, \"219\": {\"inputs\": {\"seed\": 564001504600105, \"steps\": 4, \"cfg\": 2.0, \"sampler_name\": \"dpmpp_sde\", \"scheduler\": \"karras\", \"denoise\": 1.0, \"model\": [\"2\", 0], \"positive\": [\"216\", 0], \"negative\": [\"217\", 0], \"latent_image\": [\"187\", 0]}, \"class_type\": \"KSampler\"}}, \"workflow\": {\"last_node_id\": 220, \"last_link_id\": 768, \"nodes\": [{\"id\": 45, \"type\": \"VAEDecode\", \"pos\": [2780, 590], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 759}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 763}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [758], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 187, \"type\": \"EmptyLatentImage\", \"pos\": [1970, 830], \"size\": {\"0\": 210, \"1\": 110}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [766], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [768, 768, 1]}, {\"id\": 1, \"type\": \"CheckpointLoaderSimple\", \"pos\": [-220, 720], \"size\": {\"0\": 460, \"1\": 100}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [8], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [403], \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [763], \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"SDXL\\\\dreamshaperXL_v2TurboDpmppSDE.safetensors\"]}, {\"id\": 218, \"type\": \"SaveImage\", \"pos\": [3070, 590], \"size\": {\"0\": 420, \"1\": 470}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 758}], \"properties\": {}, \"widgets_values\": [\"WithLegsV04\"]}, {\"id\": 86, \"type\": \"CLIPSetLastLayer\", \"pos\": [350, 740], \"size\": {\"0\": 210, \"1\": 60}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 403}], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [404], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPSetLastLayer\"}, \"widgets_values\": [-1]}, {\"id\": 219, \"type\": \"KSampler\", \"pos\": [2360, 590], \"size\": {\"0\": 315, \"1\": 262}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 762}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 767}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 768}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 766}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [759], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [564001504600105, \"increment\", 4, 2, \"dpmpp_sde\", \"karras\", 1]}, {\"id\": 217, \"type\": \"CLIPTextEncode\", \"pos\": [1380, 820], \"size\": {\"0\": 210, \"1\": 250}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 757}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [768], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 2, \"type\": \"LoraLoader\", \"pos\": [660, 720], \"size\": {\"0\": 350, \"1\": 130}, \"flags\": {\"collapsed\": false}, \"order\": 3, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 8}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 404}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [762], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [756, 757], \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"SDXL\\\\custom\\\\withlegs06.safetensors\", 1.5, 1.5]}, {\"id\": 216, \"type\": \"CLIPTextEncode\", \"pos\": [1380, 610], \"size\": {\"0\": 210, \"1\": 160}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 756}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [767], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"skull with legs, standing\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}], \"links\": [[8, 1, 0, 2, 0, \"MODEL\"], [403, 1, 1, 86, 0, \"CLIP\"], [404, 86, 0, 2, 1, \"CLIP\"], [756, 2, 1, 216, 0, \"CLIP\"], [757, 2, 1, 217, 0, \"CLIP\"], [758, 45, 0, 218, 0, \"IMAGE\"], [759, 219, 0, 45, 0, \"LATENT\"], [762, 2, 0, 219, 0, \"MODEL\"], [763, 1, 2, 45, 1, \"VAE\"], [766, 187, 0, 219, 3, \"LATENT\"], [767, 216, 0, 219, 1, \"CONDITIONING\"], [768, 217, 0, 219, 2, \"CONDITIONING\"]], \"groups\": [], \"config\": {}, \"extra\": {\"groupNodes\": {}}, \"version\": 0.4}}",
                "steps": 4,
                "width": 768,
                "height": 768,
                "models": [
                    "SDXL\\dreamshaperXL_v2TurboDpmppSDE.safetensors"
                ],
                "prompt": "skull with legs, standing",
                "denoise": 1,
                "sampler": "DPM++ SDE Karras",
                "cfgScale": 2,
                "modelIds": [],
                "scheduler": "karras",
                "upscalers": [],
                "versionIds": [],
                "controlNets": [],
                "additionalResources": [
                    {
                        "name": "SDXL\\custom\\withlegs06.safetensors",
                        "type": "lora",
                        "strength": 1.5,
                        "strengthClip": 1.5
                    }
                ]
            },
            "username": "Ofuld",
            "baseModel": null
        },
        {
            "id": 10821533,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1e27071f-dbf9-42fc-8478-df3eed79336a/width=1080/1e27071f-dbf9-42fc-8478-df3eed79336a.jpeg",
            "hash": "U49jAz%fIA03p{C2+EvLF~+j5p-n00,0E*-.",
            "width": 1080,
            "height": 1920,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-04-26T16:34:42.806Z",
            "postId": 2372875,
            "stats": {
                "cryCount": 25,
                "laughCount": 73,
                "likeCount": 720,
                "dislikeCount": 0,
                "heartCount": 307,
                "commentCount": 0
            },
            "meta": {
                "seed": 850800389759105,
                "steps": 11,
                "sampler": "DPM++ 2M",
                "cfgScale": 1
            },
            "username": "ipiv",
            "baseModel": null
        },
        {
            "id": 10054507,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/61ed68cb-d38d-4f47-ae5b-d1cf0a499dc8/width=1080/61ed68cb-d38d-4f47-ae5b-d1cf0a499dc8.jpeg",
            "hash": "U36Hlh~U0M039#N2tQ={0M9b?Z^%-U$*X9Ne",
            "width": 1080,
            "height": 1920,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-04-17T00:36:30.150Z",
            "postId": 2189968,
            "stats": {
                "cryCount": 0,
                "laughCount": 50,
                "likeCount": 784,
                "dislikeCount": 0,
                "heartCount": 291,
                "commentCount": 12
            },
            "meta": null,
            "username": "Grymauch",
            "baseModel": null
        },
        {
            "id": 36866115,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7f2fd54b-d0eb-43ad-8655-0349e59218d0/width=1536/7f2fd54b-d0eb-43ad-8655-0349e59218d0.jpeg",
            "hash": "UYD+e_D+~BRmNN%2Iqs:9at7IURktPRjxts.",
            "width": 1536,
            "height": 2312,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-10-27T16:10:24.506Z",
            "postId": 8419916,
            "stats": {
                "cryCount": 26,
                "laughCount": 67,
                "likeCount": 805,
                "dislikeCount": 0,
                "heartCount": 226,
                "commentCount": 1
            },
            "meta": {
                "Size": "1024x1544",
                "seed": 150557012,
                "Model": "wildcardxXLFusion_fusionOG",
                "steps": 25,
                "hashes": {
                    "model": "22ebc61141"
                },
                "Version": "v1.10.1",
                "sampler": "Euler a",
                "cfgScale": 6,
                "Mask blur": "4",
                "resources": [
                    {
                        "hash": "22ebc61141",
                        "name": "wildcardxXLFusion_fusionOG",
                        "type": "model"
                    }
                ],
                "Model hash": "22ebc61141",
                "Schedule type": "Automatic",
                "Denoising strength": "0"
            },
            "username": "Castr0",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 18000574,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b1328b8c-9ffc-4ab0-89b4-5a35a82200b1/width=832/b1328b8c-9ffc-4ab0-89b4-5a35a82200b1.jpeg",
            "hash": "UCHxjE0K0J%24nxvs*t74T-;Ipxu_ND%D%D%",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-07-01T15:05:01.072Z",
            "postId": 4025006,
            "stats": {
                "cryCount": 45,
                "laughCount": 121,
                "likeCount": 663,
                "dislikeCount": 0,
                "heartCount": 295,
                "commentCount": 0
            },
            "meta": {
                "Size": "832x1216",
                "seed": 1910306249,
                "steps": 50,
                "prompt": "gorgeous lips, cinematic, (masterpiece), (best quality), (ultra-detailed), very aesthetic, illustration, perfect composition, intricate details, absurdres, detailed face, (anime, masterpiece, intricate:1.3), (best quality, hires textures, high detail:1.2)\nblack nurse, thighhighs, nurse cap, black elbow gloves, long hair, purple hair, red eyes, mature female, 35 years old, (best quality), (high quality), {masterpiece}, perfect hands, extremely delicate and beautiful, ultra-detailed, beautiful detailed eyes, nurse, nurse hat, ((black nurse's outfit)), black legwear, zettai ryouiki, hospital, surgery room, ((black surgical mask, covered nose)), standing",
                "sampler": "DPM++ 2M Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [],
                "Created Date": "2024-07-01T1444:39.8329511Z",
                "negativePrompt": "loli, child, longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, worst quality, low quality, normal quality, watermark, artist name, signature",
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 403131,
                        "modelVersionName": "v3.1"
                    },
                    {
                        "type": "lora",
                        "weight": 0.8,
                        "modelVersionId": 129711,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "vae",
                        "weight": 1,
                        "modelVersionId": 333245,
                        "modelVersionName": "SDXL-VAE"
                    }
                ]
            },
            "username": "Fujishimi",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 14080895,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/33a8be51-2aa1-425c-b4e0-ab5762a86bb1/width=1800/33a8be51-2aa1-425c-b4e0-ab5762a86bb1.jpeg",
            "hash": "UEI}V0?b.7?a~qnh0eNFS%xax]t7_3%3x[xu",
            "width": 2048,
            "height": 2048,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-05-30T23:47:04.436Z",
            "postId": 3123374,
            "stats": {
                "cryCount": 14,
                "laughCount": 91,
                "likeCount": 743,
                "dislikeCount": 0,
                "heartCount": 276,
                "commentCount": 6
            },
            "meta": null,
            "username": "NaomiVK",
            "baseModel": ""
        },
        {
            "id": 11962880,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a5f575a3-c35b-4991-829b-ddcf8f78f7be/width=1104/a5f575a3-c35b-4991-829b-ddcf8f78f7be.jpeg",
            "hash": "UHF}co~Vxa={-P5SMxxGRj-ToJ57~B^*xuNI",
            "width": 1104,
            "height": 1616,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-05-09T11:22:43.049Z",
            "postId": 2638951,
            "stats": {
                "cryCount": 39,
                "laughCount": 69,
                "likeCount": 705,
                "dislikeCount": 0,
                "heartCount": 311,
                "commentCount": 1
            },
            "meta": {
                "NGMS": "1.5",
                "Size": "832x1216",
                "seed": 3500347292,
                "Model": "DigitalDreamV1.2",
                "steps": 40,
                "hashes": {
                    "model": "69a05275b4"
                },
                "prompt": "Woman, body art, hyper realistic eye, Satin Sheets Gold, Sapphire Blue, Peacock Blue,  skin, close-up, chaotic, flaming, skin texture, pulsating, cinematic angle,",
                "Version": "v1.7.0",
                "sampler": "DPM++ 2S a Karras",
                "cfgScale": 7,
                "clipSkip": 2,
                "resources": [
                    {
                        "hash": "69a05275b4",
                        "name": "DigitalDreamV1.2",
                        "type": "model"
                    }
                ],
                "Model hash": "69a05275b4",
                "Hires upscale": "1.33",
                "Hires upscaler": "4x-UltraSharp",
                "Denoising strength": "0.48",
                "Token merging ratio": "0.5",
                "Token merging ratio hr": "0.5"
            },
            "username": "TalesfromOurDigitalLives",
            "baseModel": "SDXL 1.0"
        },
        {
            "id": 38731080,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ed80eb56-2179-425d-a61f-6acee461dd73/width=832/ed80eb56-2179-425d-a61f-6acee461dd73.jpeg",
            "hash": "UACZL+6S5Y?ahL=^wuIo:zIorCrVMa#lNIt8",
            "width": 832,
            "height": 1216,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-11-06T22:26:53.619Z",
            "postId": 8840460,
            "stats": {
                "cryCount": 42,
                "laughCount": 222,
                "likeCount": 673,
                "dislikeCount": 0,
                "heartCount": 186,
                "commentCount": 2
            },
            "meta": null,
            "username": "UnstableGen",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 27631665,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ce964639-e0fc-4cf7-a838-1f9d432a7cad/width=1344/ce964639-e0fc-4cf7-a838-1f9d432a7cad.jpeg",
            "hash": "UIFEi,}[xZt7=|}[-pofM{xGNGs:^kIoIoxG",
            "width": 1344,
            "height": 1728,
            "nsfwLevel": "None",
            "nsfw": false,
            "browsingLevel": 1,
            "createdAt": "2024-09-04T00:01:50.962Z",
            "postId": 6179511,
            "stats": {
                "cryCount": 32,
                "laughCount": 67,
                "likeCount": 794,
                "dislikeCount": 0,
                "heartCount": 230,
                "commentCount": 3
            },
            "meta": {
                "Size": "896x1152",
                "seed": 1260328098,
                "steps": 25,
                "prompt": "hyper realistic and highly detailed, highly dynamic cinematic panorama view, a beautiful young woman is standing in the water next to a gargantuan dragon, in the style of fantasy scenes, realistic detail, magewave, ferrania p30, Bisque and Blush Pink hue, atmospheric haze, panoramic zoomed out view, highly dramatic lighting, MythP0rt\n<lora:FredFraiStyle-FLUX-Share:0.5>  <lora:FluxMythP0rtr4itStyle:0.7>   <lora:dark_fantasy_flux:0.9>",
                "sampler": "Euler",
                "cfgScale": 3.1,
                "resources": [
                    {
                        "name": "FredFraiStyle-FLUX-Share",
                        "type": "lora",
                        "weight": 0.5
                    },
                    {
                        "name": "FluxMythP0rtr4itStyle",
                        "type": "lora",
                        "weight": 0.7
                    },
                    {
                        "name": "dark_fantasy_flux",
                        "type": "lora",
                        "weight": 0.9
                    }
                ],
                "civitaiResources": [
                    {
                        "type": "checkpoint",
                        "modelVersionId": 691639,
                        "modelVersionName": "Dev"
                    },
                    {
                        "type": "lora",
                        "weight": 0.9,
                        "modelVersionId": 738658,
                        "modelVersionName": "v1.0"
                    },
                    {
                        "type": "lora",
                        "weight": 0.5,
                        "modelVersionId": 759600,
                        "modelVersionName": "FredFraiche!"
                    },
                    {
                        "type": "lora",
                        "weight": 0.7,
                        "modelVersionId": 753053,
                        "modelVersionName": "Flux"
                    }
                ]
            },
            "username": "ArtifyAI",
            "baseModel": "Flux.1 D"
        },
        {
            "id": 19794132,
            "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0677f9c8-ab50-43f3-96b2-f33b08bec2c9/width=1152/0677f9c8-ab50-43f3-96b2-f33b08bec2c9.jpeg",
            "hash": "UeNTUZRP~q%M?HxukDRj9FNG%Ms:-;ofadt7",
            "width": 1152,
            "height": 1728,
            "nsfwLevel": "Soft",
            "nsfw": true,
            "browsingLevel": 2,
            "createdAt": "2024-07-14T13:38:58.394Z",
            "postId": 4419065,
            "stats": {
                "cryCount": 33,
                "laughCount": 80,
                "likeCount": 749,
                "dislikeCount": 0,
                "heartCount": 261,
                "commentCount": 0
            },
            "meta": {
                "steps": 30,
                "prompt": "score_9, 1girl, solo, breasts, smile, bow,  looking at viewer, red bowtie, simple background, long hair, school uniform, open mouth, shirt, large breasts, upper body, mamaneeir, cowboy shot, black hair, grey eyes,",
                "sampler": "Euler a",
                "cfgScale": 8,
                "negativePrompt": "speech bubble"
            },
            "username": "spotetonee",
            "baseModel": null
        }
    ],
    "metadata": {
        "nextCursor": "4850|1727677502809",
        "nextPage": "https://civitai.com/api/v1/images?sort=Most%20Reactions&nsfw=Soft&cursor=4850%7C1727677502809"
    }
}