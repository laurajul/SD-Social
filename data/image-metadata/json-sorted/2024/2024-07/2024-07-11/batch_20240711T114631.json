[
    {
        "id": 19369635,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c519109e-01e2-4ff9-bfd1-9b1ddce9d565/width=832/c519109e-01e2-4ff9-bfd1-9b1ddce9d565.jpeg",
        "hash": "U08zcO=x00Bpl:tR0KWVTfNG%e$j00jFUZOD",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-11T11:46:31.890Z",
        "postId": 4327340,
        "stats": {
            "cryCount": 1,
            "laughCount": 0,
            "likeCount": 153,
            "dislikeCount": 0,
            "heartCount": 73,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 548203700,
            "steps": 50,
            "prompt": "a nightmare, an evil creature, (horns, bones), detailed, high resolution, eerie, atmospheric, foreboding, linquivera, (black and red ink:1.6), dripping ink, symmetrical, black background,\n((full-clothed armor)), ((long big sword in hands, long sword in hands)), \nBREAK \nstrange world background score_9, score_8_up, score_7_up, score_6_up, source_cartoon, rating_explicit, Expressiveh, (((((full body))))), dynamic pose",
            "sampler": "Euler a",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-07-11T1145:35.8502545Z",
            "negativePrompt": "score_6, score_5, score_4, censored, skin blemish, child, kid, 3D, bad anatomy, dismembered, disembodied, elderly, wrinkles, cross-eyed, deformed,  deformed fingers, short legs, body diproportion. dark scene, , disfigured, kitsch, ugly, grain, low-res, poorly drawn face, mutation, mutated, extra limb, poorly drawn hands, missing limb, blurry, floating limbs, disconnected limbs, malformed hands, blur, out of focus, long neck, long body, disgusting, poorly drawn, childish, mutilated, mangled, old, surreal, double body, double face, incorrect posture, close up, two heads, two faces, plastic, Deformed, blurry, bad anatomy, bad eyes, crossed eyes, disfigured, poorly drawn face, mutation, mutated, blender, doll, cropped, low-res, close-up, poorly-drawn face, out of frame double, two heads, blurred, ugly, disfigured, too many fingers, deformed, repetitive, text, watermark, nude, vagina, topless, furry,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 290640,
                    "modelVersionName": "V6 (start with this one)"
                },
                {
                    "type": "lora",
                    "weight": 0.15,
                    "modelVersionId": 342682,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 378830,
                    "modelVersionName": "Pony V2.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 382152,
                    "modelVersionName": "ExpressiveH"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 399443,
                    "modelVersionName": "detailed painting v1.0"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250708,
                    "modelVersionName": "safe_pos"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250712,
                    "modelVersionName": "safe_neg"
                }
            ]
        },
        "username": "LLIATATEJlb",
        "baseModel": "Pony"
    },
    {
        "id": 18709075,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a9586abe-4b67-43ea-b613-11d6eb430f4b/width=1152/a9586abe-4b67-43ea-b613-11d6eb430f4b.jpeg",
        "hash": "UBDI?:8^9]?G~q9F9]tS0fi_WYogOZ%MVrV@",
        "width": 1152,
        "height": 2016,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-06T17:20:00.973Z",
        "postId": 4178607,
        "stats": {
            "cryCount": 0,
            "laughCount": 6,
            "likeCount": 172,
            "dislikeCount": 0,
            "heartCount": 49,
            "commentCount": 0
        },
        "meta": {
            "RNG": "NV",
            "Size": "768x1344",
            "seed": 1403537348,
            "Model": "realcartoonXL_v6",
            "steps": 20,
            "hashes": {
                "model": "d370e2fbaa"
            },
            "prompt": "hyperrealistic photo of a female shield maiden, long blonde braided hair, intricate leather armor, detailed skin texture, cinematic lighting, sharp focus, ultra-realistic, 8k, very detailed, high quality",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "Euler a",
            "cfgScale": 8,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "d370e2fbaa",
                    "name": "realcartoonXL_v6",
                    "type": "model"
                }
            ],
            "Model hash": "d370e2fbaa",
            "Extra noise": "0.05",
            "Hires steps": "100",
            "ControlNet 0": {
                "Model": "thibaud_xl_openpose [c7b9cadd]",
                "Module": "dw_openpose_full",
                "Weight": "0.95",
                "Hr Option": "Both",
                "Resize Mode": "Resize and Fill",
                "Threshold A": "0.5",
                "Threshold B": "0.5",
                "Control Mode": "My prompt is more important",
                "Guidance End": "1",
                "Pixel Perfect": "False",
                "Processor Res": "512",
                "Guidance Start": "0"
            },
            "Hires upscale": "1.5",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "cartoon, drawing, low quality, blurry, distorted, unrealistic, overexposed, underexposed, low resolution, abstract, pixelated\nbad hands, fewer digits, extra digits,",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.5.1",
            "Denoising strength": "0.5",
            "ADetailer mask blur": "32",
            "ADetailer model 2nd": "full_eyes_detect_v1.pt",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer mask blur 2nd": "32",
            "ADetailer confidence 2nd": "0.3",
            "ADetailer inpaint padding": "32",
            "ADetailer ControlNet model": "thibaud_xl_openpose [c7b9cadd]",
            "ADetailer dilate erode 2nd": "4",
            "ADetailer ControlNet module": "dw_openpose_full",
            "ADetailer denoising strength": "0.5",
            "ADetailer inpaint only masked": "True",
            "ADetailer inpaint padding 2nd": "32",
            "ADetailer ControlNet model 2nd": "thibaud_xl_openpose [c7b9cadd]",
            "ADetailer ControlNet module 2nd": "animal_openpose",
            "ADetailer denoising strength 2nd": "0.5",
            "ADetailer inpaint only masked 2nd": "True"
        },
        "username": "salammy",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 18395407,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/179be03d-7248-47da-bab8-fba5a3ea5df9/width=512/179be03d-7248-47da-bab8-fba5a3ea5df9.jpeg",
        "hash": "UCATWkkD:Nn#D4ay--oI~Vofozj?ETa#z-WA",
        "width": 512,
        "height": 768,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-04T10:37:57.087Z",
        "postId": 4109660,
        "stats": {
            "cryCount": 0,
            "laughCount": 0,
            "likeCount": 227,
            "dislikeCount": 0,
            "heartCount": 0,
            "commentCount": 0
        },
        "meta": {
            "Size": "512x768",
            "seed": 248494703,
            "steps": 40,
            "prompt": "(ultra high res:1.4), (masterpiece), (beautiful lighting:1.4) , ((scenery)), raw movie poster, (masterpiece, best quality:1.5), masterpiece, best quality, high quality,extremely detailed CG unity 8k wallpaper, (ultra high res:1.4), (masterpiece), (beautiful lighting:1.4) , (RAW photo, 8k uhd, Analog style, Masterpiece, Best Quality, Highres:1.4), (dramatic, cinematic:1.2), a purple spell book flying, with flying rune or leter, magical room, library, dark background, glowing, flying paper, book page opening",
            "sampler": "Euler",
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-07-04T1037:34.6412931Z",
            "negativePrompt": "worst quality, normal quality, low quality, blurry, blurred,jpeg artifacts,((monochrome)), ((grayscale)), error,poor effort,unsharp,bad composition, ugly from far away, ugly, lowres, signature, watermark, url, website, username, patreon username, writing, text, letters, logo, out of frame, grainy, noisy, draft,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 128713,
                    "modelVersionName": "8"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208,
                    "modelVersionName": "EasyNegative"
                }
            ]
        },
        "username": "toyyy",
        "baseModel": "SD 1.5"
    },
    {
        "id": 18337179,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/95c0be7b-8b1b-4258-9d6a-08923382f792/width=1280/95c0be7b-8b1b-4258-9d6a-08923382f792.jpeg",
        "hash": "U8BC=W}uDO0_^8^7xbEL00=f%hxHAB9@Vs}b",
        "width": 1280,
        "height": 1920,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-04T00:22:08.269Z",
        "postId": 4096918,
        "stats": {
            "cryCount": 3,
            "laughCount": 9,
            "likeCount": 175,
            "dislikeCount": 0,
            "heartCount": 40,
            "commentCount": 0
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "800x1200",
            "seed": 485259418,
            "Model": "ForArtisticXL-v0.1",
            "steps": 26,
            "hashes": {
                "vae": "235745af8d",
                "model": "34cd71e533",
                "lora:CBS_novuschroma37 style_b": "6e1eab82e245"
            },
            "prompt": "Futuristic city with neon lights \n,  <lora:CBS_novuschroma37 style_b:1> novuschroma37 style, style of experimental photography, double exposure",
            "Version": "f0.0.17v1.8.0rc-latest-278-gbfee03d8",
            "sampler": "DDPM",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "6e1eab82e245",
                    "name": "CBS_novuschroma37 style_b",
                    "type": "lora"
                },
                {
                    "hash": "34cd71e533",
                    "name": "ForArtisticXL-v0.1",
                    "type": "model"
                }
            ],
            "Model hash": "34cd71e533",
            "Hires steps": "15",
            "Hires upscale": "1.6",
            "Hires upscaler": "SwinIR_4x",
            "Variation seed": "3975302483",
            "negativePrompt": "boring,  bad quality, blurry,",
            "Denoising strength": "0.28",
            "Variation seed strength": "0.76"
        },
        "username": "AIDigitalMediaAgency",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 18023669,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6eb53948-ff8e-4178-83e7-f1c2533b7995/width=864/6eb53948-ff8e-4178-83e7-f1c2533b7995.jpeg",
        "hash": "URC~^?-;xuIo~qxuozRj?bt7t7ae-;t7xuof",
        "width": 864,
        "height": 1536,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-07-01T18:22:57.165Z",
        "postId": 4029562,
        "stats": {
            "cryCount": 0,
            "laughCount": 4,
            "likeCount": 155,
            "dislikeCount": 0,
            "heartCount": 68,
            "commentCount": 0
        },
        "meta": {
            "VAE": "vae-ft-mse-840000-ema-pruned.safetensors",
            "Size": "576x1024",
            "seed": 2013755235,
            "Model": "animerge_v50",
            "steps": 25,
            "hashes": {
                "vae": "74bd301605",
                "model": "2d50bd63c7",
                "lora:backlight_slider_v10": "bce77b76fba3"
            },
            "prompt": "supergirl, upper body, platinum blonde hair, upper body, city background,  stylized,   sharp, extreme detailed, HD, HDR, , masterpiece, high quality, high resolution, breathtaking, award-winning, professional, sleeves past wrists,\n <lora:backlight_slider_v10:-1>, (photorealistic:1.5), (film grain:1.5),",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ 2M SDE Karras",
            "cfgScale": 5,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "bce77b76fba3",
                    "name": "backlight_slider_v10",
                    "type": "lora"
                },
                {
                    "hash": "2d50bd63c7",
                    "name": "animerge_v50",
                    "type": "model"
                }
            ],
            "Model hash": "2d50bd63c7",
            "Extra noise": "0.15",
            "ControlNet 0": {
                "Model": "control_v11p_sd15_openpose [cab727d4]",
                "Module": "dw_openpose_full",
                "Weight": "1",
                "Hr Option": "Both",
                "Resize Mode": "Crop and Resize",
                "Threshold A": "0.5",
                "Threshold B": "0.5",
                "Control Mode": "My prompt is more important",
                "Guidance End": "1",
                "Pixel Perfect": "True",
                "Processor Res": "683",
                "Guidance Start": "0"
            },
            "Hires upscale": "1.5",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "(FastNegativeV2:1.3), fewer digits, extra digits, bad-hands-5, bad anatomy, bad hands,",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.5.1",
            "Denoising strength": "0.5",
            "ADetailer mask blur": "4",
            "ADetailer model 2nd": "full_eyes_detect_v1.pt",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer mask blur 2nd": "4",
            "ADetailer confidence 2nd": "0.3",
            "ADetailer inpaint padding": "32",
            "ADetailer ControlNet model": "control_v11f1e_sd15_tile [a371b31b]",
            "ADetailer dilate erode 2nd": "4",
            "ADetailer ControlNet module": "tile_resample",
            "ADetailer denoising strength": "0.5",
            "ADetailer inpaint only masked": "True",
            "ADetailer inpaint padding 2nd": "32",
            "ADetailer ControlNet model 2nd": "control_v11f1e_sd15_tile [a371b31b]",
            "ADetailer ControlNet module 2nd": "tile_resample",
            "ADetailer denoising strength 2nd": "0.5",
            "ADetailer inpaint only masked 2nd": "True"
        },
        "username": "salammy",
        "baseModel": "SD 1.5"
    },
    {
        "id": 17476117,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d59c1730-1f6d-4788-bdcf-72783d0015e0/width=1344/d59c1730-1f6d-4788-bdcf-72783d0015e0.jpeg",
        "hash": "U8Bf%v~84;x]~oxVM|t84;bI-oRj4;x[={RP",
        "width": 1344,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-27T21:53:26.555Z",
        "postId": 3913854,
        "stats": {
            "cryCount": 1,
            "laughCount": 10,
            "likeCount": 158,
            "dislikeCount": 0,
            "heartCount": 58,
            "commentCount": 1
        },
        "meta": {
            "Size": "896x1152",
            "seed": 3602892396,
            "Model": "ArtiVisionXL_mixV1",
            "steps": 15,
            "hashes": {
                "model": "4e1a2c8ce7"
            },
            "prompt": "highly detailed and hyper realistic photo, by John Atkinson Grimshaw , by Jeff Easley , by Charles Mellin , a ethereal aerial Pegasus , in the style of  visionary realism, limited dark palette, unusual dark colors, faded colors, atmospheric haze, highly dramatic cinematic lighting, motion blur, film grain,  professional, excellent composition, finest details, maximized details, ultimate detail level, masterpiece, best quality",
            "Version": "v1.9.4",
            "sampler": "Euler",
            "cfgScale": 3,
            "resources": [
                {
                    "hash": "4e1a2c8ce7",
                    "name": "ArtiVisionXL_mixV1",
                    "type": "model"
                }
            ],
            "Model hash": "4e1a2c8ce7",
            "Hires steps": "25",
            "Hires upscale": "1.5",
            "Schedule type": "Automatic",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "(worst quality, greyscale, jpeg artifacts, unnatural skin:2)",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer steps": "30",
            "ADetailer prompt": {},
            "ADetailer version": "24.5.1",
            "Denoising strength": "0.4",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint width": "512",
            "ADetailer inpaint height": "768",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.3",
            "ADetailer use separate steps": "True",
            "ADetailer inpaint only masked": "True",
            "ADetailer mask only top k largest": "2",
            "ADetailer use inpaint width height": "True"
        },
        "username": "ArtifyAI",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 14020709,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/94ebcc1a-e89f-4717-a8f7-e34ba1dab7e7/width=1248/94ebcc1a-e89f-4717-a8f7-e34ba1dab7e7.jpeg",
        "hash": "UEGatC~UR%oe9zMzx@^i%LogRkEM5QxtR:NH",
        "width": 1248,
        "height": 1824,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-30T07:22:43.177Z",
        "postId": 3109486,
        "stats": {
            "cryCount": 17,
            "laughCount": 21,
            "likeCount": 146,
            "dislikeCount": 0,
            "heartCount": 43,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2482510217,
            "Model": "albedobaseXL_v21",
            "steps": 25,
            "hashes": {
                "model": "1718b5bb2d",
                "lora:add-detail-xl": "9c783c8ce46c",
                "lora:xl_more_art-full_v1": "fe3b4816be83"
            },
            "prompt": "phoenix rising from the ashes, , <lora:add-detail-xl:1> <lora:xl_more_art-full_v1:1>",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ 2M SDE Karras",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "9c783c8ce46c",
                    "name": "add-detail-xl",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "fe3b4816be83",
                    "name": "xl_more_art-full_v1",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "1718b5bb2d",
                    "name": "albedobaseXL_v21",
                    "type": "model"
                }
            ],
            "Model hash": "1718b5bb2d",
            "Hires steps": "15",
            "Hires upscale": "1.5",
            "Hires upscaler": "4x_NMKD-Superscale-SP_178000_G",
            "negativePrompt": "jpeg artifacts, blurry",
            "Denoising strength": "0.4"
        },
        "username": "popyay",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 13759812,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2046c689-fdea-463c-8f78-b5040db71ecd/width=1352/2046c689-fdea-463c-8f78-b5040db71ecd.jpeg",
        "hash": "UEJQTJ01KNgO_M8{Au%Kb_01SOR*_N$e-9Ne",
        "width": 1352,
        "height": 1920,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-27T18:29:25.282Z",
        "postId": 3049313,
        "stats": {
            "cryCount": 1,
            "laughCount": 1,
            "likeCount": 127,
            "dislikeCount": 0,
            "heartCount": 99,
            "commentCount": 0
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "ENSD": "31337",
            "Size": "848x1200",
            "seed": 2830725580,
            "Model": "autismmixSDXL_autismmixPony",
            "steps": 25,
            "hashes": {
                "vae": "235745af8d",
                "model": "821aa5537f",
                "lora:GwenTenXL": "43741bba978d"
            },
            "prompt": "(score_9,score_8_up,score_7_up,), Gwendolyn_Tennyson, (calling viewer toward her :1.2) , (beckoning, beckoning finger :1.3) , 1girl,solo,maid, side smile, collarbone ,maid headdress,looking at viewer,apron,indoors,depth of field, sitting on table, (legs, stockings) \n<lora:GwenTenXL:1>",
            "Version": "v1.9.3",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "43741bba978d",
                    "name": "GwenTenXL",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "821aa5537f",
                    "name": "autismmixSDXL_autismmixPony",
                    "type": "model"
                }
            ],
            "Model hash": "821aa5537f",
            "Hires steps": "10",
            "Hires upscale": "1.6",
            "Schedule type": "Automatic",
            "Hires upscaler": "R-ESRGAN 4x+ Anime6B",
            "negativePrompt": "(score_4,score_5,score_3,score_2,score_1),ugly,bad feet,extra,",
            "Denoising strength": "0.3"
        },
        "username": "reevee",
        "baseModel": "Pony"
    },
    {
        "id": 13488311,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0020a158-568c-4ee6-b2d3-4f89321ee096/width=832/0020a158-568c-4ee6-b2d3-4f89321ee096.jpeg",
        "hash": "USG*N3IWRR-n}-WDIWWUMyxsofM}IuocozR,",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-25T00:11:22.378Z",
        "postId": 2985288,
        "stats": {
            "cryCount": 2,
            "laughCount": 5,
            "likeCount": 153,
            "dislikeCount": 0,
            "heartCount": 67,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1652695646,
            "steps": 29,
            "prompt": "score_9, score_8_up, score_8, (solo:1.5), (fluffy:0.8), (feral:1.5), furry, (((mouse))), female, claws, (fluffy cheeks:0.5), (dress), j_cartoon, cute, (head focus, side view, portrait:1.5), (art nouveau:1.2), fca style",
            "sampler": "Euler a",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-05-24T2325:43.7801406Z",
            "negativePrompt": "score_6, score_5, score_4, (loli, cub, young, child, chibi:1.5), busty, ugly face, low res, blurry face, ugly hands, pumped body, black and white, penis, breasts, ((hair:2)), nipples, belly, extra ears, human, simple background, (extra tail), markings, tail",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 290640,
                    "modelVersionName": "V6 (start with this one)"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 302106,
                    "modelVersionName": "Line Art"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 314058,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 396609,
                    "modelVersionName": "XL v1.0"
                }
            ]
        },
        "username": "JustAMouse",
        "baseModel": "Pony"
    },
    {
        "id": 12702995,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1893b4af-80b0-4847-91cc-3ad1b0ce27f5/width=832/1893b4af-80b0-4847-91cc-3ad1b0ce27f5.jpeg",
        "hash": "UC9Q:Q.8RkWCpJ%gxuof_N%MogV@bwtRtRj@",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-17T00:53:08.631Z",
        "postId": 2807005,
        "stats": {
            "cryCount": 0,
            "laughCount": 13,
            "likeCount": 159,
            "dislikeCount": 0,
            "heartCount": 55,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2094519296,
            "steps": 47,
            "prompt": "very dark focused flash photo, amazing quality, masterpiece, best quality, extremely detailed, ultra detailed, UHD, perfect anatomy, (dnd black dragon:1.5), portrait, dof, hyper-realism, majestic, (Fighter, druid, ranger, wizard typical dnd party:1.1), awesome, inspiring, Capture the thrilling showdown between the full dnd party and the colossal black dragon boss in an epic battle amidst spraying mud and driving Rain. Embrace the action and chaos as these formidable forces clash in the heart of the bleak wasteland. cinematic composition, soft shadows, national geographic style",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "easynegative, bad proportions, long neck, glowing eyes, fire, low resolution, bad, ugly, terrible, painting, 3d, render, comic, anime, manga, unrealistic, flat, watermark, signature, worst quality, low quality, normal quality, lowres, simple background, inaccurate limb, extra fingers, fewer fingers, missing fingers, extra arms, (extra legs:1.3), inaccurate eyes, bad composition, bad anatomy, error, extra digit, fewer digits, cropped, low res, worst quality, low quality, normal quality, jpeg artifacts, extra digit, fewer digits, trademark, watermark, artist's name, username, signature, text, words, human,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 155870
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 152309
                },
                {
                    "type": "lora",
                    "weight": 0.35,
                    "modelVersionId": 258687
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 332071
                },
                {
                    "type": "lora",
                    "weight": 0.85,
                    "modelVersionId": 369959
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916
                }
            ]
        },
        "username": "yohony666",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 9674966,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/54957516-3391-4cbf-b955-284a8678e8e7/width=768/54957516-3391-4cbf-b955-284a8678e8e7.jpeg",
        "hash": "UTLE4=5RAC=_?dbJyDRPJEiws+t7TKtR%1of",
        "width": 768,
        "height": 1152,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-04-11T20:04:20.838Z",
        "postId": 2097115,
        "stats": {
            "cryCount": 4,
            "laughCount": 7,
            "likeCount": 111,
            "dislikeCount": 0,
            "heartCount": 105,
            "commentCount": 1
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "ENSD": "31337",
            "Size": "768x1152",
            "seed": 1329210489,
            "Model": "EMS-305126-EMS",
            "steps": 25,
            "TaskID": "715512367215160106",
            "hashes": {
                "lora:EMS-344951-EMS": "c2af41cb162f"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, scenery, 1girl, dress, asian, pink hair, green eyes, freckles, mole, smile, lips, curvy, large breasts, fully clothed, intricate outfit, tattoo, solo, outdoors, blue sky, castle, princess, fantasy<lora:EMS-344951-EMS:1.000000>",
            "Version": "v1.6.0.133-1-gaca9268",
            "sampler": "Euler a",
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "c2af41cb162f",
                    "name": "EMS-344951-EMS",
                    "type": "lora",
                    "weight": 1
                }
            ],
            "negativePrompt": "3d, bad hands, out of frame, watermark, signature",
            "ADetailer model": "mediapipe_face_full",
            "ADetailer version": "23.9.1",
            "Denoising strength": "0",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.5",
            "Style Selector Style": "base",
            "ADetailer dilate/erode": "4",
            "Style Selector Enabled": "True",
            "Style Selector Randomize": "False",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.25",
            "ADetailer inpaint only masked": "True"
        },
        "username": "Spartacus98",
        "baseModel": null
    },
    {
        "id": 6623230,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/24434b28-b329-42f7-99eb-4252d18ae458/width=1024/24434b28-b329-42f7-99eb-4252d18ae458.jpeg",
        "hash": "U69%e[5400v}~EIT4,?K00$+OU%OWZtRxvRP",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-14T12:20:46.501Z",
        "postId": 1430215,
        "stats": {
            "cryCount": 0,
            "laughCount": 10,
            "likeCount": 131,
            "dislikeCount": 0,
            "heartCount": 86,
            "commentCount": 3
        },
        "meta": null,
        "username": "Anna_ai_art",
        "baseModel": ""
    },
    {
        "id": 5826375,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ae1c7892-8b87-4872-85ee-f8f2a6346aae/width=1536/ae1c7892-8b87-4872-85ee-f8f2a6346aae.jpeg",
        "hash": "UFB|BPxa4mRk~C%0E1IV$cWUI=NG-:ocMyR:",
        "width": 1536,
        "height": 2400,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-01-24T07:33:04.325Z",
        "postId": 1265467,
        "stats": {
            "cryCount": 5,
            "laughCount": 7,
            "likeCount": 102,
            "dislikeCount": 0,
            "heartCount": 113,
            "commentCount": 0
        },
        "meta": {
            "ENSD": "31337",
            "Size": "768x1200",
            "seed": 1879939875,
            "Model": "aamXLAnimeMix_v10",
            "steps": 28,
            "hashes": {
                "model": "d48c2391e0"
            },
            "prompt": "a broken ruined cyborg girl in a landfill, robot, beautiful face, body is broken with scars and holes, laying on the ground, 8K, (dynamic perspective), sharp focus, (depth of field, bokeh:1.3), extremely detailed eyes and face, beautiful detailed eyes, hyperpunk scene, cinematic lighting, reflective transparent iridescent opaque jacket, long transparent iridescent RGB hair, ((masterpiece, best quality)), niji, from above, upper body, navel, sachin teng <lora:IOS_Iridescent_opal_style:0.6>",
            "Version": "v1.7.0",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "name": "IOS_Iridescent_opal_style",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "hash": "d48c2391e0",
                    "name": "aamXLAnimeMix_v10",
                    "type": "model"
                }
            ],
            "Model hash": "d48c2391e0",
            "Hires steps": "26",
            "Hires upscale": "2",
            "Hires upscaler": "Latent",
            "negativePrompt": "(low quality, worst quality:1.4), negativeXL_D, cgi,  text, signature, watermark, extra limbs",
            "Denoising strength": "0.45",
            "\"IOS_Iridescent_opal_style": "99ece5fc9ab5\""
        },
        "username": "motimalu",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 5683030,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/95151ad9-2ac1-481a-910e-9fc36b01acc8/width=1024/95151ad9-2ac1-481a-910e-9fc36b01acc8.jpeg",
        "hash": "UE9@|?yE9aVs00H?%Ltkk[x^aJM{~qt79vxu",
        "width": 1024,
        "height": 1536,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-01-20T05:55:53.775Z",
        "postId": 1237218,
        "stats": {
            "cryCount": 1,
            "laughCount": 5,
            "likeCount": 142,
            "dislikeCount": 0,
            "heartCount": 79,
            "commentCount": 2
        },
        "meta": {
            "VAE": "anythingKlF8Anime2VaeFtMse_vaeFtMse840000.safetensors",
            "Size": "512x768",
            "seed": 3397500191,
            "Model": "selaiMix_v10Bakedvae",
            "steps": 20,
            "hashes": {
                "model": "11702a5b73"
            },
            "prompt": "masterpiece,high quality,highres,1girl,solo,<lora:ophelia-parody-v1-wasabiya:1>,ophesyle,water,partially submerged,closed eyes,emotionless,branches,swamp,,(blue hair ),long hair,night ,from side ,",
            "Version": "v1.7.0",
            "sampler": "DPM++ 2M SDE Karras",
            "VAE hash": "e852361da7",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "11702a5b73",
                    "name": "selaiMix_v10Bakedvae",
                    "type": "model"
                }
            ],
            "Model hash": "11702a5b73",
            "Hires upscale": "2",
            "Hires upscaler": "R-ESRGAN 4x+ Anime6B",
            "negativePrompt": "EasyNegativeV2,negative_hand-neg,(low quality, worst quality:1.2),",
            "\"EasyNegativeV2": "339cc9210f70",
            "negative_hand-neg": "73b524a2da12\"",
            "Denoising strength": "0.35",
            "\"ophelia-parody-v1-wasabiya": "9385d9ad6956\""
        },
        "username": "Wasabiya",
        "baseModel": "SD 1.5"
    },
    {
        "id": 4561223,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d2280fe9-1038-4569-a2ea-cf23fe261c08/width=832/d2280fe9-1038-4569-a2ea-cf23fe261c08.jpeg",
        "hash": "U46*gm0L9F^*xuRjWBxu01~WV@4.Dit7xuNG",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-12-13T22:11:20.846Z",
        "postId": 995369,
        "stats": {
            "cryCount": 8,
            "laughCount": 12,
            "likeCount": 127,
            "dislikeCount": 0,
            "heartCount": 80,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 347653568,
            "steps": 38,
            "prompt": "By H.R. Giger, very long dark path over the human spine to the brain, impulses that skip, confused synapses, growing affection",
            "sampler": "Heun",
            "cfgScale": 2.5,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "low quality, watermark, ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, body out of frame, blurry, bad anatomy, blurred, watermark, grainy, signature, cut off, draft, closed eyes, text, logo",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 254534
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 447
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 107234
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 135867
                },
                {
                    "type": "lora",
                    "weight": 0.85,
                    "modelVersionId": 152309
                },
                {
                    "type": "lora",
                    "weight": -0.15,
                    "modelVersionId": 217866
                },
                {
                    "type": "lora",
                    "weight": 1.2,
                    "modelVersionId": 260505
                }
            ]
        },
        "username": "Ajuro",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 3350091,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/112e1563-f404-467c-a03a-c766150decf0/width=512/112e1563-f404-467c-a03a-c766150decf0.jpeg",
        "hash": "UZF~FG~A=^t5t.%1xtoJ9}N1IpWDNfIqIqa$",
        "width": 512,
        "height": 768,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-11-03T04:16:20.039Z",
        "postId": 767378,
        "stats": {
            "cryCount": 4,
            "laughCount": 10,
            "likeCount": 136,
            "dislikeCount": 0,
            "heartCount": 77,
            "commentCount": 2
        },
        "meta": {
            "Size": "512x768",
            "seed": 1359064735,
            "steps": 20,
            "onSite": true,
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 5,
            "clipSkip": 2,
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 208377
                }
            ]
        },
        "username": "a7art",
        "baseModel": "SD 1.5"
    },
    {
        "id": 1963648,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ed0c7409-38ad-47f0-9b7e-a16d639d187b/width=1024/ed0c7409-38ad-47f0-9b7e-a16d639d187b.jpeg",
        "hash": "UOKKi;i^~p9Zoz%Mt7M{_2-:kCxu%Lae%2of",
        "width": 1024,
        "height": 1536,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-13T23:43:23.148Z",
        "postId": 482934,
        "stats": {
            "cryCount": 0,
            "laughCount": 2,
            "likeCount": 138,
            "dislikeCount": 0,
            "heartCount": 87,
            "commentCount": 8
        },
        "meta": {
            "seed": 515179393012590,
            "vaes": [
                "sdxl_vae.safetensors",
                "vae-ft-mse-840000-ema-pruned.safetensors"
            ],
            "Model": "sd_xl_base_1.0",
            "comfy": {
                "prompt": {
                    "1": {
                        "inputs": {
                            "seed": 515179393012590,
                            "sampler": "dpmpp_2m",
                            "cfg_scale": 5,
                            "scheduler": "karras",
                            "base_steps": 15,
                            "detail_from": "penultimate_step",
                            "model_model": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "model": {
                                        "inputs": {
                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                    "strength_clip": 1,
                                    "strength_model": 0
                                },
                                "class_type": "LoraLoader"
                            },
                            "detail_level": 1,
                            "latent_image": {
                                "inputs": {
                                    "width": 1024,
                                    "height": 1536,
                                    "batch_size": 1
                                },
                                "class_type": "EmptyLatentImage"
                            },
                            "noise_source": "GPU",
                            "model_refiner": {
                                "inputs": {
                                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                },
                                "class_type": "CheckpointLoaderSimple"
                            },
                            "refiner_steps": 5,
                            "start_at_step": 0,
                            "rescale_tonemap_to": 7.5,
                            "auto_rescale_tonemap": "enable",
                            "CONDITIONING_model_neg": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "model": {
                                                "inputs": {
                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                            "strength_clip": 1,
                                            "strength_model": 0
                                        },
                                        "class_type": "LoraLoader"
                                    },
                                    "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                                },
                                "class_type": "CLIPTextEncode"
                            },
                            "CONDITIONING_model_pos": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "model": {
                                                "inputs": {
                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                            "strength_clip": 1,
                                            "strength_model": 0
                                        },
                                        "class_type": "LoraLoader"
                                    },
                                    "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                                },
                                "class_type": "CLIPTextEncode"
                            },
                            "CONDITIONING_refiner_neg": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                                },
                                "class_type": "CLIPTextEncode"
                            },
                            "CONDITIONING_refiner_pos": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                                },
                                "class_type": "CLIPTextEncode"
                            }
                        },
                        "class_type": "KSamplerSDXLAdvanced"
                    },
                    "2": {
                        "inputs": {
                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                        },
                        "class_type": "CheckpointLoaderSimple"
                    },
                    "3": {
                        "inputs": {
                            "vae_name": "sdxl_vae.safetensors"
                        },
                        "class_type": "VAELoader"
                    },
                    "4": {
                        "inputs": {
                            "clip": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "model": {
                                        "inputs": {
                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                    "strength_clip": 1,
                                    "strength_model": 0
                                },
                                "class_type": "LoraLoader"
                            },
                            "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                        },
                        "class_type": "CLIPTextEncode"
                    },
                    "8": {
                        "inputs": {
                            "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                        },
                        "class_type": "CheckpointLoaderSimple"
                    },
                    "9": {
                        "inputs": {
                            "clip": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "model": {
                                        "inputs": {
                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                    "strength_clip": 1,
                                    "strength_model": 0
                                },
                                "class_type": "LoraLoader"
                            },
                            "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                        },
                        "class_type": "CLIPTextEncode"
                    },
                    "10": {
                        "inputs": {
                            "clip": {
                                "inputs": {
                                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                },
                                "class_type": "CheckpointLoaderSimple"
                            },
                            "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                        },
                        "class_type": "CLIPTextEncode"
                    },
                    "11": {
                        "inputs": {
                            "clip": {
                                "inputs": {
                                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                },
                                "class_type": "CheckpointLoaderSimple"
                            },
                            "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                        },
                        "class_type": "CLIPTextEncode"
                    },
                    "12": {
                        "inputs": {
                            "vae": {
                                "inputs": {
                                    "vae_name": "sdxl_vae.safetensors"
                                },
                                "class_type": "VAELoader"
                            },
                            "samples": {
                                "inputs": {
                                    "seed": 515179393012590,
                                    "sampler": "dpmpp_2m",
                                    "cfg_scale": 5,
                                    "scheduler": "karras",
                                    "base_steps": 15,
                                    "detail_from": "penultimate_step",
                                    "model_model": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "model": {
                                                "inputs": {
                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                            "strength_clip": 1,
                                            "strength_model": 0
                                        },
                                        "class_type": "LoraLoader"
                                    },
                                    "detail_level": 1,
                                    "latent_image": {
                                        "inputs": {
                                            "width": 1024,
                                            "height": 1536,
                                            "batch_size": 1
                                        },
                                        "class_type": "EmptyLatentImage"
                                    },
                                    "noise_source": "GPU",
                                    "model_refiner": {
                                        "inputs": {
                                            "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "refiner_steps": 5,
                                    "start_at_step": 0,
                                    "rescale_tonemap_to": 7.5,
                                    "auto_rescale_tonemap": "enable",
                                    "CONDITIONING_model_neg": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "model": {
                                                        "inputs": {
                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                    "strength_clip": 1,
                                                    "strength_model": 0
                                                },
                                                "class_type": "LoraLoader"
                                            },
                                            "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                                        },
                                        "class_type": "CLIPTextEncode"
                                    },
                                    "CONDITIONING_model_pos": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "model": {
                                                        "inputs": {
                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                    "strength_clip": 1,
                                                    "strength_model": 0
                                                },
                                                "class_type": "LoraLoader"
                                            },
                                            "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                                        },
                                        "class_type": "CLIPTextEncode"
                                    },
                                    "CONDITIONING_refiner_neg": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                                        },
                                        "class_type": "CLIPTextEncode"
                                    },
                                    "CONDITIONING_refiner_pos": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                                        },
                                        "class_type": "CLIPTextEncode"
                                    }
                                },
                                "class_type": "KSamplerSDXLAdvanced"
                            }
                        },
                        "class_type": "VAEDecode"
                    },
                    "13": {
                        "inputs": {
                            "images": {
                                "inputs": {
                                    "image": {
                                        "inputs": {
                                            "vae": {
                                                "inputs": {
                                                    "vae_name": "sdxl_vae.safetensors"
                                                },
                                                "class_type": "VAELoader"
                                            },
                                            "samples": {
                                                "inputs": {
                                                    "seed": 515179393012590,
                                                    "sampler": "dpmpp_2m",
                                                    "cfg_scale": 5,
                                                    "scheduler": "karras",
                                                    "base_steps": 15,
                                                    "detail_from": "penultimate_step",
                                                    "model_model": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "model": {
                                                                "inputs": {
                                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                            "strength_clip": 1,
                                                            "strength_model": 0
                                                        },
                                                        "class_type": "LoraLoader"
                                                    },
                                                    "detail_level": 1,
                                                    "latent_image": {
                                                        "inputs": {
                                                            "width": 1024,
                                                            "height": 1536,
                                                            "batch_size": 1
                                                        },
                                                        "class_type": "EmptyLatentImage"
                                                    },
                                                    "noise_source": "GPU",
                                                    "model_refiner": {
                                                        "inputs": {
                                                            "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "refiner_steps": 5,
                                                    "start_at_step": 0,
                                                    "rescale_tonemap_to": 7.5,
                                                    "auto_rescale_tonemap": "enable",
                                                    "CONDITIONING_model_neg": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "clip": {
                                                                        "inputs": {
                                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                        },
                                                                        "class_type": "CheckpointLoaderSimple"
                                                                    },
                                                                    "model": {
                                                                        "inputs": {
                                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                        },
                                                                        "class_type": "CheckpointLoaderSimple"
                                                                    },
                                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                                    "strength_clip": 1,
                                                                    "strength_model": 0
                                                                },
                                                                "class_type": "LoraLoader"
                                                            },
                                                            "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                                                        },
                                                        "class_type": "CLIPTextEncode"
                                                    },
                                                    "CONDITIONING_model_pos": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "clip": {
                                                                        "inputs": {
                                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                        },
                                                                        "class_type": "CheckpointLoaderSimple"
                                                                    },
                                                                    "model": {
                                                                        "inputs": {
                                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                        },
                                                                        "class_type": "CheckpointLoaderSimple"
                                                                    },
                                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                                    "strength_clip": 1,
                                                                    "strength_model": 0
                                                                },
                                                                "class_type": "LoraLoader"
                                                            },
                                                            "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                                                        },
                                                        "class_type": "CLIPTextEncode"
                                                    },
                                                    "CONDITIONING_refiner_neg": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                                                        },
                                                        "class_type": "CLIPTextEncode"
                                                    },
                                                    "CONDITIONING_refiner_pos": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                                                        },
                                                        "class_type": "CLIPTextEncode"
                                                    }
                                                },
                                                "class_type": "KSamplerSDXLAdvanced"
                                            }
                                        },
                                        "class_type": "VAEDecode"
                                    },
                                    "facedetection": "retinaface_resnet50",
                                    "facerestore_model": {
                                        "inputs": {
                                            "model_name": "codeformer-v0.1.0.pth"
                                        },
                                        "class_type": "FaceRestoreModelLoader"
                                    }
                                },
                                "class_type": "FaceRestoreWithModel"
                            },
                            "filename_prefix": "ComfyUI"
                        },
                        "class_type": "SaveImage"
                    },
                    "16": {
                        "inputs": {
                            "width": 1024,
                            "height": 1536,
                            "batch_size": 1
                        },
                        "class_type": "EmptyLatentImage"
                    },
                    "37": {
                        "inputs": {
                            "model_name": "codeformer-v0.1.0.pth"
                        },
                        "class_type": "FaceRestoreModelLoader"
                    },
                    "38": {
                        "inputs": {
                            "image": {
                                "inputs": {
                                    "vae": {
                                        "inputs": {
                                            "vae_name": "sdxl_vae.safetensors"
                                        },
                                        "class_type": "VAELoader"
                                    },
                                    "samples": {
                                        "inputs": {
                                            "seed": 515179393012590,
                                            "sampler": "dpmpp_2m",
                                            "cfg_scale": 5,
                                            "scheduler": "karras",
                                            "base_steps": 15,
                                            "detail_from": "penultimate_step",
                                            "model_model": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "model": {
                                                        "inputs": {
                                                            "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                    "strength_clip": 1,
                                                    "strength_model": 0
                                                },
                                                "class_type": "LoraLoader"
                                            },
                                            "detail_level": 1,
                                            "latent_image": {
                                                "inputs": {
                                                    "width": 1024,
                                                    "height": 1536,
                                                    "batch_size": 1
                                                },
                                                "class_type": "EmptyLatentImage"
                                            },
                                            "noise_source": "GPU",
                                            "model_refiner": {
                                                "inputs": {
                                                    "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "refiner_steps": 5,
                                            "start_at_step": 0,
                                            "rescale_tonemap_to": 7.5,
                                            "auto_rescale_tonemap": "enable",
                                            "CONDITIONING_model_neg": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "model": {
                                                                "inputs": {
                                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                            "strength_clip": 1,
                                                            "strength_model": 0
                                                        },
                                                        "class_type": "LoraLoader"
                                                    },
                                                    "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                                                },
                                                "class_type": "CLIPTextEncode"
                                            },
                                            "CONDITIONING_model_pos": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "model": {
                                                                "inputs": {
                                                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                            "strength_clip": 1,
                                                            "strength_model": 0
                                                        },
                                                        "class_type": "LoraLoader"
                                                    },
                                                    "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                                                },
                                                "class_type": "CLIPTextEncode"
                                            },
                                            "CONDITIONING_refiner_neg": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "text": "Non-anatomical, extra feet\uff0clow quality, worst quality"
                                                },
                                                "class_type": "CLIPTextEncode"
                                            },
                                            "CONDITIONING_refiner_pos": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "ckpt_name": "sd_xl_refiner_1.0.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "text": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                                                },
                                                "class_type": "CLIPTextEncode"
                                            }
                                        },
                                        "class_type": "KSamplerSDXLAdvanced"
                                    }
                                },
                                "class_type": "VAEDecode"
                            },
                            "facedetection": "retinaface_resnet50",
                            "facerestore_model": {
                                "inputs": {
                                    "model_name": "codeformer-v0.1.0.pth"
                                },
                                "class_type": "FaceRestoreModelLoader"
                            }
                        },
                        "class_type": "FaceRestoreWithModel"
                    },
                    "39": {
                        "inputs": {
                            "clip": {
                                "inputs": {
                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                },
                                "class_type": "CheckpointLoaderSimple"
                            },
                            "model": {
                                "inputs": {
                                    "ckpt_name": "sd_xl_base_1.0.safetensors"
                                },
                                "class_type": "CheckpointLoaderSimple"
                            },
                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                            "strength_clip": 1,
                            "strength_model": 0
                        },
                        "class_type": "LoraLoader"
                    },
                    "40": {
                        "inputs": {
                            "ckpt_name": "photon_v1.safetensors"
                        },
                        "class_type": "CheckpointLoaderSimple"
                    },
                    "41": {
                        "inputs": {
                            "clip": {
                                "inputs": {
                                    "ckpt_name": "photon_v1.safetensors"
                                },
                                "class_type": "CheckpointLoaderSimple"
                            },
                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                            "strength_clip": 1,
                            "strength_model": 0
                        },
                        "class_type": "LoraLoader"
                    },
                    "44": {
                        "inputs": {
                            "width": 768,
                            "height": 1024,
                            "batch_size": 1
                        },
                        "class_type": "EmptyLatentImage"
                    },
                    "45": {
                        "inputs": {
                            "images": {
                                "inputs": {
                                    "image": {
                                        "inputs": {
                                            "vae": {
                                                "inputs": {
                                                    "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
                                                },
                                                "class_type": "VAELoader"
                                            },
                                            "samples": {
                                                "inputs": {
                                                    "cfg": 7,
                                                    "seed": 405794497763508,
                                                    "model": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "ckpt_name": "photon_v1.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                            "strength_clip": 1,
                                                            "strength_model": 0
                                                        },
                                                        "class_type": "LoraLoader"
                                                    },
                                                    "steps": 30,
                                                    "denoise": 1,
                                                    "negative": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "clip": {
                                                                        "inputs": {
                                                                            "ckpt_name": "photon_v1.safetensors"
                                                                        },
                                                                        "class_type": "CheckpointLoaderSimple"
                                                                    },
                                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                                    "strength_clip": 1,
                                                                    "strength_model": 0
                                                                },
                                                                "class_type": "LoraLoader"
                                                            },
                                                            "text": "woman,girl,naked"
                                                        },
                                                        "class_type": "CLIPTextEncode"
                                                    },
                                                    "positive": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "clip": {
                                                                        "inputs": {
                                                                            "ckpt_name": "photon_v1.safetensors"
                                                                        },
                                                                        "class_type": "CheckpointLoaderSimple"
                                                                    },
                                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                                    "strength_clip": 1,
                                                                    "strength_model": 0
                                                                },
                                                                "class_type": "LoraLoader"
                                                            },
                                                            "text": "hyper realistic of a zombie xenomorph warrior, character,  sharp, high detail, Mathew Brady, portrait, in the style of stefan gesell and emil melmoth and hr giger and klimt\uff0clook at viewer, Hybrid of Alien and Predator"
                                                        },
                                                        "class_type": "CLIPTextEncode"
                                                    },
                                                    "scheduler": "ddim_uniform",
                                                    "latent_image": {
                                                        "inputs": {
                                                            "width": 768,
                                                            "height": 1024,
                                                            "batch_size": 1
                                                        },
                                                        "class_type": "EmptyLatentImage"
                                                    },
                                                    "sampler_name": "dpmpp_2m_sde_gpu"
                                                },
                                                "class_type": "KSampler"
                                            }
                                        },
                                        "class_type": "VAEDecode"
                                    },
                                    "facedetection": "retinaface_resnet50",
                                    "facerestore_model": {
                                        "inputs": {
                                            "model_name": "codeformer-v0.1.0.pth"
                                        },
                                        "class_type": "FaceRestoreModelLoader"
                                    }
                                },
                                "class_type": "FaceRestoreWithModel"
                            },
                            "filename_prefix": "ComfyUI"
                        },
                        "class_type": "SaveImage"
                    },
                    "46": {
                        "inputs": {
                            "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
                        },
                        "class_type": "VAELoader"
                    },
                    "47": {
                        "inputs": {
                            "image": {
                                "inputs": {
                                    "vae": {
                                        "inputs": {
                                            "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
                                        },
                                        "class_type": "VAELoader"
                                    },
                                    "samples": {
                                        "inputs": {
                                            "cfg": 7,
                                            "seed": 405794497763508,
                                            "model": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "ckpt_name": "photon_v1.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                    "strength_clip": 1,
                                                    "strength_model": 0
                                                },
                                                "class_type": "LoraLoader"
                                            },
                                            "steps": 30,
                                            "denoise": 1,
                                            "negative": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "ckpt_name": "photon_v1.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                            "strength_clip": 1,
                                                            "strength_model": 0
                                                        },
                                                        "class_type": "LoraLoader"
                                                    },
                                                    "text": "woman,girl,naked"
                                                },
                                                "class_type": "CLIPTextEncode"
                                            },
                                            "positive": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "clip": {
                                                                "inputs": {
                                                                    "ckpt_name": "photon_v1.safetensors"
                                                                },
                                                                "class_type": "CheckpointLoaderSimple"
                                                            },
                                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                            "strength_clip": 1,
                                                            "strength_model": 0
                                                        },
                                                        "class_type": "LoraLoader"
                                                    },
                                                    "text": "hyper realistic of a zombie xenomorph warrior, character,  sharp, high detail, Mathew Brady, portrait, in the style of stefan gesell and emil melmoth and hr giger and klimt\uff0clook at viewer, Hybrid of Alien and Predator"
                                                },
                                                "class_type": "CLIPTextEncode"
                                            },
                                            "scheduler": "ddim_uniform",
                                            "latent_image": {
                                                "inputs": {
                                                    "width": 768,
                                                    "height": 1024,
                                                    "batch_size": 1
                                                },
                                                "class_type": "EmptyLatentImage"
                                            },
                                            "sampler_name": "dpmpp_2m_sde_gpu"
                                        },
                                        "class_type": "KSampler"
                                    }
                                },
                                "class_type": "VAEDecode"
                            },
                            "facedetection": "retinaface_resnet50",
                            "facerestore_model": {
                                "inputs": {
                                    "model_name": "codeformer-v0.1.0.pth"
                                },
                                "class_type": "FaceRestoreModelLoader"
                            }
                        },
                        "class_type": "FaceRestoreWithModel"
                    },
                    "48": {
                        "inputs": {
                            "model_name": "codeformer-v0.1.0.pth"
                        },
                        "class_type": "FaceRestoreModelLoader"
                    },
                    "49": {
                        "inputs": {
                            "vae": {
                                "inputs": {
                                    "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
                                },
                                "class_type": "VAELoader"
                            },
                            "samples": {
                                "inputs": {
                                    "cfg": 7,
                                    "seed": 405794497763508,
                                    "model": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "ckpt_name": "photon_v1.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                            "strength_clip": 1,
                                            "strength_model": 0
                                        },
                                        "class_type": "LoraLoader"
                                    },
                                    "steps": 30,
                                    "denoise": 1,
                                    "negative": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "ckpt_name": "photon_v1.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                    "strength_clip": 1,
                                                    "strength_model": 0
                                                },
                                                "class_type": "LoraLoader"
                                            },
                                            "text": "woman,girl,naked"
                                        },
                                        "class_type": "CLIPTextEncode"
                                    },
                                    "positive": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "clip": {
                                                        "inputs": {
                                                            "ckpt_name": "photon_v1.safetensors"
                                                        },
                                                        "class_type": "CheckpointLoaderSimple"
                                                    },
                                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                                    "strength_clip": 1,
                                                    "strength_model": 0
                                                },
                                                "class_type": "LoraLoader"
                                            },
                                            "text": "hyper realistic of a zombie xenomorph warrior, character,  sharp, high detail, Mathew Brady, portrait, in the style of stefan gesell and emil melmoth and hr giger and klimt\uff0clook at viewer, Hybrid of Alien and Predator"
                                        },
                                        "class_type": "CLIPTextEncode"
                                    },
                                    "scheduler": "ddim_uniform",
                                    "latent_image": {
                                        "inputs": {
                                            "width": 768,
                                            "height": 1024,
                                            "batch_size": 1
                                        },
                                        "class_type": "EmptyLatentImage"
                                    },
                                    "sampler_name": "dpmpp_2m_sde_gpu"
                                },
                                "class_type": "KSampler"
                            }
                        },
                        "class_type": "VAEDecode"
                    },
                    "50": {
                        "inputs": {
                            "clip": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "ckpt_name": "photon_v1.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                    "strength_clip": 1,
                                    "strength_model": 0
                                },
                                "class_type": "LoraLoader"
                            },
                            "text": "hyper realistic of a zombie xenomorph warrior, character,  sharp, high detail, Mathew Brady, portrait, in the style of stefan gesell and emil melmoth and hr giger and klimt\uff0clook at viewer, Hybrid of Alien and Predator"
                        },
                        "class_type": "CLIPTextEncode"
                    },
                    "51": {
                        "inputs": {
                            "clip": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "ckpt_name": "photon_v1.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                    "strength_clip": 1,
                                    "strength_model": 0
                                },
                                "class_type": "LoraLoader"
                            },
                            "text": "woman,girl,naked"
                        },
                        "class_type": "CLIPTextEncode"
                    },
                    "52": {
                        "inputs": {
                            "cfg": 7,
                            "seed": 405794497763508,
                            "model": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "ckpt_name": "photon_v1.safetensors"
                                        },
                                        "class_type": "CheckpointLoaderSimple"
                                    },
                                    "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                    "strength_clip": 1,
                                    "strength_model": 0
                                },
                                "class_type": "LoraLoader"
                            },
                            "steps": 30,
                            "denoise": 1,
                            "negative": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "ckpt_name": "photon_v1.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                            "strength_clip": 1,
                                            "strength_model": 0
                                        },
                                        "class_type": "LoraLoader"
                                    },
                                    "text": "woman,girl,naked"
                                },
                                "class_type": "CLIPTextEncode"
                            },
                            "positive": {
                                "inputs": {
                                    "clip": {
                                        "inputs": {
                                            "clip": {
                                                "inputs": {
                                                    "ckpt_name": "photon_v1.safetensors"
                                                },
                                                "class_type": "CheckpointLoaderSimple"
                                            },
                                            "lora_name": "sdxl_photorealistic_slider_v1-0.safetensors",
                                            "strength_clip": 1,
                                            "strength_model": 0
                                        },
                                        "class_type": "LoraLoader"
                                    },
                                    "text": "hyper realistic of a zombie xenomorph warrior, character,  sharp, high detail, Mathew Brady, portrait, in the style of stefan gesell and emil melmoth and hr giger and klimt\uff0clook at viewer, Hybrid of Alien and Predator"
                                },
                                "class_type": "CLIPTextEncode"
                            },
                            "scheduler": "ddim_uniform",
                            "latent_image": {
                                "inputs": {
                                    "width": 768,
                                    "height": 1024,
                                    "batch_size": 1
                                },
                                "class_type": "EmptyLatentImage"
                            },
                            "sampler_name": "dpmpp_2m_sde_gpu"
                        },
                        "class_type": "KSampler"
                    }
                },
                "workflow": {
                    "extra": {},
                    "links": [
                        [
                            2,
                            1,
                            0,
                            12,
                            0,
                            "LATENT"
                        ],
                        [
                            4,
                            14,
                            0,
                            4,
                            1,
                            "STRING"
                        ],
                        [
                            5,
                            14,
                            0,
                            10,
                            1,
                            "STRING"
                        ],
                        [
                            6,
                            15,
                            0,
                            11,
                            1,
                            "STRING"
                        ],
                        [
                            7,
                            15,
                            0,
                            9,
                            1,
                            "STRING"
                        ],
                        [
                            8,
                            8,
                            1,
                            11,
                            0,
                            "CLIP"
                        ],
                        [
                            9,
                            8,
                            1,
                            10,
                            0,
                            "CLIP"
                        ],
                        [
                            13,
                            8,
                            0,
                            1,
                            1,
                            "MODEL"
                        ],
                        [
                            14,
                            4,
                            0,
                            1,
                            2,
                            "CONDITIONING"
                        ],
                        [
                            15,
                            9,
                            0,
                            1,
                            3,
                            "CONDITIONING"
                        ],
                        [
                            16,
                            10,
                            0,
                            1,
                            4,
                            "CONDITIONING"
                        ],
                        [
                            17,
                            11,
                            0,
                            1,
                            5,
                            "CONDITIONING"
                        ],
                        [
                            18,
                            16,
                            0,
                            1,
                            6,
                            "LATENT"
                        ],
                        [
                            19,
                            17,
                            0,
                            1,
                            9,
                            "INT"
                        ],
                        [
                            82,
                            37,
                            0,
                            38,
                            0,
                            "FACERESTORE_MODEL"
                        ],
                        [
                            83,
                            38,
                            0,
                            13,
                            0,
                            "IMAGE"
                        ],
                        [
                            84,
                            12,
                            0,
                            38,
                            1,
                            "IMAGE"
                        ],
                        [
                            87,
                            39,
                            0,
                            1,
                            0,
                            "MODEL"
                        ],
                        [
                            89,
                            2,
                            1,
                            39,
                            1,
                            "CLIP"
                        ],
                        [
                            91,
                            39,
                            1,
                            4,
                            0,
                            "CLIP"
                        ],
                        [
                            94,
                            39,
                            1,
                            9,
                            0,
                            "CLIP"
                        ],
                        [
                            96,
                            40,
                            1,
                            41,
                            1,
                            "CLIP"
                        ],
                        [
                            97,
                            41,
                            1,
                            50,
                            0,
                            "CLIP"
                        ],
                        [
                            98,
                            41,
                            1,
                            51,
                            0,
                            "CLIP"
                        ],
                        [
                            99,
                            41,
                            0,
                            52,
                            0,
                            "MODEL"
                        ],
                        [
                            101,
                            51,
                            0,
                            52,
                            2,
                            "CONDITIONING"
                        ],
                        [
                            102,
                            50,
                            0,
                            52,
                            1,
                            "CONDITIONING"
                        ],
                        [
                            103,
                            44,
                            0,
                            52,
                            3,
                            "LATENT"
                        ],
                        [
                            104,
                            52,
                            0,
                            49,
                            0,
                            "LATENT"
                        ],
                        [
                            105,
                            46,
                            0,
                            49,
                            1,
                            "VAE"
                        ],
                        [
                            106,
                            49,
                            0,
                            47,
                            1,
                            "IMAGE"
                        ],
                        [
                            107,
                            48,
                            0,
                            47,
                            0,
                            "FACERESTORE_MODEL"
                        ],
                        [
                            108,
                            47,
                            0,
                            45,
                            0,
                            "IMAGE"
                        ],
                        [
                            112,
                            3,
                            0,
                            12,
                            1,
                            "VAE"
                        ],
                        [
                            114,
                            2,
                            0,
                            39,
                            0,
                            "MODEL"
                        ]
                    ],
                    "nodes": [
                        {
                            "id": 11,
                            "pos": [
                                805,
                                582.60599949646
                            ],
                            "mode": 0,
                            "size": {
                                "0": 220,
                                "1": 60
                            },
                            "type": "CLIPTextEncode",
                            "flags": {},
                            "order": 12,
                            "inputs": [
                                {
                                    "link": 8,
                                    "name": "clip",
                                    "type": "CLIP"
                                },
                                {
                                    "link": 6,
                                    "name": "text",
                                    "type": "STRING",
                                    "widget": {
                                        "name": "text",
                                        "config": [
                                            "STRING",
                                            {
                                                "multiline": true
                                            }
                                        ]
                                    }
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "CONDITIONING",
                                    "type": "CONDITIONING",
                                    "links": [
                                        17
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "CLIPTextEncode"
                            },
                            "widgets_values": [
                                ""
                            ]
                        },
                        {
                            "id": 13,
                            "pos": [
                                1453,
                                398.60599949645996
                            ],
                            "mode": 0,
                            "size": {
                                "0": 552.6556396484375,
                                "1": 575.6631469726562
                            },
                            "type": "SaveImage",
                            "flags": {
                                "collapsed": false
                            },
                            "order": 27,
                            "inputs": [
                                {
                                    "link": 83,
                                    "name": "images",
                                    "type": "IMAGE"
                                }
                            ],
                            "properties": {},
                            "widgets_values": [
                                "ComfyUI"
                            ]
                        },
                        {
                            "id": 38,
                            "pos": [
                                1446,
                                169.60599949645993
                            ],
                            "mode": 0,
                            "size": {
                                "0": 317.9464111328125,
                                "1": 78
                            },
                            "type": "FaceRestoreWithModel",
                            "flags": {},
                            "order": 25,
                            "inputs": [
                                {
                                    "link": 82,
                                    "name": "facerestore_model",
                                    "type": "FACERESTORE_MODEL"
                                },
                                {
                                    "link": 84,
                                    "name": "image",
                                    "type": "IMAGE",
                                    "slot_index": 1
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "IMAGE",
                                    "type": "IMAGE",
                                    "links": [
                                        83
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "FaceRestoreWithModel"
                            },
                            "widgets_values": [
                                "retinaface_resnet50"
                            ]
                        },
                        {
                            "id": 37,
                            "pos": [
                                1103,
                                175.60599949645993
                            ],
                            "mode": 0,
                            "size": {
                                "0": 315,
                                "1": 58
                            },
                            "type": "FaceRestoreModelLoader",
                            "flags": {},
                            "order": 0,
                            "outputs": [
                                {
                                    "name": "FACERESTORE_MODEL",
                                    "type": "FACERESTORE_MODEL",
                                    "links": [
                                        82
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "FaceRestoreModelLoader"
                            },
                            "widgets_values": [
                                "codeformer-v0.1.0.pth"
                            ]
                        },
                        {
                            "id": 14,
                            "pos": [
                                446,
                                284.6059994964599
                            ],
                            "mode": 0,
                            "size": {
                                "0": 340,
                                "1": 220
                            },
                            "type": "PrimitiveNode",
                            "color": "#232",
                            "flags": {},
                            "order": 1,
                            "title": "Positive prompt",
                            "bgcolor": "#353",
                            "outputs": [
                                {
                                    "name": "STRING",
                                    "type": "STRING",
                                    "links": [
                                        4,
                                        5
                                    ],
                                    "widget": {
                                        "name": "text",
                                        "config": [
                                            "STRING",
                                            {
                                                "multiline": true
                                            }
                                        ]
                                    },
                                    "slot_index": 0
                                }
                            ],
                            "properties": {},
                            "widgets_values": [
                                "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong"
                            ]
                        },
                        {
                            "id": 10,
                            "pos": [
                                802,
                                479.60599949645996
                            ],
                            "mode": 0,
                            "size": {
                                "0": 220,
                                "1": 60
                            },
                            "type": "CLIPTextEncode",
                            "flags": {},
                            "order": 13,
                            "inputs": [
                                {
                                    "link": 9,
                                    "name": "clip",
                                    "type": "CLIP"
                                },
                                {
                                    "link": 5,
                                    "name": "text",
                                    "type": "STRING",
                                    "widget": {
                                        "name": "text",
                                        "config": [
                                            "STRING",
                                            {
                                                "multiline": true
                                            }
                                        ]
                                    }
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "CONDITIONING",
                                    "type": "CONDITIONING",
                                    "links": [
                                        16
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "CLIPTextEncode"
                            },
                            "widgets_values": [
                                "hyper realistic of a zombie xenomorph warrior, character,  sharp, high detail, Mathew Brady, portrait, in the style of stefan gesell and emil melmoth and hr giger and klimt\uff0clook at viewer, Hybrid of Alien and Predator"
                            ]
                        },
                        {
                            "id": 9,
                            "pos": [
                                806,
                                380.60599949645996
                            ],
                            "mode": 0,
                            "size": {
                                "0": 220,
                                "1": 60
                            },
                            "type": "CLIPTextEncode",
                            "flags": {},
                            "order": 19,
                            "inputs": [
                                {
                                    "link": 94,
                                    "name": "clip",
                                    "type": "CLIP",
                                    "slot_index": 0
                                },
                                {
                                    "link": 7,
                                    "name": "text",
                                    "type": "STRING",
                                    "widget": {
                                        "name": "text",
                                        "config": [
                                            "STRING",
                                            {
                                                "multiline": true
                                            }
                                        ]
                                    }
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "CONDITIONING",
                                    "type": "CONDITIONING",
                                    "links": [
                                        15
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "CLIPTextEncode"
                            },
                            "widgets_values": [
                                ""
                            ]
                        },
                        {
                            "id": 4,
                            "pos": [
                                801,
                                280.60599949645996
                            ],
                            "mode": 0,
                            "size": {
                                "0": 220,
                                "1": 60
                            },
                            "type": "CLIPTextEncode",
                            "flags": {},
                            "order": 18,
                            "inputs": [
                                {
                                    "link": 91,
                                    "name": "clip",
                                    "type": "CLIP"
                                },
                                {
                                    "link": 4,
                                    "name": "text",
                                    "type": "STRING",
                                    "widget": {
                                        "name": "text",
                                        "config": [
                                            "STRING",
                                            {
                                                "multiline": true
                                            }
                                        ]
                                    }
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "CONDITIONING",
                                    "type": "CONDITIONING",
                                    "links": [
                                        14
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "CLIPTextEncode"
                            },
                            "widgets_values": [
                                "hyper realistic of a zombie xenomorph warrior, character,  sharp, high detail, Mathew Brady, portrait, in the style of stefan gesell and emil melmoth and hr giger and klimt\uff0clook at viewer, Hybrid of Alien and Predator"
                            ]
                        },
                        {
                            "id": 15,
                            "pos": [
                                451,
                                540.60599949646
                            ],
                            "mode": 0,
                            "size": {
                                "0": 340,
                                "1": 220
                            },
                            "type": "PrimitiveNode",
                            "color": "#322",
                            "flags": {},
                            "order": 2,
                            "title": "Negative prompt",
                            "bgcolor": "#533",
                            "outputs": [
                                {
                                    "name": "STRING",
                                    "type": "STRING",
                                    "links": [
                                        6,
                                        7
                                    ],
                                    "widget": {
                                        "name": "text",
                                        "config": [
                                            "STRING",
                                            {
                                                "multiline": true
                                            }
                                        ]
                                    },
                                    "slot_index": 0
                                }
                            ],
                            "properties": {},
                            "widgets_values": [
                                "Non-anatomical, extra feet\uff0clow quality, worst quality"
                            ]
                        },
                        {
                            "id": 1,
                            "pos": [
                                1043,
                                287.60599949645996
                            ],
                            "mode": 0,
                            "size": {
                                "0": 393,
                                "1": 690
                            },
                            "type": "KSamplerSDXLAdvanced",
                            "flags": {},
                            "order": 21,
                            "inputs": [
                                {
                                    "link": 87,
                                    "name": "model_model",
                                    "type": "MODEL"
                                },
                                {
                                    "link": 13,
                                    "name": "model_refiner",
                                    "type": "MODEL"
                                },
                                {
                                    "link": 14,
                                    "name": "CONDITIONING_model_pos",
                                    "type": "CONDITIONING"
                                },
                                {
                                    "link": 15,
                                    "name": "CONDITIONING_model_neg",
                                    "type": "CONDITIONING"
                                },
                                {
                                    "link": 16,
                                    "name": "CONDITIONING_refiner_pos",
                                    "type": "CONDITIONING"
                                },
                                {
                                    "link": 17,
                                    "name": "CONDITIONING_refiner_neg",
                                    "type": "CONDITIONING"
                                },
                                {
                                    "link": 18,
                                    "name": "latent_image",
                                    "type": "LATENT"
                                },
                                {
                                    "link": null,
                                    "name": "SD15VAE",
                                    "type": "VAE"
                                },
                                {
                                    "link": null,
                                    "name": "SDXLVAE",
                                    "type": "VAE",
                                    "slot_index": 8
                                },
                                {
                                    "link": 19,
                                    "name": "seed",
                                    "type": "INT",
                                    "widget": {
                                        "name": "seed",
                                        "config": [
                                            "INT",
                                            {
                                                "max": 18446744073709552000,
                                                "min": 0,
                                                "default": 0
                                            }
                                        ]
                                    }
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "LATENT",
                                    "type": "LATENT",
                                    "links": [
                                        2
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "KSamplerSDXLAdvanced"
                            },
                            "widgets_values": [
                                799968595972576,
                                "randomize",
                                5,
                                "dpmpp_2m",
                                "karras",
                                0,
                                15,
                                5,
                                1,
                                "penultimate_step",
                                "GPU",
                                "enable",
                                7.5
                            ]
                        },
                        {
                            "id": 17,
                            "pos": [
                                801,
                                829.60599949646
                            ],
                            "mode": 0,
                            "size": {
                                "0": 210,
                                "1": 82
                            },
                            "type": "PrimitiveNode",
                            "color": "#432",
                            "flags": {},
                            "order": 4,
                            "title": "SEED",
                            "bgcolor": "#653",
                            "outputs": [
                                {
                                    "name": "INT",
                                    "type": "INT",
                                    "links": [
                                        19
                                    ],
                                    "widget": {
                                        "name": "seed",
                                        "config": [
                                            "INT",
                                            {
                                                "max": 18446744073709552000,
                                                "min": 0,
                                                "default": 0
                                            }
                                        ]
                                    },
                                    "slot_index": 0
                                }
                            ],
                            "properties": {},
                            "widgets_values": [
                                515179393012590,
                                "randomize"
                            ]
                        },
                        {
                            "id": 49,
                            "pos": [
                                568.5743932983398,
                                -457.0309198242193
                            ],
                            "mode": 0,
                            "size": {
                                "0": 144.4130859375,
                                "1": 120.08842468261719
                            },
                            "type": "VAEDecode",
                            "flags": {},
                            "order": 22,
                            "inputs": [
                                {
                                    "link": 104,
                                    "name": "samples",
                                    "type": "LATENT"
                                },
                                {
                                    "link": 105,
                                    "name": "vae",
                                    "type": "VAE"
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "IMAGE",
                                    "type": "IMAGE",
                                    "links": [
                                        106
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "VAEDecode"
                            }
                        },
                        {
                            "id": 48,
                            "pos": [
                                598.5743932983398,
                                -297.03091982421944
                            ],
                            "mode": 0,
                            "size": {
                                "0": 315,
                                "1": 58
                            },
                            "type": "FaceRestoreModelLoader",
                            "flags": {},
                            "order": 5,
                            "outputs": [
                                {
                                    "name": "FACERESTORE_MODEL",
                                    "type": "FACERESTORE_MODEL",
                                    "links": [
                                        107
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "FaceRestoreModelLoader"
                            },
                            "widgets_values": [
                                "codeformer-v0.1.0.pth"
                            ]
                        },
                        {
                            "id": 47,
                            "pos": [
                                598.5743932983398,
                                -197.03091982421893
                            ],
                            "mode": 0,
                            "size": {
                                "0": 317.9464111328125,
                                "1": 78
                            },
                            "type": "FaceRestoreWithModel",
                            "flags": {},
                            "order": 24,
                            "inputs": [
                                {
                                    "link": 107,
                                    "name": "facerestore_model",
                                    "type": "FACERESTORE_MODEL"
                                },
                                {
                                    "link": 106,
                                    "name": "image",
                                    "type": "IMAGE",
                                    "slot_index": 1
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "IMAGE",
                                    "type": "IMAGE",
                                    "links": [
                                        108
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "FaceRestoreWithModel"
                            },
                            "widgets_values": [
                                "retinaface_resnet50"
                            ]
                        },
                        {
                            "id": 44,
                            "pos": [
                                728.5743932983398,
                                -457.0309198242193
                            ],
                            "mode": 0,
                            "size": {
                                "0": 211.4130859375,
                                "1": 118.08842468261719
                            },
                            "type": "EmptyLatentImage",
                            "color": "#323",
                            "flags": {},
                            "order": 6,
                            "bgcolor": "#535",
                            "outputs": [
                                {
                                    "name": "LATENT",
                                    "type": "LATENT",
                                    "links": [
                                        103
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "EmptyLatentImage"
                            },
                            "widgets_values": [
                                768,
                                1024,
                                1
                            ]
                        },
                        {
                            "id": 50,
                            "pos": [
                                188.57439329833983,
                                -597.0309198242186
                            ],
                            "mode": 0,
                            "size": {
                                "0": 353.4130859375,
                                "1": 216.0884246826172
                            },
                            "type": "CLIPTextEncode",
                            "color": "#232",
                            "flags": {},
                            "order": 16,
                            "inputs": [
                                {
                                    "link": 97,
                                    "name": "clip",
                                    "type": "CLIP"
                                }
                            ],
                            "bgcolor": "#353",
                            "outputs": [
                                {
                                    "name": "CONDITIONING",
                                    "type": "CONDITIONING",
                                    "links": [
                                        102
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "CLIPTextEncode"
                            },
                            "widgets_values": [
                                "hyper realistic of a zombie xenomorph warrior, character,  sharp, high detail, Mathew Brady, portrait, in the style of stefan gesell and emil melmoth and hr giger and klimt\uff0clook at viewer, Hybrid of Alien and Predator"
                            ]
                        },
                        {
                            "id": 8,
                            "pos": [
                                80,
                                418
                            ],
                            "mode": 0,
                            "size": {
                                "0": 360,
                                "1": 100
                            },
                            "type": "CheckpointLoaderSimple",
                            "flags": {},
                            "order": 7,
                            "title": "Refine",
                            "outputs": [
                                {
                                    "name": "MODEL",
                                    "type": "MODEL",
                                    "links": [
                                        13
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                },
                                {
                                    "name": "CLIP",
                                    "type": "CLIP",
                                    "links": [
                                        8,
                                        9
                                    ],
                                    "shape": 3,
                                    "slot_index": 1
                                },
                                {
                                    "name": "VAE",
                                    "type": "VAE",
                                    "links": null,
                                    "shape": 3
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "CheckpointLoaderSimple"
                            },
                            "widgets_values": [
                                "sd_xl_refiner_1.0.safetensors"
                            ]
                        },
                        {
                            "id": 12,
                            "pos": [
                                1456,
                                299
                            ],
                            "mode": 0,
                            "size": {
                                "0": 180,
                                "1": 60
                            },
                            "type": "VAEDecode",
                            "flags": {},
                            "order": 23,
                            "inputs": [
                                {
                                    "link": 2,
                                    "name": "samples",
                                    "type": "LATENT"
                                },
                                {
                                    "link": 112,
                                    "name": "vae",
                                    "type": "VAE"
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "IMAGE",
                                    "type": "IMAGE",
                                    "links": [
                                        84
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "VAEDecode"
                            }
                        },
                        {
                            "id": 51,
                            "pos": [
                                188.57439329833983,
                                -327.03091982421944
                            ],
                            "mode": 0,
                            "size": {
                                "0": 353.4130859375,
                                "1": 216.0884246826172
                            },
                            "type": "CLIPTextEncode",
                            "color": "#432",
                            "flags": {},
                            "order": 17,
                            "inputs": [
                                {
                                    "link": 98,
                                    "name": "clip",
                                    "type": "CLIP"
                                }
                            ],
                            "bgcolor": "#653",
                            "outputs": [
                                {
                                    "name": "CONDITIONING",
                                    "type": "CONDITIONING",
                                    "links": [
                                        101
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "CLIPTextEncode"
                            },
                            "widgets_values": [
                                "woman,girl,naked"
                            ]
                        },
                        {
                            "id": 45,
                            "pos": [
                                1298.57439329834,
                                -737.0309198242186
                            ],
                            "mode": 0,
                            "size": {
                                "0": 564.2449951171875,
                                "1": 632.4436645507812
                            },
                            "type": "SaveImage",
                            "flags": {
                                "collapsed": false
                            },
                            "order": 26,
                            "inputs": [
                                {
                                    "link": 108,
                                    "name": "images",
                                    "type": "IMAGE"
                                }
                            ],
                            "properties": {},
                            "widgets_values": [
                                "ComfyUI"
                            ]
                        },
                        {
                            "id": 3,
                            "pos": [
                                1658,
                                300
                            ],
                            "mode": 0,
                            "size": {
                                "0": 360,
                                "1": 60
                            },
                            "type": "VAELoader",
                            "flags": {},
                            "order": 8,
                            "outputs": [
                                {
                                    "name": "VAE",
                                    "type": "VAE",
                                    "links": [
                                        112
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "VAELoader"
                            },
                            "widgets_values": [
                                "sdxl_vae.safetensors"
                            ]
                        },
                        {
                            "id": 39,
                            "pos": [
                                110,
                                578.60599949646
                            ],
                            "mode": 0,
                            "size": {
                                "0": 315,
                                "1": 126
                            },
                            "type": "LoraLoader",
                            "flags": {},
                            "order": 15,
                            "inputs": [
                                {
                                    "link": 114,
                                    "name": "model",
                                    "type": "MODEL",
                                    "slot_index": 0
                                },
                                {
                                    "link": 89,
                                    "name": "clip",
                                    "type": "CLIP"
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "MODEL",
                                    "type": "MODEL",
                                    "links": [
                                        87
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                },
                                {
                                    "name": "CLIP",
                                    "type": "CLIP",
                                    "links": [
                                        91,
                                        94
                                    ],
                                    "shape": 3,
                                    "slot_index": 1
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "LoraLoader"
                            },
                            "widgets_values": [
                                "sdxl_photorealistic_slider_v1-0.safetensors",
                                0,
                                1
                            ]
                        },
                        {
                            "id": 40,
                            "pos": [
                                190.57439329833983,
                                -741.0309198242186
                            ],
                            "mode": 0,
                            "size": {
                                "0": 348.64495849609375,
                                "1": 98
                            },
                            "type": "CheckpointLoaderSimple",
                            "flags": {},
                            "order": 9,
                            "outputs": [
                                {
                                    "name": "MODEL",
                                    "type": "MODEL",
                                    "links": [],
                                    "shape": 3,
                                    "slot_index": 0
                                },
                                {
                                    "name": "CLIP",
                                    "type": "CLIP",
                                    "links": [
                                        96
                                    ],
                                    "shape": 3,
                                    "slot_index": 1
                                },
                                {
                                    "name": "VAE",
                                    "type": "VAE",
                                    "links": null,
                                    "shape": 3
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "CheckpointLoaderSimple"
                            },
                            "widgets_values": [
                                "photon_v1.safetensors"
                            ]
                        },
                        {
                            "id": 46,
                            "pos": [
                                568.5743932983398,
                                -567.0309198242186
                            ],
                            "mode": 0,
                            "size": {
                                "0": 368.4130859375,
                                "1": 58
                            },
                            "type": "VAELoader",
                            "flags": {},
                            "order": 10,
                            "outputs": [
                                {
                                    "name": "VAE",
                                    "type": "VAE",
                                    "links": [
                                        105
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "VAELoader"
                            },
                            "widgets_values": [
                                "vae-ft-mse-840000-ema-pruned.safetensors"
                            ]
                        },
                        {
                            "id": 52,
                            "pos": [
                                958.5743932983398,
                                -747.0309198242186
                            ],
                            "mode": 0,
                            "size": {
                                "0": 324.4130859375,
                                "1": 631.0884399414062
                            },
                            "type": "KSampler",
                            "flags": {},
                            "order": 20,
                            "inputs": [
                                {
                                    "link": 99,
                                    "name": "model",
                                    "type": "MODEL"
                                },
                                {
                                    "link": 102,
                                    "name": "positive",
                                    "type": "CONDITIONING"
                                },
                                {
                                    "link": 101,
                                    "name": "negative",
                                    "type": "CONDITIONING"
                                },
                                {
                                    "link": 103,
                                    "name": "latent_image",
                                    "type": "LATENT"
                                }
                            ],
                            "outputs": [
                                {
                                    "name": "LATENT",
                                    "type": "LATENT",
                                    "links": [
                                        104
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "KSampler"
                            },
                            "widgets_values": [
                                405794497763508,
                                "randomize",
                                30,
                                7,
                                "dpmpp_2m_sde_gpu",
                                "ddim_uniform",
                                1
                            ]
                        },
                        {
                            "id": 2,
                            "pos": [
                                77,
                                282
                            ],
                            "mode": 0,
                            "size": {
                                "0": 360,
                                "1": 100
                            },
                            "type": "CheckpointLoaderSimple",
                            "flags": {},
                            "order": 11,
                            "title": "Bass",
                            "outputs": [
                                {
                                    "name": "MODEL",
                                    "type": "MODEL",
                                    "links": [
                                        114
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                },
                                {
                                    "name": "CLIP",
                                    "type": "CLIP",
                                    "links": [
                                        89
                                    ],
                                    "shape": 3,
                                    "slot_index": 1
                                },
                                {
                                    "name": "VAE",
                                    "type": "VAE",
                                    "links": [],
                                    "shape": 3,
                                    "slot_index": 2
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "CheckpointLoaderSimple"
                            },
                            "widgets_values": [
                                "sd_xl_base_1.0.safetensors"
                            ]
                        },
                        {
                            "id": 41,
                            "pos": [
                                568.5743932983398,
                                -747.0309198242186
                            ],
                            "mode": 0,
                            "size": {
                                "0": 363.4130859375,
                                "1": 126
                            },
                            "type": "LoraLoader",
                            "color": "#233",
                            "flags": {},
                            "order": 14,
                            "inputs": [
                                {
                                    "link": null,
                                    "name": "model",
                                    "type": "MODEL",
                                    "slot_index": 0
                                },
                                {
                                    "link": 96,
                                    "name": "clip",
                                    "type": "CLIP"
                                }
                            ],
                            "bgcolor": "#355",
                            "outputs": [
                                {
                                    "name": "MODEL",
                                    "type": "MODEL",
                                    "links": [
                                        99
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                },
                                {
                                    "name": "CLIP",
                                    "type": "CLIP",
                                    "links": [
                                        97,
                                        98
                                    ],
                                    "shape": 3,
                                    "slot_index": 1
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "LoraLoader"
                            },
                            "widgets_values": [
                                "sdxl_photorealistic_slider_v1-0.safetensors",
                                0,
                                1
                            ]
                        },
                        {
                            "id": 16,
                            "pos": [
                                803,
                                683.60599949646
                            ],
                            "mode": 0,
                            "size": {
                                "0": 223.76904296875,
                                "1": 106
                            },
                            "type": "EmptyLatentImage",
                            "color": "#323",
                            "flags": {},
                            "order": 3,
                            "bgcolor": "#535",
                            "outputs": [
                                {
                                    "name": "LATENT",
                                    "type": "LATENT",
                                    "links": [
                                        18
                                    ],
                                    "shape": 3,
                                    "slot_index": 0
                                }
                            ],
                            "properties": {
                                "Node name for S&R": "EmptyLatentImage"
                            },
                            "widgets_values": [
                                1024,
                                1536,
                                1
                            ]
                        }
                    ],
                    "config": {},
                    "groups": [
                        {
                            "color": "#3f789e",
                            "title": "SDXL",
                            "bounding": [
                                7,
                                25,
                                2053,
                                1072
                            ]
                        },
                        {
                            "color": "#3f789e",
                            "title": "\u5355\u6a21\u578b",
                            "bounding": [
                                88,
                                -871,
                                1824,
                                836
                            ]
                        }
                    ],
                    "version": 0.4,
                    "last_link_id": 114,
                    "last_node_id": 52
                }
            },
            "steps": 15,
            "width": 768,
            "height": 1024,
            "models": [
                "sd_xl_base_1.0.safetensors",
                "sd_xl_refiner_1.0.safetensors",
                "photon_v1.safetensors"
            ],
            "prompt": "(masterpiece,best quality,ink,golden ratio)white background,ink painting, minimalism,1 running horse,Traditional Chinese ink painting,Rice paper,penetration,bleeding texture,muscle, unrestrained, neighing,tension,painting by Xu Beihong",
            "denoise": 1,
            "sampler": "DPM++ 2M",
            "cfgScale": 5,
            "scheduler": "ddim_uniform",
            "negativePrompt": "Non-anatomical, extra feet\uff0clow quality, worst quality"
        },
        "username": "TBBT",
        "baseModel": ""
    },
    {
        "id": 1778565,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/66056509-946e-4aa1-9177-82f7e5fd9664/width=1800/66056509-946e-4aa1-9177-82f7e5fd9664.jpeg",
        "hash": "USH2i=={~qM{t-slt7xu.8%2IUxux^WCV@oe",
        "width": 1920,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-13T18:09:29.623Z",
        "postId": 442123,
        "stats": {
            "cryCount": 15,
            "laughCount": 9,
            "likeCount": 129,
            "dislikeCount": 0,
            "heartCount": 74,
            "commentCount": 1
        },
        "meta": {
            "Size": "960x512",
            "seed": 2129007068,
            "Model": "DreamShaper8_pruned",
            "steps": 30,
            "hashes": {
                "model": "879db523c3"
            },
            "prompt": "landscape, oil on matte canvas, sharp details, the expanse scifi spacescape ceres colony, intricate, highly detailed, digital painting, rich color, smooth, sharp focus, illustration, spaceship landed, Unreal Engine 5, 8K, art by artgerm and greg rutkowski and alphonse mucha",
            "Version": "v1.4.1",
            "sampler": "DPM++ SDE Karras",
            "cfgScale": 8,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "879db523c3",
                    "name": "DreamShaper8_pruned",
                    "type": "model"
                }
            ],
            "Model hash": "879db523c3",
            "Hires steps": "20",
            "Hires upscale": "2",
            "Hires upscaler": "Latent",
            "negativePrompt": "FastNegativeV2",
            "ADetailer model": "person_yolov8n-seg.pt",
            "ADetailer prompt": "\"landscape, oil on matte canvas, sharp details, the expanse scifi spacescape ceres colony, intricate, highly detailed, digital painting, rich color, smooth, sharp focus, illustration, Unreal Engine 5, 8K, art by artgerm and greg rutkowski and alphonse mucha\"",
            "ADetailer version": "23.6.1.post0",
            "Denoising strength": "0.55",
            "ADetailer mask blur": "5",
            "ADetailer model 2nd": "hand_yolov8n.pt",
            "ADetailer confidence": "0.2",
            "ADetailer prompt 2nd": "beautiful hands",
            "ADetailer dilate/erode": "4",
            "ADetailer mask blur 2nd": "4",
            "ADetailer confidence 2nd": "0.3",
            "ADetailer inpaint padding": "0",
            "ADetailer negative prompt": "FastNegativeV2",
            "ADetailer dilate/erode 2nd": "4",
            "ADetailer denoising strength": "0.34",
            "ADetailer inpaint only masked": "True",
            "ADetailer inpaint padding 2nd": "0",
            "ADetailer negative prompt 2nd": "BadDream",
            "ADetailer denoising strength 2nd": "0.4",
            "ADetailer inpaint only masked 2nd": "True"
        },
        "username": "Lykon",
        "baseModel": "SD 1.5"
    },
    {
        "id": 808323,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c028d3fe-669c-44c0-9eac-b9d67f729492/width=832/c028d3fe-669c-44c0-9eac-b9d67f729492.jpeg",
        "hash": "UCA,k4-;4.D%~pt74.M{0KM{Vtxu0KM{?Hxu",
        "width": 832,
        "height": 1280,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-06-12T22:27:53.595Z",
        "postId": 217967,
        "stats": {
            "cryCount": 9,
            "laughCount": 8,
            "likeCount": 100,
            "dislikeCount": 0,
            "heartCount": 110,
            "commentCount": 1
        },
        "meta": {
            "Size": "512x768",
            "seed": 1261263585,
            "Model": "Lyriel_v16",
            "steps": 30,
            "hashes": {
                "model": "e96852ac4a"
            },
            "prompt": "(dark shot:1.1), epic realistic, portrait of halo, sunglasses, blue eyes, tartan scarf, white hair by atey ghailan, by greg rutkowski, by greg tocchini, by james gilleard, by joe fenton, by kaethe butcher, gradient yellow, black, brown and magenta color scheme, grunge aesthetic!!! graffiti tag wall background, art by greg rutkowski and artgerm, soft cinematic light, adobe lightroom, photolab, hdr, intricate, highly detailed, (depth of field:1.4), faded, (neutral colors:1.2), (hdr:1.4), (muted colors:1.2), hyperdetailed, (artstation:1.4), cinematic, warm lights, dramatic light, (intricate details:1.1), complex background, (rutkowski:0.66), (teal and orange:0.4)",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 9,
            "Clip skip": "2",
            "resources": [
                {
                    "hash": "e96852ac4a",
                    "name": "Lyriel_v16",
                    "type": "model"
                }
            ],
            "Model hash": "e96852ac4a",
            "Hires steps": "38",
            "Hires resize": "832x1280",
            "Hires upscaler": "Latent",
            "negativePrompt": "3d, cartoon, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name, young, loli, elf, 3d, illustration",
            "Denoising strength": "0.56"
        },
        "username": "civitai",
        "baseModel": "SD 1.5"
    },
    {
        "id": 41582369,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c6a74a47-3ad9-4cad-a7d5-e07281589929/width=1425/c6a74a47-3ad9-4cad-a7d5-e07281589929.jpeg",
        "hash": "UABy:CMwXmIp~p8{%MV@5TD*%L-n?G$$E2Ip",
        "width": 1425,
        "height": 2260,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-23T02:54:23.190Z",
        "postId": 9468379,
        "stats": {
            "cryCount": 14,
            "laughCount": 31,
            "likeCount": 135,
            "dislikeCount": 0,
            "heartCount": 46,
            "commentCount": 0
        },
        "meta": null,
        "username": "luismartinez8676287",
        "baseModel": ""
    },
    {
        "id": 41559853,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8371dc03-b57d-49eb-a071-e20515b9d38f/width=1664/8371dc03-b57d-49eb-a071-e20515b9d38f.jpeg",
        "hash": "UPI}#20LOswH_4NHN#w@4:IVxaskV?ROIU-:",
        "width": 1664,
        "height": 2432,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-23T00:17:18.071Z",
        "postId": 9463157,
        "stats": {
            "cryCount": 8,
            "laughCount": 8,
            "likeCount": 165,
            "dislikeCount": 0,
            "heartCount": 45,
            "commentCount": 0
        },
        "meta": {
            "": {
                "\\skip_factor\\": "0.4}]",
                "{\\backbone_factor\\": "1.2",
                "[{\\backbone_factor\\": "1.1"
            },
            "VAE": "fixFP16ErrorsSDXLLowerMemoryUse_v10.safetensors",
            "Size": "832x1216",
            "seed": 2772607253,
            "Model": "N40NAillous-xl",
            "steps": 32,
            "hashes": {
                "vae": "235745af8d",
                "model": "18579680fe",
                "lora:Saber illustxl": "f6889be51d59"
            },
            "prompt": "masterpiece, best quality, amazing quality, very aesthetic, absurdres, newest, scenery, 1girl, solo, huge breasts, surprised, blush, open mouth, <lora:Saber illustxl:1> artoria pendragon (fate), saber (fate), blonde hair, green eyes, ahoge, hair ribbon, blue ribbon, french braid, braided bun, single hair bun, short hair, sidelocks, blue scarf, white jacket, long sleeves, blue skirt, long skirt, black pantyhose, sitting, on chair, holding sandwich, park, outside, upper body, front view, looking down, shiny skin, masterpiece, best quality, amazing quality, very aesthetic, absurdres, newest, scenery",
            "Version": "v1.10.1",
            "sampler": "DPM++ 2M",
            "CFG mode": "Half Cosine Up",
            "cfgScale": 12,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "f6889be51d59",
                    "name": "Saber illustxl",
                    "type": "lora"
                },
                {
                    "hash": "18579680fe",
                    "name": "N40NAillous-xl",
                    "type": "model"
                }
            ],
            "Mimic mode": "Half Cosine Up",
            "Model hash": "18579680fe",
            "Hires steps": "5",
            "Mimic scale": "7",
            "FreeU Stages": {},
            "Hires prompt": "",
            "Detail Daemon": {
                "ed": "0.8",
                "st": "0.2",
                "exp": "1",
                "bias": "0.5",
                "fade": "0",
                "mode": "uncond",
                "amount": "0.4",
                "smooth": "1",
                "ed_offset": "0",
                "st_offset": "0"
            },
            "FreeU Version": "2",
            "Hires upscale": "2",
            "Schedule type": "Karras",
            "FreeU Schedule": {},
            "Hires upscaler": "R-ESRGAN 4x+ Anime6B",
            "negativePrompt": "lowres, (worst quality:1.2), (bad quality:1.2), bad anatomy, sketch, jpeg artifacts, signature, watermark, old, oldest, censored, bar censor, (pregnant), chibi, loli, simple background, conjoined, ai-generated, 3d, realistic, (shaded face:1.1)",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer steps": "28",
            "Interpolate Phi": "1",
            "ADetailer sampler": "Euler a",
            "ADetailer version": "24.9.0",
            "CFG scale minimum": "3",
            "Denoising strength": "0.4",
            "Scaling Startpoint": "MEAN",
            "ADetailer CLIP skip": "1",
            "ADetailer mask blur": "4",
            "ADetailer model 2nd": "hand_yolov8n.pt",
            "ADetailer scheduler": "Exponential",
            "Mimic scale minimum": "3",
            "Variability Measure": "AD",
            "ADetailer checkpoint": "Use same checkpoint",
            "ADetailer confidence": "0.3",
            "Threshold percentile": "97.5",
            "Hires negative prompt": "",
            "ADetailer dilate erode": "4",
            "ADetailer mask blur 2nd": "4",
            "ADetailer confidence 2nd": "0.3",
            "ADetailer inpaint padding": "32",
            "Separate Feature Channels": "True",
            "ADetailer dilate erode 2nd": "4",
            "ADetailer denoising strength": "0.4",
            "ADetailer use separate steps": "True",
            "Dynamic thresholding enabled": "True",
            "ADetailer inpaint only masked": "True",
            "ADetailer inpaint padding 2nd": "32",
            "ADetailer use separate sampler": "True",
            "ADetailer denoising strength 2nd": "0.4",
            "ADetailer use separate CLIP skip": "True",
            "ADetailer inpaint only masked 2nd": "True",
            "ADetailer use separate checkpoint": "True"
        },
        "username": "gamemon1004",
        "baseModel": "Illustrious"
    },
    {
        "id": 40437832,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/723d51c6-1152-4e0a-b91d-404beb929775/width=992/723d51c6-1152-4e0a-b91d-404beb929775.jpeg",
        "hash": "UNC7E7.8xu%g_NtRf+xu.8x]Rjof?vfRIAWV",
        "width": 992,
        "height": 1456,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-16T13:41:22.529Z",
        "postId": 9214002,
        "stats": {
            "cryCount": 9,
            "laughCount": 9,
            "likeCount": 165,
            "dislikeCount": 0,
            "heartCount": 43,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 481659304,
            "Model": "flux1-dev-fp8",
            "steps": 40,
            "hashes": {
                "model": "275ef623d3",
                "lora:ck-Orcs-000016": "d5f850519133"
            },
            "prompt": "<lora:ck-Orcs-000016:1>, ck-0rcs, this is an image of a black skinned orc, lifeless cold icy eyes, fierce look as he is aiming a giant medieval sword at the viewer, the orc is wearing intricate battle scarred armor, blood and white markers on his armor, looking at the viewer,",
            "Version": "f2.0.1v1.10.1-1.10.1",
            "sampler": "Euler",
            "Module 1": "ae",
            "Module 2": "t5xxl_fp16",
            "Module 3": "clip_l",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "d5f850519133",
                    "name": "ck-Orcs-000016",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "275ef623d3",
                    "name": "flux1-dev-fp8",
                    "type": "model"
                }
            ],
            "Model hash": "275ef623d3",
            "Hires steps": "10",
            "Hires upscale": "1.2",
            "Schedule type": "Simple",
            "Hires upscaler": "Lanczos",
            "Hires CFG Scale": "1",
            "Denoising strength": "0.24",
            "Distilled CFG Scale": "3.5",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)",
            "Hires Distilled CFG Scale": "3.5"
        },
        "username": "ChronoKnight",
        "baseModel": null
    },
    {
        "id": 39962594,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e1c36599-bb5e-4ff2-b9c6-85728714654e/width=832/e1c36599-bb5e-4ff2-b9c6-85728714654e.jpeg",
        "hash": "U8Bg6;-B00-q~Wni4.?cNFE1R%.8XmM{8_oy",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-13T21:42:48.378Z",
        "postId": 9110352,
        "stats": {
            "cryCount": 5,
            "laughCount": 15,
            "likeCount": 130,
            "dislikeCount": 0,
            "heartCount": 76,
            "commentCount": 0
        },
        "meta": {
            "seed": 2297513424,
            "steps": 35,
            "prompt": "A sci-fi cyberpunk style scene. The central figure is a gorgeous woman with pale skin and striking platinum blonde hair that cascades past her shoulders. She wears a form-fitting, shiny white bodysuit with black accents, emphasizing her curvaceous figure and large breasts. The bodysuit is adorned with a high-tech, metallic chest plate with a red emblem in the center. She is also wearing a black trench coat that is open, revealing her outfit. Her eyes are covered by a futuristic, high-tech mask with its eyes glowing in an intimidating red light. The background features a dilapidated, graffiti-covered brick wall with a large, faded graffiti tag on the left side. The wall is in shades of gray and red, with some areas showing signs of wear and decay. The lighting is dramatic, with a beam of light illuminating the subject from above, casting shadows and highlighting the textures of her outfit and the wall. The overall atmosphere is intense and gritty, typical of cyberpunk. cyberpunk style, mythp0rt, realisticanime",
            "cfgScale": 4
        },
        "username": "Qvoheu",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 39531075,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a886bee3-bde5-4aef-809b-633e853ff1ad/width=832/a886bee3-bde5-4aef-809b-633e853ff1ad.jpeg",
        "hash": "U97-{0yER5RP+ZvfR-S~znsmb^ae?^t,V@Vs",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-11T10:39:45.146Z",
        "postId": 9016295,
        "stats": {
            "cryCount": 9,
            "laughCount": 13,
            "likeCount": 164,
            "dislikeCount": 0,
            "heartCount": 40,
            "commentCount": 1
        },
        "meta": null,
        "username": "6vidit9",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 39047716,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cfc583f2-ffd5-4218-8a5d-fc552b82b216/width=768/cfc583f2-ffd5-4218-8a5d-fc552b82b216.jpeg",
        "hash": "UBHm_lNf00E1G]S~vf9G~VRkVst60fxYE2oz",
        "width": 768,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-08T17:15:48.145Z",
        "postId": 8910608,
        "stats": {
            "cryCount": 13,
            "laughCount": 39,
            "likeCount": 123,
            "dislikeCount": 0,
            "heartCount": 51,
            "commentCount": 0
        },
        "meta": {
            "Size": "768x1024",
            "seed": 2803679409,
            "Model": "flux1-dev-fp8",
            "steps": 20,
            "hashes": {
                "model": "275ef623d3",
                "lora:Cute_3d_Cartoon_Flux": "64b2df5b34dc"
            },
            "prompt": "A high-resolution, cute 3D cartoon-style image of a calm, innocent-looking cat sitting in the middle of a room.  A speech bubble above the cat reads, \"He didn't want to give me buzz\". In the room it's visible a (((bulldog trapped in a big bird cage)). The contrast between the cat's serene demeanor and the chaotic scene adds a humorous, surreal touch, <lora:Cute_3d_Cartoon_Flux:0.5>",
            "Version": "f2.0.1v1.10.1-previous-608-ge2fe29c1",
            "sampler": "Euler",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "64b2df5b34dc",
                    "name": "Cute_3d_Cartoon_Flux",
                    "type": "lora",
                    "weight": 0.5
                },
                {
                    "hash": "275ef623d3",
                    "name": "flux1-dev-fp8",
                    "type": "model"
                }
            ],
            "Model hash": "275ef623d3",
            "Schedule type": "Simple",
            "Denoising strength": "0.24",
            "Distilled CFG Scale": "3.5"
        },
        "username": "sleevs",
        "baseModel": null
    },
    {
        "id": 38870951,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f2296774-fa28-43c8-b1fe-ffbdc96db0a9/width=832/f2296774-fa28-43c8-b1fe-ffbdc96db0a9.jpeg",
        "hash": "U17n357500,93dI.HqVu00%1}x17@w}u%yAk",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-07T18:30:00.000Z",
        "postId": 8870923,
        "stats": {
            "cryCount": 18,
            "laughCount": 11,
            "likeCount": 143,
            "dislikeCount": 0,
            "heartCount": 54,
            "commentCount": 1
        },
        "meta": null,
        "username": "DoreenAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 38455979,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7cb6d52d-db74-46bd-ad7a-7f78eba965c4/width=864/7cb6d52d-db74-46bd-ad7a-7f78eba965c4.jpeg",
        "hash": "U97AJ-R$-as=9:s=NDWT-ZayoMj]NEaxxJj[",
        "width": 864,
        "height": 1152,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-11-05T09:01:24.474Z",
        "postId": 8778429,
        "stats": {
            "cryCount": 19,
            "laughCount": 20,
            "likeCount": 120,
            "dislikeCount": 0,
            "heartCount": 67,
            "commentCount": 0
        },
        "meta": {
            "RNG": "NV",
            "VAE": "sdxl_vae.safetensors",
            "Size": "864x1152",
            "seed": 376387210,
            "Model": "autismmixSDXL_autismmixPony",
            "steps": 25,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "821aa5537f",
                "lora:neonXLP": "088dc10f8634"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up,  <lora:neonXLP:1> neon, 1girl, solo, purple theme, monochrome, twintails, simple background, tongue, looking at viewer, tongue out, head rest, purple background, hair between eyes, upper body, middle finger, cleavage, large breasts,",
            "Version": "v1.10.1",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "Pad conds": "True",
            "resources": [
                {
                    "hash": "088dc10f8634",
                    "name": "neonXLP",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "821aa5537f",
                    "name": "autismmixSDXL_autismmixPony",
                    "type": "model"
                }
            ],
            "Model hash": "821aa5537f",
            "Schedule type": "Automatic",
            "negativePrompt": "watermark, signature, artist name, twitter username, english text, patreon logo, censored, child, kid, loli, muscular,",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.9.0",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.25",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.25",
            "ADetailer inpaint only masked": "True"
        },
        "username": "freckledvixon",
        "baseModel": "Pony"
    },
    {
        "id": 38351580,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9c3e6af0-8ced-4f38-8183-e5ad964b1694/width=1024/9c3e6af0-8ced-4f38-8183-e5ad964b1694.jpeg",
        "hash": "UHG7xF}=58I;-Q-Ts.Iq0gW.t7WFENENWC-T",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-04T20:30:04.035Z",
        "postId": 8755724,
        "stats": {
            "cryCount": 4,
            "laughCount": 32,
            "likeCount": 149,
            "dislikeCount": 0,
            "heartCount": 41,
            "commentCount": 0
        },
        "meta": {
            "Size": "1024x1024",
            "seed": 1026811618637456,
            "Model": "Image",
            "steps": 40,
            "hashes": {
                "model": "",
                "LORA:Flux\\Elektroschutz_flux_lora lktro.safetensors": "d12c4347e4",
                "LORA:Flux\\BUZZ_LOGO_Flux_Lora SuchBuzzLogo.safetensors": "5b91ab611c",
                "LORA:Flux\\CAVHS_flux_lora_v1 90s vhs footage, CAVHS.safetensors": "782904b196"
            },
            "prompt": "suchbuzzlogo, In a mystical laboratory, a cute yellow Minion clad in an alchemist's hat and goggles, carefully stirring a bubbling cauldron filled with glittering gemstones. Behind him, the SuchBuzzLogo, resembling a radiant lightning bolt emoji, glows brightly on a wooden plaque. Soft golden lighting illuminates the scene, reminiscent of ancient tomes and mysterious artifacts scattered about the workspace., ,suchbuzzlogo, glowing yellow logo, alchemist's lab, minion character, sparkling gemstones, bubbling cauldron, mystical atmosphere, ,<lora:Flux\\BUZZ_LOGO_Flux_Lora SuchBuzzLogo.safetensors:1.0:1.0> <lora:Flux\\Elektroschutz_flux_lora lktro.safetensors:1.0:1.0> <lora:Flux\\CAVHS_flux_lora_v1 90s vhs footage, CAVHS.safetensors:1.0:1.0>",
            "Version": "ComfyUI",
            "sampler": "deis_simple",
            "cfgScale": 3.5,
            "resources": [],
            "Model hash": ""
        },
        "username": "an303042",
        "baseModel": null
    },
    {
        "id": 38297292,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/df4ef85f-3eb1-4a1f-b9e2-22b4e36b98b4/width=896/df4ef85f-3eb1-4a1f-b9e2-22b4e36b98b4.jpeg",
        "hash": "UEKdo84m4Tt8~V?b9ZIU9F_N%L4n~oRjNGD%",
        "width": 896,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-04T14:07:22.301Z",
        "postId": 8743754,
        "stats": {
            "cryCount": 13,
            "laughCount": 28,
            "likeCount": 127,
            "dislikeCount": 0,
            "heartCount": 58,
            "commentCount": 0
        },
        "meta": null,
        "username": "wdwd132",
        "baseModel": ""
    },
    {
        "id": 37872103,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5f2c86d3-7f5f-4d31-a021-cca5f75c58ed/width=832/5f2c86d3-7f5f-4d31-a021-cca5f75c58ed.jpeg",
        "hash": "UiPQ87of~qxu9FM{%M%Mt7xuRjRj?bt7M{Rj",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-02T06:04:15.879Z",
        "postId": 8649172,
        "stats": {
            "cryCount": 13,
            "laughCount": 22,
            "likeCount": 137,
            "dislikeCount": 0,
            "heartCount": 54,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1797096626,
            "extra": {
                "remixOfId": 37765593
            },
            "steps": 26,
            "prompt": "A cup of ink spilled over with a cat walking away from it. The ground is stained with cat pawprints",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-02T0603:54.0446444Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 1000905,
                    "modelVersionName": "FLUX"
                }
            ]
        },
        "username": "Meower2024",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 37728092,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7ef13a80-1e93-4038-ba39-5826ebf60552/width=832/7ef13a80-1e93-4038-ba39-5826ebf60552.jpeg",
        "hash": "UUNTa,~pt-ogY8%L$_NG$^ae-oIV%fays*Rk",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-01T10:57:24.268Z",
        "postId": 8616597,
        "stats": {
            "cryCount": 13,
            "laughCount": 33,
            "likeCount": 128,
            "dislikeCount": 0,
            "heartCount": 52,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2311755898,
            "extra": {
                "remixOfId": 37214394
            },
            "steps": 4,
            "prompt": "score_4,score_5,score_6,score_7_up,score_8_up,score_9 ((masterpiece,best quality,ultra detailed,highres,HD,4k:1.2)), \n1 girl,solo,face focus,\nayanami_rei,rei ayanami, blue hair, ((long hair, Messy Hair:1.2)),red eyes, head gear, \nbodysuit, headgear, plugsuit, neon_genesis_evangelion, white bodysuit, \n((\"Give me Buzz.\",Beggars Board,Holding a sign, holding a sign that says, \"Give me Buzz.\"))\nwink,closed mouth,blush,Expressionless,",
            "sampler": "Undefined",
            "cfgScale": 1,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-01T1052:07.0447780Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 699279,
                    "modelVersionName": "Schnell"
                }
            ]
        },
        "username": "ahokakonnamoniran923",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 37618273,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c4b5d1bb-8104-4be9-aef7-8111acf96745/width=1152/c4b5d1bb-8104-4be9-aef7-8111acf96745.jpeg",
        "hash": "U27Sgi|_6NW;ofNu=0$PJRJRo2$P$PW:JRa|",
        "width": 1152,
        "height": 896,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-31T20:14:01.845Z",
        "postId": 8592991,
        "stats": {
            "cryCount": 17,
            "laughCount": 28,
            "likeCount": 139,
            "dislikeCount": 0,
            "heartCount": 42,
            "commentCount": 0
        },
        "meta": null,
        "username": "hellmarch9999",
        "baseModel": ""
    },
    {
        "id": 37363997,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4f2455a6-a7ba-43fa-b569-dec40e843706/width=832/4f2455a6-a7ba-43fa-b569-dec40e843706.jpeg",
        "hash": "UCC5lPA6A2Ip$XI*E*WAE4xD-UEdSZRrxYs7",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-30T10:25:03.603Z",
        "postId": 8533693,
        "stats": {
            "cryCount": 7,
            "laughCount": 16,
            "likeCount": 154,
            "dislikeCount": 0,
            "heartCount": 49,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2890983431,
            "extra": {
                "remixOfId": 29827334
            },
            "steps": 26,
            "prompt": "source: illustration,\nPunk,  90s-punk The image features a  person with punk-style hair and makeup. They has multiple colors in their mohawk style hair, predominantly purple and blue, and is wearing intricate tattoos or body art on their arms and neck.  They wear a Tanktop has a text on it (((Text on tanktop reads \"lookin' for a BUZZ\" in yellow bolt letters))), 90s. The grungy punk is lascivious (playing a guitar on a concert stage)+ ((blow a kiss a viewer))+ ironic sensual, looking at viewer,  body posture underlines her fit but voluptuous body while her sensual still ironic face expression underlines her enjoyment of the punk music scene, person is singing into a microphone, liberty spike hairstyle",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-30T1020:19.3642590Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                }
            ]
        },
        "username": "Ceadubs",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 37257746,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d1aff1c3-b873-4468-9885-ce6ce25e5268/width=1624/d1aff1c3-b873-4468-9885-ce6ce25e5268.jpeg",
        "hash": "UMFfpnsoE3sA-.oLIVWC}rfkE3aftQson5WV",
        "width": 1624,
        "height": 2368,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-29T19:45:16.577Z",
        "postId": 8508897,
        "stats": {
            "cryCount": 8,
            "laughCount": 8,
            "likeCount": 162,
            "dislikeCount": 0,
            "heartCount": 48,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 529491199693183,
            "Model": "flux_dev",
            "steps": 20,
            "hashes": {
                "model": "2eda627c8a"
            },
            "prompt": "(in Krenz Cushart style:1.2), high-quality, masterpiece, A spectral warrior, her face twisted in a silent scream of rage, the camera capturing every crack in her armor and every flicker of her fiery eyes, The background dissolves into smoke and glowing embers as her gauntleted hand rises just outside the frame gripping an unseen weapon, The focus is on her expression highlighted by the sharp glow of spectral flames around her, high contrast, dramatic close-up, glowing firelight, intense focus, (elaborate fine details:1.1), (elaborately detailed attire with extraordinary elements:1.1), (hyperdetailed:1.1), (intricate details:1.0), (Refined details:1.1), (best quality:1.1), (high resolution:1.2)",
            "Version": "ComfyUI",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 3.5,
            "resources": [
                {
                    "hash": "2eda627c8a",
                    "name": "flux_dev",
                    "type": "model"
                }
            ],
            "Model hash": "2eda627c8a"
        },
        "username": "RIDD",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 36926376,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6949695f-0a3d-4a7e-846f-031816ba42bc/width=512/6949695f-0a3d-4a7e-846f-031816ba42bc.jpeg",
        "hash": "UADvJ{59%g~W.9%g-:-;OX-;Iqo}tlx]x]I=",
        "width": 512,
        "height": 768,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-28T00:02:03.022Z",
        "postId": 8433272,
        "stats": {
            "cryCount": 11,
            "laughCount": 18,
            "likeCount": 149,
            "dislikeCount": 0,
            "heartCount": 48,
            "commentCount": 0
        },
        "meta": null,
        "username": "sbxl473",
        "baseModel": ""
    },
    {
        "id": 35920305,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0de9c46b-1be5-4124-bf7b-59e9170c6eec/width=832/0de9c46b-1be5-4124-bf7b-59e9170c6eec.jpeg",
        "hash": "U5CYUTjY01fk0:WV+soKkVjZIUS40fjZ}@s:",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-29T07:56:00.000Z",
        "postId": 8206936,
        "stats": {
            "cryCount": 1,
            "laughCount": 5,
            "likeCount": 160,
            "dislikeCount": 0,
            "heartCount": 60,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 989164297,
            "steps": 15,
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, \n1girl, 25 years old, perfect face, close view, cute, petite, \ngreen eyes, goth, \nwhite hair, long hair, twintails, parted bangs, \npointy ears, red earrings, jewelry,\nbat hair ornament, black choker, \nbat bra,\nhalloween, candles,\nblush, shy smile, \nportrait, face focus, detailed face,",
            "sampler": "DPM2 a",
            "cfgScale": 3,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-22T0753:34.2779401Z",
            "negativePrompt": "score_6, score_5, score_4, pony, furry, monochrome, curvy, fat, pubic hair, watermark, \nartist name, ugly, ugly face, mutated hands, low res, bad anatomy, bad eyes, blurry face, unfinished, sketch, greyscale, (deformed),",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 290640,
                    "modelVersionName": "V6 (start with this one)"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208,
                    "modelVersionName": "EasyNegative"
                },
                {
                    "type": "lora",
                    "weight": 0.45,
                    "modelVersionId": 382152,
                    "modelVersionName": "ExpressiveH"
                },
                {
                    "type": "lora",
                    "weight": 0.75,
                    "modelVersionId": 244808,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 398847,
                    "modelVersionName": "gothic neon v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 436219,
                    "modelVersionName": "v3.0 (PonyXL Edition)"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250708,
                    "modelVersionName": "safe_pos"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250712,
                    "modelVersionName": "safe_neg"
                }
            ]
        },
        "username": "carefull_time",
        "baseModel": "Pony"
    },
    {
        "id": 34432015,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fd9d1dda-4851-451b-8457-16b365e7d697/width=832/fd9d1dda-4851-451b-8457-16b365e7d697.jpeg",
        "hash": "UJA,FNNG0K$$5@s,-5Rk57s.-oNH}RR*AJt6",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-13T20:06:51.556Z",
        "postId": 7866810,
        "stats": {
            "cryCount": 7,
            "laughCount": 2,
            "likeCount": 167,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3425686283,
            "extra": {
                "remixOfId": 32282710
            },
            "steps": 24,
            "prompt": "there, at the very end of the earth, in an unprecedented blue distance, hearing the sounds of unprecedented words, sweetly and sweetly the blood stops, there the winds fly touching the stars, where trees are not afraid of thunderstorms, there ships are roaming the ocean, glitter, professional photo, hyper-realism, intricate detail, sunset, vivid color, chiaroscuro, aidmaimageupgrader",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-13T2003:37.9982364Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 720252,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.9,
                    "modelVersionId": 863991,
                    "modelVersionName": "FLUX v0.2"
                }
            ]
        },
        "username": "White_Rabbit_A",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 34376578,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/59daabda-b907-4b93-8087-d0a4052dd8d8/width=1344/59daabda-b907-4b93-8087-d0a4052dd8d8.jpeg",
        "hash": "U99jJw~UocxYEjxtxZIV9v9u9bIV^*WqM|s,",
        "width": 1344,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-14T00:20:00.000Z",
        "postId": 7854629,
        "stats": {
            "cryCount": 7,
            "laughCount": 2,
            "likeCount": 181,
            "dislikeCount": 0,
            "heartCount": 36,
            "commentCount": 0
        },
        "meta": {
            "Size": "896x1152",
            "seed": 1438651161,
            "Model": "flux1-dev-bnb-nf4-v2",
            "steps": 30,
            "hashes": {
                "model": "bea01d51bd",
                "lora:artisketchyfs-v02": "2097f7b0e740",
                "lora:dark_fantasy_flux": "6E5F580C0E",
                "lora:FluxMythP0rtr4itStyle": "8ea428b224a8",
                "lora:FredFraiStyle-FLUX-Share": "63BFAA1CF9",
                "lora:flux.1_lora_flyway_Epic-Characters_v1": "B73E077D02BF"
            },
            "Version": "f2.0.1v1.10.1-previous-450-gdb6448df",
            "sampler": "Euler",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "63BFAA1CF9",
                    "name": "FredFraiStyle-FLUX-Share",
                    "type": "lora"
                },
                {
                    "hash": "2097f7b0e740",
                    "name": "artisketchyfs-v02",
                    "type": "lora"
                },
                {
                    "hash": "6E5F580C0E",
                    "name": "dark_fantasy_flux",
                    "type": "lora"
                },
                {
                    "hash": "B73E077D02BF",
                    "name": "flux.1_lora_flyway_Epic-Characters_v1",
                    "type": "lora"
                },
                {
                    "hash": "8ea428b224a8",
                    "name": "FluxMythP0rtr4itStyle",
                    "type": "lora"
                },
                {
                    "hash": "bea01d51bd",
                    "name": "flux1-dev-bnb-nf4-v2",
                    "type": "model"
                }
            ],
            "Model hash": "bea01d51bd",
            "Hires steps": "25",
            "Hires upscale": "1.5",
            "Schedule type": "Normal",
            "Hires upscaler": "4x-UltraSharp",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.9.0",
            "Denoising strength": "0.45",
            "ADetailer mask blur": "8",
            "Distilled CFG Scale": "3.5",
            "ADetailer confidence": "0.3",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint width": "768",
            "ADetailer inpaint height": "1024",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True",
            "ADetailer use inpaint width height": "True"
        },
        "username": "ArtifyAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 33828229,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/181b3430-e8bd-4da1-83fd-e3ec0baa7726/width=832/181b3430-e8bd-4da1-83fd-e3ec0baa7726.jpeg",
        "hash": "U89a?aIo0f?w-N8^Ri%LOtXU$}IUXoS6xBIA",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-10T11:32:50.047Z",
        "postId": 7732605,
        "stats": {
            "cryCount": 2,
            "laughCount": 12,
            "likeCount": 153,
            "dislikeCount": 0,
            "heartCount": 59,
            "commentCount": 0
        },
        "meta": null,
        "username": "Ai_Collector",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 33191384,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c697deba-dce4-496e-9dd0-7d7b758df4ec/width=864/c697deba-dce4-496e-9dd0-7d7b758df4ec.jpeg",
        "hash": "U7By%500u5xu-pNGR%XT00_4-OD*9Z=|jF$M",
        "width": 864,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-06T21:22:32.528Z",
        "postId": 7594967,
        "stats": {
            "cryCount": 32,
            "laughCount": 3,
            "likeCount": 139,
            "dislikeCount": 0,
            "heartCount": 52,
            "commentCount": 0
        },
        "meta": {
            "RNG": "NV",
            "VAE": "sdxl_vae.safetensors",
            "Size": "864x1152",
            "seed": 576908269,
            "Model": "autismmixSDXL_autismmixPony",
            "steps": 30,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "821aa5537f",
                "lora:JohnKafkaXLP": "5056c839a193"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up,  <lora:JohnKafkaXLP:1> john kafka, 1girl, curvy, colourful, graffiti, portrait,",
            "Version": "v1.10.1",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "5056c839a193",
                    "name": "JohnKafkaXLP",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "821aa5537f",
                    "name": "autismmixSDXL_autismmixPony",
                    "type": "model"
                }
            ],
            "Model hash": "821aa5537f",
            "Schedule type": "Automatic",
            "negativePrompt": "watermark, signature, artist name, twitter username, 3d, censored, realistic,",
            "ADetailer model": "FacesV1.pt",
            "ADetailer version": "24.9.0",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.3",
            "ADetailer inpaint only masked": "True"
        },
        "username": "freckledvixon",
        "baseModel": "Pony"
    },
    {
        "id": 32853156,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bd1b4b49-d462-4de0-baf2-f5b8a0ae1228/width=832/bd1b4b49-d462-4de0-baf2-f5b8a0ae1228.jpeg",
        "hash": "UCCjO}i_00yXELRPH=oz00M_=}w|*0fl-ps,",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-04T23:22:00.166Z",
        "postId": 7518310,
        "stats": {
            "cryCount": 6,
            "laughCount": 18,
            "likeCount": 151,
            "dislikeCount": 0,
            "heartCount": 51,
            "commentCount": 0
        },
        "meta": {
            "seed": 93768518664815,
            "vaes": [
                "ae.sft"
            ],
            "comfy": "{\"prompt\": {\"5\": {\"inputs\": {\"width\": [\"70\", 0], \"height\": [\"71\", 0], \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"6\": {\"inputs\": {\"text\": [\"28\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"MarkuryFLUX\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"10\": {\"inputs\": {\"vae_name\": \"ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp16.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux1-dev.sft\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"5\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 25, \"denoise\": 1.0, \"model\": [\"61\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"61\", 0], \"conditioning\": [\"60\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 93768518664815}, \"class_type\": \"RandomNoise\"}, \"28\": {\"inputs\": {\"string\": \"ghostly banshee jelly dessert, professional, high quality, super cute, kawaii, 8k, adorable,\"}, \"class_type\": \"String Literal\"}, \"60\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"6\", 0]}, \"class_type\": \"FluxGuidance\"}, \"61\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5, \"width\": [\"70\", 0], \"height\": [\"71\", 0], \"model\": [\"72\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"70\": {\"inputs\": {\"int\": 832}, \"class_type\": \"Int Literal\"}, \"71\": {\"inputs\": {\"int\": 1216}, \"class_type\": \"Int Literal\"}, \"72\": {\"inputs\": {\"lora_name\": \"FluxGhost-000001.safetensors\", \"strength_model\": 1.0, \"model\": [\"12\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}}, \"workflow\": {\"last_node_id\": 72, \"last_link_id\": 108, \"nodes\": [{\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 26, \"1\": 379}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.sft\"]}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 424.71875, \"1\": 618.052001953125}, \"size\": {\"0\": 210, \"1\": 54}, \"flags\": {\"collapsed\": false}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 108}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 47, \"slot_index\": 1, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [86], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 5, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 422, \"1\": 101}, \"size\": {\"0\": 330.5548400878906, \"1\": 78}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 101, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 103, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [23], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 893.71875, \"1\": 612.052001953125}, \"size\": {\"0\": 196.9998779296875, \"1\": 62.66668701171875}, \"flags\": {\"collapsed\": false}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 94, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 87, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [30], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 52, \"type\": \"Note\", \"pos\": {\"0\": 1148.09375, \"1\": 611.84375}, \"size\": {\"0\": 346.2236022949219, \"1\": 58}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"To see the preview, update your ComfyUI and go into the Manager menu. Set \\\"Preview Method\\\" to \\\"Auto\\\"\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1143.252685546875, \"1\": 89.17115783691406}, \"size\": {\"0\": 352.4039611816406, \"1\": 463.3393859863281}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 30, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 23, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 61, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 754, \"1\": 383}, \"size\": {\"0\": 321.8402404785156, \"1\": 122}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 106}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 102, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 104, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [93, 94], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 1024, 1024]}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1613, \"1\": 62}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [9], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 60, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 659, \"1\": 614}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 86}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [87], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": {\"0\": 1585, \"1\": 245}, \"size\": {\"0\": 399.1837463378906, \"1\": 508.5245666503906}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 9}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"MarkuryFLUX\"]}, {\"id\": 53, \"type\": \"Note\", \"pos\": {\"0\": 445, \"1\": 746}, \"size\": {\"0\": 621.5443725585938, \"1\": 305.7030029296875}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The checkpoint goes in ComfyUI/models/unet (not checkpoints)\\nDownload the original weights here:\\nhttps://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/flux1-dev.sft\\n\\nDownload the fp8 version for <24gb vram systems:\\nhttps://huggingface.co/Kijai/flux-fp8/blob/main/flux1-dev-fp8.safetensors\\n\\nText encoders go in ComfyUI/models/clip:\\nhttps://huggingface.co/comfyanonymous/flux_text_encoders/tree/main\\n\\nVAE (ae.sft) goes in ComfyUI/models/vae:\\nhttps://huggingface.co/black-forest-labs/FLUX.1-schnell/blob/main/ae.sft\\n\\nDownload the fp8 t5xxl for degraded quality but less RAM use\\nLaunch ComfyUI with \\\"--lowvram\\\" arg (in the .bat file) to offload text encoder to CPU.\\n\\nI can confirm this runs on:\\n- RTX 3090 (24gb) 1.29s/it\\n- RTX 4070 (12gb) 85s/it\\nBoth running the fp8 quantized version. The 4070 is very slow though.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": 18, \"1\": 84}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [107], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev.sft\", \"fp8_e4m3fn\"]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 22, \"1\": 214}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [108], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp16.safetensors\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 809, \"1\": 261}, \"size\": {\"0\": 268.2277526855469, \"1\": 58}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 71, \"type\": \"Int Literal\", \"pos\": {\"0\": 28, \"1\": 610}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [103, 104], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Height\", \"properties\": {\"Node name for S&R\": \"Int Literal\"}, \"widgets_values\": [1216]}, {\"id\": 70, \"type\": \"Int Literal\", \"pos\": {\"0\": 25, \"1\": 495}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [101, 102], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Width\", \"properties\": {\"Node name for S&R\": \"Int Literal\"}, \"widgets_values\": [832]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 797, \"1\": 94}, \"size\": {\"0\": 281.2428283691406, \"1\": 106}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 93, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 25, 1]}, {\"id\": 72, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": 419, \"1\": 403}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 107}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [106], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"FluxGhost-000001.safetensors\", 1]}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 424, \"1\": 236}, \"size\": {\"0\": 327.1990661621094, \"1\": 94.58134460449219}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [93768518664815, \"randomize\"]}, {\"id\": 28, \"type\": \"String Literal\", \"pos\": {\"0\": 26.5353946685791, \"1\": 790.639892578125}, \"size\": {\"0\": 317.8795471191406, \"1\": 202.01535034179688}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [47], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"String Literal\"}, \"widgets_values\": [\"ghostly banshee jelly dessert, professional, high quality, super cute, kawaii, 8k, adorable,\"]}], \"links\": [[9, 8, 0, 9, 0, \"IMAGE\"], [12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [23, 5, 0, 13, 4, \"LATENT\"], [24, 13, 0, 8, 0, \"LATENT\"], [30, 22, 0, 13, 1, \"GUIDER\"], [37, 25, 0, 13, 0, \"NOISE\"], [47, 28, 0, 6, 1, \"STRING\"], [86, 6, 0, 60, 0, \"CONDITIONING\"], [87, 60, 0, 22, 1, \"CONDITIONING\"], [93, 61, 0, 17, 0, \"MODEL\"], [94, 61, 0, 22, 0, \"MODEL\"], [101, 70, 0, 5, 0, \"INT\"], [102, 70, 0, 61, 1, \"INT\"], [103, 71, 0, 5, 1, \"INT\"], [104, 71, 0, 61, 2, \"INT\"], [106, 72, 0, 61, 0, \"MODEL\"], [107, 12, 0, 72, 0, \"MODEL\"], [108, 11, 0, 6, 0, \"CLIP\"]], \"groups\": [{\"title\": \"Load FLUX.1\", \"bounding\": [1, 2, 369, 693], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Set Parameters\", \"bounding\": [379, 0, 733, 526], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"FLUX Prompt\", \"bounding\": [1, 704, 368, 318], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Conditioning\", \"bounding\": [379, 535, 732, 159], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"1st Pass\", \"bounding\": [1119, 0, 402, 693], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.3310000000000006, \"offset\": [-45.23076249471365, -86.94115478084915]}}, \"version\": 0.4}}",
            "steps": 25,
            "width": 832,
            "height": 1216,
            "models": [],
            "prompt": "ghostly banshee jelly dessert, professional, high quality, super cute, kawaii, 8k, adorable,",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 3.5,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "FluxGhost-000001.safetensors",
                    "type": "lora",
                    "strength": 1
                }
            ]
        },
        "username": "Faeia",
        "baseModel": null
    },
    {
        "id": 32101255,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/53ed312d-41e1-46a6-a099-773087a0ccd2/width=832/53ed312d-41e1-46a6-a099-773087a0ccd2.jpeg",
        "hash": "UDEyoQ%h00xup{yD%2bwt6Td%hkW01OY_3NH",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-30T13:21:27.125Z",
        "postId": 7344446,
        "stats": {
            "cryCount": 18,
            "laughCount": 35,
            "likeCount": 107,
            "dislikeCount": 0,
            "heartCount": 66,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3101466258,
            "steps": 14,
            "prompt": "((masterpiece,best quality,ultra detailed,highres,HD,4k:1.2)),\n(large breast,large butt:1.2),1 cute girl,solo,girl focus,solo focus,face focus,\nhatsune miku,absurdly long hair,aqua hair,twintails,hair ornament,sidelocks,hair between eyes,parted bangs, white shirt,collared shirt,bare shoulders,sleeveless shirt,aqua necktie,detached sleeves,black sleeves,shoulder tattoo,fringe,black thighhighs,black miniskirt,pleated skirt,zettai ryouiki,thigh boots, sailor collar,thighs,microskirt,pleated skirt,socks,\nStreamer, PC, watching viewers, sitting in a gaming chair,Waving to the audience,\nblush,smile,open mouth,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-30T1427:05.1889524Z",
            "negativePrompt": "(Macho, muscular, old man, fat man,Nostrils,\n,text,yuri,roll one \u0019s eyes:1.5),(worst quality, low quality:1.4), (patreon username, patreon logo, signature, watermark,easynegative,negative_hand-neg, bad-hands-5,low quality,bad-hands-5,extra limbs,missing limb,extra digit,fewer digit,missing digit,missing fingers,mutated hands and fingers,fused limb,bad hands,long neck,long body,bad anatomy,disfigured,deformed,poorly drawn,mutation,extra nippless,extra breasts,disembodied penis,:1.4)",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 828380,
                    "modelVersionName": "v3"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 898980,
                    "modelVersionName": "V1"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208,
                    "modelVersionName": "EasyNegative"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250708,
                    "modelVersionName": "safe_pos"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250712,
                    "modelVersionName": "safe_neg"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "tousaku555913485",
        "baseModel": "Pony"
    },
    {
        "id": 31688138,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e09ba9ca-d784-4aa3-8301-20a2da9ca07f/width=832/e09ba9ca-d784-4aa3-8301-20a2da9ca07f.jpeg",
        "hash": "UDC~6}$f0JJB5*f-wgW90JW?}]jD}vs7SvW?",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-28T03:22:07.158Z",
        "postId": 7143608,
        "stats": {
            "cryCount": 0,
            "laughCount": 16,
            "likeCount": 177,
            "dislikeCount": 0,
            "heartCount": 33,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2347180908,
            "extra": {
                "remixOfId": 30258509
            },
            "steps": 20,
            "prompt": "on an old antique table is a translucent sparkling chrysolite palace, a sparkling dragon flies above the palace, aesthetically pleasing, beautiful, close-up, luminescence, pastel lighting, vivid colors, illustration, hyper detailed, hyper-realistic, professional photoshoot, chiaroscuro lighting, aidmaimageupgrader, Hollywood Cinematic Film style, Pastel, crayons",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-25T1536:52.1395724Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 720252,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.9,
                    "modelVersionId": 863991,
                    "modelVersionName": "FLUX v0.2"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 805067,
                    "modelVersionName": "Cinematic Flux1D v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 762314,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "White_Rabbit_A",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 31603650,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9e69824a-6d72-4870-8156-c5c67028f980/width=832/9e69824a-6d72-4870-8156-c5c67028f980.jpeg",
        "hash": "UFCFh_4-xwjI+gkVIAocIUxuM_of~XM{g3n,",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-27T19:00:00.000Z",
        "postId": 7116270,
        "stats": {
            "cryCount": 10,
            "laughCount": 11,
            "likeCount": 149,
            "dislikeCount": 0,
            "heartCount": 56,
            "commentCount": 1
        },
        "meta": null,
        "username": "DoreenAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 31485537,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4eadc85f-95a6-4c34-84f9-2716b0ccf7a9/width=1328/4eadc85f-95a6-4c34-84f9-2716b0ccf7a9.jpeg",
        "hash": "UEEV?14nM|?b~qIAM{tRM|WV4nM|x^WAD%WW",
        "width": 1328,
        "height": 1944,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-26T19:50:44.964Z",
        "postId": 7038179,
        "stats": {
            "cryCount": 0,
            "laughCount": 8,
            "likeCount": 170,
            "dislikeCount": 0,
            "heartCount": 49,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 874126193277338,
            "Model": "FLUX1-Dev",
            "steps": 40,
            "hashes": {
                "model": "",
                "LORA:ARTifacts.safetensors": "d0a09d4c73",
                "LORA:Movie_Portrait.safetensors": "37a9de5a80",
                "LORA:m100-style_v.02.safetensors": "af2c80fbe0",
                "LORA:FluxMythP0rtr4itStyle.safetensors": "c12dbc5885",
                "LORA:frazetta_flux_v2-000150.safetensors": "ff6aa3c468",
                "LORA:FredFraiStyle-FLUX-Share.safetensors": "63bfaa1cf9",
                "LORA:- Flux1 - vanta_black_V1.0.safetensors": "fb86f1dc7a",
                "LORA:Warhammer_Rogue_Trader_Style_flux-000021.safetensors": "45b85de20e"
            },
            "prompt": "analog film photo . A towering, high-ranking BlackT40k hero stands amidst the devastation of battle, his face shadowed beneath a white hood adorned with intricate gold and black embellishments. A long, regal white cloak with matching gold-black detailing flows majestically behind him as he strides forward, the embodiment of warlike grace and power. In each hand, he wields a beautifully ornate katana, their polished blades catching the light with a razor-sharp gleam. The katanas' hilts are intricately carved, covered in ancient runes and sacred symbols, reflecting his unrivaled status and combat mastery. His face, shrouded in shadow beneath the hood, adds a mystique that enhances his commanding presence. The scene, captured in a hyper-realistic, photographic style, features heroic backlighting, casting him in a near-holy glow. The radiant light from the horizon illuminates the billowing cloak and his armor, with the faint embers of the battlefield framing the figure. Shot from a low angle, the composition glorifies his power and authority, while the contrast of light and shadow intensifies the awe-inspiring aura surrounding him. . grimdark, mythp0rt, FredFraiStyle <lora:- Flux1 - vanta_black_V1.0.safetensors:0.5>,  <lora:FluxMythP0rtr4itStyle.safetensors:0.76>,  <lora:FredFraiStyle-FLUX-Share.safetensors:0.75>,  <lora:Warhammer_Rogue_Trader_Style_flux-000021.safetensors:0.5>,   <lora:ARTifacts.safetensors:0.5>,  <lora:Movie_Portrait.safetensors:0.5>,  <lora:m100-style_v.02.safetensors:0.25>,  <lora:frazetta_flux_v2-000150.safetensors:0.5>,   . faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage",
            "Version": "ComfyUI",
            "sampler": "DPM++ 2M",
            "cfgScale": 3.5,
            "resources": [
                {
                    "name": "FluxMythP0rtr4itStyle.safetensors",
                    "type": "lora",
                    "weight": 0.76
                },
                {
                    "name": "FredFraiStyle-FLUX-Share.safetensors",
                    "type": "lora",
                    "weight": 0.75
                },
                {
                    "name": "Warhammer_Rogue_Trader_Style_flux-000021.safetensors",
                    "type": "lora",
                    "weight": 0.5
                },
                {
                    "name": "ARTifacts.safetensors",
                    "type": "lora",
                    "weight": 0.5
                },
                {
                    "name": "Movie_Portrait.safetensors",
                    "type": "lora",
                    "weight": 0.5
                },
                {
                    "name": "m100-style_v.02.safetensors",
                    "type": "lora",
                    "weight": 0.25
                },
                {
                    "name": "frazetta_flux_v2-000150.safetensors",
                    "type": "lora",
                    "weight": 0.5
                }
            ],
            "Model hash": ""
        },
        "username": "zidius",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 30751590,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1ce55d2f-22c5-4c30-9d46-6ca3e458a53b/width=832/1ce55d2f-22c5-4c30-9d46-6ca3e458a53b.jpeg",
        "hash": "UaGlko_NozIU_N%MxuRQaeVsbbWBt8M{WCt7",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-22T13:15:27.854Z",
        "postId": 6878131,
        "stats": {
            "cryCount": 5,
            "laughCount": 2,
            "likeCount": 175,
            "dislikeCount": 0,
            "heartCount": 44,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3287048284,
            "steps": 24,
            "prompt": "Colour film 35mm 1976, rule of thirds, right, down, monster:0.5 (close-up, portrait of bizarre robotic organism in robe, dark dystopian desert landscape), a giant futuristic building in rock city in the background, liminal space, fog",
            "sampler": "Euler a",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-19T0240:10.3168553Z",
            "negativePrompt": "half head, chopped head, yellow skin, pubic hair, discolored labia, blurred eyes, badly drawn eyes, worst quality eyes, (worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 293240,
                    "modelVersionName": "v3.0 VAE"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 5637,
                    "modelVersionName": "V1 75T"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 95263,
                    "modelVersionName": "epiCNegative"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 166373,
                    "modelVersionName": "General_Neg1 (AC)"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 167891,
                    "modelVersionName": "Variant 1 (Maja)"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 220262,
                    "modelVersionName": "epiCPhoto"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 240247,
                    "modelVersionName": "v0.8"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 294259,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 649266,
                    "modelVersionName": "Canon-EOS-R5"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "OrlandoOrso",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 30721950,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e69de522-6a61-45b8-8904-a6e0919cafb5/width=832/e69de522-6a61-45b8-8904-a6e0919cafb5.jpeg",
        "hash": "UgFNMm}ut8WFAaJVxHxF-B$*soWXr@enWBWX",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-22T09:13:22.001Z",
        "postId": 6871953,
        "stats": {
            "cryCount": 12,
            "laughCount": 24,
            "likeCount": 140,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 260556699,
            "steps": 4,
            "prompt": "digital art, young korean woman with a neon board with text \"hugs for buzz\", cute, night club, neon, darkness, beautiful, tattoos, kawaii, perfect face, shy smile, bunny ears",
            "sampler": "Undefined",
            "cfgScale": 1,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-22T0910:06.9237357Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 699279,
                    "modelVersionName": "Schnell"
                }
            ]
        },
        "username": "FemboyAttack",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 29765382,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/45c1d7cc-3987-49a2-aa5d-cacb9d6ffa95/width=832/45c1d7cc-3987-49a2-aa5d-cacb9d6ffa95.jpeg",
        "hash": "UA9tMqoI?F-.~oozZ~xuR,of9HM|bcjYNeRj",
        "width": 832,
        "height": 1296,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-16T20:49:23.798Z",
        "postId": 6660455,
        "stats": {
            "cryCount": 3,
            "laughCount": 13,
            "likeCount": 161,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1296",
            "seed": 2313945068,
            "Model": "flux1-dev-fp8",
            "steps": 20,
            "hashes": {
                "model": "275ef623d3",
                "lora:- Flux1 - soothing_atmo_V2.0": "6cb3ee7d0ffb"
            },
            "prompt": "a human toothy smiling while wearing a mechanical costume, <lora:- Flux1 - soothing_atmo_V2.0:.8>",
            "Version": "f2.0.1v1.10.1-previous-531-g210af4f8",
            "sampler": "Euler",
            "Module 1": "ae",
            "Module 2": "clip_l",
            "Module 3": "t5xxl_fp8_e4m3fn",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "6cb3ee7d0ffb",
                    "name": "- Flux1 - soothing_atmo_V2.0",
                    "type": "lora"
                },
                {
                    "hash": "275ef623d3",
                    "name": "flux1-dev-fp8",
                    "type": "model"
                }
            ],
            "Model hash": "275ef623d3",
            "Schedule type": "Simple",
            "Distilled CFG Scale": "3.5",
            "Style Selector Style": "base",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)",
            "Style Selector Enabled": "True",
            "Style Selector Randomize": "False"
        },
        "username": "TijuanaSlumlord",
        "baseModel": null
    },
    {
        "id": 29715545,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7e09a2d7-9b23-4aa7-87d4-e5c866d15cd3/width=832/7e09a2d7-9b23-4aa7-87d4-e5c866d15cd3.jpeg",
        "hash": "UCF}~300_3D%~B9FN{%29uIpNH-p_NIUM{R-",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-16T13:07:52.596Z",
        "postId": 6648806,
        "stats": {
            "cryCount": 9,
            "laughCount": 16,
            "likeCount": 133,
            "dislikeCount": 0,
            "heartCount": 68,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 443829371,
            "extra": {
                "remixOfId": 29691097
            },
            "steps": 15,
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, 1girl, pale skin, milf, mature woman, hair swept back, high ponytail hairstyle, blonde hair, eyeliner, half-closed eyes, white button-up business shirt, high collar, medium perky breasts,  white bedroom background, warm sunlight through window, depth of field, blurry background, blush, hot red lipstick, blue eyes, sexy smirk, black eyeshadow, gradient eyes, mid shot, slight low angle",
            "sampler": "DPM2 a",
            "cfgScale": 3,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-16T1306:42.2636732Z",
            "negativePrompt": "core_6, score_5, score_4, worst quality, low quality, text, censored, deformed, bad hand, blurry, (watermark), extra hands, washed out colors, (((plain background))), naked, exposed breasts",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 290640,
                    "modelVersionName": "V6 (start with this one)"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208,
                    "modelVersionName": "EasyNegative"
                },
                {
                    "type": "lora",
                    "weight": 0.45,
                    "modelVersionId": 382152,
                    "modelVersionName": "ExpressiveH"
                },
                {
                    "type": "lora",
                    "weight": 0.35,
                    "modelVersionId": 398847,
                    "modelVersionName": "gothic neon v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 436219,
                    "modelVersionName": "v3.0 (PonyXL Edition)"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250708,
                    "modelVersionName": "safe_pos"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250712,
                    "modelVersionName": "safe_neg"
                }
            ]
        },
        "username": "teddy19",
        "baseModel": "Pony"
    },
    {
        "id": 29372006,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/992cb273-b855-4d0a-b43a-099818dcec93/width=768/992cb273-b855-4d0a-b43a-099818dcec93.jpeg",
        "hash": "UNK1,sMc5P9Z%jD%I]ozD+xut5S4x^%3W.s:",
        "width": 768,
        "height": 1216,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-09-14T11:17:47.022Z",
        "postId": 6571677,
        "stats": {
            "cryCount": 1,
            "laughCount": 7,
            "likeCount": 157,
            "dislikeCount": 0,
            "heartCount": 61,
            "commentCount": 0
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "768x1216",
            "seed": 3171412869,
            "Model": "xlsusjelomixPony_v10",
            "steps": 25,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "89fa3f3b51",
                "lora:frieren": "70c095719467"
            },
            "prompt": "score_9,score_8_up,score_7_up masterpiece,best quality BREAK <lora:frieren:1>,frierenSDXL,1girl,solo,long hair,l skirt,shirt,long sleeves,dress,twintails,jewelry,green eyes,black belt,white hair,pantyhose,cowboy shot,earrings,outdoors,pointy ears,striped,parted bangs,black pantyhose,capelet,white skirt,elf,striped shirt,white capelet,landscape,from behind,looking back, ass focus,",
            "Version": "f0.0.17v1.8.0rc-latest-274-ge48533bd",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "70c095719467",
                    "name": "frieren",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "89fa3f3b51",
                    "name": "xlsusjelomixPony_v10",
                    "type": "model"
                }
            ],
            "Model hash": "89fa3f3b51",
            "negativePrompt": "monochrome,patreon logo,",
            "ADetailer model": "Anzhc Face seg 640 v2 y8n.pt",
            "ADetailer prompt": {},
            "ADetailer version": "24.6.0",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.35",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "Marlosart",
        "baseModel": "Pony"
    },
    {
        "id": 9327578,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/404d347f-8c95-49f0-be6b-13c9de59f3e9/width=832/404d347f-8c95-49f0-be6b-13c9de59f3e9.jpeg",
        "hash": "UNEW5H~So#E5?^?E%1WY4poJslxsH?E4M|o0",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-07T03:24:07.832Z",
        "postId": 2017357,
        "stats": {
            "cryCount": 2,
            "laughCount": 7,
            "likeCount": 160,
            "dislikeCount": 0,
            "heartCount": 67,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1256672390,
            "steps": 50,
            "prompt": "((masterpiece, best quality, high quality, highres, ultra-detailed)),  ,a moving train <lora:soldart:0.6> <lora:AngelicAI:0.1> <lora:add_detail:1>,, against the background of the a moving train, blue sky, sunny day, epic clouds, (oil painting:0.1),  (best quality, 8K, high resolution, extreme detail, outstanding composition:1.4), art by Jeremy Mann, god rays, dramatic light,   (oxygen-rich air and sheltered atmosphere, , aesthetic of hard - edge painting:0.1),",
            "sampler": "DPM++ 2M",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "name": "soldart",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "name": "AngelicAI",
                    "type": "lora",
                    "weight": 0.1
                },
                {
                    "name": "add_detail",
                    "type": "lora",
                    "weight": 1
                }
            ],
            "negativePrompt": "((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, bad anatomy, large breasts, red eyes, muscular, low quality,medium quality, 3d,frame,bw,watermark,logo,((letters)),paint,draw,(text),(worst quality:2), (low quality:2), (normal quality:2), lowres, bad anatomy, bad hands, normal quality, ((monochrome)), ((grayscale)),",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 348913
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 42247
                }
            ]
        },
        "username": "EBYGRALE",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 8417636,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4e8ef5e6-e31b-4910-b416-affdca200eed/width=1416/4e8ef5e6-e31b-4910-b416-affdca200eed.jpeg",
        "hash": "U4DJ3U%M00n5*JaK4pIo00M{McR.~oX4Hqro",
        "width": 1416,
        "height": 2064,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-03-23T09:39:07.970Z",
        "postId": 1821101,
        "stats": {
            "cryCount": 0,
            "laughCount": 8,
            "likeCount": 116,
            "dislikeCount": 0,
            "heartCount": 112,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 525035978,
            "steps": 30,
            "hashes": {
                "model": "67ab2fd8ec",
                "LORA:sdxl\\Concept Art Twilight Style SDXL_LoRA_Pony Diffusion V6 XL": "2d9ee3fc65"
            },
            "prompt": "score_9, score_8_up, score_7_up,   1girl, blonde hair, long hair, mid parted hair, from front, green eyes, (red kimono), fantasy, purple theme, black theme, delicate and smooth skin, highly detailed, hand on chest, abstract purple flowers, a puzzling chaotic mandala of purple flowers on a simple black backdrop  <lora:sdxl\\Concept Art Twilight Style SDXL_LoRA_Pony Diffusion V6 XL:0.8>",
            "sampler": "Euler a Karras",
            "cfgScale": 7,
            "resources": [],
            "Model hash": "67ab2fd8ec",
            "negativePrompt": "score_6, score_5, score_4, pubic hair, pony, gaping, muscular, makeup, censored, furry, child, kid, chibi, teen, 3d, source_anime",
            "ponyDiffusionV6XL_v6StartWithThisOne Version": "ComfyUI"
        },
        "username": "NickAI",
        "baseModel": "Pony"
    },
    {
        "id": 6248970,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/34c23ed1-9793-47b3-9d68-52c0761fa555/width=768/34c23ed1-9793-47b3-9d68-52c0761fa555.jpeg",
        "hash": "U7B|1*Hr040LL2Di^+4.Y;RoyA=_00_4I9%2",
        "width": 768,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-04T14:08:00.344Z",
        "postId": 1351801,
        "stats": {
            "cryCount": 1,
            "laughCount": 8,
            "likeCount": 133,
            "dislikeCount": 0,
            "heartCount": 94,
            "commentCount": 1
        },
        "meta": {
            "VAE": "vaeFtMse840000Ema_v10.safetensors",
            "Size": "512x768",
            "seed": 5,
            "LowRA": "0dfc93870ba3",
            "Model": "kirit0vision_V106",
            "steps": 25,
            "hashes": {
                "vae": "735e4c3a44",
                "model": "6327ed5fe1",
                "lora:LowRA": "348071db54",
                "embed:BadDream": "758aac4435",
                "lora:GothicCv2": "81c2e476b3",
                "embed:badhandv4": "5e40d722fc",
                "embed:abby_d0ws3": "adf8fee773",
                "embed:easynegative": "c74b4e810b",
                "embed:Asian-Less-Neg": "22d2f003e7",
                "embed:ng_deepnegative_v1_75t": "54e7e4826d",
                "lora:HeadphonesWithCatearsV2": "94f9dcd061",
                "lora:emotion_happy_slider_v1": "7a6b61a3bd"
            },
            "prompt": "(dim lit:1) <lora:weight_slider_v2:-0.9> , <lora:LowRA:0.6> , ( sweat, blush:1), (at night:1),\n<lora:GothicCv2:0.8> (GothicC:1.1), half buzzcut hairstyle, black hair, (tattoos:1.4), (ponytail, bangs, high ponytail:1.1), (inside a techno punk studio, listening to music:1.3), (wearing large headphones), (sitting listening to music:1.3), (glowing red light:1.4), (sensual, sexy, seductive, erotic, nsfw), <lora:HeadphonesWithCatearsV2:1> (incrsheadphones:1.3),(blushing:1.5), (abby_d0ws3:1.2) <lora:emotion_happy_slider_v1:2.8>, (30-year- old norwegian beautiful slender petite woman supermodel),(wide jaw sharp jawline),(long wavy thick blonde hair), (perfect oval large eyes that gazes at the viewer), beautiful detailed face, blue gorgeous perfect eyes, (blonde hair ponytail), (attractive young woman:1.3), (thick amazing hair), (seductive:1.1), (blushing:1.1)",
            "Version": "v1.6.0",
            "sampler": "DPM++ 2M Karras",
            "BadDream": "758aac443515",
            "VAE hash": "735e4c3a44",
            "cfgScale": 7,
            "clipSkip": 2,
            "GothicCv2": "ba08492c5002",
            "Pad conds": "True",
            "resources": [
                {
                    "name": "LowRA",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "name": "GothicCv2",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "name": "HeadphonesWithCatearsV2",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "name": "emotion_happy_slider_v1",
                    "type": "lora",
                    "weight": 2.8
                },
                {
                    "hash": "6327ed5fe1",
                    "name": "kirit0vision_V106",
                    "type": "model"
                }
            ],
            "\"badhandv4": "5e40d722fc3d",
            "Model hash": "6327ed5fe1",
            "Hires steps": "10",
            "easynegative": "c74b4e810b03",
            "Hires upscale": "1.5",
            "Asian-Less-Neg": "22d2f003e76f\"",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "(worst quality, low quality, normal quality:2), gloves,window, clothes,horse ears, ears, animal ears, , badhandv4, , (tattoos:1.3), (metal collar), (tongue out:1.5), BadDream, easynegative, badhandv4,  NegfeetV2,  ng_deepnegative_v1_75t, underwater, Asian-Less-Neg, childish, child, kid",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer prompt": "\"seductive,\"",
            "Face restoration": "CodeFormer",
            "\"weight_slider_v2": "296d2c26f900",
            "ADetailer version": "24.1.2",
            "Denoising strength": "0.15",
            "ADetailer mask blur": "4",
            "ADetailer model 2nd": "mediapipe_face_mesh_eyes_only",
            "Token merging ratio": "0.6",
            "ADetailer confidence": "0.3",
            "ADetailer prompt 2nd": "\"perfect eyes",
            "ADetailer dilate erode": "4",
            "Token merging ratio hr": "0.6",
            "ng_deepnegative_v1_75t": "54e7e4826d53",
            "ADetailer mask blur 2nd": "4",
            "HeadphonesWithCatearsV2": "6c1558f4bd21",
            "emotion_happy_slider_v1": "35b68a861865\"",
            "ADetailer confidence 2nd": "0.3",
            "ADetailer inpaint padding": "32",
            "ADetailer dilate erode 2nd": "4",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True",
            "ADetailer inpaint padding 2nd": "32",
            "ADetailer denoising strength 2nd": "0.4",
            "ADetailer inpaint only masked 2nd": "True"
        },
        "username": "Lady_Valeria",
        "baseModel": "SD 1.5"
    },
    {
        "id": 6194936,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/28b74221-1a80-4f7d-8bce-ed92b138a6cf/width=1120/28b74221-1a80-4f7d-8bce-ed92b138a6cf.jpeg",
        "hash": "UACZUmt603fP}8ayBpkCIFWC9HV[%|oeH@ae",
        "width": 1120,
        "height": 1680,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-03T00:30:12.302Z",
        "postId": 1340234,
        "stats": {
            "cryCount": 1,
            "laughCount": 15,
            "likeCount": 148,
            "dislikeCount": 0,
            "heartCount": 72,
            "commentCount": 0
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "640x960",
            "seed": 1644372481,
            "Model": "ultraspiceXLTURBO_v10",
            "steps": 10,
            "hashes": {
                "vae": "235745af8d",
                "model": "f24c75eaba",
                "lora:more_art": "15e31fe2b6",
                "lora:aesthetic": "1484fb726d",
                "lora:attractive": "6ced1bb73a",
                "lora:RMSDXL_Photo": "4bdd54952a",
                "lora:perfect_eyes": "f248364cf0",
                "lora:XDetail_heavy": "5621c1a2f5",
                "lora:perfect_hands": "6bf36964d8",
                "lora:RMSDXL_Enhance": "cdcab446f3",
                "lora:great_lighting": "1b816b11f0",
                "lora:RMSDXL_Creative": "a43f8c4670",
                "lora:clothing_slider": "084426d444",
                "lora:huge_anime_eyes": "a6a6d1b4cf",
                "lora:looking_at_viewer": "b0f2bc8342",
                "lora:RMSDXL_Darkness_Cinema": "aeb5174b53",
                "lora:photorealistic_portrait": "93330564f0"
            },
            "prompt": "by Andy Kehoe and Reylia Slaby in the style of Gediminas Pranckevicius  <lora:more_art:0.20><lora:huge_anime_eyes:0.85><lora:attractive:0.75><lora:great_lighting:1.00><lora:aesthetic:0.85><lora:photorealistic_portrait:0.85><lora:clothing_slider:1.00><lora:RMSDXL_Enhance:0.45><lora:RMSDXL_Creative:0.35><lora:RMSDXL_Photo:0.45><lora:RMSDXL_Darkness_Cinema:0.50><lora:XDetail_heavy:0.45><lora:perfect_eyes:0.15><lora:perfect_hands:0.15><lora:midjourney:-0.15><lora:looking_at_viewer:0.75>",
            "sampler": "DPM++ SDE Karras",
            "VAE hash": "235745af8d",
            "cfgScale": 3,
            "\"more_art": "fe3b4816be83",
            "aesthetic": "03c577eda4d1",
            "resources": [
                {
                    "name": "more_art",
                    "type": "lora",
                    "weight": 0.2
                },
                {
                    "name": "huge_anime_eyes",
                    "type": "lora",
                    "weight": 0.85
                },
                {
                    "name": "attractive",
                    "type": "lora",
                    "weight": 0.75
                },
                {
                    "name": "great_lighting",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "name": "aesthetic",
                    "type": "lora",
                    "weight": 0.85
                },
                {
                    "name": "photorealistic_portrait",
                    "type": "lora",
                    "weight": 0.85
                },
                {
                    "name": "clothing_slider",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "name": "RMSDXL_Enhance",
                    "type": "lora",
                    "weight": 0.45
                },
                {
                    "name": "RMSDXL_Creative",
                    "type": "lora",
                    "weight": 0.35
                },
                {
                    "name": "RMSDXL_Photo",
                    "type": "lora",
                    "weight": 0.45
                },
                {
                    "name": "RMSDXL_Darkness_Cinema",
                    "type": "lora",
                    "weight": 0.5
                },
                {
                    "name": "XDetail_heavy",
                    "type": "lora",
                    "weight": 0.45
                },
                {
                    "name": "perfect_eyes",
                    "type": "lora",
                    "weight": 0.15
                },
                {
                    "name": "perfect_hands",
                    "type": "lora",
                    "weight": 0.15
                },
                {
                    "name": "looking_at_viewer",
                    "type": "lora",
                    "weight": 0.75
                },
                {
                    "hash": "f24c75eaba",
                    "name": "ultraspiceXLTURBO_v10",
                    "type": "model"
                }
            ],
            "Model hash": "f24c75eaba",
            "attractive": "d64efd941dfd",
            "midjourney": "000c96b6bd08",
            "Hires steps": "6",
            "RMSDXL_Photo": "a4afcfe7c196",
            "perfect_eyes": "8167a8057946",
            "Hires upscale": "1.75",
            "XDetail_heavy": "a27a7b65839e",
            "perfect_hands": "8448755682f7",
            "Hires upscaler": "4x-UltraSharp",
            "RMSDXL_Enhance": "79fda7f6861b",
            "great_lighting": "068399395bb8",
            "negativePrompt": "poorly drawn, deviantart, mess, low quality, blurry, doll, painted face",
            "normal quality": "2.0), Unspeakable-Horrors-Composition-4v, deepnegative_v1_75t, BadDream\"",
            "ADetailer model": "face_yolov8n.pt",
            "RMSDXL_Creative": "ed00d3159d3b",
            "clothing_slider": "f9f94186f06b",
            "huge_anime_eyes": "5c3598cf495f",
            "ADetailer prompt": "\"__prompt__ __detailer/face__ [SEP]\\n__prompt__ __blank__ __detailer/face__[SEP]\\n__prompt__ __blank__ __blank__ __detailer/face__[SEP]\\n__prompt__ __blank__ __blank__ __blank__ __detailer/face__[SEP]\\n__prompt__ __blank__ __blank__ __blank__ __blank__ __detailer/face__\"",
            "ADetailer VAE 3rd": "vae-ft-mse-840000-ema-pruned.ckpt",
            "ADetailer version": "24.1.1",
            "Negative Template": "\"poorly drawn, deviantart, mess, low quality, blurry, doll, painted face\"",
            "looking_at_viewer": "0.75>\"",
            "Denoising strength": "0.5",
            "ADetailer mask blur": "12",
            "ADetailer model 2nd": "hand_yolov8n.pt",
            "ADetailer model 3rd": "female_breast_v3.2.pt",
            "ADetailer steps 3rd": "20",
            "ADetailer checkpoint": "realvisxlV30Turbo_v30TurboBakedvae.safetensors",
            "ADetailer confidence": "0.5",
            "ADetailer prompt 2nd": "__prompt__ __detailer/hands__",
            "ADetailer prompt 3rd": "__prompt__ __detailer/breasts__",
            "ADetailer sampler 3rd": "DPM++ 2M Karras",
            "ADetailer dilate erode": "12",
            "RMSDXL_Darkness_Cinema": "246490f20190",
            "ADetailer CFG scale 3rd": "7.0",
            "ADetailer inpaint width": "1024",
            "ADetailer mask blur 2nd": "12",
            "ADetailer mask blur 3rd": "24",
            "photorealistic_portrait": "bd4aed2bf93f",
            "ADetailer checkpoint 3rd": "wafflemix7.safetensors [4844f773bb]",
            "ADetailer confidence 2nd": "0.5",
            "ADetailer confidence 3rd": "0.5",
            "ADetailer inpaint height": "1024",
            "ADetailer mask min ratio": "0.001",
            "ADetailer inpaint padding": "256",
            "ADetailer dilate erode 2nd": "12",
            "ADetailer dilate erode 3rd": "24",
            "ADetailer inpaint width 2nd": "896",
            "ADetailer inpaint width 3rd": "768",
            "ADetailer denoising strength": "0.5",
            "ADetailer inpaint height 2nd": "896",
            "ADetailer inpaint height 3rd": "768",
            "ADetailer mask min ratio 2nd": "0.001",
            "ADetailer mask min ratio 3rd": "0.001",
            "ADetailer inpaint only masked": "True",
            "ADetailer inpaint padding 2nd": "256",
            "ADetailer inpaint padding 3rd": "256",
            "ADetailer negative prompt 3rd": "\"cartoon, painting, illustration, (worst quality, low quality",
            "ADetailer use separate VAE 3rd": "True",
            "ADetailer denoising strength 2nd": "0.4",
            "ADetailer denoising strength 3rd": "0.5",
            "ADetailer use separate steps 3rd": "True",
            "ADetailer inpaint only masked 2nd": "True",
            "ADetailer inpaint only masked 3rd": "True",
            "ADetailer mask only top k largest": "5",
            "ADetailer use separate checkpoint": "True",
            "ADetailer use inpaint width height": "True",
            "ADetailer use separate sampler 3rd": "True",
            "ADetailer use separate CFG scale 3rd": "True",
            "ADetailer mask only top k largest 2nd": "6",
            "ADetailer mask only top k largest 3rd": "4",
            "ADetailer use separate checkpoint 3rd": "True",
            "ADetailer use inpaint width height 2nd": "True",
            "ADetailer use inpaint width height 3rd": "True"
        },
        "username": "LordTerror",
        "baseModel": "SDXL Turbo"
    },
    {
        "id": 4696507,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/de01461a-57b6-4e82-8075-a5732a1f2f84/width=768/de01461a-57b6-4e82-8075-a5732a1f2f84.jpeg",
        "hash": "UOID?P%LxtRR}sOFE3NL0gSgobxt1PnOtPXR",
        "width": 768,
        "height": 1344,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-12-18T22:43:01.642Z",
        "postId": 1023229,
        "stats": {
            "cryCount": 0,
            "laughCount": 86,
            "likeCount": 98,
            "dislikeCount": 0,
            "heartCount": 52,
            "commentCount": 2
        },
        "meta": {
            "Size": "768x1344",
            "seed": 1298105953,
            "Model": "juggernautXL_version6Rundiffusion",
            "steps": 107,
            "hashes": {
                "model": "1fe6c7ec54"
            },
            "prompt": "detailed, in the style of Edvard Munch, a painting of (((gift box falling from the sky))), \nAND, \na man  with a woman  screaming, the scream painting, surreal oil painting, surreal painting, epic surrealism 8k oil painting, <lora:FF-Style-Edvard-Munch-vpred:1>,",
            "RP Flip": "False",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7.5,
            "RP Active": "True",
            "RP Ratios": "\"1,1\"",
            "resources": [
                {
                    "hash": "1fe6c7ec54",
                    "name": "juggernautXL_version6Rundiffusion",
                    "type": "model"
                }
            ],
            "Model hash": "1fe6c7ec54",
            "RP Options": "[False]",
            "RP Use Base": "False",
            "RP Calc Mode": "Attention",
            "RP threshold": "0.4",
            "RP Use Common": "False",
            "RP Base Ratios": "0.2",
            "RP Divide mode": "Matrix",
            "RP Use Ncommon": "False",
            "negativePrompt": "text, logo, watermark, deformed eyes, extra fingers, mutated hands, poorly drawn eyes, ((poorly drawn hands)), ((poorly drawn face)), (((mutation))), ((bad anatomy)), (((bad proportions))),",
            "RP Mask submode": "Mask",
            "RP LoRA Stop Step": "0",
            "RP Matrix submode": "Rows",
            "RP Prompt submode": "Prompt",
            "RP LoRA Neg U Ratios": "0",
            "Style Selector Style": "base",
            "RP LoRA Neg Te Ratios": "0",
            "Style Selector Enabled": "True",
            "RP LoRA Hires Stop Step": "0",
            "Style Selector Randomize": "False",
            "\"FF-Style-Edvard-Munch-vpred": "e20741e3d2c8\""
        },
        "username": "MagisterVerborum",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 4586014,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/211d7138-9b56-47b7-889a-0cf41b612327/width=832/211d7138-9b56-47b7-889a-0cf41b612327.jpeg",
        "hash": "UEAwJ3%1ELNI00R+VsV@_Ns:$Njb9FRjS$oz",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-12-14T20:10:26.558Z",
        "postId": 1000371,
        "stats": {
            "cryCount": 6,
            "laughCount": 13,
            "likeCount": 143,
            "dislikeCount": 0,
            "heartCount": 74,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1431206019,
            "steps": 50,
            "prompt": "universe, aesthetics of cosmic motifs, art Research, use, symbolism of space, planet in various artistic directions, centered spase ship-reindeer with red Christmas tree",
            "sampler": "Euler",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "(deformed iris, deformed pupils), text, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, (extra fingers), (mutated hands), poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, (fused fingers), (too many fingers), long neck, camera",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 235598
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 94057
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 6056
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 135867
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 98441
                }
            ]
        },
        "username": "akovanew",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 3804963,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/10a41559-a735-47f3-a976-7527f47a445d/width=680/10a41559-a735-47f3-a976-7527f47a445d.jpeg",
        "hash": "UNH_uu^*R%?b?aM|I9WX=w9Z9FtR~VRkI=xu",
        "width": 680,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-11-21T15:03:24.845Z",
        "postId": 858256,
        "stats": {
            "cryCount": 0,
            "laughCount": 43,
            "likeCount": 123,
            "dislikeCount": 0,
            "heartCount": 70,
            "commentCount": 0
        },
        "meta": {
            "Size": "680x1024",
            "seed": 1555871997,
            "Model": "SDXL_juggernautXL_version6Rundiffusion",
            "steps": 44,
            "hashes": {
                "model": "1fe6c7ec54"
            },
            "prompt": "photograph head  portrait of blue fluffy fur Cookie monster holding a bitten off cookie,, looks with a grin at viewer, (lot of cookie crumbled ), detailed photograph shot on kodak, high depth of field, background of a street (metallic rubbish bin)",
            "Version": "v1.6.0-2-g4afaaf8a",
            "sampler": "DPM++ 3M SDE Karras",
            "cfgScale": 5.5,
            "resources": [
                {
                    "hash": "1fe6c7ec54",
                    "name": "SDXL_juggernautXL_version6Rundiffusion",
                    "type": "model"
                }
            ],
            "Model hash": "1fe6c7ec54",
            "negativePrompt": "painting, drawing, sketch, cartoon, anime, manga, render, watermark, signature, label, bw, monochrome, jewellry,"
        },
        "username": "sevenof9247",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 1917136,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/270b159f-d91b-424b-8ac6-14857726f1f1/width=1800/270b159f-d91b-424b-8ac6-14857726f1f1.jpeg",
        "hash": "UjHBSroJays._4oJazs.?cWDayWXpJa}oLWX",
        "width": 2698,
        "height": 1158,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-08-07T14:55:02.627Z",
        "postId": 471994,
        "stats": {
            "cryCount": 4,
            "laughCount": 13,
            "likeCount": 144,
            "dislikeCount": 0,
            "heartCount": 75,
            "commentCount": 0
        },
        "meta": {
            "Size": "896x1024",
            "seed": 4138801743,
            "Model": "dreamshaperXL10_alpha2Xl10",
            "steps": 20,
            "Script": "X/Y/Z plot",
            "X Type": "Prompt S/R",
            "hashes": {
                "model": "82b5f664ae"
            },
            "prompt": "anime, road, mountains, sunset, village, <lora:add-detail-xl:-1.5>",
            "Version": "v1.5.1",
            "sampler": "DPM++ SDE Karras",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "82b5f664ae",
                    "name": "dreamshaperXL10_alpha2Xl10",
                    "type": "model"
                }
            ],
            "Model hash": "82b5f664ae",
            "add-detail-xl": "1.5>\"",
            "\"add-detail-xl": "9c783c8ce46c\""
        },
        "username": "w4r10ck",
        "baseModel": null
    },
    {
        "id": 1831238,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/330de17a-b370-48b9-a237-efefc42c02ef/width=1024/330de17a-b370-48b9-a237-efefc42c02ef.jpeg",
        "hash": "U89t48~q9uIUtRa~s8WB4oD%RjoewIM{Ips:",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-11T05:35:32.714Z",
        "postId": 453431,
        "stats": {
            "cryCount": 0,
            "laughCount": 50,
            "likeCount": 134,
            "dislikeCount": 0,
            "heartCount": 52,
            "commentCount": 1
        },
        "meta": {
            "NGMS": "2",
            "Size": "1024x1024",
            "seed": 3975258235,
            "Model": "sd_xl_base_1.0",
            "steps": 15,
            "hashes": {
                "model": "31e35c80fc"
            },
            "prompt": "masterpice,high quaity,portrait,\n <lora:PE_PowerArmor:1> PEPowerArmor,\neating a turkey",
            "Version": "v1.5.1",
            "sampler": "Euler",
            "cfgScale": 7,
            "resources": [
                {
                    "name": "PE_PowerArmor",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "31e35c80fc",
                    "name": "sd_xl_base_1.0",
                    "type": "model"
                }
            ],
            "Model hash": "31e35c80fc",
            "\"PE_PowerArmor": "6e57d30433f2\"",
            "Token merging ratio": "0.5"
        },
        "username": "Proompt_Engineer",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 955446,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c173856e-0a10-4150-b83c-1c2eee692605/width=1280/c173856e-0a10-4150-b83c-1c2eee692605.jpeg",
        "hash": "UZN9:^RO_NoMJ7xu-VWBWUWAoKRkxuWBoet7",
        "width": 1280,
        "height": 1842,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-09T05:55:30.879Z",
        "postId": 252409,
        "stats": {
            "cryCount": 1,
            "laughCount": 5,
            "likeCount": 122,
            "dislikeCount": 0,
            "heartCount": 108,
            "commentCount": 4
        },
        "meta": null,
        "username": "Yuki_Hotaru",
        "baseModel": "SD 1.5"
    },
    {
        "id": 877458,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c0e0fdee-cbd0-47be-b6ee-4af3835c194c/width=864/c0e0fdee-cbd0-47be-b6ee-4af3835c194c.jpeg",
        "hash": "UJHLbx0K00~V~XRjVrR+%h9a%1WBx]R*aes:",
        "width": 864,
        "height": 1304,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-09T18:48:40.783Z",
        "postId": 234548,
        "stats": {
            "cryCount": 0,
            "laughCount": 1,
            "likeCount": 142,
            "dislikeCount": 0,
            "heartCount": 93,
            "commentCount": 9
        },
        "meta": {
            "ENSD": "31337",
            "Size": "512x768",
            "seed": 3488769169,
            "Model": "DreamShaper_6_BakedVae",
            "steps": 50,
            "hashes": {
                "model": "b76cc78ad9"
            },
            "prompt": "(8k, RAW photo, best quality, masterpiece:1.2), (realistic, photo-realistic:1.37), octane render, ultra high res, ultra-detailed , professional lighting, photon mapping, radiosity, physically-based rendering, ue5, ((island sanctuary)), ((ancient fallen kingdom)), ((reflections in water)), ((raytracing)), ((drowned city))",
            "sampler": "DPM++ SDE Karras",
            "cfgScale": 7,
            "Clip skip": "2",
            "resources": [
                {
                    "hash": "b76cc78ad9",
                    "name": "DreamShaper_6_BakedVae",
                    "type": "model"
                }
            ],
            "Model hash": "b76cc78ad9",
            "Hires steps": "25",
            "Hires upscale": "1.7",
            "Hires upscaler": "8x_NMKD-Superscale_150000_G",
            "negativePrompt": "BadDream UnrealisticDream",
            "Denoising strength": "0.5"
        },
        "username": "Lykon",
        "baseModel": "SD 1.5"
    },
    {
        "id": 667878,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1de1b4da-e9eb-43bf-9e9c-050e51cbbb25/width=1800/1de1b4da-e9eb-43bf-9e9c-050e51cbbb25.jpeg",
        "hash": "U{N0*lofkCt6~qofj[j[kWayj[WVayWBj[ay",
        "width": 2304,
        "height": 1450,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-08T22:24:34.957Z",
        "postId": 184267,
        "stats": {
            "cryCount": 2,
            "laughCount": 5,
            "likeCount": 152,
            "dislikeCount": 0,
            "heartCount": 78,
            "commentCount": 3
        },
        "meta": null,
        "username": "Nerfgun3",
        "baseModel": null
    },
    {
        "id": 539213,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f8718950-2a4c-4a5b-1df6-25fe07efde00/width=832/f8718950-2a4c-4a5b-1df6-25fe07efde00.jpeg",
        "hash": "U6GHVu-r00yExu0}0L}r=]54=@-W-D^P%L0f",
        "width": 832,
        "height": 1280,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2023-04-19T19:43:26.554Z",
        "postId": 154870,
        "stats": {
            "cryCount": 0,
            "laughCount": 0,
            "likeCount": 107,
            "dislikeCount": 0,
            "heartCount": 129,
            "commentCount": 8
        },
        "meta": {
            "Size": "512x768",
            "seed": 4146499890,
            "Model": "lyriel v1.5",
            "steps": 35,
            "hashes": {
                "model": "4d91c4c217"
            },
            "prompt": "shukezouma, octane render, hdr, (hyperdetailed:1.15), (soft light, sharp:1.2), 1girl, beautiful girl, ultra detailed eyes, mature, plump, thick, rainbow painting drops, paint teardrops, woman made up from paint, entirely paint, splat, splash, long colored hair, kimono made from paint, ultra detailed texture kimono, rainbow paint kimono, paint bulb, paint drops, (hair ornaments, earrings, flowers hair ornaments, butterflies hair ornaments), outdoors, sakura trees",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "4d91c4c217",
                    "name": "lyriel v1.5",
                    "type": "model"
                }
            ],
            "Model hash": "4d91c4c217",
            "Hires steps": "40",
            "Hires resize": "832x1280",
            "Hires upscaler": "Latent",
            "negativePrompt": "3d, cartoon, anime, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, bad anatomy, girl, loli, young, large breasts, red eyes, muscular, over saturated, over saturated, over saturated",
            "Denoising strength": "0.52"
        },
        "username": "civitai",
        "baseModel": "SD 1.5"
    },
    {
        "id": 40961202,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b11d3b68-2019-4bbf-a496-74ad552c7ae7/width=1024/b11d3b68-2019-4bbf-a496-74ad552c7ae7.jpeg",
        "hash": "U58q+tx?00Rk00Mz?b%LETwirFE1~Bs*9aIp",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-19T14:39:46.109Z",
        "postId": 9331734,
        "stats": {
            "cryCount": 15,
            "laughCount": 25,
            "likeCount": 143,
            "dislikeCount": 0,
            "heartCount": 52,
            "commentCount": 0
        },
        "meta": {
            "Size": "1024x1024",
            "seed": 1875448838,
            "steps": 25,
            "prompt": "A cute curious, small alien creature peers out from behind a lush fern in the dense, vibrant jungle, investigating where a spaceship wreckage lies half-submerged in the murky water. A distress beacon on the wreckage displays a warning message: 'Low Buzz'.",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-19T1412:07.6686168Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 922358,
                    "modelVersionName": "Pro 1.1"
                }
            ]
        },
        "username": "Alienwarek",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 40882250,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8d884cf1-77db-4362-bcf0-37b7e8f161ad/width=1024/8d884cf1-77db-4362-bcf0-37b7e8f161ad.jpeg",
        "hash": "U8A^8@t803OuAJs,%2Rk00M_}pv|^+R*E0so",
        "width": 1024,
        "height": 1536,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-19T03:23:52.060Z",
        "postId": 9314167,
        "stats": {
            "cryCount": 6,
            "laughCount": 22,
            "likeCount": 153,
            "dislikeCount": 0,
            "heartCount": 54,
            "commentCount": 1
        },
        "meta": {
            "Size": "1024x1536",
            "seed": 49716620241,
            "Model": "IL\\waiNSFWIllustrious_v70.safetensors",
            "steps": 20,
            "hashes": {
                "model": "04ba0dfcc1",
                "lora:USNR STYLE_XL_lokr": "67f65fb190",
                "lora:USNR_STYLE_XL_lokr": "67f65fb190",
                "lora:frostbitev2_Illu_dwnsty": "dc698bd10c",
                "lora:ponyv4_noob1_2_adamW-000017": "bf047b0dc0"
            },
            "prompt": "masterpiece, best quality, amazing quality, very aesthetic, absurdres, newest, dark and moody lighting, green and blue and brown, light hair but dark eyebrows, e-girl makeup, black choker, flirting, teasing, different poses, inset reaction shot, rich & seductive, erotic aesthetics, freckle,ceremonial, BREAK style by Yuumei,\nmesmerise celestial fireworks starry sky,floral atmosphere,vibrant godray effect on a realistic,hyperdetailed vibrant glowing petal,luminous foliage,dreamlike wonderland-garden naughty butterflies slutty inspired by Yuumei huge busy extremely detailed scene <lora:ponyv4_noob1_2_adamW-000017:0.7000000000000001> <lora:USNR_STYLE_XL_lokr:1> <lora:frostbitev2_Illu_dwnsty:0.45>",
            "sampler": "Euler a",
            "cfgScale": 5.5,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "bf047b0dc0",
                    "name": "ponyv4_noob1_2_adamW-000017",
                    "type": "lora",
                    "weight": 0.7000000000000001
                },
                {
                    "hash": "67f65fb190",
                    "name": "USNR_STYLE_XL_lokr",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "dc698bd10c",
                    "name": "frostbitev2_Illu_dwnsty",
                    "type": "lora",
                    "weight": 0.45
                },
                {
                    "hash": "04ba0dfcc1",
                    "name": "IL\\waiNSFWIllustrious_v70.safetensors",
                    "type": "model"
                }
            ],
            "Model hash": "04ba0dfcc1",
            "negativePrompt": "lowres,(bad quality,worst quality:1.2),\nbad anatomy,watermark, username"
        },
        "username": "openmn793",
        "baseModel": "Illustrious"
    },
    {
        "id": 40799575,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fe842295-9f1a-457a-bb00-cfd83068a84e/width=1024/fe842295-9f1a-457a-bb00-cfd83068a84e.jpeg",
        "hash": "UDCF99n+05kU}?o259W;^MazEPox9]ay$*j@",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-18T16:05:33.849Z",
        "postId": 9295109,
        "stats": {
            "cryCount": 0,
            "laughCount": 27,
            "likeCount": 161,
            "dislikeCount": 0,
            "heartCount": 47,
            "commentCount": 0
        },
        "meta": {
            "seed": 270646047433573,
            "vaes": [
                "FLUX.safetensors"
            ],
            "comfy": "{\"prompt\": {\"1\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5, \"width\": [\"19\", 1], \"height\": [\"19\", 2], \"model\": [\"11\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"2\": {\"inputs\": {\"text\": \"Buzz Lightyear bathed in yellow spotlights against inky black with glowing neon sign that read BUZZ. Swirling light trails mimic Alberto Seveso's ink-in-water photography, capturing Peter Coulson's dance dynamism.  EDM energy pulsates.  Q8, Q5, and Q4  shaped text accents.\\n\", \"clip\": [\"13\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"3\": {\"inputs\": {\"seed\": 270646047433573, \"steps\": 20, \"cfg\": 1.0, \"sampler_name\": \"dpmpp_2s_ancestral\", \"scheduler\": \"simple\", \"denoise\": 1.0, \"model\": [\"1\", 0], \"positive\": [\"7\", 0], \"negative\": [\"4\", 0], \"latent_image\": [\"5\", 0]}, \"class_type\": \"KSampler\"}, \"4\": {\"inputs\": {\"conditioning\": [\"7\", 0]}, \"class_type\": \"ConditioningZeroOut\"}, \"5\": {\"inputs\": {\"width\": [\"19\", 1], \"height\": [\"19\", 2], \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"7\": {\"inputs\": {\"guidance\": 3.4000000000000004, \"conditioning\": [\"2\", 0]}, \"class_type\": \"FluxGuidance\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX.safetensors\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"unet_name\": \"flux1-dev-Q8_0.gguf\"}, \"class_type\": \"UnetLoaderGGUF\"}, \"12\": {\"inputs\": {\"tile_size\": 320, \"samples\": [\"3\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecodeTiled\"}, \"13\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp16.safetensors\", \"clip_name2\": \"flux-clip-vit-large-patch14\\\\text_encoder\\\\flux-clip_vit_large_model.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoaderGGUF\"}, \"14\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"12\", 0]}, \"class_type\": \"SaveImage\"}, \"19\": {\"inputs\": {\"aspect_ratio\": \"1:1\", \"mp_size\": \"1\", \"upscale_by\": 2.0, \"mode\": \"FLUX\"}, \"class_type\": \"BobsFluxSDXLLatentNode\"}}, \"workflow\": {\"last_node_id\": 19, \"last_link_id\": 27, \"nodes\": [{\"id\": 2, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1580, \"1\": 286}, \"size\": {\"0\": 310, \"1\": 100}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 4, \"slot_index\": 0}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 22, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [11], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"Buzz Lightyear bathed in yellow spotlights against inky black with glowing neon sign that read BUZZ. Swirling light trails mimic Alberto Seveso's ink-in-water photography, capturing Peter Coulson's dance dynamism.  EDM energy pulsates.  Q8, Q5, and Q4  shaped text accents.\\n\"]}, {\"id\": 4, \"type\": \"ConditioningZeroOut\", \"pos\": {\"0\": 2003.3006591796875, \"1\": 350.12890625}, \"size\": {\"0\": 275.56280517578125, \"1\": 26}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 8}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [6], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningZeroOut\"}, \"widgets_values\": []}, {\"id\": 5, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 1949, \"1\": 485}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 26, \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 27, \"slot_index\": 1, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [7], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [512, 512, 1]}, {\"id\": 8, \"type\": \"Note\", \"pos\": {\"0\": 2022, \"1\": 90}, \"size\": {\"0\": 253.2170867919922, \"1\": 58}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"title\": \"Enable this For DEV model\", \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"For DEV model enable Guidance & increase steps to 20 or more \\n\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 9, \"type\": \"LoraLoader\", \"pos\": {\"0\": 1155, \"1\": 200}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 6, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 13}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 14}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [1], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [4], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"microx.safetensors\", 1, 1]}, {\"id\": 12, \"type\": \"VAEDecodeTiled\", \"pos\": {\"0\": 2986.300537109375, \"1\": 192.12890625}, \"size\": {\"0\": 315, \"1\": 78}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 12}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 20}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [17], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecodeTiled\"}, \"widgets_values\": [320]}, {\"id\": 15, \"type\": \"Reroute\", \"pos\": {\"0\": 1071.027099609375, \"1\": 890.8124389648438}, \"size\": [75, 26], \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 18}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [19], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 16, \"type\": \"Reroute\", \"pos\": {\"0\": 2984, \"1\": 891}, \"size\": [75, 26], \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 19}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [20], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 18, \"type\": \"Reroute\", \"pos\": {\"0\": 1441, \"1\": -13}, \"size\": [75, 26], \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 23, \"widget\": {\"name\": \"value\"}}], \"outputs\": [{\"name\": \"\", \"type\": \"STRING\", \"links\": [22], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 11, \"type\": \"UnetLoaderGGUF\", \"pos\": {\"0\": 670, \"1\": 170}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [13], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UnetLoaderGGUF\"}, \"widgets_values\": [\"flux1-dev-Q8_0.gguf\"]}, {\"id\": 13, \"type\": \"DualCLIPLoaderGGUF\", \"pos\": {\"0\": 666, \"1\": 301}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [14], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoaderGGUF\"}, \"widgets_values\": [\"t5xxl_fp16.safetensors\", \"flux-clip-vit-large-patch14\\\\text_encoder\\\\flux-clip_vit_large_model.safetensors\", \"flux\"]}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 672, \"1\": 503}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [18], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX.safetensors\"]}, {\"id\": 3, \"type\": \"KSampler\", \"pos\": {\"0\": 2413, \"1\": 217}, \"size\": {\"0\": 399.0461120605469, \"1\": 592.950927734375}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 16}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 5, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 6}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 7, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [12], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [270646047433573, \"fixed\", 20, 1, \"dpmpp_2s_ancestral\", \"simple\", 1]}, {\"id\": 17, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 655, \"1\": -15}, \"size\": [354.7385559082031, 122.5875015258789], \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [23], \"widget\": {\"name\": \"value\"}}], \"title\": \"ThePrompt\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [\"Buzz Lightyear bathed in yellow spotlights against inky black with glowing neon sign that read BUZZ. Swirling light trails mimic Alberto Seveso's ink-in-water photography, capturing Peter Coulson's dance dynamism.  EDM energy pulsates.  Q8, Q5, and Q4  shaped text accents.\\n\"]}, {\"id\": 1, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 1584, \"1\": 93}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 1}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 24, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 25, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [16], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 1024, 1024]}, {\"id\": 14, \"type\": \"SaveImage\", \"pos\": {\"0\": 3315, \"1\": -11}, \"size\": {\"0\": 945.4000244140625, \"1\": 984.5428466796875}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 17}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 19, \"type\": \"BobsFluxSDXLLatentNode\", \"pos\": {\"0\": 1343, \"1\": 551}, \"size\": {\"0\": 315, \"1\": 190}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"latent\", \"type\": \"LATENT\", \"links\": null}, {\"name\": \"tile_width\", \"type\": \"INT\", \"links\": [24, 26], \"slot_index\": 1}, {\"name\": \"tile_height\", \"type\": \"INT\", \"links\": [25, 27], \"slot_index\": 2}, {\"name\": \"upscale_by\", \"type\": \"FLOAT\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"BobsFluxSDXLLatentNode\"}, \"widgets_values\": [\"1:1\", \"1\", 2, \"FLUX\"]}, {\"id\": 7, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 1993, \"1\": 230}, \"size\": {\"0\": 291.9638977050781, \"1\": 58}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 11}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [5, 8], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.4000000000000004]}], \"links\": [[1, 9, 0, 1, 0, \"MODEL\"], [4, 9, 1, 2, 0, \"CLIP\"], [5, 7, 0, 3, 1, \"CONDITIONING\"], [6, 4, 0, 3, 2, \"CONDITIONING\"], [7, 5, 0, 3, 3, \"LATENT\"], [8, 7, 0, 4, 0, \"CONDITIONING\"], [11, 2, 0, 7, 0, \"CONDITIONING\"], [12, 3, 0, 12, 0, \"LATENT\"], [13, 11, 0, 9, 0, \"MODEL\"], [14, 13, 0, 9, 1, \"CLIP\"], [16, 1, 0, 3, 0, \"MODEL\"], [17, 12, 0, 14, 0, \"IMAGE\"], [18, 10, 0, 15, 0, \"*\"], [19, 15, 0, 16, 0, \"*\"], [20, 16, 0, 12, 1, \"VAE\"], [22, 18, 0, 2, 1, \"STRING\"], [23, 17, 0, 18, 0, \"*\"], [24, 19, 1, 1, 1, \"INT\"], [25, 19, 2, 1, 2, \"INT\"], [26, 19, 1, 5, 0, \"INT\"], [27, 19, 2, 5, 1, \"INT\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.1, \"offset\": [-1071.8874897272706, 55.09669290909128]}}, \"version\": 0.4}}",
            "steps": 20,
            "width": {
                "inputs": {
                    "mode": "FLUX",
                    "mp_size": "1",
                    "upscale_by": 2,
                    "aspect_ratio": "1:1"
                },
                "class_type": "BobsFluxSDXLLatentNode"
            },
            "height": {
                "inputs": {
                    "mode": "FLUX",
                    "mp_size": "1",
                    "upscale_by": 2,
                    "aspect_ratio": "1:1"
                },
                "class_type": "BobsFluxSDXLLatentNode"
            },
            "models": [],
            "prompt": "Buzz Lightyear bathed in yellow spotlights against inky black with glowing neon sign that read BUZZ. Swirling light trails mimic Alberto Seveso's ink-in-water photography, capturing Peter Coulson's dance dynamism.  EDM energy pulsates.  Q8, Q5, and Q4  shaped text accents.\n",
            "denoise": 1,
            "sampler": "DPM++ 2S a",
            "cfgScale": 1,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": []
        },
        "username": "mystifying",
        "baseModel": ""
    },
    {
        "id": 40779502,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3643300c-d196-4934-bf88-e342fee75cfa/width=832/3643300c-d196-4934-bf88-e342fee75cfa.jpeg",
        "hash": "U697Y100?vM{~VD%%MIUxuIU%fIV-:IAtRR*",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-18T13:31:18.099Z",
        "postId": 9290582,
        "stats": {
            "cryCount": 10,
            "laughCount": 27,
            "likeCount": 148,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "nsfw": true,
            "seed": 1195116277,
            "draft": false,
            "steps": 24,
            "width": 832,
            "height": 1216,
            "prompt": "An atmospheric scene set in the Skyrim world, featuring a male Khajiit beggar sitting on a cold, stone-paved street in a bustling medieval town. His fur is slightly matted, his ears drooping with weariness, and his clothing is tattered and patched. He holds a wooden sign with written words: 'Spare some buzz for an old beggar.' Snowflakes gently fall around him, and a warm glow emanates from nearby lanterns and shopfronts, contrasting with his somber, downtrodden appearance. The background shows a detailed Skyrim-style town with wooden and stone architecture, NPCs bustling in the distance, and an immersive, wintry atmosphere. (aidmaimageupgrader, aidmaMJ6.1, in the style of Jed-clrfl),",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "fluxMode": "urn:air:flux1:checkpoint:civitai:618692@691639",
            "quantity": 1,
            "workflow": "txt2img",
            "baseModel": "Flux1",
            "resources": [],
            "Created Date": "2024-11-18T1328:19.1293922Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 984672,
                    "modelVersionName": "FLUX v0.3"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 981456,
                    "modelVersionName": "FLUX v0.4"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 827995,
                    "modelVersionName": "V2"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 720252,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 1041442,
                    "modelVersionName": "V1"
                }
            ]
        },
        "username": "Erikus313",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 40772992,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/04ada0ae-56f5-4f78-8bf9-4ed477dcd5f5/width=832/04ada0ae-56f5-4f78-8bf9-4ed477dcd5f5.jpeg",
        "hash": "UJLpX1oOZy~9#jxVxaj^NMt4Mxae_2t8MdM{",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-18T12:32:45.478Z",
        "postId": 9289101,
        "stats": {
            "cryCount": 13,
            "laughCount": 15,
            "likeCount": 145,
            "dislikeCount": 0,
            "heartCount": 62,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 379644399,
            "steps": 11,
            "prompt": "Egon Schiele artstyle, 19 year old hip female colombian supermodel wearing tanktop jersey with \"BUZZ\" written on it. The shirt has \"buzz written on it\", side profile, cute pastel bucket hat with civitai buzz logo, bold lightning \u26a1 pattern on background wall",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-18T1229:58.7777772Z",
            "negativePrompt": "(CyberRealistic_Negative-neg:0.8), , curvy, big tits, (deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, tail, cat ears, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, amputation, closed eyes, shirt",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 345685,
                    "modelVersionName": "FUSION OG"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "ZGHE",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 40651292,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/40d7cf2e-6067-4816-9327-c37a73900738/width=1024/40d7cf2e-6067-4816-9327-c37a73900738.jpeg",
        "hash": "UhO3RJs:_NofyCWVaLoLb_oexVWV-UayNHj?",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-17T19:01:19.727Z",
        "postId": 9261998,
        "stats": {
            "cryCount": 9,
            "laughCount": 16,
            "likeCount": 159,
            "dislikeCount": 0,
            "heartCount": 51,
            "commentCount": 0
        },
        "meta": null,
        "username": "mjzelinskas134",
        "baseModel": ""
    },
    {
        "id": 40387300,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c7975bf9-7982-4a94-a601-95d3d614223e/width=1800/c7975bf9-7982-4a94-a601-95d3d614223e.jpeg",
        "hash": "UCD[|b_NMxD%;O?btQD%#SRjtSogD49FIU-;",
        "width": 3584,
        "height": 4608,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-16T06:16:19.092Z",
        "postId": 9203429,
        "stats": {
            "cryCount": 0,
            "laughCount": 26,
            "likeCount": 163,
            "dislikeCount": 0,
            "heartCount": 48,
            "commentCount": 0
        },
        "meta": {
            "seed": 528360185018974,
            "steps": 30,
            "sampler": "Euler",
            "cfgScale": 3
        },
        "username": "cFeussic",
        "baseModel": ""
    },
    {
        "id": 40295498,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f9499d09-6398-425b-9366-b5532618ee7a/width=832/f9499d09-6398-425b-9366-b5532618ee7a.jpeg",
        "hash": "U7Gabh0K}+^l5yEL0fs+D~abnjNE=_4,xTS7",
        "width": 832,
        "height": 1456,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-15T19:02:00.000Z",
        "postId": 9183683,
        "stats": {
            "cryCount": 6,
            "laughCount": 13,
            "likeCount": 156,
            "dislikeCount": 0,
            "heartCount": 60,
            "commentCount": 0
        },
        "meta": null,
        "username": "Pinkielicious",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 39795276,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/36789667-b409-4ae1-8da8-8eaaa1aa9a33/width=720/36789667-b409-4ae1-8da8-8eaaa1aa9a33.jpeg",
        "hash": "U5D1Kv4X0056zA;K1n-}Hqm-$eX*4?xb|A6B",
        "width": 720,
        "height": 1040,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-12T22:15:55.159Z",
        "postId": 9073921,
        "stats": {
            "cryCount": 6,
            "laughCount": 33,
            "likeCount": 151,
            "dislikeCount": 0,
            "heartCount": 45,
            "commentCount": 0
        },
        "meta": null,
        "username": "UnstableGen",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 39152711,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f0f42ce8-b7b0-4a62-8b73-e774877f7592/width=1536/f0f42ce8-b7b0-4a62-8b73-e774877f7592.jpeg",
        "hash": "U47e9gyE00L#$^v}r?a|4TvL?vu5_NRmt8t5",
        "width": 1536,
        "height": 2304,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-09T07:01:00.000Z",
        "postId": 8934042,
        "stats": {
            "cryCount": 13,
            "laughCount": 17,
            "likeCount": 159,
            "dislikeCount": 0,
            "heartCount": 46,
            "commentCount": 1
        },
        "meta": null,
        "username": "cfchang",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 38901183,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/68df06fb-7e0e-4591-b46e-7578d4465e5b/width=1568/68df06fb-7e0e-4591-b46e-7578d4465e5b.jpeg",
        "hash": "UIBN+say00j[.Tj]ITae00of?aWB4Tf6-:kC",
        "width": 1568,
        "height": 2768,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-07T21:34:01.355Z",
        "postId": 8877984,
        "stats": {
            "cryCount": 5,
            "laughCount": 6,
            "likeCount": 181,
            "dislikeCount": 0,
            "heartCount": 43,
            "commentCount": 1
        },
        "meta": {
            "VAE": "ae.sft",
            "Size": "784x1384",
            "seed": 273,
            "Model": "flux1-dev.safetensors",
            "steps": 20,
            "hashes": {
                "vae": "afc8e28272",
                "model": "4610115bb0",
                "lora:Pro Flux 1.1": "93e9758b1d"
            },
            "sampler": "euler_beta",
            "resources": [
                {
                    "hash": "4610115bb0",
                    "name": "flux1-dev.safetensors",
                    "type": "model"
                }
            ],
            "Model hash": "4610115bb0",
            "Lora_0 Model hash": "93e9758b1d",
            "Lora_0 Model name": "Pro Flux 1.1.safetensors",
            "Lora_0 Strength clip": "1",
            "Lora_0 Strength model": "1"
        },
        "username": "Ragnar890",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 38736357,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b9eae39e-a919-4fdb-8631-81a6bb411a89/width=832/b9eae39e-a919-4fdb-8631-81a6bb411a89.jpeg",
        "hash": "UfLqqmog_3xv~qWXE1f6IAWBD%ogRjWBj]WB",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-06T23:11:02.748Z",
        "postId": 8841851,
        "stats": {
            "cryCount": 4,
            "laughCount": 12,
            "likeCount": 162,
            "dislikeCount": 0,
            "heartCount": 57,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3876790336,
            "extra": {
                "remixOfId": 37494030
            },
            "steps": 30,
            "prompt": "score_9, score_8, score_7, a high detail RAW color professional photo of a 30yo beautiful stunning woman posing for a picture, Expressiveh. arlecchino gi, plump lips,luscious lips, red lips, multicolored hair, short hair, two-tone hair, white hair, black hair, streaked hair, hair between eye, abs, muscle, very muscular, ultra muscular body, (huge fake tits, covered), perfectly round tits, muscular arms, muscular thighs, hypermuscle, bodybuilder, thin waist, perfect body, slender, wide hips, narrow waist, broad shoulders, muscular and voluptuous body, large round breasts, breasts together, black leather trench coat, black leather shirt, featureless black leather pants, black leather boots, black gloves, chest covered, futuristic city at night background, matrix theme, soft lighting, 8k, perfect lighting, cinematic lighting, highly detailed eyes, highly detailed pupils, highly detailed face, highly detailed skin texture, highly detailed facial features, highly detailed hair texture, highly detailed body, highly detailed hands and fingers, highly detailed nails, highly detailed background, cowboy shot, looking at the viewer, f/2.8, 50mm focal length, ISO 200, photographed on a Canon EOS 90D Camera",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-31T0327:32.1603563Z",
            "negativePrompt": "3D | | Low Quality | | text logos | | watermarks | | signatures | | out of frame | | jpeg artifacts | | ugly | | poorly drawn | | extra limbs | | extra hands | | extra feet | | backwards limbs | | extra fingers | | extra toes | | unrealistic, incorrect, bad anatomy | | cut off body pieces | | strange body positions | | impossible body positioning | | Mismatched eyes | | cross eyed | | crooked face | | crooked lips | | unclear | | undefined | | mutations | | deformities | | off center | | poor_composition | | duplicate faces, plastic, fake, tiny, negativity, blurry, blurred, doll, unclear, NSFW, Cleavage, negative_hand, easynegative, bad dynamic pose",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 912470,
                    "modelVersionName": "2.5-B3C4N3"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208,
                    "modelVersionName": "EasyNegative"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 60938,
                    "modelVersionName": "negative_hand"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 135867,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 382152,
                    "modelVersionName": "ExpressiveH"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 407574,
                    "modelVersionName": "Pony"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 457534,
                    "modelVersionName": "pony"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 522995,
                    "modelVersionName": "Pony"
                },
                {
                    "type": "lora",
                    "weight": 0.25,
                    "modelVersionId": 552486,
                    "modelVersionName": "v2.0 Pony"
                },
                {
                    "type": "lora",
                    "weight": 1.4,
                    "modelVersionId": 621385,
                    "modelVersionName": "slider"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250708,
                    "modelVersionName": "safe_pos"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250712,
                    "modelVersionName": "safe_neg"
                }
            ]
        },
        "username": "Schrike",
        "baseModel": "Pony"
    },
    {
        "id": 38377995,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/13eefb1c-b90f-4d9f-a4b5-e8995d20e545/width=1024/13eefb1c-b90f-4d9f-a4b5-e8995d20e545.jpeg",
        "hash": "UHCGeMD+0CRlDsM#^|WC4rt7-$fP_Axt4Zj@",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-04T23:48:23.802Z",
        "postId": 8761702,
        "stats": {
            "cryCount": 0,
            "laughCount": 19,
            "likeCount": 164,
            "dislikeCount": 0,
            "heartCount": 52,
            "commentCount": 0
        },
        "meta": {
            "vaes": [],
            "Model": "Anime_(Ponytail)_Pony",
            "comfy": "{\"prompt\": {\"1\": {\"inputs\": {\"ckpt_name\": \"Anime_(Ponytail)_Pony.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\", \"_meta\": {\"title\": \"Load Checkpoint\"}}, \"3\": {\"inputs\": {\"lora_name\": \"Character\\\\Krismallow.New_Pony.safetensors\", \"strength_model\": 0.5, \"strength_clip\": 0.5, \"model\": [\"1\", 0], \"clip\": [\"1\", 1]}, \"class_type\": \"LoraLoader\", \"_meta\": {\"title\": \"Character Lora\"}}, \"4\": {\"inputs\": {\"lora_name\": \"Artstyle\\\\Cursed.Emoji_Pony.safetensors\", \"strength_model\": 0.0, \"strength_clip\": 0.0, \"model\": [\"3\", 0], \"clip\": [\"3\", 1]}, \"class_type\": \"LoraLoader\", \"_meta\": {\"title\": \"Artstyle Lora\"}}, \"5\": {\"inputs\": {\"lora_name\": \"Artstyle\\\\Orb_Pony.safetensors\", \"strength_model\": 0.0, \"strength_clip\": 0.0, \"model\": [\"4\", 0], \"clip\": [\"4\", 1]}, \"class_type\": \"LoraLoader\", \"_meta\": {\"title\": \"Concept Lora\"}}, \"7\": {\"inputs\": {\"lora_name\": \"Artstyle\\\\Cute.Anime.Style_Pony.safetensors\", \"strength_model\": 0.0, \"strength_clip\": 0.0, \"model\": [\"5\", 0], \"clip\": [\"5\", 1]}, \"class_type\": \"LoraLoader\", \"_meta\": {\"title\": \"Other Lora\"}}, \"10\": {\"inputs\": {\"text\": \"1boy, solo, Bandage on cheek, freckles, Purple Glasses, Purple Eyes, CatBoy, Purple Cat Ears, Purple Hair, Red Hair Streak, Multicolored Hair, Hair over eyes, black fingernails, Oversized Black Open Hoodie Jacket, Purple T-Shirt, black jogging pants, shoes, \", \"clip\": [\"511\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Positive prompt\"}}, \"11\": {\"inputs\": {\"text\": \"\", \"clip\": [\"511\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Negative Prompt\"}}, \"12\": {\"inputs\": {\"text\": \"high resolution, detailed face, details, best quality, \", \"clip\": [\"511\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Standart Positive Prompt\"}}, \"13\": {\"inputs\": {\"text\": \"lowres, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature, pubic hair, \", \"clip\": [\"511\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"Standart Negative Prompt\"}}, \"17\": {\"inputs\": {\"upscale_method\": \"nearest-exact\", \"width\": 1024, \"height\": 1024, \"crop\": \"center\"}, \"class_type\": \"LatentUpscale\", \"_meta\": {\"title\": \"Upscale Latent\"}}, \"18\": {\"inputs\": {\"seed\": 454152117158103, \"steps\": 30, \"cfg\": 8.5, \"sampler_name\": \"euler_ancestral\", \"scheduler\": \"normal\", \"denoise\": 0.8, \"model\": [\"511\", 0], \"positive\": [\"54\", 0], \"negative\": [\"55\", 0], \"latent_image\": [\"17\", 0]}, \"class_type\": \"KSampler\", \"_meta\": {\"title\": \"KSampler\"}}, \"20\": {\"inputs\": {\"samples\": [\"18\", 0], \"vae\": [\"1\", 2]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"54\": {\"inputs\": {\"conditioning_1\": [\"10\", 0], \"conditioning_2\": [\"12\", 0]}, \"class_type\": \"ConditioningCombine\", \"_meta\": {\"title\": \"Positive Prompt Combiner\"}}, \"55\": {\"inputs\": {\"conditioning_1\": [\"11\", 0], \"conditioning_2\": [\"13\", 0]}, \"class_type\": \"ConditioningCombine\", \"_meta\": {\"title\": \"Negative Prompt Combiner\"}}, \"294\": {\"inputs\": {\"latent\": [\"18\", 0]}, \"class_type\": \"PreviewLatent\", \"_meta\": {\"title\": \"Preview Latent\"}}, \"297\": {\"inputs\": {\"filename_prefix\": \"ComfyUI_Latent.Upscale_\", \"images\": [\"20\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}, \"459\": {\"inputs\": {\"images\": [\"463\", 1]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"460\": {\"inputs\": {\"images\": [\"463\", 5]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"461\": {\"inputs\": {\"images\": [\"463\", 2]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"462\": {\"inputs\": {\"filename_prefix\": \"ComfyUI_FaceDetailer\", \"images\": [\"463\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}, \"463\": {\"inputs\": {\"guide_size\": 1024.0, \"guide_size_for\": true, \"max_size\": 1024.0, \"seed\": 753427192534881, \"steps\": 20, \"cfg\": 8.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.5, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.5, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3.0, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"model\": [\"511\", 0], \"clip\": [\"511\", 1], \"vae\": [\"1\", 2], \"positive\": [\"54\", 0], \"negative\": [\"55\", 0], \"bbox_detector\": [\"466\", 0], \"sam_model_opt\": [\"468\", 0], \"segm_detector_opt\": [\"467\", 1]}, \"class_type\": \"FaceDetailer\", \"_meta\": {\"title\": \"FaceDetailer\"}}, \"466\": {\"inputs\": {\"model_name\": \"bbox/hand_yolov8s.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\", \"_meta\": {\"title\": \"UltralyticsDetectorProvider\"}}, \"467\": {\"inputs\": {\"model_name\": \"segm/person_yolov8m-seg.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\", \"_meta\": {\"title\": \"UltralyticsDetectorProvider\"}}, \"468\": {\"inputs\": {\"model_name\": \"sam_vit_b_01ec64.pth\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\", \"_meta\": {\"title\": \"SAMLoader (Impact)\"}}, \"469\": {\"inputs\": {}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"470\": {\"inputs\": {\"images\": [\"474\", 1]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"471\": {\"inputs\": {\"images\": [\"474\", 5]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"472\": {\"inputs\": {\"images\": [\"474\", 2]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"473\": {\"inputs\": {\"filename_prefix\": \"ComfyUI_FaceDetailer\", \"images\": [\"474\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}, \"474\": {\"inputs\": {\"guide_size\": 1024.0, \"guide_size_for\": true, \"max_size\": 1024.0, \"seed\": 391359526448722, \"steps\": 20, \"cfg\": 8.0, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"denoise\": 0.5, \"feather\": 5, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.5, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3.0, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"image\": [\"463\", 0], \"model\": [\"511\", 0], \"clip\": [\"511\", 1], \"vae\": [\"1\", 2], \"positive\": [\"54\", 0], \"negative\": [\"55\", 0], \"bbox_detector\": [\"477\", 0], \"sam_model_opt\": [\"479\", 0], \"segm_detector_opt\": [\"478\", 1]}, \"class_type\": \"FaceDetailer\", \"_meta\": {\"title\": \"FaceDetailer\"}}, \"477\": {\"inputs\": {\"model_name\": \"bbox/face_yolov8m.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\", \"_meta\": {\"title\": \"UltralyticsDetectorProvider\"}}, \"478\": {\"inputs\": {\"model_name\": \"segm/person_yolov8m-seg.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\", \"_meta\": {\"title\": \"UltralyticsDetectorProvider\"}}, \"479\": {\"inputs\": {\"model_name\": \"sam_vit_b_01ec64.pth\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\", \"_meta\": {\"title\": \"SAMLoader (Impact)\"}}, \"480\": {\"inputs\": {\"images\": [\"463\", 0]}, \"class_type\": \"PreviewImage\", \"_meta\": {\"title\": \"Preview Image\"}}, \"496\": {\"inputs\": {\"ckpt_name\": \"sd3.5_large.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\", \"_meta\": {\"title\": \"Load Checkpoint\"}}, \"497\": {\"inputs\": {\"text\": \"image of a reactor standing in a mecanical room glowing yellow, a sign standing in front of it saying \\\"out of order: Need buzz to operate\\\", a lightning bolt illustration is on the sign,\", \"clip\": [\"510\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Prompt)\"}}, \"498\": {\"inputs\": {\"samples\": [\"508\", 0], \"vae\": [\"496\", 2]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"499\": {\"inputs\": {\"clip_name1\": \"clip_g.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"clip_name3\": \"t5xxl_fp16.safetensors\"}, \"class_type\": \"TripleCLIPLoader\", \"_meta\": {\"title\": \"TripleCLIPLoader\"}}, \"500\": {\"inputs\": {\"shift\": 3.0, \"model\": [\"496\", 0]}, \"class_type\": \"ModelSamplingSD3\", \"_meta\": {\"title\": \"ModelSamplingSD3\"}}, \"502\": {\"inputs\": {\"conditioning\": [\"506\", 0]}, \"class_type\": \"ConditioningZeroOut\", \"_meta\": {\"title\": \"ConditioningZeroOut\"}}, \"503\": {\"inputs\": {\"start\": 0.1, \"end\": 1.0, \"conditioning\": [\"502\", 0]}, \"class_type\": \"ConditioningSetTimestepRange\", \"_meta\": {\"title\": \"ConditioningSetTimestepRange\"}}, \"504\": {\"inputs\": {\"conditioning_1\": [\"503\", 0], \"conditioning_2\": [\"505\", 0]}, \"class_type\": \"ConditioningCombine\", \"_meta\": {\"title\": \"Conditioning (Combine)\"}}, \"505\": {\"inputs\": {\"start\": 0.0, \"end\": 0.1, \"conditioning\": [\"506\", 0]}, \"class_type\": \"ConditioningSetTimestepRange\", \"_meta\": {\"title\": \"ConditioningSetTimestepRange\"}}, \"506\": {\"inputs\": {\"text\": \"\", \"clip\": [\"510\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Prompt)\"}}, \"507\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\", \"_meta\": {\"title\": \"EmptySD3LatentImage\"}}, \"508\": {\"inputs\": {\"seed\": 1063918640702793, \"steps\": 30, \"cfg\": 4.5, \"sampler_name\": \"dpmpp_2m\", \"scheduler\": \"sgm_uniform\", \"denoise\": 1.0, \"model\": [\"510\", 0], \"positive\": [\"497\", 0], \"negative\": [\"504\", 0], \"latent_image\": [\"507\", 0]}, \"class_type\": \"KSampler\", \"_meta\": {\"title\": \"KSampler\"}}, \"509\": {\"inputs\": {\"lora_name\": \"Artstyle\\\\Ultra.Realistic_SD3.5.safetensors\", \"strength_model\": 0.5, \"strength_clip\": 1.0, \"model\": [\"500\", 0], \"clip\": [\"499\", 0]}, \"class_type\": \"LoraLoader\", \"_meta\": {\"title\": \"Load LoRA\"}}, \"510\": {\"inputs\": {\"lora_name\": \"Detail Stuff\\\\Detailifier_SD3.5.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"509\", 0], \"clip\": [\"509\", 1]}, \"class_type\": \"LoraLoader\", \"_meta\": {\"title\": \"Load LoRA\"}}, \"511\": {\"inputs\": {\"lora_name\": \"Detail Stuff\\\\Negative_Pony.safetensors\", \"strength_model\": 0.0, \"strength_clip\": 0.0, \"model\": [\"7\", 0], \"clip\": [\"7\", 1]}, \"class_type\": \"LoraLoader\", \"_meta\": {\"title\": \"Negative Embedding\"}}, \"514\": {\"inputs\": {\"filename_prefix\": \"ComfyUI_SD3.5_Output_\", \"images\": [\"498\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}}, \"workflow\": {\"last_node_id\": 514, \"last_link_id\": 892, \"nodes\": [{\"id\": 19, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1550, \"1\": 600}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 119, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 464}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 81}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [467], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 308, \"type\": \"workflow>Positive/Negative Reroute\", \"pos\": {\"0\": 2870, \"1\": -1020}, \"size\": {\"0\": 320, \"1\": 50}, \"flags\": {}, \"order\": 106, \"mode\": 2, \"inputs\": [{\"name\": \"Positive\", \"type\": \"*\", \"link\": 572, \"slot_index\": 0}, {\"name\": \"Negative\", \"type\": \"*\", \"link\": 573, \"slot_index\": 1}], \"outputs\": [{\"name\": \"Positive\", \"type\": \"*\", \"links\": [480], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Negative\", \"type\": \"*\", \"links\": [481], \"slot_index\": 1, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 305, \"type\": \"Note\", \"pos\": {\"0\": 3220, \"1\": -1140}, \"size\": {\"0\": 230, \"1\": 170}, \"flags\": {}, \"order\": 0, \"mode\": 2, \"inputs\": [], \"outputs\": [], \"title\": \"How to use:\", \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"To use this, you need to connect the positive and negative of the \\\"Apply ControlNet\\\" to the positive and negative of the \\\"KSampler Reroutes\\\".\\n\\nPose Path:\\nD:\\\\AI.Stuff\\\\pinocio\\\\api\\\\comfyui.git\\\\app\\\\models\\\\controlnet\\\\OpenPose Poses\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 332, \"type\": \"IPAdapterModelLoader\", \"pos\": {\"0\": 2164.934326171875, \"1\": -1366.9207763671875}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 1, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IPADAPTER\", \"type\": \"IPADAPTER\", \"links\": [522], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"IPAdapterModelLoader\"}, \"widgets_values\": [\"ip-adapter-plus_sdxl_vit-h.safetensors\"]}, {\"id\": 333, \"type\": \"CLIPVisionLoader\", \"pos\": {\"0\": 2164.934326171875, \"1\": -1266.9207763671875}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 2, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP_VISION\", \"type\": \"CLIP_VISION\", \"links\": [524], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPVisionLoader\"}, \"widgets_values\": [\"CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\"]}, {\"id\": 334, \"type\": \"PrepImageForClipVision\", \"pos\": {\"0\": 2524.934326171875, \"1\": -1366.9207763671875}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 48, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 525}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [523], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"PrepImageForClipVision\"}, \"widgets_values\": [\"LANCZOS\", \"top\", 0.15]}, {\"id\": 353, \"type\": \"Note\", \"pos\": {\"0\": 1813.0391845703125, \"1\": -837.489501953125}, \"size\": {\"0\": 320, \"1\": 180}, \"flags\": {}, \"order\": 3, \"mode\": 2, \"inputs\": [], \"outputs\": [], \"title\": \"How to use:\", \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"To use this, you need to connect the Model of the \\\"IPAdapter Embeds\\\" to the Model of the \\\"KSampler Reroutes\\\".\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 355, \"type\": \"workflow>Positive/Negative Reroute\", \"pos\": {\"0\": 870, \"1\": -760}, \"size\": {\"0\": 280, \"1\": 50}, \"flags\": {}, \"order\": 95, \"mode\": 0, \"inputs\": [{\"name\": \"Positive\", \"type\": \"*\", \"link\": 571, \"slot_index\": 0}, {\"name\": \"Negative\", \"type\": \"*\", \"link\": 570, \"slot_index\": 1}], \"outputs\": [{\"name\": \"Positive\", \"type\": \"*\", \"links\": [572], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Negative\", \"type\": \"*\", \"links\": [573], \"slot_index\": 1, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 314, \"type\": \"Note\", \"pos\": {\"0\": 2524.934326171875, \"1\": -856.9207763671875}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 4, \"mode\": 2, \"inputs\": [], \"outputs\": [], \"title\": \"How to use:\", \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"To use this, you need to connect the Model of the \\\"IPAdapter Advanced\\\" to the Model of the \\\"KSampler Reroutes\\\".\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 338, \"type\": \"IPAdapterEncoder\", \"pos\": {\"0\": 1463.0391845703125, \"1\": -1367.489501953125}, \"size\": {\"0\": 315, \"1\": 118}, \"flags\": {}, \"order\": 49, \"mode\": 2, \"inputs\": [{\"name\": \"ipadapter\", \"type\": \"IPADAPTER\", \"link\": 540}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 541}, {\"name\": \"mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}, {\"name\": \"clip_vision\", \"type\": \"CLIP_VISION\", \"link\": 542, \"shape\": 7}], \"outputs\": [{\"name\": \"pos_embed\", \"type\": \"EMBEDS\", \"links\": [554], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"neg_embed\", \"type\": \"EMBEDS\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"IPAdapterEncoder\"}, \"widgets_values\": [1]}, {\"id\": 340, \"type\": \"IPAdapterModelLoader\", \"pos\": {\"0\": 1463.0391845703125, \"1\": -1027.489501953125}, \"size\": {\"0\": 320, \"1\": 140}, \"flags\": {}, \"order\": 5, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IPADAPTER\", \"type\": \"IPADAPTER\", \"links\": [540, 544, 550], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"IPAdapterModelLoader\"}, \"widgets_values\": [\"ip-adapter-plus_sdxl_vit-h.safetensors\"]}, {\"id\": 302, \"type\": \"ControlNetLoader\", \"pos\": {\"0\": 2870, \"1\": -1140}, \"size\": {\"0\": 310, \"1\": 60}, \"flags\": {}, \"order\": 6, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [468], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"OpenPose\\\\OpenPose_SDXL.safetensors\"]}, {\"id\": 294, \"type\": \"PreviewLatent\", \"pos\": {\"0\": 1550, \"1\": 260}, \"size\": {\"0\": 210, \"1\": 250}, \"flags\": {}, \"order\": 132, \"mode\": 0, \"inputs\": [{\"name\": \"latent\", \"type\": \"LATENT\", \"link\": 458, \"slot_index\": 0}], \"outputs\": [{\"name\": \"latent\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"PreviewLatent\"}, \"widgets_values\": []}, {\"id\": 352, \"type\": \"Reroute\", \"pos\": {\"0\": 1183.0391845703125, \"1\": -697.489501953125}, \"size\": [75, 26], \"flags\": {}, \"order\": 105, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 574}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [552], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 335, \"type\": \"Reroute\", \"pos\": {\"0\": 2164.934326171875, \"1\": -826.9207763671875}, \"size\": [75, 26], \"flags\": {}, \"order\": 104, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 568}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [561], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 354, \"type\": \"Reroute\", \"pos\": {\"0\": 870, \"1\": -700}, \"size\": [75, 26], \"flags\": {}, \"order\": 93, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 567}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [568, 574], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 358, \"type\": \"VAEEncode\", \"pos\": {\"0\": 2500, \"1\": 3780}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 108, \"mode\": 2, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 582}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 592}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [602], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 367, \"type\": \"PreviewLatent\", \"pos\": {\"0\": 3080, \"1\": 3890}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 134, \"mode\": 2, \"inputs\": [{\"name\": \"latent\", \"type\": \"LATENT\", \"link\": 588}], \"outputs\": [{\"name\": \"latent\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"PreviewLatent\"}, \"widgets_values\": []}, {\"id\": 364, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3080, \"1\": 3780}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 135, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 589}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 599}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [590], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 373, \"type\": \"SetLatentNoiseMask\", \"pos\": {\"0\": 2500, \"1\": 3850}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 121, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 602}, {\"name\": \"mask\", \"type\": \"MASK\", \"link\": 604}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [603], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SetLatentNoiseMask\"}, \"widgets_values\": []}, {\"id\": 366, \"type\": \"SaveImage\", \"pos\": {\"0\": 3320, \"1\": 3780}, \"size\": {\"0\": 210, \"1\": 360}, \"flags\": {}, \"order\": 141, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 590}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI_Inpaint_\"]}, {\"id\": 368, \"type\": \"Reroute\", \"pos\": {\"0\": 2150, \"1\": 3710}, \"size\": [75, 26], \"flags\": {}, \"order\": 98, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 613}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [592, 599], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 369, \"type\": \"Reroute\", \"pos\": {\"0\": 2150, \"1\": 3700}, \"size\": [75, 26], \"flags\": {}, \"order\": 94, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 594, \"slot_index\": 0}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [595], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 370, \"type\": \"Reroute\", \"pos\": {\"0\": 2150, \"1\": 3690}, \"size\": [75, 26], \"flags\": {}, \"order\": 81, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 614}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [598, 601], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 382, \"type\": \"VAEDecode\", \"pos\": {\"0\": 2560, \"1\": 4100}, \"size\": {\"0\": 320, \"1\": 50}, \"flags\": {}, \"order\": 136, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 626}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 625}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [627], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 388, \"type\": \"VAEEncode\", \"pos\": {\"0\": 2470, \"1\": 2810}, \"size\": {\"0\": 320, \"1\": 50}, \"flags\": {}, \"order\": 109, \"mode\": 2, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 635}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 636}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [634], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 387, \"type\": \"VAEEncode\", \"pos\": {\"0\": 2470, \"1\": 2920}, \"size\": {\"0\": 320, \"1\": 50}, \"flags\": {}, \"order\": 110, \"mode\": 2, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 683}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 637}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [633], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 404, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 870, \"1\": 2970}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 7, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [646], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [1024, 1024, 1]}, {\"id\": 400, \"type\": \"LoadImage\", \"pos\": {\"0\": 870, \"1\": 3140}, \"size\": {\"0\": 320, \"1\": 314}, \"flags\": {}, \"order\": 8, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [651], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ComfyUI_Latent.Upscale_1__00754_.png\", \"image\"]}, {\"id\": 405, \"type\": \"ConditioningZeroOut\", \"pos\": {\"0\": 1220, \"1\": 3270}, \"size\": {\"0\": 320, \"1\": 30}, \"flags\": {}, \"order\": 112, \"mode\": 2, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 650}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [656], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningZeroOut\"}, \"widgets_values\": []}, {\"id\": 406, \"type\": \"CLIPVisionEncode\", \"pos\": {\"0\": 1220, \"1\": 3450}, \"size\": {\"0\": 320, \"1\": 50}, \"flags\": {}, \"order\": 53, \"mode\": 2, \"inputs\": [{\"name\": \"clip_vision\", \"type\": \"CLIP_VISION\", \"link\": 654}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 669}], \"outputs\": [{\"name\": \"CLIP_VISION_OUTPUT\", \"type\": \"CLIP_VISION_OUTPUT\", \"links\": [658], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPVisionEncode\"}, \"widgets_values\": []}, {\"id\": 408, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1570, \"1\": 2700}, \"size\": {\"0\": 450, \"1\": 50}, \"flags\": {}, \"order\": 137, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 661}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 667}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [662], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 396, \"type\": \"unCLIPConditioning\", \"pos\": {\"0\": 1220, \"1\": 3560}, \"size\": {\"0\": 320, \"1\": 102}, \"flags\": {}, \"order\": 123, \"mode\": 2, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 657}, {\"name\": \"clip_vision_output\", \"type\": \"CLIP_VISION_OUTPUT\", \"link\": 659}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [655, 660], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"unCLIPConditioning\"}, \"widgets_values\": [1, 0]}, {\"id\": 409, \"type\": \"SaveImage\", \"pos\": {\"0\": 1570, \"1\": 2810}, \"size\": {\"0\": 450, \"1\": 1010}, \"flags\": {}, \"order\": 143, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 662}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI_Combined.Image_\"]}, {\"id\": 407, \"type\": \"unCLIPConditioning\", \"pos\": {\"0\": 1220, \"1\": 3720}, \"size\": {\"0\": 320, \"1\": 102}, \"flags\": {}, \"order\": 130, \"mode\": 2, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 655}, {\"name\": \"clip_vision_output\", \"type\": \"CLIP_VISION_OUTPUT\", \"link\": 658}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"unCLIPConditioning\"}, \"widgets_values\": [1, 0]}, {\"id\": 402, \"type\": \"workflow>KSampler Reroutes\", \"pos\": {\"0\": 870, \"1\": 2700}, \"size\": {\"0\": 320, \"1\": 90}, \"flags\": {}, \"order\": 100, \"mode\": 2, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 664, \"slot_index\": 0}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"link\": 663}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"link\": 665}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 666, \"slot_index\": 3}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [643], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"links\": [648], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"links\": [650], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [667], \"slot_index\": 3, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 403, \"type\": \"KSampler\", \"pos\": {\"0\": 1220, \"1\": 2700}, \"size\": {\"0\": 320, \"1\": 262}, \"flags\": {}, \"order\": 131, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 643}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 660}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 656}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 646}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [661], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1123352509576504, \"randomize\", 30, 8, \"euler_ancestral\", \"normal\", 1]}, {\"id\": 410, \"type\": \"ImageScale\", \"pos\": {\"0\": 1220, \"1\": 3010}, \"size\": {\"0\": 330, \"1\": 130}, \"flags\": {}, \"order\": 44, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 668}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [669], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"nearest-exact\", 1024, 1024, \"disabled\"]}, {\"id\": 398, \"type\": \"CLIPVisionEncode\", \"pos\": {\"0\": 1220, \"1\": 3360}, \"size\": {\"0\": 320, \"1\": 50}, \"flags\": {}, \"order\": 45, \"mode\": 2, \"inputs\": [{\"name\": \"clip_vision\", \"type\": \"CLIP_VISION\", \"link\": 652}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 651}], \"outputs\": [{\"name\": \"CLIP_VISION_OUTPUT\", \"type\": \"CLIP_VISION_OUTPUT\", \"links\": [659], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPVisionEncode\"}, \"widgets_values\": []}, {\"id\": 397, \"type\": \"ConditioningZeroOut\", \"pos\": {\"0\": 1220, \"1\": 3200}, \"size\": {\"0\": 320, \"1\": 30}, \"flags\": {}, \"order\": 111, \"mode\": 2, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 648}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [657], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningZeroOut\"}, \"widgets_values\": []}, {\"id\": 401, \"type\": \"LoadImage\", \"pos\": {\"0\": 870, \"1\": 3510}, \"size\": {\"0\": 320, \"1\": 314}, \"flags\": {}, \"order\": 9, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [668], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"Original_Hug.png\", \"image\"]}, {\"id\": 399, \"type\": \"CLIPVisionLoader\", \"pos\": {\"0\": 870, \"1\": 2850}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 10, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP_VISION\", \"type\": \"CLIP_VISION\", \"links\": [652, 654], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPVisionLoader\"}, \"widgets_values\": [\"clip-vit-large-patch14-336.bin\"]}, {\"id\": 301, \"type\": \"ControlNetApplyAdvanced\", \"pos\": {\"0\": 3220, \"1\": -1370}, \"size\": {\"0\": 230, \"1\": 186}, \"flags\": {}, \"order\": 117, \"mode\": 2, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 480}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 481}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 468}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 469}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetApplyAdvanced\"}, \"widgets_values\": [1, 0, 1]}, {\"id\": 303, \"type\": \"LoadImage\", \"pos\": {\"0\": 2870, \"1\": -1370}, \"size\": {\"0\": 310, \"1\": 314}, \"flags\": {}, \"order\": 11, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [469], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"Waveing.png\", \"image\"]}, {\"id\": 380, \"type\": \"KSampler\", \"pos\": {\"0\": 2470, \"1\": 3360}, \"size\": {\"0\": 320, \"1\": 262}, \"flags\": {}, \"order\": 129, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 620}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 621}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 624}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 615}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [626], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [137992571678960, \"randomize\", 30, 8.5, \"euler_ancestral\", \"normal\", 0.8]}, {\"id\": 392, \"type\": \"ImageScale\", \"pos\": {\"0\": 2480, \"1\": 3170}, \"size\": {\"0\": 310, \"1\": 130}, \"flags\": {}, \"order\": 46, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 641}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [683], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"nearest-exact\", 1024, 1024, \"disabled\"]}, {\"id\": 376, \"type\": \"LoadImage\", \"pos\": {\"0\": 2050, \"1\": 2850}, \"size\": {\"0\": 390, \"1\": 350}, \"flags\": {}, \"order\": 12, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [635], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ComfyUI_Latent.Upscale_1__00009_.png\", \"image\"]}, {\"id\": 377, \"type\": \"LoadImage\", \"pos\": {\"0\": 2050, \"1\": 3260}, \"size\": {\"0\": 390, \"1\": 360}, \"flags\": {}, \"order\": 13, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [641], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ComfyUI_Main.Generation__00018_.png\", \"image\"]}, {\"id\": 378, \"type\": \"LatentBlend\", \"pos\": {\"0\": 2470, \"1\": 3030}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 122, \"mode\": 2, \"inputs\": [{\"name\": \"samples1\", \"type\": \"LATENT\", \"link\": 634}, {\"name\": \"samples2\", \"type\": \"LATENT\", \"link\": 633, \"slot_index\": 1}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [615], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentBlend\"}, \"widgets_values\": [0.5]}, {\"id\": 298, \"type\": \"SaveImage\", \"pos\": {\"0\": 1790, \"1\": 600}, \"size\": {\"0\": 220, \"1\": 350}, \"flags\": {}, \"order\": 126, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 467}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI_Main.Generation_\"]}, {\"id\": 295, \"type\": \"PreviewLatent\", \"pos\": {\"0\": 1550, \"1\": 700}, \"size\": {\"0\": 210, \"1\": 250}, \"flags\": {}, \"order\": 118, \"mode\": 2, \"inputs\": [{\"name\": \"latent\", \"type\": \"LATENT\", \"link\": 460, \"slot_index\": 0}], \"outputs\": [{\"name\": \"latent\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"PreviewLatent\"}, \"widgets_values\": []}, {\"id\": 430, \"type\": \"CRMPreprocessForPoser\", \"pos\": {\"0\": 1470, \"1\": 3910}, \"size\": {\"0\": 317.4000244140625, \"1\": 78}, \"flags\": {}, \"order\": 55, \"mode\": 2, \"inputs\": [{\"name\": \"reference_image\", \"type\": \"IMAGE\", \"link\": 714}, {\"name\": \"reference_mask\", \"type\": \"MASK\", \"link\": 700}], \"outputs\": [{\"name\": \"processed\", \"type\": \"IMAGE\", \"links\": [701, 707], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CRMPreprocessForPoser\"}, \"widgets_values\": [1]}, {\"id\": 432, \"type\": \"CRMPoserConfig\", \"pos\": {\"0\": 1800, \"1\": 3910}, \"size\": {\"0\": 320, \"1\": 130}, \"flags\": {}, \"order\": 59, \"mode\": 2, \"inputs\": [{\"name\": \"processed_image\", \"type\": \"IMAGE\", \"link\": 701}], \"outputs\": [{\"name\": \"CRM_POSE_CONFIG\", \"type\": \"CRM_POSE_CONFIG\", \"links\": [702, 708], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CRMPoserConfig\"}, \"widgets_values\": [1082634028520267, \"randomize\", 5.5, 30]}, {\"id\": 437, \"type\": \"PreviewImage\", \"pos\": {\"0\": 1470, \"1\": 4030}, \"size\": {\"0\": 320, \"1\": 30}, \"flags\": {}, \"order\": 60, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 707}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 436, \"type\": \"PreviewImage\", \"pos\": {\"0\": 870, \"1\": 4270}, \"size\": {\"0\": 320, \"1\": 240}, \"flags\": {}, \"order\": 54, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 706}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 439, \"type\": \"PreviewImage\", \"pos\": {\"0\": 1040, \"1\": 4550}, \"size\": {\"0\": 150, \"1\": 30}, \"flags\": {}, \"order\": 72, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 711}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 440, \"type\": \"PreviewImage\", \"pos\": {\"0\": 870, \"1\": 4550}, \"size\": {\"0\": 150, \"1\": 30}, \"flags\": {}, \"order\": 67, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 712}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 434, \"type\": \"CRMViewer\", \"pos\": {\"0\": 1210, \"1\": 4220}, \"size\": [600, 500], \"flags\": {}, \"order\": 76, \"mode\": 2, \"inputs\": [{\"name\": \"mesh\", \"type\": \"MESH\", \"link\": 703}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"CRMViewer\"}, \"widgets_values\": [null]}, {\"id\": 433, \"type\": \"CRMModelerCuda\", \"pos\": {\"0\": 1860, \"1\": 4220}, \"size\": {\"0\": 210, \"1\": 66}, \"flags\": {}, \"order\": 71, \"mode\": 2, \"inputs\": [{\"name\": \"crm_model\", \"type\": \"CRM_MODEL\", \"link\": 704}, {\"name\": \"poses\", \"type\": \"IMAGE\", \"link\": 705}, {\"name\": \"coordinates\", \"type\": \"IMAGE\", \"link\": 710}], \"outputs\": [{\"name\": \"MESH\", \"type\": \"MESH\", \"links\": [703], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CRMModelerCuda\"}, \"widgets_values\": []}, {\"id\": 435, \"type\": \"CRMModelLoader\", \"pos\": {\"0\": 1200, \"1\": 3980}, \"size\": {\"0\": 260, \"1\": 60}, \"flags\": {}, \"order\": 14, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"CRM_MODEL\", \"type\": \"CRM_MODEL\", \"links\": [704], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CRMModelLoader\"}, \"widgets_values\": [\"Anime_(AutisimMix)_Pony.safetensors\"]}, {\"id\": 438, \"type\": \"CCMSampler\", \"pos\": {\"0\": 1200, \"1\": 4080}, \"size\": {\"0\": 260, \"1\": 80}, \"flags\": {}, \"order\": 66, \"mode\": 2, \"inputs\": [{\"name\": \"config\", \"type\": \"CRM_POSE_CONFIG\", \"link\": 708}, {\"name\": \"poses\", \"type\": \"IMAGE\", \"link\": 709}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [710, 711], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CCMSampler\"}, \"widgets_values\": [\"Anime_(AutisimMix)_Pony.safetensors\"]}, {\"id\": 431, \"type\": \"CRMPoseSampler\", \"pos\": {\"0\": 1800, \"1\": 4080}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 63, \"mode\": 2, \"inputs\": [{\"name\": \"config\", \"type\": \"CRM_POSE_CONFIG\", \"link\": 702}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [705, 709, 712], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CRMPoseSampler\"}, \"widgets_values\": [\"Anime_(AutisimMix)_Pony.safetensors\"]}, {\"id\": 428, \"type\": \"LoadImage\", \"pos\": {\"0\": 870, \"1\": 3910}, \"size\": {\"0\": 320, \"1\": 320}, \"flags\": {}, \"order\": 15, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [698], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [700], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"(2) Free.Art.By_nerdy.k1tty.png\", \"image\"]}, {\"id\": 429, \"type\": \"Image Remove Background (rembg)\", \"pos\": {\"0\": 1200, \"1\": 3910}, \"size\": {\"0\": 260.3999938964844, \"1\": 30}, \"flags\": {}, \"order\": 47, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 698}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [706, 714], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Remove Background (rembg)\"}, \"widgets_values\": []}, {\"id\": 446, \"type\": \"PreviewImage\", \"pos\": {\"0\": 2920, \"1\": 230}, \"size\": {\"0\": 210, \"1\": 250}, \"flags\": {}, \"order\": 149, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 741}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 445, \"type\": \"PreviewImage\", \"pos\": {\"0\": 2920, \"1\": 520}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 147, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 739}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 447, \"type\": \"PreviewImage\", \"pos\": {\"0\": 2920, \"1\": 810}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 148, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 740}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 448, \"type\": \"SaveImage\", \"pos\": {\"0\": 3140, \"1\": 150}, \"size\": {\"0\": 320, \"1\": 900}, \"flags\": {}, \"order\": 144, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 738}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI_FaceDetailer\"]}, {\"id\": 455, \"type\": \"SAMLoader\", \"pos\": {\"0\": 2040, \"1\": 930}, \"size\": {\"0\": 300, \"1\": 82}, \"flags\": {}, \"order\": 16, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [749], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 20, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1550, \"1\": 150}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 133, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 463}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 89}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [466, 755, 756], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 458, \"type\": \"PreviewImage\", \"pos\": {\"0\": 2040, \"1\": 330}, \"size\": {\"0\": 300, \"1\": 300}, \"flags\": {}, \"order\": 140, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 756}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 381, \"type\": \"workflow>KSampler Reroutes\", \"pos\": {\"0\": 2050, \"1\": 2710}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 99, \"mode\": 2, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 618}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"link\": 619}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"link\": 622}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 623}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [620], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"links\": [621], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"links\": [624], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [625, 636, 637], \"slot_index\": 3, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 454, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2040, \"1\": 810}, \"size\": {\"0\": 300, \"1\": 80}, \"flags\": {}, \"order\": 17, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [748], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/person_yolov8m-seg.pt\"]}, {\"id\": 459, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4370, \"1\": 520}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 153, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 757}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 460, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4370, \"1\": 230}, \"size\": {\"0\": 210, \"1\": 250}, \"flags\": {}, \"order\": 155, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 758}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 467, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 3490, \"1\": 810}, \"size\": {\"0\": 300, \"1\": 80}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [768], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/person_yolov8m-seg.pt\"]}, {\"id\": 468, \"type\": \"SAMLoader\", \"pos\": {\"0\": 3490, \"1\": 930}, \"size\": {\"0\": 300, \"1\": 82}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [767], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 469, \"type\": \"PreviewImage\", \"pos\": {\"0\": 3490, \"1\": 330}, \"size\": {\"0\": 300, \"1\": 300}, \"flags\": {}, \"order\": 146, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 796}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 462, \"type\": \"SaveImage\", \"pos\": {\"0\": 4590, \"1\": 150}, \"size\": {\"0\": 320, \"1\": 900}, \"flags\": {}, \"order\": 150, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 760}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI_FaceDetailer\"]}, {\"id\": 453, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 2040, \"1\": 690}, \"size\": {\"0\": 300, \"1\": 80}, \"flags\": {}, \"order\": 20, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [747], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/person_yolov8m-seg.pt\"]}, {\"id\": 466, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 3490, \"1\": 690}, \"size\": {\"0\": 300, \"1\": 80}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [766], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/hand_yolov8s.pt\"]}, {\"id\": 470, \"type\": \"PreviewImage\", \"pos\": {\"0\": 5820, \"1\": 520}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 157, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 770}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 471, \"type\": \"PreviewImage\", \"pos\": {\"0\": 5820, \"1\": 230}, \"size\": {\"0\": 210, \"1\": 250}, \"flags\": {}, \"order\": 159, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 771}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 472, \"type\": \"PreviewImage\", \"pos\": {\"0\": 5820, \"1\": 810}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 158, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 772}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 473, \"type\": \"SaveImage\", \"pos\": {\"0\": 6040, \"1\": 150}, \"size\": {\"0\": 320, \"1\": 900}, \"flags\": {}, \"order\": 156, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 773}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI_FaceDetailer\"]}, {\"id\": 474, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 5270, \"1\": 150}, \"size\": {\"0\": 519, \"1\": 900}, \"flags\": {}, \"order\": 151, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 794}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 774}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 775}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 776}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 777}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 778}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 779}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 780, \"shape\": 7}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 781, \"shape\": 7}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null, \"shape\": 7}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [773], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [770], \"slot_index\": 1, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [772], \"slot_index\": 2, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 3, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": [771], \"slot_index\": 5, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [1024, true, 1024, 391359526448722, \"randomize\", 20, 8, \"euler\", \"normal\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 477, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 4940, \"1\": 690}, \"size\": {\"0\": 300, \"1\": 80}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [779], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 478, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 4940, \"1\": 810}, \"size\": {\"0\": 300, \"1\": 80}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [781], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/person_yolov8m-seg.pt\"]}, {\"id\": 479, \"type\": \"SAMLoader\", \"pos\": {\"0\": 4940, \"1\": 930}, \"size\": {\"0\": 300, \"1\": 82}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [780], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 480, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4940, \"1\": 330}, \"size\": {\"0\": 300, \"1\": 300}, \"flags\": {}, \"order\": 152, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 795}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 451, \"type\": \"workflow>KSampler Reroutes\", \"pos\": {\"0\": 2040, \"1\": 150}, \"size\": {\"0\": 300, \"1\": 90}, \"flags\": {}, \"order\": 101, \"mode\": 2, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 750}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"link\": 751}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"link\": 752}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 753}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [742, 782], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"links\": [743, 783], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"links\": [744, 784], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [745, 785], \"slot_index\": 3, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 465, \"type\": \"Reroute\", \"pos\": {\"0\": 3490, \"1\": 240}, \"size\": [75, 26], \"flags\": {}, \"order\": 88, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 786}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [762, 791], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 476, \"type\": \"Reroute\", \"pos\": {\"0\": 4940, \"1\": 240}, \"size\": [75, 26], \"flags\": {}, \"order\": 91, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 791}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [775]}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 464, \"type\": \"workflow>KSampler Reroutes\", \"pos\": {\"0\": 3490, \"1\": 150}, \"size\": {\"0\": 300, \"1\": 90}, \"flags\": {}, \"order\": 113, \"mode\": 0, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 782}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"link\": 783}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"link\": 784}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 785}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [761, 787], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"links\": [764, 788], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"links\": [765, 789], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [763, 790], \"slot_index\": 3, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 475, \"type\": \"workflow>KSampler Reroutes\", \"pos\": {\"0\": 4940, \"1\": 150}, \"size\": {\"0\": 300, \"1\": 90}, \"flags\": {}, \"order\": 124, \"mode\": 0, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 787}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"link\": 788}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"link\": 789}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 790}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [774], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"links\": [777], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"links\": [778], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [776], \"slot_index\": 3, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 463, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 3820, \"1\": 150}, \"size\": {\"0\": 519, \"1\": 900}, \"flags\": {}, \"order\": 145, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 793}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 761}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 762}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 763}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 764}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 765}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 766}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 767, \"shape\": 7}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 768, \"shape\": 7}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null, \"shape\": 7}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [760, 794, 795], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [757], \"slot_index\": 1, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [759], \"slot_index\": 2, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 3, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": [758], \"slot_index\": 5, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [1024, true, 1024, 753427192534881, \"randomize\", 20, 8, \"euler\", \"normal\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 450, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 2370, \"1\": 150}, \"size\": {\"0\": 519, \"1\": 900}, \"flags\": {}, \"order\": 139, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 755}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 742}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 746}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 745}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 743}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 744}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 747}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 749, \"shape\": 7}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 748, \"shape\": 7}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null, \"shape\": 7}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [738, 793, 796], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [739], \"slot_index\": 1, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [740], \"slot_index\": 2, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 3, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": [741], \"slot_index\": 5, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [1024, true, 1024, 189781565026105, \"randomize\", 20, 8, \"euler\", \"normal\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 383, \"type\": \"SaveImage\", \"pos\": {\"0\": 2820, \"1\": 2710}, \"size\": {\"0\": 360, \"1\": 920}, \"flags\": {}, \"order\": 142, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 627}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI_Blend.Image_\"]}, {\"id\": 452, \"type\": \"Reroute\", \"pos\": {\"0\": 2040, \"1\": 240}, \"size\": [75, 26], \"flags\": {}, \"order\": 82, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 754}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [746, 786], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 375, \"type\": \"Note\", \"pos\": {\"0\": -410, \"1\": 120}, \"size\": {\"0\": 210, \"1\": 170}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"title\": \"Wolfi Prompt\", \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"1boy, full body, solo, femboy, Furry, Wolf Furry, wolf ears, wolf tail with pink tip, Brown Furr, middle hair, Brown Hair, Pink striped hair, multicolored hair, pink eyes, \"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 461, \"type\": \"PreviewImage\", \"pos\": {\"0\": 4370, \"1\": 810}, \"size\": {\"0\": 210, \"1\": 246}, \"flags\": {}, \"order\": 154, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 759}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}, \"widgets_values\": []}, {\"id\": 481, \"type\": \"Note\", \"pos\": {\"0\": -630, \"1\": -20}, \"size\": {\"0\": 430, \"1\": 100}, \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"black onesie, (hood up:1.2), wolf onesie, wolf ears, animal onesie,\\n\\n1girl, (cute:1.2), solo, long hair, light brown hair, light brown eyes, rawr, \"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 414, \"type\": \"Note\", \"pos\": {\"0\": -630, \"1\": -130}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"title\": \"Sticker Prompt\", \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"twitch emote, chibi, outline, sticker,\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 411, \"type\": \"Note\", \"pos\": {\"0\": -410, \"1\": -130}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"title\": \"Emote Prompt\", \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"score_9, score_8_up, score_8, half body, Emote , high quality, high res , highly detailed face, white background, chibi, upper body close up, (face close up:1.1),\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 484, \"type\": \"Note\", \"pos\": {\"0\": -410, \"1\": 330}, \"size\": {\"0\": 210, \"1\": 170}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"title\": \"AI Prompt\", \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"1girl, black hair, \"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 330, \"type\": \"LoadImage\", \"pos\": {\"0\": 2164.934326171875, \"1\": -1146.9207763671875}, \"size\": {\"0\": 320, \"1\": 314}, \"flags\": {}, \"order\": 30, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [525], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ComfyUI_Latent.Upscale_1__00018_.png\", \"image\"]}, {\"id\": 331, \"type\": \"IPAdapterAdvanced\", \"pos\": {\"0\": 2524.934326171875, \"1\": -1196.9207763671875}, \"size\": {\"0\": 320, \"1\": 280}, \"flags\": {}, \"order\": 115, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 561, \"slot_index\": 0}, {\"name\": \"ipadapter\", \"type\": \"IPADAPTER\", \"link\": 522, \"slot_index\": 1}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 523}, {\"name\": \"image_negative\", \"type\": \"IMAGE\", \"link\": null, \"shape\": 7}, {\"name\": \"attn_mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}, {\"name\": \"clip_vision\", \"type\": \"CLIP_VISION\", \"link\": 524, \"slot_index\": 5, \"shape\": 7}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"IPAdapterAdvanced\"}, \"widgets_values\": [0.4, \"linear\", \"concat\", 0, 1, \"V only\"]}, {\"id\": 54, \"type\": \"ConditioningCombine\", \"pos\": {\"0\": 300, \"1\": 400}, \"size\": {\"0\": 230, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 85, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning_1\", \"type\": \"CONDITIONING\", \"link\": 104}, {\"name\": \"conditioning_2\", \"type\": \"CONDITIONING\", \"link\": 103}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [825], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Positive Prompt Combiner\", \"properties\": {\"Node name for S&R\": \"ConditioningCombine\"}, \"widgets_values\": [], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 343, \"type\": \"IPAdapterEncoder\", \"pos\": {\"0\": 1463.0391845703125, \"1\": -1207.489501953125}, \"size\": {\"0\": 320, \"1\": 120}, \"flags\": {}, \"order\": 50, \"mode\": 2, \"inputs\": [{\"name\": \"ipadapter\", \"type\": \"IPADAPTER\", \"link\": 544}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 545}, {\"name\": \"mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}, {\"name\": \"clip_vision\", \"type\": \"CLIP_VISION\", \"link\": 543, \"shape\": 7}], \"outputs\": [{\"name\": \"pos_embed\", \"type\": \"EMBEDS\", \"links\": [828], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"neg_embed\", \"type\": \"EMBEDS\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"IPAdapterEncoder\"}, \"widgets_values\": [1]}, {\"id\": 345, \"type\": \"IPAdapterCombineEmbeds\", \"pos\": {\"0\": 1813.0391845703125, \"1\": -1357.489501953125}, \"size\": {\"0\": 320, \"1\": 140}, \"flags\": {}, \"order\": 56, \"mode\": 2, \"inputs\": [{\"name\": \"embed1\", \"type\": \"EMBEDS\", \"link\": 554}, {\"name\": \"embed2\", \"type\": \"EMBEDS\", \"link\": 828, \"shape\": 7}, {\"name\": \"embed3\", \"type\": \"EMBEDS\", \"link\": null, \"shape\": 7}, {\"name\": \"embed4\", \"type\": \"EMBEDS\", \"link\": null, \"shape\": 7}, {\"name\": \"embed5\", \"type\": \"EMBEDS\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"EMBEDS\", \"type\": \"EMBEDS\", \"links\": [830], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"IPAdapterCombineEmbeds\"}, \"widgets_values\": [\"concat\"]}, {\"id\": 341, \"type\": \"LoadImage\", \"pos\": {\"0\": 1183.7498779296875, \"1\": -1361.266845703125}, \"size\": {\"0\": 250, \"1\": 314}, \"flags\": {}, \"order\": 31, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [541], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"gdgfdfgdfg.jpg\", \"image\"]}, {\"id\": 344, \"type\": \"LoadImage\", \"pos\": {\"0\": 1183.0391845703125, \"1\": -1017.489501953125}, \"size\": {\"0\": 250, \"1\": 314}, \"flags\": {}, \"order\": 32, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [545], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"217cfb1f89b0da3dba6bjkhjk640cd008454d.jpg\", \"image\"]}, {\"id\": 280, \"type\": \"workflow>KSampler Reroutes\", \"pos\": {\"0\": 570, \"1\": 850}, \"size\": {\"0\": 262, \"1\": 90}, \"flags\": {}, \"order\": 90, \"mode\": 0, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 813}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"link\": 825}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"link\": 850}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 448}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [567, 594, 618, 664, 750, 831, 832], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"links\": [436, 440, 571, 619, 663, 751], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"links\": [437, 441, 570, 622, 665, 752], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [438, 442, 613, 623, 666, 753], \"slot_index\": 3, \"shape\": 3}], \"title\": \"Main Reroutes\", \"properties\": {}, \"widgets_values\": []}, {\"id\": 342, \"type\": \"CLIPVisionLoader\", \"pos\": {\"0\": 1463.0391845703125, \"1\": -847.489501953125}, \"size\": {\"0\": 320, \"1\": 140}, \"flags\": {}, \"order\": 33, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP_VISION\", \"type\": \"CLIP_VISION\", \"links\": [542, 543, 549], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPVisionLoader\"}, \"widgets_values\": [\"CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\"]}, {\"id\": 351, \"type\": \"IPAdapterEmbeds\", \"pos\": {\"0\": 1813.0391845703125, \"1\": -1167.489501953125}, \"size\": {\"0\": 320, \"1\": 260}, \"flags\": {}, \"order\": 116, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 552}, {\"name\": \"ipadapter\", \"type\": \"IPADAPTER\", \"link\": 550}, {\"name\": \"pos_embed\", \"type\": \"EMBEDS\", \"link\": 830}, {\"name\": \"neg_embed\", \"type\": \"EMBEDS\", \"link\": null, \"shape\": 7}, {\"name\": \"attn_mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}, {\"name\": \"clip_vision\", \"type\": \"CLIP_VISION\", \"link\": 549, \"shape\": 7}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"IPAdapterEmbeds\"}, \"widgets_values\": [0.8, \"linear\", 0, 1, \"V only\"]}, {\"id\": 53, \"type\": \"workflow>KSampler Reroutes\", \"pos\": {\"0\": 910, \"1\": 150}, \"size\": {\"0\": 262, \"1\": 90}, \"flags\": {}, \"order\": 97, \"mode\": 0, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 832}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"link\": 440}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"link\": 441}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 442}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [843], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"links\": [87], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"links\": [88], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [89], \"slot_index\": 3, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 48, \"type\": \"workflow>KSampler Reroutes\", \"pos\": {\"0\": 910, \"1\": 600}, \"size\": {\"0\": 262, \"1\": 90}, \"flags\": {}, \"order\": 96, \"mode\": 2, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 831}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"link\": 436}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"link\": 437}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 438}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [844], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"links\": [672], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"links\": [673], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [81], \"slot_index\": 3, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 415, \"type\": \"Note\", \"pos\": {\"0\": -630, \"1\": 120}, \"size\": {\"0\": 210, \"1\": 170}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"1boy, solo, furry, fox tail, fox ears, fox, orange, Nick Wilde, heterochromia, left baby blue eye, right mint green eye, femboy, pink hoodie, pink collar, Upper body,\\n\\nhalf body, Emote , high quality, high res , highly detailed face, white background, chibi, upper body close up, face close up,\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 55, \"type\": \"ConditioningCombine\", \"pos\": {\"0\": 300, \"1\": 650}, \"size\": {\"0\": 230, \"1\": 50}, \"flags\": {}, \"order\": 84, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning_1\", \"type\": \"CONDITIONING\", \"link\": 113}, {\"name\": \"conditioning_2\", \"type\": \"CONDITIONING\", \"link\": 112}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [850], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Negative Prompt Combiner\", \"properties\": {\"Node name for S&R\": \"ConditioningCombine\"}, \"widgets_values\": [], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 495, \"type\": \"Note\", \"pos\": {\"0\": 133.27796936035156, \"1\": 107.82374572753906}, \"size\": {\"0\": 210, \"1\": 120}, \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"Anime, 1girl, long black hair, black eyebrows, grey eyes, Black Hoodie, black joggign pants with white stripe, black socks, no shoes, \"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 360, \"type\": \"LoadImage\", \"pos\": {\"0\": 2150, \"1\": 3780}, \"size\": {\"0\": 320, \"1\": 360}, \"flags\": {}, \"order\": 36, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [582], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [604], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"clipspace/clipspace-mask-3000352.799999997.png [input]\", \"image\"]}, {\"id\": 372, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2500, \"1\": 4060}, \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 87, \"mode\": 2, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 601}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [690], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"ear rings\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 363, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2500, \"1\": 3940}, \"size\": {\"0\": 210, \"1\": 90}, \"flags\": {}, \"order\": 86, \"mode\": 2, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 598}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [691], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"ear\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 362, \"type\": \"KSampler\", \"pos\": {\"0\": 2740, \"1\": 3780}, \"size\": {\"0\": 310, \"1\": 360}, \"flags\": {}, \"order\": 128, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 595}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 691}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 690}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 603}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [588, 589], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [663778349033965, \"randomize\", 30, 8, \"euler_ancestral\", \"normal\", 0.9]}, {\"id\": 3, \"type\": \"LoraLoader\", \"pos\": {\"0\": -1150, \"1\": 650}, \"size\": {\"0\": 320, \"1\": 130}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 720}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 2}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [3], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [4], \"slot_index\": 1, \"shape\": 3}], \"title\": \"Character Lora\", \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"Character\\\\Krismallow.New_Pony.safetensors\", 0.5, 0.5]}, {\"id\": 17, \"type\": \"LatentUpscale\", \"pos\": {\"0\": 910, \"1\": 300}, \"size\": {\"0\": 260, \"1\": 210}, \"flags\": {}, \"order\": 120, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 846}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [800], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentUpscale\"}, \"widgets_values\": [\"nearest-exact\", 1024, 1024, \"center\"]}, {\"id\": 16, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 910, \"1\": 750}, \"size\": {\"0\": 260, \"1\": 200}, \"flags\": {}, \"order\": 37, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [871], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [512, 512, 1]}, {\"id\": 11, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 60, \"1\": 590}, \"size\": {\"0\": 210, \"1\": 180}, \"flags\": {\"collapsed\": false}, \"order\": 77, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 95}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [113], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Negative Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 4, \"type\": \"LoraLoader\", \"pos\": {\"0\": -800, \"1\": 650}, \"size\": {\"0\": 320, \"1\": 130}, \"flags\": {\"collapsed\": false}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 3}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 4}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [5], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [6], \"slot_index\": 1, \"shape\": 3}], \"title\": \"Artstyle Lora\", \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"Artstyle\\\\Cursed.Emoji_Pony.safetensors\", 0, 0]}, {\"id\": 357, \"type\": \"Note\", \"pos\": {\"0\": -630, \"1\": 330}, \"size\": {\"0\": 210, \"1\": 170}, \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"title\": \"Krismallow Prompt\", \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"1boy, solo, Bandage on cheek, freckles, Purple Glasses, Purple Eyes, CatBoy, Purple Cat Ears, Purple Cat Tail, Purple Hair, Red Hair Streak, Multicolored Hair, Hair over eyes, \\n\\nOversized Black Open Hoodie Jacket, Purple T-Shirt, black jogging pants, shoes, \"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 52, \"type\": \"workflow>Model Reroutes\", \"pos\": {\"0\": -470, \"1\": 840}, \"size\": {\"0\": 320, \"1\": 130}, \"flags\": {}, \"order\": 73, \"mode\": 0, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 874}, {\"name\": \"Clip\", \"type\": \"*\", \"link\": 875}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 101}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [813], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"Clip\", \"type\": \"*\", \"links\": [95, 96, 97, 120, 614, 754], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [448], \"slot_index\": 2, \"shape\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 7, \"type\": \"LoraLoader\", \"pos\": {\"0\": -1150, \"1\": 840}, \"size\": {\"0\": 320, \"1\": 130}, \"flags\": {}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 8}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 7}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [872], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [873], \"slot_index\": 1, \"shape\": 3}], \"title\": \"Other Lora\", \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"Artstyle\\\\Cute.Anime.Style_Pony.safetensors\", 0, 0]}, {\"id\": 12, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 70, \"1\": 550}, \"size\": {\"0\": 210, \"1\": 180}, \"flags\": {\"collapsed\": true}, \"order\": 79, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 97}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [103], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Standart Positive Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"high resolution, detailed face, details, best quality, \"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 10, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 60, \"1\": 330}, \"size\": {\"0\": 210, \"1\": 180}, \"flags\": {}, \"order\": 80, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 120}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [104], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Positive prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"1boy, solo, Bandage on cheek, freckles, Purple Glasses, Purple Eyes, CatBoy, Purple Cat Ears, Purple Hair, Red Hair Streak, Multicolored Hair, Hair over eyes, black fingernails, Oversized Black Open Hoodie Jacket, Purple T-Shirt, black jogging pants, shoes, \"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 15, \"type\": \"KSampler\", \"pos\": {\"0\": 1200, \"1\": 600}, \"size\": {\"0\": 320, \"1\": 350}, \"flags\": {}, \"order\": 107, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 844}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 672, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 673}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 871}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [460, 464, 846], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [10712554220689, \"randomize\", 20, 8.5, \"euler_ancestral\", \"normal\", 1]}, {\"id\": 18, \"type\": \"KSampler\", \"pos\": {\"0\": 1200, \"1\": 150}, \"size\": {\"0\": 320, \"1\": 360}, \"flags\": {}, \"order\": 127, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 843}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 87}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 88}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 800}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [458, 463], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [454152117158103, \"randomize\", 30, 8.5, \"euler_ancestral\", \"normal\", 0.8]}, {\"id\": 5, \"type\": \"LoraLoader\", \"pos\": {\"0\": -1500, \"1\": 840}, \"size\": {\"0\": 320, \"1\": 130}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 5}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 6}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [8], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [7], \"slot_index\": 1, \"shape\": 3}], \"title\": \"Concept Lora\", \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"Artstyle\\\\Orb_Pony.safetensors\", 0, 0]}, {\"id\": 1, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": -1500, \"1\": 650}, \"size\": {\"0\": 320, \"1\": 130}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [720], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [2], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [101], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"Anime_(Ponytail)_Pony.safetensors\"]}, {\"id\": 13, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 70, \"1\": 810}, \"size\": {\"0\": 210, \"1\": 180}, \"flags\": {\"collapsed\": true}, \"order\": 78, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 96}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [112], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Standart Negative Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"lowres, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature, pubic hair, \"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 500, \"type\": \"ModelSamplingSD3\", \"pos\": {\"0\": 1210, \"1\": -350}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {\"collapsed\": false}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 855}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [867], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingSD3\"}, \"widgets_values\": [3]}, {\"id\": 496, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": 910, \"1\": -350}, \"size\": {\"0\": 300, \"1\": 130}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [855], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": null, \"slot_index\": 1, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [878], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"sd3.5_large.safetensors\"]}, {\"id\": 512, \"type\": \"workflow>Model Reroutes\", \"pos\": {\"0\": 2090, \"1\": -350}, \"size\": {\"0\": 140, \"1\": 130}, \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 876}, {\"name\": \"Clip\", \"type\": \"*\", \"link\": 877}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 878}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [881], \"slot_index\": 0}, {\"name\": \"Clip\", \"type\": \"*\", \"links\": [879, 880], \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [882], \"slot_index\": 2}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 505, \"type\": \"ConditioningSetTimestepRange\", \"pos\": {\"0\": 2620, \"1\": -140}, \"size\": {\"0\": 317.4000244140625, \"1\": 82}, \"flags\": {}, \"order\": 75, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 861, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [860], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningSetTimestepRange\"}, \"widgets_values\": [0, 0.1]}, {\"id\": 502, \"type\": \"ConditioningZeroOut\", \"pos\": {\"0\": 2620, \"1\": -20}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 74, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 857}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [858], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningZeroOut\"}, \"widgets_values\": []}, {\"id\": 503, \"type\": \"ConditioningSetTimestepRange\", \"pos\": {\"0\": 2950, \"1\": -20}, \"size\": {\"0\": 240, \"1\": 82}, \"flags\": {}, \"order\": 83, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 858}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [859], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningSetTimestepRange\"}, \"widgets_values\": [0.1, 1]}, {\"id\": 504, \"type\": \"ConditioningCombine\", \"pos\": {\"0\": 2950, \"1\": -140}, \"size\": {\"0\": 240, \"1\": 80}, \"flags\": {}, \"order\": 89, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning_1\", \"type\": \"CONDITIONING\", \"link\": 859}, {\"name\": \"conditioning_2\", \"type\": \"CONDITIONING\", \"link\": 860}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [883], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningCombine\"}, \"widgets_values\": []}, {\"id\": 499, \"type\": \"TripleCLIPLoader\", \"pos\": {\"0\": 1110, \"1\": -130}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [868], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"TripleCLIPLoader\"}, \"widgets_values\": [\"clip_g.safetensors\", \"clip_l.safetensors\", \"t5xxl_fp16.safetensors\"]}, {\"id\": 510, \"type\": \"LoraLoader\", \"pos\": {\"0\": 1760, \"1\": -350}, \"size\": {\"0\": 300, \"1\": 130}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 869}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 870}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [876], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [877], \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"Detail Stuff\\\\Detailifier_SD3.5.safetensors\", 1, 1]}, {\"id\": 511, \"type\": \"LoraLoader\", \"pos\": {\"0\": -800, \"1\": 840}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 68, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 872}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 873}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [874], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [875], \"slot_index\": 1}], \"title\": \"Negative Embedding\", \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"Detail Stuff\\\\Negative_Pony.safetensors\", 0, 0]}, {\"id\": 498, \"type\": \"VAEDecode\", \"pos\": {\"0\": 4050, \"1\": -320}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 114, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 853}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 888}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [889], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 297, \"type\": \"SaveImage\", \"pos\": {\"0\": 1790, \"1\": 150}, \"size\": {\"0\": 220, \"1\": 360}, \"flags\": {}, \"order\": 138, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 466}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI_Latent.Upscale_\"]}, {\"id\": 514, \"type\": \"SaveImage\", \"pos\": {\"0\": 4290, \"1\": -320}, \"size\": [460, 380], \"flags\": {}, \"order\": 125, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 889}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"ComfyUI_SD3.5_Output_\"]}, {\"id\": 506, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2260, \"1\": -140}, \"size\": {\"0\": 350, \"1\": 200}, \"flags\": {}, \"order\": 70, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 880}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [857, 861], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 497, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2260, \"1\": -350}, \"size\": {\"0\": 350, \"1\": 170}, \"flags\": {}, \"order\": 69, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 879}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [884], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"image of a reactor standing in a mecanical room glowing yellow, a sign standing in front of it saying \\\"out of order: Need buzz to operate\\\", a lightning bolt illustration is on the sign,\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 509, \"type\": \"LoraLoader\", \"pos\": {\"0\": 1450, \"1\": -350}, \"size\": {\"0\": 300, \"1\": 130}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 867}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 868}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [869], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [870], \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"Artstyle\\\\Ultra.Realistic_SD3.5.safetensors\", 0.5, 1]}, {\"id\": 513, \"type\": \"workflow>KSampler Reroutes\", \"pos\": {\"0\": 3220, \"1\": -320}, \"size\": {\"0\": 393, \"1\": 86}, \"flags\": {}, \"order\": 92, \"mode\": 0, \"inputs\": [{\"name\": \"Model\", \"type\": \"*\", \"link\": 881}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"link\": 884}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"link\": 883}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 882}], \"outputs\": [{\"name\": \"Model\", \"type\": \"*\", \"links\": [885], \"slot_index\": 0}, {\"name\": \"Positive Prompt\", \"type\": \"*\", \"links\": [886], \"slot_index\": 1}, {\"name\": \"Negative Prompt\", \"type\": \"*\", \"links\": [887], \"slot_index\": 2}, {\"name\": \"VAE\", \"type\": \"*\", \"links\": [888, 891], \"slot_index\": 3}], \"properties\": {}, \"widgets_values\": []}, {\"id\": 494, \"type\": \"LoadImage\", \"pos\": {\"0\": 3650, \"1\": -920}, \"size\": [320, 310], \"flags\": {}, \"order\": 42, \"mode\": 2, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [833], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ComfyUI_SD3.5_Output__00003_.png\", \"image\"]}, {\"id\": 493, \"type\": \"VAEEncode\", \"pos\": {\"0\": 3650, \"1\": -570}, \"size\": [320, 50], \"flags\": {}, \"order\": 103, \"mode\": 2, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 833}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 891}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 508, \"type\": \"KSampler\", \"pos\": {\"0\": 3640, \"1\": -320}, \"size\": {\"0\": 380, \"1\": 270}, \"flags\": {}, \"order\": 102, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 885}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 886}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 887}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 892}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [853], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1063918640702793, \"randomize\", 30, 4.5, \"dpmpp_2m\", \"sgm_uniform\", 1]}, {\"id\": 507, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 3350, \"1\": -100}, \"size\": {\"0\": 260, \"1\": 110}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [892], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [1024, 1024, 1]}], \"links\": [[2, 1, 1, 3, 1, \"CLIP\"], [3, 3, 0, 4, 0, \"MODEL\"], [4, 3, 1, 4, 1, \"CLIP\"], [5, 4, 0, 5, 0, \"MODEL\"], [6, 4, 1, 5, 1, \"CLIP\"], [7, 5, 1, 7, 1, \"CLIP\"], [8, 5, 0, 7, 0, \"MODEL\"], [81, 48, 3, 19, 1, \"VAE\"], [87, 53, 1, 18, 1, \"CONDITIONING\"], [88, 53, 2, 18, 2, \"CONDITIONING\"], [89, 53, 3, 20, 1, \"VAE\"], [95, 52, 1, 11, 0, \"CLIP\"], [96, 52, 1, 13, 0, \"CLIP\"], [97, 52, 1, 12, 0, \"CLIP\"], [101, 1, 2, 52, 2, \"*\"], [103, 12, 0, 54, 1, \"CONDITIONING\"], [104, 10, 0, 54, 0, \"CONDITIONING\"], [112, 13, 0, 55, 1, \"CONDITIONING\"], [113, 11, 0, 55, 0, \"CONDITIONING\"], [120, 52, 1, 10, 0, \"CLIP\"], [436, 280, 1, 48, 1, \"*\"], [437, 280, 2, 48, 2, \"*\"], [438, 280, 3, 48, 3, \"*\"], [440, 280, 1, 53, 1, \"*\"], [441, 280, 2, 53, 2, \"*\"], [442, 280, 3, 53, 3, \"*\"], [448, 52, 2, 280, 3, \"*\"], [458, 18, 0, 294, 0, \"LATENT\"], [460, 15, 0, 295, 0, \"LATENT\"], [463, 18, 0, 20, 0, \"LATENT\"], [464, 15, 0, 19, 0, \"LATENT\"], [466, 20, 0, 297, 0, \"IMAGE\"], [467, 19, 0, 298, 0, \"IMAGE\"], [468, 302, 0, 301, 2, \"CONTROL_NET\"], [469, 303, 0, 301, 3, \"IMAGE\"], [480, 308, 0, 301, 0, \"CONDITIONING\"], [481, 308, 1, 301, 1, \"CONDITIONING\"], [522, 332, 0, 331, 1, \"IPADAPTER\"], [523, 334, 0, 331, 2, \"IMAGE\"], [524, 333, 0, 331, 5, \"CLIP_VISION\"], [525, 330, 0, 334, 0, \"IMAGE\"], [540, 340, 0, 338, 0, \"IPADAPTER\"], [541, 341, 0, 338, 1, \"IMAGE\"], [542, 342, 0, 338, 3, \"CLIP_VISION\"], [543, 342, 0, 343, 3, \"CLIP_VISION\"], [544, 340, 0, 343, 0, \"IPADAPTER\"], [545, 344, 0, 343, 1, \"IMAGE\"], [549, 342, 0, 351, 5, \"CLIP_VISION\"], [550, 340, 0, 351, 1, \"IPADAPTER\"], [552, 352, 0, 351, 0, \"MODEL\"], [554, 338, 0, 345, 0, \"EMBEDS\"], [561, 335, 0, 331, 0, \"MODEL\"], [567, 280, 0, 354, 0, \"*\"], [568, 354, 0, 335, 0, \"*\"], [570, 280, 2, 355, 1, \"*\"], [571, 280, 1, 355, 0, \"*\"], [572, 355, 0, 308, 0, \"*\"], [573, 355, 1, 308, 1, \"*\"], [574, 354, 0, 352, 0, \"*\"], [582, 360, 0, 358, 0, \"IMAGE\"], [588, 362, 0, 367, 0, \"LATENT\"], [589, 362, 0, 364, 0, \"LATENT\"], [590, 364, 0, 366, 0, \"IMAGE\"], [592, 368, 0, 358, 1, \"VAE\"], [594, 280, 0, 369, 0, \"*\"], [595, 369, 0, 362, 0, \"MODEL\"], [598, 370, 0, 363, 0, \"CLIP\"], [599, 368, 0, 364, 1, \"VAE\"], [601, 370, 0, 372, 0, \"CLIP\"], [602, 358, 0, 373, 0, \"LATENT\"], [603, 373, 0, 362, 3, \"LATENT\"], [604, 360, 1, 373, 1, \"MASK\"], [613, 280, 3, 368, 0, \"*\"], [614, 52, 1, 370, 0, \"*\"], [615, 378, 0, 380, 3, \"LATENT\"], [618, 280, 0, 381, 0, \"*\"], [619, 280, 1, 381, 1, \"*\"], [620, 381, 0, 380, 0, \"MODEL\"], [621, 381, 1, 380, 1, \"CONDITIONING\"], [622, 280, 2, 381, 2, \"*\"], [623, 280, 3, 381, 3, \"*\"], [624, 381, 2, 380, 2, \"CONDITIONING\"], [625, 381, 3, 382, 1, \"VAE\"], [626, 380, 0, 382, 0, \"LATENT\"], [627, 382, 0, 383, 0, \"IMAGE\"], [633, 387, 0, 378, 1, \"LATENT\"], [634, 388, 0, 378, 0, \"LATENT\"], [635, 376, 0, 388, 0, \"IMAGE\"], [636, 381, 3, 388, 1, \"VAE\"], [637, 381, 3, 387, 1, \"VAE\"], [641, 377, 0, 392, 0, \"IMAGE\"], [643, 402, 0, 403, 0, \"MODEL\"], [646, 404, 0, 403, 3, \"LATENT\"], [648, 402, 1, 397, 0, \"CONDITIONING\"], [650, 402, 2, 405, 0, \"CONDITIONING\"], [651, 400, 0, 398, 1, \"IMAGE\"], [652, 399, 0, 398, 0, \"CLIP_VISION\"], [654, 399, 0, 406, 0, \"CLIP_VISION\"], [655, 396, 0, 407, 0, \"CONDITIONING\"], [656, 405, 0, 403, 2, \"CONDITIONING\"], [657, 397, 0, 396, 0, \"CONDITIONING\"], [658, 406, 0, 407, 1, \"CLIP_VISION_OUTPUT\"], [659, 398, 0, 396, 1, \"CLIP_VISION_OUTPUT\"], [660, 396, 0, 403, 1, \"CONDITIONING\"], [661, 403, 0, 408, 0, \"LATENT\"], [662, 408, 0, 409, 0, \"IMAGE\"], [663, 280, 1, 402, 1, \"*\"], [664, 280, 0, 402, 0, \"*\"], [665, 280, 2, 402, 2, \"*\"], [666, 280, 3, 402, 3, \"*\"], [667, 402, 3, 408, 1, \"VAE\"], [668, 401, 0, 410, 0, \"IMAGE\"], [669, 410, 0, 406, 1, \"IMAGE\"], [672, 48, 1, 15, 1, \"CONDITIONING\"], [673, 48, 2, 15, 2, \"CONDITIONING\"], [683, 392, 0, 387, 0, \"IMAGE\"], [690, 372, 0, 362, 2, \"CONDITIONING\"], [691, 363, 0, 362, 1, \"CONDITIONING\"], [698, 428, 0, 429, 0, \"IMAGE\"], [700, 428, 1, 430, 1, \"MASK\"], [701, 430, 0, 432, 0, \"IMAGE\"], [702, 432, 0, 431, 0, \"CRM_POSE_CONFIG\"], [703, 433, 0, 434, 0, \"MESH\"], [704, 435, 0, 433, 0, \"CRM_MODEL\"], [705, 431, 0, 433, 1, \"IMAGE\"], [706, 429, 0, 436, 0, \"IMAGE\"], [707, 430, 0, 437, 0, \"IMAGE\"], [708, 432, 0, 438, 0, \"CRM_POSE_CONFIG\"], [709, 431, 0, 438, 1, \"IMAGE\"], [710, 438, 0, 433, 2, \"IMAGE\"], [711, 438, 0, 439, 0, \"IMAGE\"], [712, 431, 0, 440, 0, \"IMAGE\"], [714, 429, 0, 430, 0, \"IMAGE\"], [720, 1, 0, 3, 0, \"MODEL\"], [738, 450, 0, 448, 0, \"IMAGE\"], [739, 450, 1, 445, 0, \"IMAGE\"], [740, 450, 2, 447, 0, \"IMAGE\"], [741, 450, 5, 446, 0, \"IMAGE\"], [742, 451, 0, 450, 1, \"MODEL\"], [743, 451, 1, 450, 4, \"CONDITIONING\"], [744, 451, 2, 450, 5, \"CONDITIONING\"], [745, 451, 3, 450, 3, \"VAE\"], [746, 452, 0, 450, 2, \"CLIP\"], [747, 453, 0, 450, 6, \"BBOX_DETECTOR\"], [748, 454, 1, 450, 8, \"SEGM_DETECTOR\"], [749, 455, 0, 450, 7, \"SAM_MODEL\"], [750, 280, 0, 451, 0, \"*\"], [751, 280, 1, 451, 1, \"*\"], [752, 280, 2, 451, 2, \"*\"], [753, 280, 3, 451, 3, \"*\"], [754, 52, 1, 452, 0, \"*\"], [755, 20, 0, 450, 0, \"IMAGE\"], [756, 20, 0, 458, 0, \"IMAGE\"], [757, 463, 1, 459, 0, \"IMAGE\"], [758, 463, 5, 460, 0, \"IMAGE\"], [759, 463, 2, 461, 0, \"IMAGE\"], [760, 463, 0, 462, 0, \"IMAGE\"], [761, 464, 0, 463, 1, \"MODEL\"], [762, 465, 0, 463, 2, \"CLIP\"], [763, 464, 3, 463, 3, \"VAE\"], [764, 464, 1, 463, 4, \"CONDITIONING\"], [765, 464, 2, 463, 5, \"CONDITIONING\"], [766, 466, 0, 463, 6, \"BBOX_DETECTOR\"], [767, 468, 0, 463, 7, \"SAM_MODEL\"], [768, 467, 1, 463, 8, \"SEGM_DETECTOR\"], [770, 474, 1, 470, 0, \"IMAGE\"], [771, 474, 5, 471, 0, \"IMAGE\"], [772, 474, 2, 472, 0, \"IMAGE\"], [773, 474, 0, 473, 0, \"IMAGE\"], [774, 475, 0, 474, 1, \"MODEL\"], [775, 476, 0, 474, 2, \"CLIP\"], [776, 475, 3, 474, 3, \"VAE\"], [777, 475, 1, 474, 4, \"CONDITIONING\"], [778, 475, 2, 474, 5, \"CONDITIONING\"], [779, 477, 0, 474, 6, \"BBOX_DETECTOR\"], [780, 479, 0, 474, 7, \"SAM_MODEL\"], [781, 478, 1, 474, 8, \"SEGM_DETECTOR\"], [782, 451, 0, 464, 0, \"*\"], [783, 451, 1, 464, 1, \"*\"], [784, 451, 2, 464, 2, \"*\"], [785, 451, 3, 464, 3, \"*\"], [786, 452, 0, 465, 0, \"*\"], [787, 464, 0, 475, 0, \"*\"], [788, 464, 1, 475, 1, \"*\"], [789, 464, 2, 475, 2, \"*\"], [790, 464, 3, 475, 3, \"*\"], [791, 465, 0, 476, 0, \"*\"], [793, 450, 0, 463, 0, \"IMAGE\"], [794, 463, 0, 474, 0, \"IMAGE\"], [795, 463, 0, 480, 0, \"IMAGE\"], [796, 450, 0, 469, 0, \"IMAGE\"], [800, 17, 0, 18, 3, \"LATENT\"], [813, 52, 0, 280, 0, \"*\"], [825, 54, 0, 280, 1, \"*\"], [828, 343, 0, 345, 1, \"EMBEDS\"], [830, 345, 0, 351, 2, \"EMBEDS\"], [831, 280, 0, 48, 0, \"*\"], [832, 280, 0, 53, 0, \"*\"], [833, 494, 0, 493, 0, \"IMAGE\"], [843, 53, 0, 18, 0, \"MODEL\"], [844, 48, 0, 15, 0, \"MODEL\"], [846, 15, 0, 17, 0, \"LATENT\"], [850, 55, 0, 280, 2, \"*\"], [853, 508, 0, 498, 0, \"LATENT\"], [855, 496, 0, 500, 0, \"MODEL\"], [857, 506, 0, 502, 0, \"CONDITIONING\"], [858, 502, 0, 503, 0, \"CONDITIONING\"], [859, 503, 0, 504, 0, \"CONDITIONING\"], [860, 505, 0, 504, 1, \"CONDITIONING\"], [861, 506, 0, 505, 0, \"CONDITIONING\"], [867, 500, 0, 509, 0, \"MODEL\"], [868, 499, 0, 509, 1, \"CLIP\"], [869, 509, 0, 510, 0, \"MODEL\"], [870, 509, 1, 510, 1, \"CLIP\"], [871, 16, 0, 15, 3, \"LATENT\"], [872, 7, 0, 511, 0, \"MODEL\"], [873, 7, 1, 511, 1, \"CLIP\"], [874, 511, 0, 52, 0, \"*\"], [875, 511, 1, 52, 1, \"*\"], [876, 510, 0, 512, 0, \"*\"], [877, 510, 1, 512, 1, \"*\"], [878, 496, 2, 512, 2, \"*\"], [879, 512, 1, 497, 0, \"CLIP\"], [880, 512, 1, 506, 0, \"CLIP\"], [881, 512, 0, 513, 0, \"*\"], [882, 512, 2, 513, 3, \"*\"], [883, 504, 0, 513, 2, \"*\"], [884, 497, 0, 513, 1, \"*\"], [885, 513, 0, 508, 0, \"MODEL\"], [886, 513, 1, 508, 1, \"CONDITIONING\"], [887, 513, 2, 508, 2, \"CONDITIONING\"], [888, 513, 3, 498, 1, \"VAE\"], [889, 498, 0, 514, 0, \"IMAGE\"], [891, 513, 3, 493, 1, \"VAE\"], [892, 507, 0, 508, 3, \"LATENT\"]], \"groups\": [{\"title\": \"SD3.5 (Big Model)\", \"bounding\": [900, -420, 3860, 490], \"color\": \"#a1309b\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Models\", \"bounding\": [-1510, 580, 1370, 400], \"color\": \"#88A\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Prompts\", \"bounding\": [50, 260, 490, 560], \"color\": \"#444\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Image generation\", \"bounding\": [900, 530, 1120, 430], \"color\": \"#a1309b\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Latent Upscale\", \"bounding\": [900, 80, 1120, 440], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"OpenPose [ControlNet]\", \"bounding\": [2860, -1440, 600, 480], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Face Cloner [IPAdapter] (Realistic Only)\", \"bounding\": [2155, -1436, 700, 650], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Clotheing Changer [IPAdapter]\", \"bounding\": [1173, -1439, 970, 780], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Injector Reroutes\", \"bounding\": [860, -830, 300, 170], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Inpaint\", \"bounding\": [2140, 3640, 1400, 510], \"color\": \"#a1309b\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Blend Images\", \"bounding\": [2040, 2630, 1150, 1000], \"color\": \"#a1309b\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Image Combiner (Broken)\", \"bounding\": [860, 2630, 1170, 1200], \"color\": \"#A88\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"3D Modeling\", \"bounding\": [860, 3840, 1270, 920], \"color\": \"#A88\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Body Detailer\", \"bounding\": [2030, 80, 1440, 980], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Hand Detailer\", \"bounding\": [3480, 80, 1440, 980], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Face Detailer\", \"bounding\": [4930, 80, 1440, 980], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"VAE Encode\", \"bounding\": [3640, -990, 340, 480], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 3.1863081771035664, \"offset\": [-4364.056393898569, 182.194167555261]}, \"groupNodes\": {\"KSampler Reroutes\": {\"nodes\": [{\"type\": \"Reroute\", \"pos\": [1900, 600], \"size\": [75, 26], \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null, \"slot_index\": 0}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"index\": 0}, {\"type\": \"Reroute\", \"pos\": [1900, 640], \"size\": [75, 26], \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"index\": 1}, {\"type\": \"Reroute\", \"pos\": [1900, 680], \"size\": [75, 26], \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"index\": 2}, {\"type\": \"Reroute\", \"pos\": [1900, 720], \"size\": [75, 26], \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"index\": 3}], \"links\": [], \"external\": [], \"config\": {\"0\": {\"input\": {\"*\": {\"name\": \"Model\"}}, \"output\": {\"0\": {\"name\": \"Model\"}}}, \"1\": {\"input\": {\"*\": {\"name\": \"Positive Prompt\"}}, \"output\": {\"0\": {\"name\": \"Positive Prompt\"}}}, \"2\": {\"input\": {\"*\": {\"name\": \"Negative Prompt\"}}, \"output\": {\"0\": {\"name\": \"Negative Prompt\"}}}, \"3\": {\"input\": {\"*\": {\"name\": \"VAE\"}}, \"output\": {\"0\": {\"name\": \"VAE\"}}}}}, \"Model Reroutes\": {\"nodes\": [{\"type\": \"Reroute\", \"pos\": [1500, 340], \"size\": [75, 26], \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"index\": 0}, {\"type\": \"Reroute\", \"pos\": [1500, 380], \"size\": [75, 26], \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"index\": 1}, {\"type\": \"Reroute\", \"pos\": [1500, 310], \"size\": [75, 26], \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"index\": 2}], \"links\": [], \"external\": [], \"config\": {\"0\": {\"input\": {\"*\": {\"name\": \"Model\"}}, \"output\": {\"0\": {\"name\": \"Model\"}}}, \"1\": {\"output\": {\"0\": {\"name\": \"Clip\"}}, \"input\": {\"*\": {\"name\": \"Clip\"}}}, \"2\": {\"input\": {\"*\": {\"name\": \"VAE\"}}, \"output\": {\"0\": {\"name\": \"VAE\"}}}}}, \"Positive/Negative Reroute\": {\"nodes\": [{\"type\": \"Reroute\", \"pos\": [217.66973017230663, -325.8786025517568], \"size\": [75, 26], \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"index\": 0}, {\"type\": \"Reroute\", \"pos\": [220, -364], \"size\": [75, 26], \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"index\": 1}], \"links\": [], \"external\": [], \"config\": {\"0\": {\"input\": {\"*\": {\"name\": \"Positive\"}}, \"output\": {\"0\": {\"name\": \"Positive\"}}}, \"1\": {\"output\": {\"0\": {\"name\": \"Negative\"}}, \"input\": {\"*\": {\"name\": \"Negative\"}}}}}}}, \"version\": 0.4}}",
            "steps": 30,
            "width": 1024,
            "height": 1024,
            "models": [
                "Anime_(Ponytail)_Pony.safetensors",
                "sd3.5_large.safetensors"
            ],
            "prompt": "image of a reactor standing in a mecanical room glowing yellow, a sign standing in front of it saying \"out of order: Need buzz to operate\", a lightning bolt illustration is on the sign,",
            "denoise": 0.8,
            "sampler": "DPM++ 2M",
            "cfgScale": 5,
            "modelIds": [],
            "scheduler": "normal",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "Character\\Krismallow.New_Pony.safetensors",
                    "type": "lora",
                    "strength": 0.5,
                    "strengthClip": 0.5
                },
                {
                    "name": "Artstyle\\Ultra.Realistic_SD3.5.safetensors",
                    "type": "lora",
                    "strength": 0.5,
                    "strengthClip": 1
                },
                {
                    "name": "Detail Stuff\\Detailifier_SD3.5.safetensors",
                    "type": "lora",
                    "strength": 1,
                    "strengthClip": 1
                }
            ]
        },
        "username": "Max02",
        "baseModel": ""
    },
    {
        "id": 38347344,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/aeecce75-256f-4c2b-9739-7a513103b1d1/width=832/aeecce75-256f-4c2b-9739-7a513103b1d1.jpeg",
        "hash": "U29GaYMy0f~U%iIpiwPW%iF{0JRQ~C}nt173",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-04T20:01:19.596Z",
        "postId": 8754640,
        "stats": {
            "cryCount": 16,
            "laughCount": 19,
            "likeCount": 151,
            "dislikeCount": 0,
            "heartCount": 49,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1611404061,
            "extra": {
                "remixOfId": 37701650
            },
            "steps": 23,
            "prompt": "Create a stunning hybrid creature artwork of Balor and Serkahn in a detailed,  a monstrous mass of veins and sinew, [eldritch], colorful, evil sinister, horror, Cosmic abomination, bodyhorror, action shot, detailed background, otherworldly, angled sideview, establishing shotcinematic concept art style, with vibrant and intense colors, and a mix of futuristic and ancient elements. The artwork should be highly detailed, with precise anatomy and dynamic lighting, resembling the work of top digital artists such as Greg Rutkowski and Stanley Artgerm Lau. The composition should be epic and dramatic, with a focus on creating a visually striking and awe-inspiring image.safe_neg,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-04T1957:12.3531438Z",
            "negativePrompt": "bad proportions, low resolution, bad, ugly, terrible, , pink skin creepy, meat skin,comic, anime, manga, unrealistic, flat, FastNegativeV2, watermark, signature, worst quality, low quality, normal quality, lowres, simple background, inaccurate limb, extra fingers, fewer fingers, missing fingers, extra arms, (extra legs:1.6), inaccurate eyes, bad composition, bad anatomy, error, extra digit, fewer digits, cropped, low res, worst quality, low quality, normal quality, jpeg artifacts, extra digit, fewer digits, trademark, watermark, artist's name, username, signature, text, words, (malformed hand:1.2), (disassembled lightsaber handle:1.5)",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 345685,
                    "modelVersionName": "FUSION OG"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208,
                    "modelVersionName": "EasyNegative"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 383563,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 657273,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 678485,
                    "modelVersionName": "v2.0"
                }
            ]
        },
        "username": "EBYGRALE",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 38254518,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/664a42ba-aef7-415e-bd08-31d232627d0c/width=832/664a42ba-aef7-415e-bd08-31d232627d0c.jpeg",
        "hash": "UHEC%,.T4mtRxbMwM{kXa{wIxvo}?bo}xaxZ",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-04T07:34:53.368Z",
        "postId": 8733580,
        "stats": {
            "cryCount": 18,
            "laughCount": 26,
            "likeCount": 142,
            "dislikeCount": 0,
            "heartCount": 49,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3243111167,
            "extra": {
                "remixOfId": 36995738
            },
            "steps": 19,
            "prompt": "surreal scifi cyberpunk theme, cowboy body shot of a futuristic female bunny cyborg, eating a pink carrot, sleek white armor, black visor, pink ears, detailed aeration holes, high contrast lighting, smooth contours and sharp lines, sex shop background, sci-fi elements, cyberpunk, design with integrated communication devices, 3d rendering, inspired by ralph mcquarrie, atmospheric, Max Details, sharp focus, colorful, high contrast, stylized, dark, clear, surreal, ultra quality, 8k, best quality, masterpiece,\nmidjourneyv6.1",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 8.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-28T1351:34.1202323Z",
            "negativePrompt": "watermark, easynegative, makeup, flag, bad hands, bad eyes, bad fingers, deformed hands, extra fingers, visible face, child, minor,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 916744,
                    "modelVersionName": "v10.0"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 627153,
                    "modelVersionName": "SDXL"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 723149,
                    "modelVersionName": "SDXL"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250708,
                    "modelVersionName": "safe_pos"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250712,
                    "modelVersionName": "safe_neg"
                }
            ]
        },
        "username": "martinffm_pg",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 38199760,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d995b43a-1556-4466-92ee-eec5cee05818/width=832/d995b43a-1556-4466-92ee-eec5cee05818.jpeg",
        "hash": "U36HT2R601%gi_oLX8NH01xu~BD%pINGnO-o",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-04T01:02:09.030Z",
        "postId": 8721815,
        "stats": {
            "cryCount": 6,
            "laughCount": 19,
            "likeCount": 154,
            "dislikeCount": 0,
            "heartCount": 56,
            "commentCount": 1
        },
        "meta": null,
        "username": "Rhailo",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 38181583,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/64142629-048e-4858-b159-9ff74362af02/width=832/64142629-048e-4858-b159-9ff74362af02.jpeg",
        "hash": "UI6l=QQ,L}*0lBR5nNtktlV@Vtt6tlWBV@n#",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-04T00:26:00.000Z",
        "postId": 8718034,
        "stats": {
            "cryCount": 5,
            "laughCount": 12,
            "likeCount": 198,
            "dislikeCount": 0,
            "heartCount": 20,
            "commentCount": 0
        },
        "meta": null,
        "username": null,
        "baseModel": "Flux.1 D"
    },
    {
        "id": 38076987,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ad56a94a-5736-4088-bdba-cb086fd22245/width=832/ad56a94a-5736-4088-bdba-cb086fd22245.jpeg",
        "hash": "UYF%9mt6_Mog17ayIvR-$fj?MxayR.WXt3kB",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-03T09:42:29.253Z",
        "postId": 8695076,
        "stats": {
            "cryCount": 8,
            "laughCount": 31,
            "likeCount": 158,
            "dislikeCount": 0,
            "heartCount": 38,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 890352917,
            "extra": {
                "remixOfId": 24133739
            },
            "steps": 24,
            "prompt": "by Jeffrey Smith art, by Duy Huynh, by Masaaki Masamoto , gigantic, gargantuan, huge, massive, enormous, tall, colossal, poster, highly detailed and hyper realistic, perfect composition, harmonic colors, dramatic lighting",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 3,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-31T1447:31.6039883Z",
            "negativePrompt": "(worst quality, greyscale, jpeg artifacts, unnatural skin:1.2)",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 782002,
                    "modelVersionName": "Jugg_XI_by_RunDiffusion"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 135867,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 152309,
                    "modelVersionName": "xl_more_art-full-v1"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "OrlandoOrso",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 37609262,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f05e412a-e1f2-459f-98ed-cffeba2996d8/width=1216/f05e412a-e1f2-459f-98ed-cffeba2996d8.jpeg",
        "hash": "UI6csWQRxtysT|VXWVX8i]RjkCi^tQRjo}ax",
        "width": 1216,
        "height": 832,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-31T18:54:43.011Z",
        "postId": 8590865,
        "stats": {
            "cryCount": 13,
            "laughCount": 25,
            "likeCount": 147,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 0
        },
        "meta": {
            "Size": "1216x832",
            "seed": 3317679864,
            "extra": {
                "remixOfId": 35577464
            },
            "steps": 50,
            "prompt": "A mysterious, hooded figure stands atop a skyscraper at night, silhouetted against a city skyline lit with a sea of neon lights. The figure\u2019s cloak billows in the wind, revealing hints of futuristic armor underneath, sleek and metallic with glowing accents. In one hand, he holds a small, high-tech sign that projects a hologram of a lightning bolt symbol, like a digital \u201cbuzz\u201d emblem, spinning slowly in the air. The sign reads in sharp, bold letters: \u201cOnly the worthy may buzz.\u201d\nThe figure\u2019s face is mostly hidden by his hood, but a faint, piercing glow shines from one of his eyes, hinting at a powerful, enigmatic presence. Around him, the skyscraper\u2019s lights flash in rhythm, almost as if the whole city pulses with anticipation. High-tech drones hover nearby, each displaying the same lightning symbol, casting a cool, electric blue light across the scene. In the distance, clouds part to reveal a full moon, adding to the dark, cyberpunk vibe.\nThis image has a sleek, intense energy, capturing a sense of power and mystery as if this lone figure is summoning only those who dare to \u201cbuzz\u201d up to his level.",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-31T1854:07.0899506Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                }
            ]
        },
        "username": "Elredai",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 37276237,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/28ca0156-ead1-4783-9dbc-0af732529f19/width=832/28ca0156-ead1-4783-9dbc-0af732529f19.jpeg",
        "hash": "UHBC.Fw{0eOD.mS#Mdr?_4soMxSg^+fkE1jZ",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-29T22:24:46.149Z",
        "postId": 8513521,
        "stats": {
            "cryCount": 5,
            "laughCount": 12,
            "likeCount": 171,
            "dislikeCount": 0,
            "heartCount": 47,
            "commentCount": 0
        },
        "meta": null,
        "username": "Carcamagnu",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 37187821,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ee6e3ad7-ed22-4144-a298-7299ad1d5001/width=896/ee6e3ad7-ed22-4144-a298-7299ad1d5001.jpeg",
        "hash": "UEDAPt%NSzNF%fo0x]M{%#xuMdof_N.8IURP",
        "width": 896,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-29T10:26:14.117Z",
        "postId": 8492539,
        "stats": {
            "cryCount": 5,
            "laughCount": 14,
            "likeCount": 154,
            "dislikeCount": 0,
            "heartCount": 62,
            "commentCount": 1
        },
        "meta": {
            "seed": 389852199435043,
            "vaes": [
                "flux_vae.safetensors"
            ],
            "comfy": "{\"prompt\": {\"96\": {\"inputs\": {\"vae_name\": \"flux_vae.safetensors\"}, \"class_type\": \"VAELoader\"}, \"97\": {\"inputs\": {\"clip_name1\": \"flux\\\\t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"flux\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"98\": {\"inputs\": {\"unet_name\": \"flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"99\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"100\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 33, \"denoise\": 1.0, \"model\": [\"167\", 0]}, \"class_type\": \"BasicScheduler\"}, \"102\": {\"inputs\": {\"samples\": [\"103\", 0], \"vae\": [\"96\", 0]}, \"class_type\": \"VAEDecode\"}, \"103\": {\"inputs\": {\"guider\": [\"104\", 0], \"noise\": [\"109\", 0], \"sampler\": [\"99\", 0], \"sigmas\": [\"100\", 0], \"latent_image\": [\"110\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"104\": {\"inputs\": {\"conditioning\": [\"106\", 0], \"model\": [\"167\", 0]}, \"class_type\": \"BasicGuider\"}, \"106\": {\"inputs\": {\"guidance\": 2.7, \"conditioning\": [\"123\", 0]}, \"class_type\": \"FluxGuidance\"}, \"108\": {\"inputs\": {\"lora_name\": \"SDXL\\\\flux.1_lora_flyway_Epic_gorgeous_Details_v1.safetensors\", \"strength_model\": 0.75, \"model\": [\"98\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"109\": {\"inputs\": {\"noise_seed\": 389852199435043}, \"class_type\": \"RandomNoise\"}, \"110\": {\"inputs\": {\"resolution\": \"896x1152 (0.78)\", \"batch_size\": 2}, \"class_type\": \"SDXLEmptyLatentSizePicker+\"}, \"111\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"102\", 0]}, \"class_type\": \"SaveImage\"}, \"112\": {\"inputs\": {\"VAE\": [\"96\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"115\": {\"inputs\": {\"IMAGE\": [\"102\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"120\": {\"inputs\": {\"CLIP\": [\"97\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"123\": {\"inputs\": {\"text\": \"Mysticism. The concept. Surrealism. An allegory. A complex, multidimensional.\\n \\nNobody believes it,\\nMiracle of miracles:\\nA girl behind the flowers\\nHe goes to the winter forest.\\n\\nIt is not in the greenery,\\nLike in the July heat,\\nHe's snow-whitewashed,\\nIt shines white..\\n\\n\\nimpressive lighting, analog photography, cinematography, unimaginable quality, 8K, UHD, \\n\\n (Depth of field), Fujica GW690 camera, medium 20mm film. Kodak Portra 400 analog film stocks,  aidmaimageupgrader,\", \"speak_and_recognation\": true, \"clip\": [\"97\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"124\": {\"inputs\": {\"CONDITIONING\": [\"123\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"130\": {\"inputs\": {\"LATENT\": [\"110\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"131\": {\"inputs\": {\"INT\": [\"110\", 1]}, \"class_type\": \"Anything Everywhere\"}, \"132\": {\"inputs\": {\"INT\": [\"110\", 2]}, \"class_type\": \"Anything Everywhere\"}, \"133\": {\"inputs\": {\"SAMPLER\": [\"99\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"134\": {\"inputs\": {\"MODEL\": [\"167\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"135\": {\"inputs\": {\"SIGMAS\": [\"100\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"136\": {\"inputs\": {\"NOISE\": [\"109\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"160\": {\"inputs\": {\"rgthree_comparer\": {\"images\": [{\"name\": \"A1\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rcexf_00619_.png&type=temp&subfolder=&rand=0.5391070946208498\"}, {\"name\": \"A2\", \"selected\": false, \"url\": \"/api/view?filename=rgthree.compare._temp_rcexf_00620_.png&type=temp&subfolder=&rand=0.639232688121693\"}, {\"name\": \"B1\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rcexf_00621_.png&type=temp&subfolder=&rand=0.13210475839086744\"}, {\"name\": \"B2\", \"selected\": false, \"url\": \"/api/view?filename=rgthree.compare._temp_rcexf_00622_.png&type=temp&subfolder=&rand=0.46681010255589794\"}]}, \"image_a\": [\"161\", 0], \"image_b\": [\"163\", 0]}, \"class_type\": \"Image Comparer (rgthree)\"}, \"161\": {\"inputs\": {\"text\": \"\\u041e\\u0440\\u0438\\u0433\\u0438\\u043d\\u0430\\u043b\", \"align\": \"bottom center\", \"opacity\": 1.0, \"font_name\": \"AlumniSansCollegiateOne-Regular.ttf\", \"font_size\": 50, \"font_color\": \"custom\", \"x_margin\": 20, \"y_margin\": 20, \"font_color_hex\": \"#ff0000\", \"image\": [\"102\", 0]}, \"class_type\": \"CR Simple Text Watermark\"}, \"163\": {\"inputs\": {\"text\": \"\\u0420\\u0435\\u0437\\u0443\\u043b\\u044c\\u0442\\u0430\\u0442 \\u043f\\u043e\\u0441\\u043b\\u0435 Hires\", \"align\": \"bottom center\", \"opacity\": 1.0, \"font_name\": \"AlumniSansCollegiateOne-Regular.ttf\", \"font_size\": 50, \"font_color\": \"custom\", \"x_margin\": 20, \"y_margin\": 20, \"font_color_hex\": \"#ff0000\", \"image\": [\"102\", 0]}, \"class_type\": \"CR Simple Text Watermark\"}, \"166\": {\"inputs\": {\"lora_name\": \"SDXL\\\\Kodak Portra 400 analog film stocks v1.safetensors\", \"strength_model\": 1.0, \"model\": [\"108\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"167\": {\"inputs\": {\"lora_name\": \"SDXL\\\\Flux_artisketchyfs-v02.safetensors\", \"strength_model\": 0.22, \"model\": [\"166\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}}, \"workflow\": {\"last_node_id\": 167, \"last_link_id\": 753, \"nodes\": [{\"id\": 63, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 1816.8018798828125, \"1\": -25.4261417388916}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 0, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [98], \"slot_index\": 0, \"shape\": 3, \"label\": \"UPSCALE_MODEL\"}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x_NMKD-Siax_200k.pth\"]}, {\"id\": 64, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 2167.80126953125, \"1\": -153.4261016845703}, \"size\": {\"0\": 300, \"1\": 50}, \"flags\": {}, \"order\": 29, \"mode\": 4, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 98, \"slot_index\": 0, \"label\": \"upscale_model\"}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 99, \"slot_index\": 1, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [105], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"widgets_values\": []}, {\"id\": 71, \"type\": \"SaveImage\", \"pos\": {\"0\": 2979.896484375, \"1\": -163.5517120361328}, \"size\": {\"0\": 337.4764099121094, \"1\": 402.99481201171875}, \"flags\": {}, \"order\": 50, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 319, \"label\": \"images\"}], \"outputs\": [], \"title\": \"\\u0421\\u043e\\u0445\\u0440\\u0430\\u043d\\u0435\\u043d\\u0438\\u0435 \\u0433\\u0435\\u043d\\u0435\\u0440\\u0430\\u0446\\u0438\\u0438 \\u0441 Upscale (Hires)\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 102, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1481.15283203125, \"1\": -665.7596435546875}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 175, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 176, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [195], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 104, \"type\": \"BasicGuider\", \"pos\": {\"0\": 1435.15283203125, \"1\": -804.7596435546875}, \"size\": {\"0\": 240, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0, \"label\": \"model\"}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 206, \"slot_index\": 1, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [178], \"slot_index\": 0, \"shape\": 3, \"label\": \"GUIDER\"}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 124, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 2222, \"1\": -287}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"CONDITIONING\", \"type\": \"*\", \"link\": 205, \"color_on\": \"#FFA931\", \"label\": \"CONDITIONING\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 131, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1992, \"1\": -529}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"INT\", \"type\": \"*\", \"link\": 215, \"color_on\": \"#29699C\", \"label\": \"INT\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 132, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1803, \"1\": -526}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"INT\", \"type\": \"*\", \"link\": 216, \"color_on\": \"#29699C\", \"label\": \"INT\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 133, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 2341, \"1\": -837}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"SAMPLER\", \"type\": \"*\", \"link\": 217, \"color_on\": \"#ECB4B4\", \"label\": \"SAMPLER\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 135, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 2551, \"1\": -830}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"SIGMAS\", \"type\": \"*\", \"link\": 219, \"color_on\": \"#CDFFCD\", \"label\": \"SIGMAS\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 136, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 2128, \"1\": -837}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"NOISE\", \"type\": \"*\", \"link\": 220, \"color_on\": \"#B0B0B0\", \"label\": \"NOISE\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 157, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 760.2666625976562, \"1\": -329.2444763183594}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": false}, \"order\": 36, \"mode\": 4, \"inputs\": [{\"name\": \"IMAGE\", \"type\": \"*\", \"link\": 247, \"color_on\": \"#64B5F6\", \"label\": \"IMAGE\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 156, \"type\": \"VAEDecode\", \"pos\": {\"0\": 763.2666625976562, \"1\": -444.2444763183594}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {\"collapsed\": false}, \"order\": 20, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 246, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [247], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 155, \"type\": \"KSampler\", \"pos\": {\"0\": 370.26666259765625, \"1\": -547.2444458007812}, \"size\": {\"0\": 315, \"1\": 262}, \"flags\": {}, \"order\": 1, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": null, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": null, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": null, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [246], \"slot_index\": 0, \"label\": \"LATENT\"}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [737461146179432, \"randomize\", 30, 6, \"dpmpp_2m\", \"beta\", 1]}, {\"id\": 154, \"type\": \"Anything Everywhere3\", \"pos\": {\"0\": 769.2666625976562, \"1\": -818.2445068359375}, \"size\": {\"0\": 252, \"1\": 66}, \"flags\": {}, \"order\": 37, \"mode\": 4, \"inputs\": [{\"name\": \"MODEL\", \"type\": \"*\", \"link\": 251, \"color_on\": \"#B39DDB\", \"label\": \"MODEL\", \"shape\": 7}, {\"name\": \"CLIP\", \"type\": \"*\", \"link\": 248, \"color_on\": \"#FFD500\", \"label\": \"CLIP\", \"shape\": 7}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 245, \"color_on\": \"#FF6E6E\", \"label\": \"VAE\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere3\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 153, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": 381.26666259765625, \"1\": -820.2445068359375}, \"size\": {\"0\": 315, \"1\": 98}, \"flags\": {}, \"order\": 2, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [250], \"slot_index\": 0, \"shape\": 3, \"label\": \"MODEL\"}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [249], \"slot_index\": 1, \"shape\": 3, \"label\": \"CLIP\"}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [245], \"slot_index\": 2, \"shape\": 3, \"label\": \"VAE\"}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"Degenerate_deliberateV1.safetensors\"]}, {\"id\": 158, \"type\": \"LoraLoader\", \"pos\": {\"0\": 706.2667236328125, \"1\": -683.2444458007812}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 21, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 250, \"label\": \"model\"}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 249, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [251], \"slot_index\": 0, \"shape\": 3, \"label\": \"MODEL\"}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [248], \"slot_index\": 1, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"Concept Art Twilight Style SDXL_LoRA_Pony Diffusion V6 XL.safetensors\", 0, 1]}, {\"id\": 69, \"type\": \"VAEEncodeTiled\", \"pos\": {\"0\": 2497.5576171875, \"1\": -161.67327880859375}, \"size\": {\"0\": 210, \"1\": 84.27013397216797}, \"flags\": {}, \"order\": 40, \"mode\": 4, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 105, \"slot_index\": 0, \"label\": \"pixels\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null, \"slot_index\": 1, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [164], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}], \"properties\": {\"Node name for S&R\": \"VAEEncodeTiled\"}, \"widgets_values\": [1024]}, {\"id\": 161, \"type\": \"CR Simple Text Watermark\", \"pos\": {\"0\": 3034, \"1\": -681}, \"size\": {\"0\": 315, \"1\": 270}, \"flags\": {\"collapsed\": true}, \"order\": 3, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [262], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3, \"label\": \"show_help\"}], \"properties\": {\"Node name for S&R\": \"CR Simple Text Watermark\"}, \"widgets_values\": [\"\\u041e\\u0440\\u0438\\u0433\\u0438\\u043d\\u0430\\u043b\", \"bottom center\", 1, \"AlumniSansCollegiateOne-Regular.ttf\", 50, \"custom\", 20, 20, \"#ff0000\"]}, {\"id\": 163, \"type\": \"CR Simple Text Watermark\", \"pos\": {\"0\": 3027, \"1\": -615}, \"size\": {\"0\": 315, \"1\": 270}, \"flags\": {\"collapsed\": true}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 318, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [263], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3, \"label\": \"show_help\"}], \"properties\": {\"Node name for S&R\": \"CR Simple Text Watermark\"}, \"widgets_values\": [\"\\u0420\\u0435\\u0437\\u0443\\u043b\\u044c\\u0442\\u0430\\u0442 \\u043f\\u043e\\u0441\\u043b\\u0435 Hires\", \"bottom center\", 1, \"AlumniSansCollegiateOne-Regular.ttf\", 50, \"custom\", 20, 20, \"#ff0000\"]}, {\"id\": 30, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 368, \"1\": 59}, \"size\": {\"0\": 360, \"1\": 110}, \"flags\": {}, \"order\": 22, \"mode\": 4, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": null, \"label\": \"noise\"}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 54, \"label\": \"guider\"}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": null, \"label\": \"sampler\"}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": null, \"label\": \"sigmas\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": null, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [53], \"slot_index\": 0, \"shape\": 3, \"label\": \"output\"}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3, \"label\": \"denoised_output\"}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 774, \"1\": 121}, \"size\": {\"0\": 240, \"1\": 50}, \"flags\": {}, \"order\": 4, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0, \"label\": \"model\"}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": null, \"slot_index\": 1, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [54], \"slot_index\": 0, \"shape\": 3, \"label\": \"GUIDER\"}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 793, \"1\": 22}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 38, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 53, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null, \"slot_index\": 1, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [196], \"slot_index\": 0, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 116, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 815, \"1\": -25}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 42, \"mode\": 4, \"inputs\": [{\"name\": \"IMAGE\", \"type\": \"*\", \"link\": 196, \"color_on\": \"#64B5F6\", \"label\": \"IMAGE\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 165, \"type\": \"Anything Everywhere3\", \"pos\": {\"0\": 823, \"1\": -154}, \"size\": {\"0\": 168, \"1\": 66}, \"flags\": {}, \"order\": 23, \"mode\": 4, \"inputs\": [{\"name\": \"MODEL\", \"type\": \"*\", \"link\": 267, \"label\": \"MODEL\", \"shape\": 7, \"color_on\": \"#B39DDB\"}, {\"name\": \"CLIP\", \"type\": \"*\", \"link\": 268, \"label\": \"CLIP\", \"shape\": 7, \"color_on\": \"#FFD500\"}, {\"name\": \"VAE\", \"type\": \"*\", \"link\": 269, \"label\": \"VAE\", \"shape\": 7, \"color_on\": \"#FF6E6E\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere3\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 31, \"type\": \"CheckpointLoaderNF4\", \"pos\": {\"0\": 375, \"1\": -143}, \"size\": {\"0\": 408.759521484375, \"1\": 100.71900939941406}, \"flags\": {}, \"order\": 5, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [267], \"slot_index\": 0, \"shape\": 3, \"label\": \"MODEL\"}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [268], \"slot_index\": 1, \"shape\": 3, \"label\": \"CLIP\"}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [269], \"slot_index\": 2, \"shape\": 3, \"label\": \"VAE\"}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderNF4\"}, \"widgets_values\": [\"Degenerate_deliberateV1.safetensors\"]}, {\"id\": 97, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 1089, \"1\": -404}, \"size\": {\"0\": 293.1114501953125, \"1\": 106}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [202], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"flux\\\\t5xxl_fp8_e4m3fn.safetensors\", \"flux\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 98, \"type\": \"UNETLoader\", \"pos\": {\"0\": 1090, \"1\": -236}, \"size\": {\"0\": 289.5245056152344, \"1\": 88.92181396484375}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [224], \"slot_index\": 0, \"shape\": 3, \"label\": \"MODEL\"}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"]}, {\"id\": 96, \"type\": \"VAELoader\", \"pos\": {\"0\": 1095.15283203125, \"1\": -523.7596435546875}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [176, 192], \"slot_index\": 0, \"shape\": 3, \"label\": \"VAE\"}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"flux_vae.safetensors\"]}, {\"id\": 99, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 2124, \"1\": -790}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [217], \"slot_index\": 0, \"shape\": 3, \"label\": \"SAMPLER\"}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 134, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1452, \"1\": -304}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": false}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"MODEL\", \"type\": \"*\", \"link\": 283, \"color_on\": \"#B39DDB\", \"label\": \"MODEL\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 103, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1096, \"1\": -698}, \"size\": {\"0\": 360, \"1\": 110}, \"flags\": {\"collapsed\": false}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": null, \"slot_index\": 0, \"label\": \"noise\"}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 178, \"slot_index\": 1, \"label\": \"guider\"}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": null, \"slot_index\": 2, \"label\": \"sampler\"}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": null, \"slot_index\": 3, \"label\": \"sigmas\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": null, \"slot_index\": 4, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [175], \"slot_index\": 0, \"shape\": 3, \"label\": \"output\"}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3, \"label\": \"denoised_output\"}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 95, \"type\": \"Fast Groups Bypasser (rgthree)\", \"pos\": {\"0\": 1320, \"1\": 126}, \"size\": {\"0\": 434.7193603515625, \"1\": 112.7430419921875}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null, \"label\": \"OPT_CONNECTION\"}], \"title\": \"\\u0412\\u044b\\u0431\\u043e\\u0440 \\u043c\\u043e\\u0434\\u0435\\u043b\\u0438 \\u0434\\u043b\\u044f \\u0433\\u0435\\u043d\\u0435\\u0440\\u0430\\u0446\\u0438\\u0438\", \"properties\": {\"matchColors\": \"pale_blue\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"always one\"}, \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 68, \"type\": \"VAEDecodeTiled\", \"pos\": {\"0\": 2731.80126953125, \"1\": -161.4261016845703}, \"size\": {\"0\": 210, \"1\": 89.7719497680664}, \"flags\": {}, \"order\": 47, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 141, \"label\": \"samples\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null, \"slot_index\": 1, \"label\": \"vae\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [318, 319], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"VAEDecodeTiled\"}, \"widgets_values\": [1024]}, {\"id\": 85, \"type\": \"KSampler\", \"pos\": {\"0\": 2274.80126953125, \"1\": -28.42607307434082}, \"size\": {\"0\": 315, \"1\": 262}, \"flags\": {}, \"order\": 44, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"label\": \"model\"}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": null, \"label\": \"positive\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 140, \"label\": \"negative\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 164, \"label\": \"latent_image\"}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [141], \"slot_index\": 0, \"shape\": 3, \"tooltip\": \"The denoised latent.\", \"label\": \"LATENT\"}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [864745813409438, \"randomize\", 10, 1, \"euler\", \"simple\", 0.25], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 120, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1492, \"1\": -366}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"CLIP\", \"type\": \"*\", \"link\": 202, \"color_on\": \"#FFD500\", \"label\": \"CLIP\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 112, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1457, \"1\": -454}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"VAE\", \"type\": \"*\", \"link\": 192, \"color_on\": \"#FF6E6E\", \"label\": \"VAE\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 115, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1491, \"1\": -524}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"IMAGE\", \"type\": \"*\", \"link\": 195, \"color_on\": \"#64B5F6\", \"label\": \"IMAGE\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 109, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1791, \"1\": -880}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [220], \"slot_index\": 0, \"shape\": 3, \"label\": \"NOISE\"}], \"title\": \"Seed\", \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [389852199435043, \"randomize\"], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 86, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1821.8974609375, \"1\": 81.44808197021484}, \"size\": {\"0\": 420, \"1\": 160}, \"flags\": {}, \"order\": 12, \"mode\": 4, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [140], \"slot_index\": 0, \"label\": \"CONDITIONING\"}], \"title\": \"\\u041d\\u0435\\u0433\\u0430\\u0442\\u0438\\u0432\\u043d\\u044b\\u0439 \\u043f\\u0440\\u043e\\u043c\\u043f\\u0442\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"text, watermark,  asian\", true], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 130, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 2184, \"1\": -530}, \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"LATENT\", \"type\": \"*\", \"link\": 214, \"color_on\": \"#FF9CF9\", \"label\": \"LATENT\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 65, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 1815.8018798828125, \"1\": -154.4261016845703}, \"size\": {\"0\": 320, \"1\": 82}, \"flags\": {}, \"order\": 13, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null, \"slot_index\": 0, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [99], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.37]}, {\"id\": 159, \"type\": \"Fast Groups Bypasser (rgthree)\", \"pos\": {\"0\": 1330, \"1\": 293}, \"size\": {\"0\": 425.4561767578125, \"1\": 78.49747467041016}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null, \"label\": \"OPT_CONNECTION\"}], \"title\": \"\\u0412\\u043a\\u043b\\u044e\\u0447\\u0438\\u0442\\u044c Hires \\u043f\\u043e\\u0441\\u043b\\u0435 \\u0433\\u0435\\u043d\\u0435\\u0440\\u0430\\u0446\\u0438\\u0438\", \"properties\": {\"matchColors\": \"yellow\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}, \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 160, \"type\": \"Image Comparer (rgthree)\", \"pos\": {\"0\": 2882, \"1\": -793}, \"size\": {\"0\": 463.24591064453125, \"1\": 519.562255859375}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"link\": 262, \"dir\": 3, \"label\": \"image_a\"}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"link\": 263, \"dir\": 3, \"label\": \"image_b\"}], \"outputs\": [], \"properties\": {\"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A1\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rcexf_00619_.png&type=temp&subfolder=&rand=0.5391070946208498\"}, {\"name\": \"A2\", \"selected\": false, \"url\": \"/api/view?filename=rgthree.compare._temp_rcexf_00620_.png&type=temp&subfolder=&rand=0.639232688121693\"}, {\"name\": \"B1\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rcexf_00621_.png&type=temp&subfolder=&rand=0.13210475839086744\"}, {\"name\": \"B2\", \"selected\": false, \"url\": \"/api/view?filename=rgthree.compare._temp_rcexf_00622_.png&type=temp&subfolder=&rand=0.46681010255589794\"}]]}, {\"id\": 110, \"type\": \"SDXLEmptyLatentSizePicker+\", \"pos\": {\"0\": 1791, \"1\": -744}, \"size\": {\"0\": 309.3191833496094, \"1\": 170}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [214], \"slot_index\": 0, \"shape\": 3, \"label\": \"LATENT\"}, {\"name\": \"width\", \"type\": \"INT\", \"links\": [215], \"slot_index\": 1, \"shape\": 3, \"label\": \"width\"}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [216], \"slot_index\": 2, \"shape\": 3, \"label\": \"height\"}], \"title\": \"\\u0420\\u0430\\u0437\\u043c\\u0435\\u0440\\u044b \\u043a\\u0430\\u0440\\u0442\\u0438\\u043d\\u043a\\u0438\", \"properties\": {\"Node name for S&R\": \"SDXLEmptyLatentSizePicker+\"}, \"widgets_values\": [\"896x1152 (0.78)\", 2], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 167, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": 1422, \"1\": -202}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"collapsed\": false}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 284, \"slot_index\": 0, \"label\": \"model\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [283], \"slot_index\": 0, \"shape\": 3, \"label\": \"MODEL\"}], \"title\": \"\\u0412\\u044b\\u0431\\u043e\\u0440 \\u041b\\u043e\\u0440\\u044b \\u0434\\u043b\\u044f FLUX\", \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"SDXL\\\\Flux_artisketchyfs-v02.safetensors\", 0.22], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 166, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": 1420, \"1\": -66}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"collapsed\": false}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 271, \"label\": \"model\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [284], \"slot_index\": 0, \"shape\": 3, \"label\": \"MODEL\"}], \"title\": \"\\u0412\\u044b\\u0431\\u043e\\u0440 \\u041b\\u043e\\u0440\\u044b \\u0434\\u043b\\u044f FLUX\", \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"SDXL\\\\Kodak Portra 400 analog film stocks v1.safetensors\", 1], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 108, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": 1099, \"1\": -71}, \"size\": [300.4590790762454, 84.82654969398982], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 224, \"label\": \"model\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [271], \"slot_index\": 0, \"shape\": 3, \"label\": \"MODEL\"}], \"title\": \"\\u0412\\u044b\\u0431\\u043e\\u0440 \\u041b\\u043e\\u0440\\u044b \\u0434\\u043b\\u044f FLUX\", \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"SDXL\\\\flux.1_lora_flyway_Epic_gorgeous_Details_v1.safetensors\", 0.75], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 106, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 1093.15283203125, \"1\": -810.7596435546875}, \"size\": {\"0\": 317.4000244140625, \"1\": 58}, \"flags\": {\"collapsed\": false}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": null, \"label\": \"conditioning\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [206], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONDITIONING\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [2.7]}, {\"id\": 100, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 2125, \"1\": -684}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0, \"label\": \"model\"}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [219], \"shape\": 3, \"label\": \"SIGMAS\"}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 33, 1], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}, {\"id\": 111, \"type\": \"SaveImage\", \"pos\": {\"0\": 2455, \"1\": -789}, \"size\": {\"0\": 374.6842346191406, \"1\": 518.2783813476562}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": null, \"label\": \"images\"}], \"outputs\": [], \"title\": \"\\u0421\\u043e\\u0445\\u0440\\u0430\\u043d\\u0435\\u043d\\u0438\\u0435 \\u0433\\u0435\\u043d\\u0435\\u0440\\u0430\\u0446\\u0438\\u0438 \\u0431\\u0435\\u0437 HIRES\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 123, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1789, \"1\": -497}, \"size\": {\"0\": 645.6934814453125, \"1\": 226.56117248535156}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null, \"label\": \"clip\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [205], \"slot_index\": 0, \"label\": \"CONDITIONING\"}], \"title\": \"\\u041f\\u043e\\u0437\\u0438\\u0442\\u0438\\u0432\\u043d\\u044b\\u0439 \\u043f\\u0440\\u043e\\u043c\\u043f\\u0442\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"Mysticism. The concept. Surrealism. An allegory. A complex, multidimensional.\\n \\nNobody believes it,\\nMiracle of miracles:\\nA girl behind the flowers\\nHe goes to the winter forest.\\n\\nIt is not in the greenery,\\nLike in the July heat,\\nHe's snow-whitewashed,\\nIt shines white..\\n\\n\\nimpressive lighting, analog photography, cinematography, unimaginable quality, 8K, UHD, \\n\\n (Depth of field), Fujica GW690 camera, medium 20mm film. Kodak Portra 400 analog film stocks,  aidmaimageupgrader,\", true], \"color\": \"#476947\", \"bgcolor\": \"#335533\"}], \"links\": [[53, 30, 0, 8, 0, \"LATENT\"], [54, 22, 0, 30, 1, \"GUIDER\"], [98, 63, 0, 64, 0, \"UPSCALE_MODEL\"], [99, 65, 0, 64, 1, \"IMAGE\"], [105, 64, 0, 69, 0, \"IMAGE\"], [140, 86, 0, 85, 2, \"CONDITIONING\"], [141, 85, 0, 68, 0, \"LATENT\"], [164, 69, 0, 85, 3, \"LATENT\"], [175, 103, 0, 102, 0, \"LATENT\"], [176, 96, 0, 102, 1, \"VAE\"], [178, 104, 0, 103, 1, \"GUIDER\"], [192, 96, 0, 112, 0, \"VAE\"], [195, 102, 0, 115, 0, \"IMAGE\"], [196, 8, 0, 116, 0, \"IMAGE\"], [202, 97, 0, 120, 0, \"CLIP\"], [205, 123, 0, 124, 0, \"CONDITIONING\"], [206, 106, 0, 104, 1, \"CONDITIONING\"], [214, 110, 0, 130, 0, \"LATENT\"], [215, 110, 1, 131, 0, \"INT\"], [216, 110, 2, 132, 0, \"INT\"], [217, 99, 0, 133, 0, \"SAMPLER\"], [219, 100, 0, 135, 0, \"SIGMAS\"], [220, 109, 0, 136, 0, \"NOISE\"], [224, 98, 0, 108, 0, \"MODEL\"], [245, 153, 2, 154, 2, \"VAE\"], [246, 155, 0, 156, 0, \"LATENT\"], [247, 156, 0, 157, 0, \"IMAGE\"], [248, 158, 1, 154, 1, \"CLIP\"], [249, 153, 1, 158, 1, \"CLIP\"], [250, 153, 0, 158, 0, \"MODEL\"], [251, 158, 0, 154, 0, \"MODEL\"], [252, 156, 0, 93, 0, \"IMAGE\"], [253, 156, 0, 93, 1, \"IMAGE\"], [254, 156, 0, 111, 0, \"IMAGE\"], [255, 153, 0, 100, 0, \"MODEL\"], [256, 153, 2, 156, 1, \"VAE\"], [257, 153, 0, 155, 0, \"MODEL\"], [258, 123, 0, 155, 1, \"CONDITIONING\"], [259, 123, 0, 155, 2, \"CONDITIONING\"], [260, 110, 0, 155, 3, \"LATENT\"], [261, 153, 1, 123, 0, \"CLIP\"], [262, 161, 0, 160, 0, \"IMAGE\"], [263, 163, 0, 160, 1, \"IMAGE\"], [267, 31, 0, 165, 0, \"MODEL\"], [268, 31, 1, 165, 1, \"CLIP\"], [269, 31, 2, 165, 2, \"VAE\"], [271, 108, 0, 166, 0, \"MODEL\"], [272, 109, 0, 103, 0, \"NOISE\"], [273, 99, 0, 103, 2, \"SAMPLER\"], [274, 100, 0, 103, 3, \"SIGMAS\"], [275, 110, 0, 103, 4, \"LATENT\"], [276, 166, 0, 104, 0, \"MODEL\"], [277, 123, 0, 106, 0, \"CONDITIONING\"], [278, 102, 0, 161, 0, \"IMAGE\"], [279, 102, 0, 163, 0, \"IMAGE\"], [280, 102, 0, 111, 0, \"IMAGE\"], [281, 166, 0, 100, 0, \"MODEL\"], [282, 97, 0, 123, 0, \"CLIP\"], [283, 167, 0, 134, 0, \"MODEL\"], [284, 166, 0, 167, 0, \"MODEL\"], [285, 109, 0, 103, 0, \"NOISE\"], [286, 99, 0, 103, 2, \"SAMPLER\"], [287, 100, 0, 103, 3, \"SIGMAS\"], [288, 110, 0, 103, 4, \"LATENT\"], [289, 166, 0, 104, 0, \"MODEL\"], [290, 123, 0, 106, 0, \"CONDITIONING\"], [291, 102, 0, 161, 0, \"IMAGE\"], [292, 102, 0, 163, 0, \"IMAGE\"], [293, 102, 0, 111, 0, \"IMAGE\"], [294, 166, 0, 100, 0, \"MODEL\"], [295, 97, 0, 123, 0, \"CLIP\"], [296, 109, 0, 103, 0, \"NOISE\"], [297, 99, 0, 103, 2, \"SAMPLER\"], [298, 100, 0, 103, 3, \"SIGMAS\"], [299, 110, 0, 103, 4, \"LATENT\"], [300, 166, 0, 104, 0, \"MODEL\"], [301, 102, 0, 161, 0, \"IMAGE\"], [302, 102, 0, 163, 0, \"IMAGE\"], [303, 102, 0, 111, 0, \"IMAGE\"], [304, 123, 0, 106, 0, \"CONDITIONING\"], [305, 97, 0, 123, 0, \"CLIP\"], [306, 166, 0, 100, 0, \"MODEL\"], [307, 98, 0, 104, 0, \"MODEL\"], [308, 102, 0, 161, 0, \"IMAGE\"], [309, 102, 0, 163, 0, \"IMAGE\"], [310, 102, 0, 111, 0, \"IMAGE\"], [311, 123, 0, 106, 0, \"CONDITIONING\"], [312, 109, 0, 103, 0, \"NOISE\"], [313, 99, 0, 103, 2, \"SAMPLER\"], [314, 100, 0, 103, 3, \"SIGMAS\"], [315, 110, 0, 103, 4, \"LATENT\"], [316, 97, 0, 123, 0, \"CLIP\"], [317, 98, 0, 100, 0, \"MODEL\"], [318, 68, 0, 163, 0, \"IMAGE\"], [319, 68, 0, 71, 0, \"IMAGE\"], [320, 167, 0, 104, 0, \"MODEL\"], [321, 102, 0, 161, 0, \"IMAGE\"], [322, 102, 0, 163, 0, \"IMAGE\"], [323, 109, 0, 103, 0, \"NOISE\"], [324, 99, 0, 103, 2, \"SAMPLER\"], [325, 100, 0, 103, 3, \"SIGMAS\"], [326, 110, 0, 103, 4, \"LATENT\"], [327, 102, 0, 111, 0, \"IMAGE\"], [328, 123, 0, 106, 0, \"CONDITIONING\"], [329, 167, 0, 100, 0, \"MODEL\"], [330, 97, 0, 123, 0, \"CLIP\"], [331, 167, 0, 104, 0, \"MODEL\"], [332, 102, 0, 161, 0, \"IMAGE\"], [333, 102, 0, 163, 0, \"IMAGE\"], [334, 109, 0, 103, 0, \"NOISE\"], [335, 99, 0, 103, 2, \"SAMPLER\"], [336, 100, 0, 103, 3, \"SIGMAS\"], [337, 110, 0, 103, 4, \"LATENT\"], [338, 102, 0, 111, 0, \"IMAGE\"], [339, 123, 0, 106, 0, \"CONDITIONING\"], [340, 97, 0, 123, 0, \"CLIP\"], [341, 167, 0, 100, 0, \"MODEL\"], [342, 167, 0, 104, 0, \"MODEL\"], [343, 102, 0, 161, 0, \"IMAGE\"], [344, 102, 0, 163, 0, \"IMAGE\"], [345, 109, 0, 103, 0, \"NOISE\"], [346, 99, 0, 103, 2, \"SAMPLER\"], [347, 100, 0, 103, 3, \"SIGMAS\"], [348, 110, 0, 103, 4, \"LATENT\"], [349, 102, 0, 111, 0, \"IMAGE\"], [350, 123, 0, 106, 0, \"CONDITIONING\"], [351, 97, 0, 123, 0, \"CLIP\"], [352, 167, 0, 100, 0, \"MODEL\"], [353, 167, 0, 104, 0, \"MODEL\"], [354, 102, 0, 161, 0, \"IMAGE\"], [355, 102, 0, 163, 0, \"IMAGE\"], [356, 109, 0, 103, 0, \"NOISE\"], [357, 99, 0, 103, 2, \"SAMPLER\"], [358, 100, 0, 103, 3, \"SIGMAS\"], [359, 110, 0, 103, 4, \"LATENT\"], [360, 102, 0, 111, 0, \"IMAGE\"], [361, 167, 0, 100, 0, \"MODEL\"], [362, 123, 0, 106, 0, \"CONDITIONING\"], [363, 97, 0, 123, 0, \"CLIP\"], [364, 167, 0, 104, 0, \"MODEL\"], [365, 102, 0, 161, 0, \"IMAGE\"], [366, 102, 0, 163, 0, \"IMAGE\"], [367, 109, 0, 103, 0, \"NOISE\"], [368, 99, 0, 103, 2, \"SAMPLER\"], [369, 100, 0, 103, 3, \"SIGMAS\"], [370, 110, 0, 103, 4, \"LATENT\"], [371, 102, 0, 111, 0, \"IMAGE\"], [372, 167, 0, 100, 0, \"MODEL\"], [373, 123, 0, 106, 0, \"CONDITIONING\"], [374, 97, 0, 123, 0, \"CLIP\"], [375, 167, 0, 104, 0, \"MODEL\"], [376, 102, 0, 161, 0, \"IMAGE\"], [377, 102, 0, 163, 0, \"IMAGE\"], [378, 109, 0, 103, 0, \"NOISE\"], [379, 99, 0, 103, 2, \"SAMPLER\"], [380, 100, 0, 103, 3, \"SIGMAS\"], [381, 110, 0, 103, 4, \"LATENT\"], [382, 102, 0, 111, 0, \"IMAGE\"], [383, 123, 0, 106, 0, \"CONDITIONING\"], [384, 167, 0, 100, 0, \"MODEL\"], [385, 97, 0, 123, 0, \"CLIP\"], [386, 167, 0, 104, 0, \"MODEL\"], [387, 102, 0, 161, 0, \"IMAGE\"], [388, 102, 0, 163, 0, \"IMAGE\"], [389, 109, 0, 103, 0, \"NOISE\"], [390, 99, 0, 103, 2, \"SAMPLER\"], [391, 100, 0, 103, 3, \"SIGMAS\"], [392, 110, 0, 103, 4, \"LATENT\"], [393, 102, 0, 111, 0, \"IMAGE\"], [394, 123, 0, 106, 0, \"CONDITIONING\"], [395, 97, 0, 123, 0, \"CLIP\"], [396, 167, 0, 100, 0, \"MODEL\"], [397, 167, 0, 104, 0, \"MODEL\"], [398, 102, 0, 161, 0, \"IMAGE\"], [399, 102, 0, 163, 0, \"IMAGE\"], [400, 109, 0, 103, 0, \"NOISE\"], [401, 99, 0, 103, 2, \"SAMPLER\"], [402, 100, 0, 103, 3, \"SIGMAS\"], [403, 110, 0, 103, 4, \"LATENT\"], [404, 102, 0, 111, 0, \"IMAGE\"], [405, 123, 0, 106, 0, \"CONDITIONING\"], [406, 97, 0, 123, 0, \"CLIP\"], [407, 167, 0, 100, 0, \"MODEL\"], [408, 167, 0, 104, 0, \"MODEL\"], [409, 102, 0, 161, 0, \"IMAGE\"], [410, 102, 0, 163, 0, \"IMAGE\"], [411, 109, 0, 103, 0, \"NOISE\"], [412, 99, 0, 103, 2, \"SAMPLER\"], [413, 100, 0, 103, 3, \"SIGMAS\"], [414, 110, 0, 103, 4, \"LATENT\"], [415, 102, 0, 111, 0, \"IMAGE\"], [416, 123, 0, 106, 0, \"CONDITIONING\"], [417, 167, 0, 100, 0, \"MODEL\"], [418, 97, 0, 123, 0, \"CLIP\"], [419, 167, 0, 104, 0, \"MODEL\"], [420, 102, 0, 161, 0, \"IMAGE\"], [421, 102, 0, 163, 0, \"IMAGE\"], [422, 109, 0, 103, 0, \"NOISE\"], [423, 99, 0, 103, 2, \"SAMPLER\"], [424, 100, 0, 103, 3, \"SIGMAS\"], [425, 110, 0, 103, 4, \"LATENT\"], [426, 102, 0, 111, 0, \"IMAGE\"], [427, 97, 0, 123, 0, \"CLIP\"], [428, 123, 0, 106, 0, \"CONDITIONING\"], [429, 167, 0, 100, 0, \"MODEL\"], [430, 167, 0, 104, 0, \"MODEL\"], [431, 102, 0, 161, 0, \"IMAGE\"], [432, 102, 0, 163, 0, \"IMAGE\"], [433, 109, 0, 103, 0, \"NOISE\"], [434, 99, 0, 103, 2, \"SAMPLER\"], [435, 100, 0, 103, 3, \"SIGMAS\"], [436, 110, 0, 103, 4, \"LATENT\"], [437, 102, 0, 111, 0, \"IMAGE\"], [438, 97, 0, 123, 0, \"CLIP\"], [439, 123, 0, 106, 0, \"CONDITIONING\"], [440, 167, 0, 100, 0, \"MODEL\"], [441, 167, 0, 104, 0, \"MODEL\"], [442, 102, 0, 161, 0, \"IMAGE\"], [443, 102, 0, 163, 0, \"IMAGE\"], [444, 109, 0, 103, 0, \"NOISE\"], [445, 99, 0, 103, 2, \"SAMPLER\"], [446, 100, 0, 103, 3, \"SIGMAS\"], [447, 110, 0, 103, 4, \"LATENT\"], [448, 102, 0, 111, 0, \"IMAGE\"], [449, 123, 0, 106, 0, \"CONDITIONING\"], [450, 97, 0, 123, 0, \"CLIP\"], [451, 167, 0, 100, 0, \"MODEL\"], [452, 167, 0, 104, 0, \"MODEL\"], [453, 102, 0, 161, 0, \"IMAGE\"], [454, 102, 0, 163, 0, \"IMAGE\"], [455, 109, 0, 103, 0, \"NOISE\"], [456, 99, 0, 103, 2, \"SAMPLER\"], [457, 100, 0, 103, 3, \"SIGMAS\"], [458, 110, 0, 103, 4, \"LATENT\"], [459, 102, 0, 111, 0, \"IMAGE\"], [460, 123, 0, 106, 0, \"CONDITIONING\"], [461, 167, 0, 100, 0, \"MODEL\"], [462, 97, 0, 123, 0, \"CLIP\"], [463, 167, 0, 104, 0, \"MODEL\"], [464, 102, 0, 161, 0, \"IMAGE\"], [465, 102, 0, 163, 0, \"IMAGE\"], [466, 109, 0, 103, 0, \"NOISE\"], [467, 99, 0, 103, 2, \"SAMPLER\"], [468, 100, 0, 103, 3, \"SIGMAS\"], [469, 110, 0, 103, 4, \"LATENT\"], [470, 102, 0, 111, 0, \"IMAGE\"], [471, 123, 0, 106, 0, \"CONDITIONING\"], [472, 97, 0, 123, 0, \"CLIP\"], [473, 167, 0, 100, 0, \"MODEL\"], [474, 167, 0, 104, 0, \"MODEL\"], [475, 102, 0, 161, 0, \"IMAGE\"], [476, 102, 0, 163, 0, \"IMAGE\"], [477, 109, 0, 103, 0, \"NOISE\"], [478, 99, 0, 103, 2, \"SAMPLER\"], [479, 100, 0, 103, 3, \"SIGMAS\"], [480, 110, 0, 103, 4, \"LATENT\"], [481, 123, 0, 106, 0, \"CONDITIONING\"], [482, 102, 0, 111, 0, \"IMAGE\"], [483, 167, 0, 100, 0, \"MODEL\"], [484, 97, 0, 123, 0, \"CLIP\"], [485, 167, 0, 104, 0, \"MODEL\"], [486, 102, 0, 161, 0, \"IMAGE\"], [487, 102, 0, 163, 0, \"IMAGE\"], [488, 109, 0, 103, 0, \"NOISE\"], [489, 99, 0, 103, 2, \"SAMPLER\"], [490, 100, 0, 103, 3, \"SIGMAS\"], [491, 110, 0, 103, 4, \"LATENT\"], [492, 123, 0, 106, 0, \"CONDITIONING\"], [493, 102, 0, 111, 0, \"IMAGE\"], [494, 97, 0, 123, 0, \"CLIP\"], [495, 167, 0, 100, 0, \"MODEL\"], [496, 167, 0, 104, 0, \"MODEL\"], [497, 102, 0, 161, 0, \"IMAGE\"], [498, 102, 0, 163, 0, \"IMAGE\"], [499, 109, 0, 103, 0, \"NOISE\"], [500, 99, 0, 103, 2, \"SAMPLER\"], [501, 100, 0, 103, 3, \"SIGMAS\"], [502, 110, 0, 103, 4, \"LATENT\"], [503, 123, 0, 106, 0, \"CONDITIONING\"], [504, 102, 0, 111, 0, \"IMAGE\"], [505, 97, 0, 123, 0, \"CLIP\"], [506, 167, 0, 100, 0, \"MODEL\"], [507, 167, 0, 104, 0, \"MODEL\"], [508, 102, 0, 161, 0, \"IMAGE\"], [509, 102, 0, 163, 0, \"IMAGE\"], [510, 109, 0, 103, 0, \"NOISE\"], [511, 99, 0, 103, 2, \"SAMPLER\"], [512, 100, 0, 103, 3, \"SIGMAS\"], [513, 110, 0, 103, 4, \"LATENT\"], [514, 123, 0, 106, 0, \"CONDITIONING\"], [515, 102, 0, 111, 0, \"IMAGE\"], [516, 167, 0, 100, 0, \"MODEL\"], [517, 97, 0, 123, 0, \"CLIP\"], [518, 167, 0, 104, 0, \"MODEL\"], [519, 102, 0, 161, 0, \"IMAGE\"], [520, 102, 0, 163, 0, \"IMAGE\"], [521, 109, 0, 103, 0, \"NOISE\"], [522, 99, 0, 103, 2, \"SAMPLER\"], [523, 100, 0, 103, 3, \"SIGMAS\"], [524, 110, 0, 103, 4, \"LATENT\"], [525, 123, 0, 106, 0, \"CONDITIONING\"], [526, 102, 0, 111, 0, \"IMAGE\"], [527, 97, 0, 123, 0, \"CLIP\"], [528, 167, 0, 100, 0, \"MODEL\"], [529, 166, 0, 104, 0, \"MODEL\"], [530, 102, 0, 161, 0, \"IMAGE\"], [531, 102, 0, 163, 0, \"IMAGE\"], [532, 109, 0, 103, 0, \"NOISE\"], [533, 99, 0, 103, 2, \"SAMPLER\"], [534, 100, 0, 103, 3, \"SIGMAS\"], [535, 110, 0, 103, 4, \"LATENT\"], [536, 102, 0, 111, 0, \"IMAGE\"], [537, 166, 0, 100, 0, \"MODEL\"], [538, 123, 0, 106, 0, \"CONDITIONING\"], [539, 97, 0, 123, 0, \"CLIP\"], [540, 167, 0, 104, 0, \"MODEL\"], [541, 102, 0, 161, 0, \"IMAGE\"], [542, 102, 0, 163, 0, \"IMAGE\"], [543, 109, 0, 103, 0, \"NOISE\"], [544, 99, 0, 103, 2, \"SAMPLER\"], [545, 100, 0, 103, 3, \"SIGMAS\"], [546, 110, 0, 103, 4, \"LATENT\"], [547, 167, 0, 100, 0, \"MODEL\"], [548, 102, 0, 111, 0, \"IMAGE\"], [549, 123, 0, 106, 0, \"CONDITIONING\"], [550, 97, 0, 123, 0, \"CLIP\"], [551, 167, 0, 104, 0, \"MODEL\"], [552, 102, 0, 161, 0, \"IMAGE\"], [553, 102, 0, 163, 0, \"IMAGE\"], [554, 109, 0, 103, 0, \"NOISE\"], [555, 99, 0, 103, 2, \"SAMPLER\"], [556, 100, 0, 103, 3, \"SIGMAS\"], [557, 110, 0, 103, 4, \"LATENT\"], [558, 167, 0, 100, 0, \"MODEL\"], [559, 123, 0, 106, 0, \"CONDITIONING\"], [560, 102, 0, 111, 0, \"IMAGE\"], [561, 97, 0, 123, 0, \"CLIP\"], [562, 167, 0, 104, 0, \"MODEL\"], [563, 102, 0, 161, 0, \"IMAGE\"], [564, 102, 0, 163, 0, \"IMAGE\"], [565, 109, 0, 103, 0, \"NOISE\"], [566, 99, 0, 103, 2, \"SAMPLER\"], [567, 100, 0, 103, 3, \"SIGMAS\"], [568, 110, 0, 103, 4, \"LATENT\"], [569, 167, 0, 100, 0, \"MODEL\"], [570, 123, 0, 106, 0, \"CONDITIONING\"], [571, 102, 0, 111, 0, \"IMAGE\"], [572, 97, 0, 123, 0, \"CLIP\"], [573, 167, 0, 104, 0, \"MODEL\"], [574, 102, 0, 161, 0, \"IMAGE\"], [575, 102, 0, 163, 0, \"IMAGE\"], [576, 109, 0, 103, 0, \"NOISE\"], [577, 99, 0, 103, 2, \"SAMPLER\"], [578, 100, 0, 103, 3, \"SIGMAS\"], [579, 110, 0, 103, 4, \"LATENT\"], [580, 123, 0, 106, 0, \"CONDITIONING\"], [581, 167, 0, 100, 0, \"MODEL\"], [582, 102, 0, 111, 0, \"IMAGE\"], [583, 97, 0, 123, 0, \"CLIP\"], [584, 167, 0, 104, 0, \"MODEL\"], [585, 102, 0, 161, 0, \"IMAGE\"], [586, 102, 0, 163, 0, \"IMAGE\"], [587, 109, 0, 103, 0, \"NOISE\"], [588, 99, 0, 103, 2, \"SAMPLER\"], [589, 100, 0, 103, 3, \"SIGMAS\"], [590, 110, 0, 103, 4, \"LATENT\"], [591, 102, 0, 111, 0, \"IMAGE\"], [592, 123, 0, 106, 0, \"CONDITIONING\"], [593, 167, 0, 100, 0, \"MODEL\"], [594, 97, 0, 123, 0, \"CLIP\"], [595, 167, 0, 104, 0, \"MODEL\"], [596, 102, 0, 161, 0, \"IMAGE\"], [597, 102, 0, 163, 0, \"IMAGE\"], [598, 109, 0, 103, 0, \"NOISE\"], [599, 99, 0, 103, 2, \"SAMPLER\"], [600, 100, 0, 103, 3, \"SIGMAS\"], [601, 110, 0, 103, 4, \"LATENT\"], [602, 123, 0, 106, 0, \"CONDITIONING\"], [603, 102, 0, 111, 0, \"IMAGE\"], [604, 97, 0, 123, 0, \"CLIP\"], [605, 167, 0, 100, 0, \"MODEL\"], [606, 167, 0, 104, 0, \"MODEL\"], [607, 102, 0, 161, 0, \"IMAGE\"], [608, 102, 0, 163, 0, \"IMAGE\"], [609, 109, 0, 103, 0, \"NOISE\"], [610, 99, 0, 103, 2, \"SAMPLER\"], [611, 100, 0, 103, 3, \"SIGMAS\"], [612, 110, 0, 103, 4, \"LATENT\"], [613, 123, 0, 106, 0, \"CONDITIONING\"], [614, 102, 0, 111, 0, \"IMAGE\"], [615, 167, 0, 100, 0, \"MODEL\"], [616, 97, 0, 123, 0, \"CLIP\"], [617, 166, 0, 104, 0, \"MODEL\"], [618, 102, 0, 161, 0, \"IMAGE\"], [619, 102, 0, 163, 0, \"IMAGE\"], [620, 109, 0, 103, 0, \"NOISE\"], [621, 99, 0, 103, 2, \"SAMPLER\"], [622, 100, 0, 103, 3, \"SIGMAS\"], [623, 110, 0, 103, 4, \"LATENT\"], [624, 123, 0, 106, 0, \"CONDITIONING\"], [625, 166, 0, 100, 0, \"MODEL\"], [626, 97, 0, 123, 0, \"CLIP\"], [627, 102, 0, 111, 0, \"IMAGE\"], [628, 167, 0, 104, 0, \"MODEL\"], [629, 102, 0, 161, 0, \"IMAGE\"], [630, 102, 0, 163, 0, \"IMAGE\"], [631, 109, 0, 103, 0, \"NOISE\"], [632, 99, 0, 103, 2, \"SAMPLER\"], [633, 100, 0, 103, 3, \"SIGMAS\"], [634, 110, 0, 103, 4, \"LATENT\"], [635, 123, 0, 106, 0, \"CONDITIONING\"], [636, 97, 0, 123, 0, \"CLIP\"], [637, 102, 0, 111, 0, \"IMAGE\"], [638, 167, 0, 100, 0, \"MODEL\"], [639, 167, 0, 104, 0, \"MODEL\"], [640, 102, 0, 161, 0, \"IMAGE\"], [641, 102, 0, 163, 0, \"IMAGE\"], [642, 109, 0, 103, 0, \"NOISE\"], [643, 99, 0, 103, 2, \"SAMPLER\"], [644, 100, 0, 103, 3, \"SIGMAS\"], [645, 110, 0, 103, 4, \"LATENT\"], [646, 123, 0, 106, 0, \"CONDITIONING\"], [647, 102, 0, 111, 0, \"IMAGE\"], [648, 167, 0, 100, 0, \"MODEL\"], [649, 97, 0, 123, 0, \"CLIP\"], [650, 167, 0, 104, 0, \"MODEL\"], [651, 102, 0, 161, 0, \"IMAGE\"], [652, 102, 0, 163, 0, \"IMAGE\"], [653, 109, 0, 103, 0, \"NOISE\"], [654, 99, 0, 103, 2, \"SAMPLER\"], [655, 100, 0, 103, 3, \"SIGMAS\"], [656, 110, 0, 103, 4, \"LATENT\"], [657, 123, 0, 106, 0, \"CONDITIONING\"], [658, 102, 0, 111, 0, \"IMAGE\"], [659, 167, 0, 100, 0, \"MODEL\"], [660, 97, 0, 123, 0, \"CLIP\"], [661, 167, 0, 104, 0, \"MODEL\"], [662, 102, 0, 161, 0, \"IMAGE\"], [663, 102, 0, 163, 0, \"IMAGE\"], [664, 109, 0, 103, 0, \"NOISE\"], [665, 99, 0, 103, 2, \"SAMPLER\"], [666, 100, 0, 103, 3, \"SIGMAS\"], [667, 110, 0, 103, 4, \"LATENT\"], [668, 123, 0, 106, 0, \"CONDITIONING\"], [669, 167, 0, 100, 0, \"MODEL\"], [670, 102, 0, 111, 0, \"IMAGE\"], [671, 97, 0, 123, 0, \"CLIP\"], [672, 98, 0, 104, 0, \"MODEL\"], [673, 102, 0, 161, 0, \"IMAGE\"], [674, 102, 0, 163, 0, \"IMAGE\"], [675, 109, 0, 103, 0, \"NOISE\"], [676, 99, 0, 103, 2, \"SAMPLER\"], [677, 100, 0, 103, 3, \"SIGMAS\"], [678, 110, 0, 103, 4, \"LATENT\"], [679, 123, 0, 106, 0, \"CONDITIONING\"], [680, 102, 0, 111, 0, \"IMAGE\"], [681, 97, 0, 123, 0, \"CLIP\"], [682, 98, 0, 100, 0, \"MODEL\"], [683, 167, 0, 104, 0, \"MODEL\"], [684, 102, 0, 161, 0, \"IMAGE\"], [685, 102, 0, 163, 0, \"IMAGE\"], [686, 109, 0, 103, 0, \"NOISE\"], [687, 99, 0, 103, 2, \"SAMPLER\"], [688, 100, 0, 103, 3, \"SIGMAS\"], [689, 110, 0, 103, 4, \"LATENT\"], [690, 167, 0, 100, 0, \"MODEL\"], [691, 123, 0, 106, 0, \"CONDITIONING\"], [692, 102, 0, 111, 0, \"IMAGE\"], [693, 97, 0, 123, 0, \"CLIP\"], [694, 167, 0, 104, 0, \"MODEL\"], [695, 102, 0, 161, 0, \"IMAGE\"], [696, 102, 0, 163, 0, \"IMAGE\"], [697, 109, 0, 103, 0, \"NOISE\"], [698, 99, 0, 103, 2, \"SAMPLER\"], [699, 100, 0, 103, 3, \"SIGMAS\"], [700, 110, 0, 103, 4, \"LATENT\"], [701, 167, 0, 100, 0, \"MODEL\"], [702, 123, 0, 106, 0, \"CONDITIONING\"], [703, 102, 0, 111, 0, \"IMAGE\"], [704, 97, 0, 123, 0, \"CLIP\"], [705, 166, 0, 104, 0, \"MODEL\"], [706, 96, 0, 69, 1, \"VAE\"], [707, 102, 0, 161, 0, \"IMAGE\"], [708, 109, 0, 103, 0, \"NOISE\"], [709, 99, 0, 103, 2, \"SAMPLER\"], [710, 100, 0, 103, 3, \"SIGMAS\"], [711, 110, 0, 103, 4, \"LATENT\"], [712, 96, 0, 68, 1, \"VAE\"], [713, 166, 0, 85, 0, \"MODEL\"], [714, 123, 0, 85, 1, \"CONDITIONING\"], [715, 97, 0, 86, 0, \"CLIP\"], [716, 123, 0, 106, 0, \"CONDITIONING\"], [717, 166, 0, 100, 0, \"MODEL\"], [718, 102, 0, 65, 0, \"IMAGE\"], [719, 102, 0, 111, 0, \"IMAGE\"], [720, 97, 0, 123, 0, \"CLIP\"], [721, 167, 0, 104, 0, \"MODEL\"], [722, 102, 0, 161, 0, \"IMAGE\"], [723, 102, 0, 163, 0, \"IMAGE\"], [724, 109, 0, 103, 0, \"NOISE\"], [725, 99, 0, 103, 2, \"SAMPLER\"], [726, 100, 0, 103, 3, \"SIGMAS\"], [727, 110, 0, 103, 4, \"LATENT\"], [728, 123, 0, 106, 0, \"CONDITIONING\"], [729, 167, 0, 100, 0, \"MODEL\"], [730, 102, 0, 111, 0, \"IMAGE\"], [731, 97, 0, 123, 0, \"CLIP\"], [732, 166, 0, 104, 0, \"MODEL\"], [733, 102, 0, 161, 0, \"IMAGE\"], [734, 102, 0, 163, 0, \"IMAGE\"], [735, 109, 0, 103, 0, \"NOISE\"], [736, 99, 0, 103, 2, \"SAMPLER\"], [737, 100, 0, 103, 3, \"SIGMAS\"], [738, 110, 0, 103, 4, \"LATENT\"], [739, 123, 0, 106, 0, \"CONDITIONING\"], [740, 166, 0, 100, 0, \"MODEL\"], [741, 102, 0, 111, 0, \"IMAGE\"], [742, 97, 0, 123, 0, \"CLIP\"], [743, 167, 0, 104, 0, \"MODEL\"], [744, 102, 0, 161, 0, \"IMAGE\"], [745, 102, 0, 163, 0, \"IMAGE\"], [746, 109, 0, 103, 0, \"NOISE\"], [747, 99, 0, 103, 2, \"SAMPLER\"], [748, 100, 0, 103, 3, \"SIGMAS\"], [749, 110, 0, 103, 4, \"LATENT\"], [750, 123, 0, 106, 0, \"CONDITIONING\"], [751, 167, 0, 100, 0, \"MODEL\"], [752, 102, 0, 111, 0, \"IMAGE\"], [753, 97, 0, 123, 0, \"CLIP\"]], \"groups\": [{\"title\": \"\\u0413\\u0435\\u043d\\u0435\\u0440\\u0430\\u0446\\u0438\\u044f \\u043a\\u0430\\u0440\\u0442\\u0438\\u043d\\u043a\\u0438 \\u0432 SD/SDXL\", \"bounding\": [349, -917, 693, 654], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"\\u0413\\u0435\\u043d\\u0435\\u0440\\u0430\\u0446\\u0438\\u044f \\u043a\\u0430\\u0440\\u0442\\u0438\\u043d\\u043a\\u0438 \\u0432 FLUX (fp16, fp8)\", \"bounding\": [1067, -912, 695, 958], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Hires.fix\", \"bounding\": [1788, -243, 1549, 495], \"color\": \"#b58b2a\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"\\u0413\\u0435\\u043d\\u0435\\u0440\\u0430\\u0446\\u0438\\u044f \\u043a\\u0430\\u0440\\u0442\\u0438\\u043d\\u043a\\u0438 \\u0432 FLUX BNB NF4\", \"bounding\": [347, -239, 692, 430], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.8797616762370812, \"offset\": [-1566.7965482671932, 859.4711340993842]}}, \"version\": 0.4, \"widget_idx_map\": {\"85\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"99\": {\"sampler_name\": 0}, \"100\": {\"scheduler\": 0}, \"109\": {\"noise_seed\": 0}, \"155\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"85\": 0, \"109\": 0, \"155\": 0}}}",
            "steps": 33,
            "models": [],
            "prompt": "Mysticism. The concept. Surrealism. An allegory. A complex, multidimensional.\n \nNobody believes it,\nMiracle of miracles:\nA girl behind the flowers\nHe goes to the winter forest.\n\nIt is not in the greenery,\nLike in the July heat,\nHe's snow-whitewashed,\nIt shines white..\n\n\nimpressive lighting, analog photography, cinematography, unimaginable quality, 8K, UHD, \n\n (Depth of field), Fujica GW690 camera, medium 20mm film. Kodak Portra 400 analog film stocks,  aidmaimageupgrader,",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 2.7,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "SDXL\\flux.1_lora_flyway_Epic_gorgeous_Details_v1.safetensors",
                    "type": "lora",
                    "strength": 0.75
                },
                {
                    "name": "SDXL\\Kodak Portra 400 analog film stocks v1.safetensors",
                    "type": "lora",
                    "strength": 1
                },
                {
                    "name": "SDXL\\Flux_artisketchyfs-v02.safetensors",
                    "type": "lora",
                    "strength": 0.22
                }
            ]
        },
        "username": "doc_team",
        "baseModel": null
    },
    {
        "id": 36656882,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2c1c45c3-0f51-4f25-bb04-4feef35d41fa/width=832/2c1c45c3-0f51-4f25-bb04-4feef35d41fa.jpeg",
        "hash": "U9DIarRO00?wNfEhnNoLAH%0RjRj0gkCX8IU",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-26T11:55:00.706Z",
        "postId": 8373040,
        "stats": {
            "cryCount": 10,
            "laughCount": 12,
            "likeCount": 149,
            "dislikeCount": 0,
            "heartCount": 64,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 4010478713,
            "extra": {
                "remixOfId": 28041096
            },
            "steps": 15,
            "prompt": "translucent painting: marrakesh market of old Marrakesh at dawn, atmospheric lighting, awesome background, highly detailed, cinematicfantasy, beautiful gentle morning sunlight, best quality, detailed, masterpiece, award winning, great soft lighting, detailxl",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 3.8,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-25T1455:41.8398791Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 126688,
                    "modelVersionName": "alpha2 (xl1.0)"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 135867,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 283697,
                    "modelVersionName": "v1.2"
                },
                {
                    "type": "lora",
                    "weight": 1.5,
                    "modelVersionId": 383563,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 539032,
                    "modelVersionName": "Overall Detail XL"
                },
                {
                    "type": "lora",
                    "weight": 1.5,
                    "modelVersionId": 258416,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 554793,
                    "modelVersionName": "Flexible Theme & Color"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "Lady_Luminous",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 35370539,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/04acb3fe-1ee9-4870-8d1e-e56fe8d0dd42/width=768/04acb3fe-1ee9-4870-8d1e-e56fe8d0dd42.jpeg",
        "hash": "U4FifDyYVD~A~qi^S5NGDiRiNL4:ITD%t7Rk",
        "width": 768,
        "height": 1280,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-19T04:41:42.704Z",
        "postId": 8082916,
        "stats": {
            "cryCount": 10,
            "laughCount": 5,
            "likeCount": 170,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 6
        },
        "meta": {
            "Size": "768x1280",
            "seed": 362279414825932,
            "Model": "flux1-dev-fp8",
            "steps": 28,
            "hashes": {
                "model": "",
                "LORA:flux1-D\\araminta_k_flux_koda.safetensors": "1c835c0967",
                "LORA:flux1-D\\flux.1_lora_flyway_Epic-detail_v2.safetensors": "df61e68b14"
            },
            "prompt": "Polaroids hanging on a clothesline;  The background is a grid of other Polaroids and photos by different artists.  The focus is on the clothesline, on which a blue butterfly rests.<lora:flux1-D\\araminta_k_flux_koda.safetensors:0.8:1.0> <lora:flux1-D\\flux.1_lora_flyway_Epic-detail_v2.safetensors:0.8:1.0>",
            "Version": "ComfyUI",
            "sampler": "DDIM",
            "cfgScale": 3.5,
            "resources": [],
            "Model hash": ""
        },
        "username": "flyway",
        "baseModel": null
    },
    {
        "id": 35283967,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/82ddec33-53be-4758-b180-e5a548158414/width=1024/82ddec33-53be-4758-b180-e5a548158414.jpeg",
        "hash": "UUL:oz%N~3IV=BM_%0%1x[xtxutRoyt5M{RP",
        "width": 1024,
        "height": 1536,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-15T07:00:00.000Z",
        "postId": 8063492,
        "stats": {
            "cryCount": 7,
            "laughCount": 11,
            "likeCount": 165,
            "dislikeCount": 0,
            "heartCount": 53,
            "commentCount": 0
        },
        "meta": {
            "Size": "512x768",
            "seed": 3776144868,
            "steps": 25,
            "hashes": {
                "model": "6eb603f778",
                "embed:Negative\\EasyNegativeV2": "339cc9210f",
                "LORA:Kasumi_BlueArchive_Citron": "1312719c70",
                "embed:Negative\\negative_hand-neg": "73b524a2da",
                "embed:Negative\\ng_deepnegative_v1_75t": "54e7e4826d",
                "embed:Negative\\verybadimagenegative_v1.3": "d70463f870"
            },
            "prompt": "((masterpiece,best quality)), absurdres,  BREAK, , <lora:Kasumi_BlueArchive_Citron:0.8>, zzKasumi, black hair, demon horns, long hair, ahoge, halo, black horns, red halo, tail, yellow eyes, demon tail, black tail, fang, small breasts black shorts, collared shirt, lab coat, sandals, shirt tucked in, looking at viewer, smile, simple background, white coat, open mouth, blush , BREAK, leaning forward, head tilt, blush, upper body,, BREAK, solo, smile, looking at viewer, cowboy shot,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "resources": [
                {
                    "name": "Kasumi_BlueArchive_Citron",
                    "type": "lora",
                    "weight": 0.8
                }
            ],
            "Model hash": "6eb603f778",
            "negativePrompt": "embedding:Negative\\negative_hand-neg,  embedding:Negative\\ng_deepnegative_v1_75t, embedding:Negative\\verybadimagenegative_v1.3, embedding:Negative\\EasyNegativeV2,",
            "CATalyst_v1 Version": "ComfyUI"
        },
        "username": "CitronLegacy",
        "baseModel": "SD 1.5"
    },
    {
        "id": 34930986,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7751547a-cccf-4e7e-a7d6-4110cad428fe/width=720/7751547a-cccf-4e7e-a7d6-4110cad428fe.jpeg",
        "hash": "U4B:]EL#0Mv}?^H@0PxtHqtl00.7@EE20g%f",
        "width": 720,
        "height": 1120,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-16T16:29:20.053Z",
        "postId": 7983501,
        "stats": {
            "cryCount": 13,
            "laughCount": 42,
            "likeCount": 126,
            "dislikeCount": 0,
            "heartCount": 54,
            "commentCount": 1
        },
        "meta": null,
        "username": "jihaamies",
        "baseModel": ""
    },
    {
        "id": 34914182,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/558fedf4-87e8-4d48-98e9-8ae2a4bd793f/width=832/558fedf4-87e8-4d48-98e9-8ae2a4bd793f.jpeg",
        "hash": "UBI#Jh_34.tPHXIU?^?bX:tS9Gxa0LIUv~ad",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-16T14:29:45.430Z",
        "postId": 7979844,
        "stats": {
            "cryCount": 6,
            "laughCount": 43,
            "likeCount": 115,
            "dislikeCount": 0,
            "heartCount": 71,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3592309443,
            "extra": {
                "remixOfId": 34890495
            },
            "steps": 38,
            "prompt": "score_9, score_8_up, score_7_up, rating_explicit, uncensored, very detailed, realistic photograph, depth of field, bokeh, award winning photograph, dramatic lighting, rays of light, vivid colors, golden hour,\n(cutesie:2.1), (cuteness overload:2.0), lovely, sweetie, ultra-cute, (bimbo:1.8), (dolled-up:1.6), seductive, shortstack, exaggerated femininity, heavy make-up, long eyelashes, bimbo lips, very full lips,\nslim, skinny, tiny waist, narrow waist,\nadorable, charming, darling, precious, lovely, endearing, winsome, pretty, lovable,  appealing,\n(gigantic breasts:2.2),\nDisney's Princess Anna, ginger, braided twintails, diamond tiara, princess dress, fitted bodice, puffed white sleeves, lace apron, slave collar, vibrant skirt, embroidered patterns, shiny skin, simple jewelry, ribbon ties, traditional blouse, freckles, laced corset, laced bra, laced gloves, laced stockings, latex corset, shiny latex, reflective latex, laced bow, \nfocus on beautiful face,",
            "sampler": "DPM2 a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-16T1426:42.3225742Z",
            "negativePrompt": "score_4, score_5, score_6, old, fat, poorly drawn face,  blurry face, watermark, boring background, simple background,, asian, teeth, text,\nunattractive, unsightly, disfigured, grotesque, misshapen, unappealing, hideous, distorted, repulsive, unpleasant, monstrous, grim, haggard, wrinkled, scarred, gaunt, flat, simple, vague, plain walls",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 714766,
                    "modelVersionName": "GoR_PONY_v2art_fix+VAE!"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250708,
                    "modelVersionName": "safe_pos"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250712,
                    "modelVersionName": "safe_neg"
                }
            ]
        },
        "username": "lionuber",
        "baseModel": "Pony"
    },
    {
        "id": 34561521,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a70954bd-6775-4fe9-a40e-3833b4dfcafb/width=832/a70954bd-6775-4fe9-a40e-3833b4dfcafb.jpeg",
        "hash": "U13ul=%NS4%M~q%gx]xu_2%g%Mt8_3x]%M%M",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-14T14:21:52.626Z",
        "postId": 7897055,
        "stats": {
            "cryCount": 0,
            "laughCount": 4,
            "likeCount": 164,
            "dislikeCount": 0,
            "heartCount": 67,
            "commentCount": 2
        },
        "meta": {
            "seed": 623150737775287,
            "vaes": [
                "flux1DevVAE_stock.safetensors"
            ],
            "comfy": "{\"prompt\": {\"6\": {\"inputs\": {\"text\": \"studio light photography, analog raw photo, A glamorous fashion model in a futuristic rendition of couture style,fantastic aesthetic,fashion magazine style,a beautiful scandinavian girl posing,<lora:Paper_Marbling_Flux:1>midjourney_whisper_avant_couture<lora:midjourney_whisper_avant_couture_v01:1>, (Soft Lighting Photography by Mimoza Veliu and Mario Giacomelli:1.2), award winning photo, inspired by Vogue and Louis Vuitton, pinup posing, with a peaceful expression on her face, the background is dark and the overall mood of the image is somber and contemplative, cinematic , shot on Phase One XF IQ4 150MP, Schneider Kreuznach 80mm LS f/2.8\\nstylish, a beautiful fashion model girl, 18 years old, small natural breasts, slim, nsfw, nude, dynamic pose, best quality, high quality, photograph, hyperrealism, masterpiece, stunning Beautiful fashion girls, Marianna Rothen Style - slight faded photo photo corners, Grain Risograph A full body wide-angle Cinematic haze heavy bokeh rembrandt lighting portrait in the heavy haze hazy soft diffused Late afternoon sunlight of a 1980's french girl 20 years old, pretty face, large breast exposed, in the style of photography david hamilton with heavy hazy Hamilton Blur 50mm rokkor f1. 7 lens and KODACHROME 3200 with heavy film grain shot through a black PRO MIST FILTER, Luminance cubic film grain dreamy portrait with a film grain Granularity of 100, heavy bokeh, heavy cinematic\", \"clip\": [\"43\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"10\": {\"inputs\": {\"vae_name\": \"flux1DevVAE_stock.safetensors\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"flux1T5TextEncoder_stock.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux1-dev-fp8-all-in-one.safetensors\", \"weight_dtype\": \"default\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"45\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"dpm_2\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 50, \"denoise\": 0.8, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 623150737775287}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"51\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.8, \"width\": 832, \"height\": 1216, \"model\": [\"43\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"40\": {\"inputs\": {\"image\": \"pexels-photo-2387793.jpeg\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"da6b1ab8f6c2571770b1a4a0084605e65890cf2faf38873c963e1eb2c461ddb6\"]}, \"42\": {\"inputs\": {\"grow_mask_by\": 6, \"pixels\": [\"54\", 0], \"vae\": [\"10\", 0], \"mask\": [\"40\", 1]}, \"class_type\": \"VAEEncodeForInpaint\"}, \"43\": {\"inputs\": {\"lora_name\": \"FLUX\\\\Paper Marbling Flux.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"46\", 0], \"clip\": [\"46\", 1]}, \"class_type\": \"LoraLoader\"}, \"45\": {\"inputs\": {\"x\": 0, \"y\": 8, \"feather\": 40, \"samples_to\": [\"27\", 0], \"samples_from\": [\"42\", 0]}, \"class_type\": \"LatentComposite\"}, \"46\": {\"inputs\": {\"lora_name\": \"FLUX\\\\midjourney_whisper_avant_couture_v01.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"51\": {\"inputs\": {\"conditioning_1\": [\"6\", 0], \"conditioning_2\": [\"53\", 2]}, \"class_type\": \"ConditioningCombine\"}, \"53\": {\"inputs\": {\"wildcard_text\": \"studio light photography, analog raw photo, A glamorous fashion model in a futuristic rendition of couture style,fantastic aesthetic,fashion magazine style,a beautiful scandinavian girl posing,<lora:Paper_Marbling_Flux:1>midjourney_whisper_avant_couture<lora:midjourney_whisper_avant_couture_v01:1>, (Soft Lighting Photography by Mimoza Veliu and Mario Giacomelli:1.2), award winning photo, inspired by Vogue and Louis Vuitton, pinup posing, with a peaceful expression on her face, the background is dark and the overall mood of the image is somber and contemplative, cinematic , shot on Phase One XF IQ4 150MP, Schneider Kreuznach 80mm LS f/2.8\\nstylish, a beautiful fashion model girl, 18 years old, small natural breasts, slim, nsfw, nude, dynamic pose, best quality, high quality, photograph, hyperrealism, masterpiece, stunning Beautiful fashion girls, Marianna Rothen Style - slight faded photo photo corners, Grain Risograph A full body wide-angle Cinematic haze heavy bokeh rembrandt lighting portrait in the heavy haze hazy soft diffused Late afternoon sunlight of a 1980's french girl 20 years old, pretty face, large breast exposed, in the style of photography david hamilton with heavy hazy Hamilton Blur 50mm rokkor f1. 7 lens and KODACHROME 3200 with heavy film grain shot through a black PRO MIST FILTER, Luminance cubic film grain dreamy portrait with a film grain Granularity of 100, heavy bokeh, heavy cinematic\", \"populated_text\": \"studio light photography, analog raw photo, A glamorous fashion model in a futuristic rendition of couture style,fantastic aesthetic,fashion magazine style,a beautiful scandinavian girl posing,<lora:Paper_Marbling_Flux:1>midjourney_whisper_avant_couture<lora:midjourney_whisper_avant_couture_v01:1>, (Soft Lighting Photography by Mimoza Veliu and Mario Giacomelli:1.2), award winning photo, inspired by Vogue and Louis Vuitton, pinup posing, with a peaceful expression on her face, the background is dark and the overall mood of the image is somber and contemplative, cinematic , shot on Phase One XF IQ4 150MP, Schneider Kreuznach 80mm LS f/2.8\\nstylish, a beautiful fashion model girl, 18 years old, small natural breasts, slim, nsfw, nude, dynamic pose, best quality, high quality, photograph, hyperrealism, masterpiece, stunning Beautiful fashion girls, Marianna Rothen Style - slight faded photo photo corners, Grain Risograph A full body wide-angle Cinematic haze heavy bokeh rembrandt lighting portrait in the heavy haze hazy soft diffused Late afternoon sunlight of a 1980's french girl 20 years old, pretty face, large breast exposed, in the style of photography david hamilton with heavy hazy Hamilton Blur 50mm rokkor f1. 7 lens and KODACHROME 3200 with heavy film grain shot through a black PRO MIST FILTER, Luminance cubic film grain dreamy portrait with a film grain Granularity of 100, heavy bokeh, heavy cinematic\", \"mode\": false, \"Select to add LoRA\": \"Select the LoRA to add to the text\", \"Select to add Wildcard\": \"Select the Wildcard to add to the text\", \"seed\": 829714793417806, \"model\": [\"43\", 0], \"clip\": [\"43\", 1]}, \"class_type\": \"ImpactWildcardEncode\"}, \"54\": {\"inputs\": {\"upscale_method\": \"nearest-exact\", \"width\": 832, \"height\": 1216, \"crop\": \"center\", \"image\": [\"40\", 0]}, \"class_type\": \"ImageScale\"}, \"55\": {\"inputs\": {\"channel\": \"green\", \"image\": [\"54\", 0]}, \"class_type\": \"ImageToMask\"}}, \"workflow\": {\"last_node_id\": 55, \"last_link_id\": 183, \"nodes\": [{\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 523, \"1\": 498}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [9], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 55, \"type\": \"ImageToMask\", \"pos\": {\"0\": -1023, \"1\": 492}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 172}], \"outputs\": [{\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageToMask\"}, \"widgets_values\": [\"green\"]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 517, \"1\": 179}, \"size\": {\"0\": 227.60690307617188, \"1\": 46}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 178, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 156, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [30], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 42, \"type\": \"VAEEncodeForInpaint\", \"pos\": {\"0\": -675, \"1\": 518}, \"size\": {\"0\": 315.9949645996094, \"1\": 98}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 171}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 118}, {\"name\": \"mask\", \"type\": \"MASK\", \"link\": 180}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [182], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncodeForInpaint\"}, \"widgets_values\": [6]}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": -286, \"1\": 421}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [112, 115], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [832, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": -70, \"1\": 421}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1216, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 194, \"1\": 78}, \"size\": {\"0\": 283.45623779296875, \"1\": 58}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 155}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [156], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -1242, \"1\": 112}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [140], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"flux1T5TextEncoder_stock.safetensors\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 174, \"1\": -85}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 112, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": -772, \"1\": -257}, \"size\": {\"0\": 311.81634521484375, \"1\": 60.429901123046875}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12, 118], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"flux1DevVAE_stock.safetensors\"]}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": -649, \"1\": 815}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 45, \"type\": \"LatentComposite\", \"pos\": {\"0\": 522, \"1\": 281}, \"size\": {\"0\": 224.7407684326172, \"1\": 126}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"samples_to\", \"type\": \"LATENT\", \"link\": 183}, {\"name\": \"samples_from\", \"type\": \"LATENT\", \"link\": 182}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [138], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentComposite\"}, \"widgets_values\": [0, 8, 40]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 851, \"1\": 191}, \"size\": {\"0\": 240.0536346435547, \"1\": 346.0881652832031}, \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 30, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 138, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": -1095, \"1\": 682}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": -292, \"1\": 691}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 175, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [176, 178], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.8, 832, 1216]}, {\"id\": 54, \"type\": \"ImageScale\", \"pos\": {\"0\": -1232, \"1\": 274}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 170}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [171, 172], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScale\"}, \"widgets_values\": [\"nearest-exact\", 832, 1216, \"center\"]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": -326, \"1\": 572}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"dpm_2\"]}, {\"id\": 51, \"type\": \"ConditioningCombine\", \"pos\": {\"0\": 184, \"1\": 192}, \"size\": {\"0\": 292.96337890625, \"1\": 46}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning_1\", \"type\": \"CONDITIONING\", \"link\": 150}, {\"name\": \"conditioning_2\", \"type\": \"CONDITIONING\", \"link\": 161}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [155], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningCombine\"}, \"widgets_values\": []}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": -675, \"1\": 666}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [623150737775287, \"randomize\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -1246, \"1\": -92}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [174], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev-fp8-all-in-one.safetensors\", \"default\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 53, \"type\": \"ImpactWildcardEncode\", \"pos\": {\"0\": -309, \"1\": -10}, \"size\": {\"0\": 432.8894958496094, \"1\": 342.7430725097656}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 179}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 160}], \"outputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"clip\", \"type\": \"CLIP\", \"links\": null, \"shape\": 3}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"links\": [161], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"populated_text\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImpactWildcardEncode\"}, \"widgets_values\": [\"studio light photography, analog raw photo, A glamorous fashion model in a futuristic rendition of couture style,fantastic aesthetic,fashion magazine style,a beautiful scandinavian girl posing,<lora:Paper_Marbling_Flux:1>midjourney_whisper_avant_couture<lora:midjourney_whisper_avant_couture_v01:1>, (Soft Lighting Photography by Mimoza Veliu and Mario Giacomelli:1.2), award winning photo, inspired by Vogue and Louis Vuitton, pinup posing, with a peaceful expression on her face, the background is dark and the overall mood of the image is somber and contemplative, cinematic , shot on Phase One XF IQ4 150MP, Schneider Kreuznach 80mm LS f/2.8\\nstylish, a beautiful fashion model girl, 18 years old, small natural breasts, slim, nsfw, nude, dynamic pose, best quality, high quality, photograph, hyperrealism, masterpiece, stunning Beautiful fashion girls, Marianna Rothen Style - slight faded photo photo corners, Grain Risograph A full body wide-angle Cinematic haze heavy bokeh rembrandt lighting portrait in the heavy haze hazy soft diffused Late afternoon sunlight of a 1980's french girl 20 years old, pretty face, large breast exposed, in the style of photography david hamilton with heavy hazy Hamilton Blur 50mm rokkor f1. 7 lens and KODACHROME 3200 with heavy film grain shot through a black PRO MIST FILTER, Luminance cubic film grain dreamy portrait with a film grain Granularity of 100, heavy bokeh, heavy cinematic\", \"studio light photography, analog raw photo, A glamorous fashion model in a futuristic rendition of couture style,fantastic aesthetic,fashion magazine style,a beautiful scandinavian girl posing,<lora:Paper_Marbling_Flux:1>midjourney_whisper_avant_couture<lora:midjourney_whisper_avant_couture_v01:1>, (Soft Lighting Photography by Mimoza Veliu and Mario Giacomelli:1.2), award winning photo, inspired by Vogue and Louis Vuitton, pinup posing, with a peaceful expression on her face, the background is dark and the overall mood of the image is somber and contemplative, cinematic , shot on Phase One XF IQ4 150MP, Schneider Kreuznach 80mm LS f/2.8\\nstylish, a beautiful fashion model girl, 18 years old, small natural breasts, slim, nsfw, nude, dynamic pose, best quality, high quality, photograph, hyperrealism, masterpiece, stunning Beautiful fashion girls, Marianna Rothen Style - slight faded photo photo corners, Grain Risograph A full body wide-angle Cinematic haze heavy bokeh rembrandt lighting portrait in the heavy haze hazy soft diffused Late afternoon sunlight of a 1980's french girl 20 years old, pretty face, large breast exposed, in the style of photography david hamilton with heavy hazy Hamilton Blur 50mm rokkor f1. 7 lens and KODACHROME 3200 with heavy film grain shot through a black PRO MIST FILTER, Luminance cubic film grain dreamy portrait with a film grain Granularity of 100, heavy bokeh, heavy cinematic\", false, \"Select the LoRA to add to the text\", \"Select the Wildcard to add to the text\", 829714793417806, \"randomize\"]}, {\"id\": 43, \"type\": \"LoraLoader\", \"pos\": {\"0\": -836, \"1\": 223}, \"size\": {\"0\": 497.63690185546875, \"1\": 202.54066467285156}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 141}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 142}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [175, 179], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [154, 160], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"FLUX\\\\Paper Marbling Flux.safetensors\", 1, 1]}, {\"id\": 46, \"type\": \"LoraLoader\", \"pos\": {\"0\": -838, \"1\": -101}, \"size\": {\"0\": 503.47900390625, \"1\": 247.38265991210938}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 174}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 140}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [141], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [142], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"FLUX\\\\midjourney_whisper_avant_couture_v01.safetensors\", 1, 1]}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -288, \"1\": -261}, \"size\": {\"0\": 421.11541748046875, \"1\": 216.94781494140625}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 154}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [150], \"slot_index\": 0}], \"title\": \"CLIP Text Encode (Positive Prompt)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"studio light photography, analog raw photo, A glamorous fashion model in a futuristic rendition of couture style,fantastic aesthetic,fashion magazine style,a beautiful scandinavian girl posing,<lora:Paper_Marbling_Flux:1>midjourney_whisper_avant_couture<lora:midjourney_whisper_avant_couture_v01:1>, (Soft Lighting Photography by Mimoza Veliu and Mario Giacomelli:1.2), award winning photo, inspired by Vogue and Louis Vuitton, pinup posing, with a peaceful expression on her face, the background is dark and the overall mood of the image is somber and contemplative, cinematic , shot on Phase One XF IQ4 150MP, Schneider Kreuznach 80mm LS f/2.8\\nstylish, a beautiful fashion model girl, 18 years old, small natural breasts, slim, nsfw, nude, dynamic pose, best quality, high quality, photograph, hyperrealism, masterpiece, stunning Beautiful fashion girls, Marianna Rothen Style - slight faded photo photo corners, Grain Risograph A full body wide-angle Cinematic haze heavy bokeh rembrandt lighting portrait in the heavy haze hazy soft diffused Late afternoon sunlight of a 1980's french girl 20 years old, pretty face, large breast exposed, in the style of photography david hamilton with heavy hazy Hamilton Blur 50mm rokkor f1. 7 lens and KODACHROME 3200 with heavy film grain shot through a black PRO MIST FILTER, Luminance cubic film grain dreamy portrait with a film grain Granularity of 100, heavy bokeh, heavy cinematic\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": {\"0\": 441, \"1\": 612}, \"size\": {\"0\": 1024.0201416015625, \"1\": 924.1073608398438}, \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 9}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 40, \"type\": \"LoadImage\", \"pos\": {\"0\": -356, \"1\": 949}, \"size\": {\"0\": 726.09423828125, \"1\": 690.5527954101562}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [170], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": [180], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"pexels-photo-2387793.jpeg\", \"image\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 182, \"1\": 447}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 176, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 50, 0.8]}], \"links\": [[9, 8, 0, 9, 0, \"IMAGE\"], [12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [24, 13, 0, 8, 0, \"LATENT\"], [30, 22, 0, 13, 1, \"GUIDER\"], [37, 25, 0, 13, 0, \"NOISE\"], [112, 34, 0, 27, 0, \"INT\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [118, 10, 0, 42, 1, \"VAE\"], [138, 45, 0, 13, 4, \"LATENT\"], [140, 11, 0, 46, 1, \"CLIP\"], [141, 46, 0, 43, 0, \"MODEL\"], [142, 46, 1, 43, 1, \"CLIP\"], [150, 6, 0, 51, 0, \"CONDITIONING\"], [154, 43, 1, 6, 0, \"CLIP\"], [155, 51, 0, 26, 0, \"CONDITIONING\"], [156, 26, 0, 22, 1, \"CONDITIONING\"], [160, 43, 1, 53, 1, \"CLIP\"], [161, 53, 2, 51, 1, \"CONDITIONING\"], [170, 40, 0, 54, 0, \"IMAGE\"], [171, 54, 0, 42, 0, \"IMAGE\"], [172, 54, 0, 55, 0, \"IMAGE\"], [174, 12, 0, 46, 0, \"MODEL\"], [175, 43, 0, 30, 0, \"MODEL\"], [176, 30, 0, 17, 0, \"MODEL\"], [178, 30, 0, 22, 0, \"MODEL\"], [179, 43, 0, 53, 0, \"MODEL\"], [180, 40, 1, 42, 2, \"MASK\"], [182, 42, 0, 45, 1, \"LATENT\"], [183, 27, 0, 45, 0, \"LATENT\"]], \"groups\": [{\"title\": \"Dimensions\", \"bounding\": [-290, 344, 437, 180], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.3073560549142819, \"offset\": {\"0\": 2068.794677734375, \"1\": -49.83509826660156}}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"53\": {\"seed\": 5}}, \"seed_widgets\": {\"25\": 0, \"53\": 5}}}",
            "steps": 50,
            "models": [],
            "denoise": 0.8,
            "sampler": "DPM2",
            "cfgScale": 3.5,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "FLUX\\Paper Marbling Flux.safetensors",
                    "type": "lora",
                    "strength": 1,
                    "strengthClip": 1
                },
                {
                    "name": "FLUX\\midjourney_whisper_avant_couture_v01.safetensors",
                    "type": "lora",
                    "strength": 1,
                    "strengthClip": 1
                }
            ]
        },
        "username": "samon777",
        "baseModel": null
    },
    {
        "id": 34243568,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/544d9c0c-8526-4601-8dce-83555229465f/width=1624/544d9c0c-8526-4601-8dce-83555229465f.jpeg",
        "hash": "UG8}.4tS?aMI?wkC?vxt%1t7%hxuw[V@x]tR",
        "width": 1624,
        "height": 2368,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-12T19:37:40.110Z",
        "postId": 7825997,
        "stats": {
            "cryCount": 3,
            "laughCount": 6,
            "likeCount": 173,
            "dislikeCount": 0,
            "heartCount": 53,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 22702194658157,
            "Model": "flux_dev",
            "steps": 20,
            "hashes": {
                "model": "2eda627c8a"
            },
            "prompt": "(in Krenz Cushart style:1.2), high-quality, masterpiece, A ghostly swordswoman, her face partially illuminated by the blade of her cracked sword, The camera focuses tightly on her eyes burning with a fierce ghostly light as she prepares to strike, Her breath fogs in the cold air, the faint glow of her skeletal hand grips the sword hilt with fractured armor trailing mist, The blurred battlefield behind her hints at fallen enemies and rising spirits, high contrast, dramatic close-up, motion blur, eerie glow, (elaborate fine details:1.1), (elaborately detailed attire with extraordinary elements:1.1), (hyperdetailed:1.1), (intricate details:1.0), (Refined details:1.1), (best quality:1.1), (high resolution:1.2)",
            "Version": "ComfyUI",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 3.5,
            "resources": [
                {
                    "hash": "2eda627c8a",
                    "name": "flux_dev",
                    "type": "model"
                }
            ],
            "Model hash": "2eda627c8a"
        },
        "username": "RIDD",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 33759232,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1d8fb403-00b8-498c-91dc-fb8aa4ebf830/width=832/1d8fb403-00b8-498c-91dc-fb8aa4ebf830.jpeg",
        "hash": "ULBM_XWVD%V@_Na{D$aytRt7IUj[xuWBjba{",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-10T01:58:42.120Z",
        "postId": 7718771,
        "stats": {
            "cryCount": 14,
            "laughCount": 20,
            "likeCount": 134,
            "dislikeCount": 0,
            "heartCount": 67,
            "commentCount": 0
        },
        "meta": {
            "seed": 749,
            "vaes": [],
            "Model": "ponyDiffusionV6XL_v6StartWithThisOne",
            "comfy": "{\"prompt\": {\"33\": {\"inputs\": {\"ckpt_name\": \"ponyDiffusionV6XL_v6StartWithThisOne.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"35\": {\"inputs\": {\"text\": \"score_5, score_4, score_3, ugly, fat\", \"clip\": [\"95\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"36\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"41\": {\"inputs\": {\"text\": \"score_9, score_8_up, score_7_up, flat color, gthan, gothic, 1girl, blood, solo, long hair, blood on face, looking at viewer, white hair, nosebleed, pink eyes, hair between eyes, portrait, lips, closed mouth, freckles, bangs\", \"clip\": [\"95\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"95\": {\"inputs\": {\"stop_at_clip_layer\": -2, \"clip\": [\"33\", 1]}, \"class_type\": \"CLIPSetLastLayer\"}, \"290\": {\"inputs\": {\"category\": \"#PLACEHOLDER\", \"preset\": \"#PRESET\", \"text\": \"4K, Anatomically Correct, Accurate, Best Quality, Highres, Masterpiece, Retina, Super Detail, Textured Skin, Studio Portrait, Soft Pastel Glow Lighting, Glowing Light, Photorealism Style, Depth Of Field\"}, \"class_type\": \"PromptBuilder //Inspire\"}, \"313\": {\"inputs\": {\"seed\": 749, \"steps\": 25, \"cfg\": 7.0, \"sampler_name\": \"euler_ancestral\", \"scheduler\": \"karras\", \"denoise\": 1.0, \"model\": [\"315\", 0], \"positive\": [\"41\", 0], \"negative\": [\"35\", 0], \"latent_image\": [\"36\", 0]}, \"class_type\": \"KSampler\"}, \"314\": {\"inputs\": {\"samples\": [\"313\", 0], \"vae\": [\"33\", 2]}, \"class_type\": \"VAEDecode\"}, \"315\": {\"inputs\": {\"lora_name\": \"MyLoRas\\\\GTHAN2.safetensors\", \"strength_model\": 0.8, \"model\": [\"33\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"362\": {\"inputs\": {\"model_name\": \"remacri_original.pt\"}, \"class_type\": \"UpscaleModelLoader\"}, \"369\": {\"inputs\": {\"text\": \"score_9, score_8_up, score_7_up, score_6_up, drkdl, low key, dramatic lighting, dark theme, 1girl, perfecteyes, detailed, realistic, photorealistic\", \"clip\": [\"33\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"388\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"314\", 0]}, \"class_type\": \"SaveImage\"}}, \"workflow\": {\"last_node_id\": 388, \"last_link_id\": 583, \"nodes\": [{\"id\": 128, \"type\": \"LoraLoaderModelOnly\", \"pos\": [1410, -300], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 23, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 235}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [237], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0.3], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 181, \"type\": \"Reroute\", \"pos\": [-10, -380], \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 306, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 176, \"type\": \"Reroute\", \"pos\": [470, -460], \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 305, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 182, \"type\": \"Reroute\", \"pos\": [380, -470], \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 308, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [309], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 120, \"type\": \"Reroute\", \"pos\": [-49, -433], \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 309, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [580], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 183, \"type\": \"Reroute\", \"pos\": [790, 1030], \"size\": [75, 26], \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 311}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 186, \"type\": \"Reroute\", \"pos\": [1693, -449], \"size\": [75, 26], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 319, \"slot_index\": 0}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [323], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 187, \"type\": \"Reroute\", \"pos\": [1710, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 323, \"slot_index\": 0, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [472], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 190, \"type\": \"Reroute\", \"pos\": [1270, -50], \"size\": [75, 26], \"flags\": {}, \"order\": 74, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 328}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [329], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 110, \"type\": \"Reroute\", \"pos\": [30, 1030], \"size\": [75, 26], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 206}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [284, 311], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 174, \"type\": \"Reroute\", \"pos\": [40, 1090], \"size\": [75, 26], \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 284}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [313], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 193, \"type\": \"Reroute\", \"pos\": [130, 990], \"size\": [75, 26], \"flags\": {}, \"order\": 108, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 332}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [333], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 192, \"type\": \"Reroute\", \"pos\": [810, 980], \"size\": [75, 26], \"flags\": {}, \"order\": 113, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 333}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [334], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 196, \"type\": \"Reroute\", \"pos\": [671, -719], \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 338}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [339], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 197, \"type\": \"Reroute\", \"pos\": [-60, -721], \"size\": [75, 26], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 339}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [340], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 198, \"type\": \"Reroute\", \"pos\": [-25, -662], \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 340, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [341], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 200, \"type\": \"Reroute\", \"pos\": [210, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 342}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [343, 344], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 201, \"type\": \"Reroute\", \"pos\": [-100, 1070], \"size\": [75, 26], \"flags\": {}, \"order\": 63, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 345, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [346], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 121, \"type\": \"Reroute\", \"pos\": [-101, 203], \"size\": [75, 26], \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 347, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [345], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 199, \"type\": \"Reroute\", \"pos\": [-10, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 341, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [342, 347], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 191, \"type\": \"Reroute\", \"pos\": [50, 970], \"size\": [75, 26], \"flags\": {}, \"order\": 104, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 330, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [332], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 180, \"type\": \"Reroute\", \"pos\": [660, -480], \"size\": [75, 26], \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 302, \"slot_index\": 0}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [319], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 118, \"type\": \"Reroute\", \"pos\": [470, 220], \"size\": [75, 26], \"flags\": {}, \"order\": 85, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 351}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 203, \"type\": \"Reroute\", \"pos\": [660, 220], \"size\": [75, 26], \"flags\": {}, \"order\": 75, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 350}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [351], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 202, \"type\": \"Reroute\", \"pos\": [120, 210], \"size\": [75, 26], \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 348}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [349, 357], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 209, \"type\": \"Reroute\", \"pos\": [1140, 200], \"size\": [75, 26], \"flags\": {}, \"order\": 99, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 360}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [361], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 133, \"type\": \"SaveImage\", \"pos\": [1210, 320], \"size\": {\"0\": 580, \"1\": 630}, \"flags\": {\"pinned\": true}, \"order\": 100, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 248}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx_facefix\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 211, \"type\": \"Reroute\", \"pos\": [1760, 180], \"size\": [75, 26], \"flags\": {}, \"order\": 110, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 362, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [363], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 206, \"type\": \"Reroute\", \"pos\": [1780, 250], \"size\": [75, 26], \"flags\": {}, \"order\": 98, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 354, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [356], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 195, \"type\": \"Reroute\", \"pos\": [1750, 120], \"size\": [75, 26], \"flags\": {}, \"order\": 118, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 337, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [336], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 155, \"type\": \"KSampler\", \"pos\": [1839, 82], \"size\": {\"0\": 320, \"1\": 470}, \"flags\": {}, \"order\": 119, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 336, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 268, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 269, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 279, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [303], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [268954017807171, \"randomize\", 8, 2.5, \"dpmpp_2m_alt\", \"karras\", 1]}, {\"id\": 172, \"type\": \"VAEDecode\", \"pos\": [1918, -22], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 120, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 303, \"slot_index\": 0}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 318, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [281], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 150, \"type\": \"MeshGraphormer-DepthMapPreprocessor\", \"pos\": [1838, 691], \"size\": {\"0\": 320, \"1\": 220}, \"flags\": {}, \"order\": 101, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 262}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [267], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"INPAINTING_MASK\", \"type\": \"MASK\", \"links\": [278], \"shape\": 3, \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"MeshGraphormer-DepthMapPreprocessor\"}, \"widgets_values\": [15, 256, \"based_on_depth\", 5, 88, 0.6, 0.6]}, {\"id\": 153, \"type\": \"ControlNetApplyAdvanced\", \"pos\": [1926, 594], \"size\": {\"0\": 320, \"1\": 170}, \"flags\": {\"collapsed\": true}, \"order\": 115, \"mode\": 2, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 363}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 356}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 264, \"slot_index\": 2}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 267}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [268], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [269], \"shape\": 3, \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"ControlNetApplyAdvanced\"}, \"widgets_values\": [0.6, 0, 1]}, {\"id\": 154, \"type\": \"ControlNetLoader\", \"pos\": [1825, 647], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": true}, \"order\": 0, \"mode\": 2, \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [264], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"control_v11f1p_sd15_depth_fp16.safetensors\"]}, {\"id\": 205, \"type\": \"Reroute\", \"pos\": [1650, 220], \"size\": [75, 26], \"flags\": {}, \"order\": 86, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 353}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [354], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 156, \"type\": \"SetLatentNoiseMask\", \"pos\": [2216, 957], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 112, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 274, \"slot_index\": 0}, {\"name\": \"mask\", \"type\": \"MASK\", \"link\": 278, \"slot_index\": 1}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [279], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SetLatentNoiseMask\"}}, {\"id\": 185, \"type\": \"Reroute\", \"pos\": [1708, 1021], \"size\": [75, 26], \"flags\": {}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 316}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [317, 318], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 173, \"type\": \"SaveImage\", \"pos\": [2190, -322], \"size\": {\"0\": 930, \"1\": 1230}, \"flags\": {}, \"order\": 121, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 281}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"RealVisFaceHands\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 194, \"type\": \"Reroute\", \"pos\": [1660, 990], \"size\": [75, 26], \"flags\": {}, \"order\": 117, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 334}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [337], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 170, \"type\": \"VAEEncode\", \"pos\": [1876, 964], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 107, \"mode\": 4, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 276}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 317}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [274], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}}, {\"id\": 167, \"type\": \"Reroute\", \"pos\": [1260, 970], \"size\": [75, 26], \"flags\": {}, \"order\": 102, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 275}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [276], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 111, \"type\": \"Reroute\", \"pos\": [780, 1130], \"size\": [75, 26], \"flags\": {}, \"order\": 83, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 213}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 210, \"type\": \"Reroute\", \"pos\": [1650, 180], \"size\": [75, 26], \"flags\": {}, \"order\": 106, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 361}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [362, 457], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 184, \"type\": \"Reroute\", \"pos\": [790, 1080], \"size\": [75, 26], \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 313}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [316, 458], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 281, \"type\": \"UpscaleModelLoader\", \"pos\": [691, 1301], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 1, \"mode\": 2, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [452], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 280, \"type\": \"SaveImage\", \"pos\": [1048, 1281], \"size\": {\"0\": 280, \"1\": 300}, \"flags\": {}, \"order\": 116, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 453}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 279, \"type\": \"UltimateSDUpscale\", \"pos\": [688, 1404], \"size\": {\"0\": 320, \"1\": 830}, \"flags\": {\"collapsed\": false}, \"order\": 111, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 460}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 455, \"slot_index\": 1}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 457, \"slot_index\": 2}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 456, \"slot_index\": 3}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 458, \"slot_index\": 4}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 452}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [453], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.5, 901377669312158, \"randomize\", 8, 4, \"dpmpp_2m_alt\", \"karras\", 0.2, \"Linear\", 768, 1024, 8, 32, \"None\", 1, 64, 8, 16, true, false], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 126, \"type\": \"LoraLoaderModelOnly\", \"pos\": [1070, -300], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 15, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 231}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [235], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", -2], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 207, \"type\": \"Reroute\", \"pos\": [400, 210], \"size\": [75, 26], \"flags\": {}, \"order\": 77, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 357}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [358], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 220, \"type\": \"Switch any [Crystools]\", \"pos\": [1290, 90], \"size\": {\"0\": 310, \"1\": 80}, \"flags\": {}, \"order\": 59, \"mode\": 2, \"inputs\": [{\"name\": \"on_true\", \"type\": \"*\", \"link\": 372}, {\"name\": \"on_false\", \"type\": \"*\", \"link\": 464}], \"outputs\": [{\"name\": \"*\", \"type\": \"*\", \"links\": [455], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"Switch any [Crystools]\"}, \"widgets_values\": [false]}, {\"id\": 298, \"type\": \"IPAdapterInsightFaceLoader\", \"pos\": [860, -650], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 2, \"mode\": 2, \"outputs\": [{\"name\": \"INSIGHTFACE\", \"type\": \"INSIGHTFACE\", \"links\": [467], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"IPAdapterInsightFaceLoader\"}, \"widgets_values\": [\"CPU\"]}, {\"id\": 296, \"type\": \"CLIPVisionLoader\", \"pos\": [860, -540], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 3, \"mode\": 2, \"outputs\": [{\"name\": \"CLIP_VISION\", \"type\": \"CLIP_VISION\", \"links\": [466], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPVisionLoader\"}, \"widgets_values\": [\"IPAdapter_image_encoder_sd15.safetensors\"]}, {\"id\": 295, \"type\": \"IPAdapterModelLoader\", \"pos\": [860, -770], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 4, \"mode\": 2, \"outputs\": [{\"name\": \"IPADAPTER\", \"type\": \"IPADAPTER\", \"links\": [465], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"IPAdapterModelLoader\"}, \"widgets_values\": [\"ip-adapter-faceid-plusv2_sd15.bin\"]}, {\"id\": 292, \"type\": \"IPAdapterFaceID\", \"pos\": [1270, -740], \"size\": {\"0\": 320, \"1\": 320}, \"flags\": {}, \"order\": 53, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 463}, {\"name\": \"ipadapter\", \"type\": \"IPADAPTER\", \"link\": 465}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 473}, {\"name\": \"image_negative\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"attn_mask\", \"type\": \"MASK\", \"link\": null}, {\"name\": \"clip_vision\", \"type\": \"CLIP_VISION\", \"link\": 466}, {\"name\": \"insightface\", \"type\": \"INSIGHTFACE\", \"link\": 467}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [464], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"face_image\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"IPAdapterFaceID\"}, \"widgets_values\": [1, 1, \"linear\", \"concat\", 0, 1, \"V only\"]}, {\"id\": 138, \"type\": \"LoraLoaderModelOnly\", \"pos\": [930, 80], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 45, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 325, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [463], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", -2], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 189, \"type\": \"Reroute\", \"pos\": [1620, -40], \"size\": [75, 26], \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 471, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [328], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 306, \"type\": \"LoraLoaderModelOnly\", \"pos\": [1430, -150], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 58, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 470}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [471], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0.7000000000000001], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 188, \"type\": \"Reroute\", \"pos\": [840, 140], \"size\": [75, 26], \"flags\": {}, \"order\": 39, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 472, \"slot_index\": 0, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [325], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 147, \"type\": \"PreviewImage\", \"pos\": [950, 600], \"size\": {\"0\": 250, \"1\": 340}, \"flags\": {}, \"order\": 103, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 260}], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 113, \"type\": \"Reroute\", \"pos\": [60, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 84, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 329}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [197], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 305, \"type\": \"LoadImage\", \"pos\": [1220, -1110], \"size\": [320, 310], \"flags\": {}, \"order\": 5, \"mode\": 2, \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"7d6f57171d6a0cff937326c2e493f63a.png\", \"image\"]}, {\"id\": 308, \"type\": \"LoadImage\", \"pos\": [1540, -1110], \"size\": [320, 310], \"flags\": {}, \"order\": 6, \"mode\": 2, \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [473], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"pasted/image (42).png\", \"image\"]}, {\"id\": 204, \"type\": \"Reroute\", \"pos\": [920, 240], \"size\": [75, 26], \"flags\": {}, \"order\": 76, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 352}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [353, 456], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 94, \"type\": \"LoraLoaderModelOnly\", \"pos\": [1080, -160], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 52, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 240}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [372, 470], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 208, \"type\": \"Reroute\", \"pos\": [850, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 87, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 358}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [360], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 130, \"type\": \"LoraLoaderModelOnly\", \"pos\": [740, -170], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 44, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 239}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [240], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0.6], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 129, \"type\": \"LoraLoaderModelOnly\", \"pos\": [70, -160], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 30, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 237}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [238], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"Kenva.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 101, \"type\": \"Reroute\", \"pos\": [-110, -627], \"size\": [75, 26], \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 171, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"LATENT\", \"links\": [474], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 127, \"type\": \"LoraLoaderModelOnly\", \"pos\": [410, -170], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 38, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 238}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [239], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"incase_style_v3-1_ponyxl_ilff.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 93, \"type\": \"LoraLoaderModelOnly\", \"pos\": [740, -300], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 7, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [231], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0.4], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 42, \"type\": \"VAEDecode\", \"pos\": [-1680, 1090], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 109, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 51}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [53], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 40, \"type\": \"KSampler\", \"pos\": [-1680, 590], \"size\": {\"0\": 210, \"1\": 470}, \"flags\": {\"pinned\": false}, \"order\": 105, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 475, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 349, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 216, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 215, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [51], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [5901, \"increment\", 25, 6, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 345, \"type\": \"KSampler\", \"pos\": [-2030, 590], \"size\": {\"0\": 210, \"1\": 470}, \"flags\": {\"pinned\": false}, \"order\": 72, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 521, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 526, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 527, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 525, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [523], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [5901, \"increment\", 25, 6, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 346, \"type\": \"VAEDecode\", \"pos\": [-2030, 1080], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 82, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 523}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 524, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [522], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 344, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-2030, -110], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 33, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 531, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [521], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 343, \"type\": \"SaveImage\", \"pos\": [-2030, 0], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 95, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 522}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 91, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-1680, -110], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 32, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 498, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [475], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 349, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-730, -430], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 34, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 533, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [550], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0.6], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 43, \"type\": \"SaveImage\", \"pos\": [-1820, -10], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 114, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 53}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 336, \"type\": \"VAEDecode\", \"pos\": [-980, 1130], \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 80, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 505}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 507, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [506], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 119, \"type\": \"Reroute\", \"pos\": [-30, 1130], \"size\": [75, 26], \"flags\": {}, \"order\": 73, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 346}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [213], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 112, \"type\": \"Reroute\", \"pos\": [110, 330], \"size\": [75, 26], \"flags\": {}, \"order\": 96, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 197, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [330], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 340, \"type\": \"VAEDecode\", \"pos\": [-1320, 1130], \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 81, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 512}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 517, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [511], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 339, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-1330, -120], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 40, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 550, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [510], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 109, \"type\": \"Reroute\", \"pos\": [110, 370], \"size\": [75, 26], \"flags\": {}, \"order\": 97, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [216], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 335, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-980, -120], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 48, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 549, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [502], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 108, \"type\": \"Reroute\", \"pos\": [-100, -230], \"size\": [75, 26], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 474, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"LATENT\", \"links\": [215], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 290, \"type\": \"PromptBuilder //Inspire\", \"pos\": [-750, 1200], \"size\": {\"0\": 310, \"1\": 220}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"PromptBuilder //Inspire\"}, \"widgets_values\": [\"Picture Effect\", \"#PRESET\", \"4K, Anatomically Correct, Accurate, Best Quality, Highres, Masterpiece, Retina, Super Detail, Textured Skin, Studio Portrait, Soft Pastel Glow Lighting, Glowing Light, Photorealism Style, Depth Of Field\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 134, \"type\": \"UltralyticsDetectorProvider\", \"pos\": [940, 400], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 9, \"mode\": 2, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [251], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [], \"shape\": 3, \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 136, \"type\": \"SAMLoader\", \"pos\": [940, 440], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 10, \"mode\": 2, \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [253], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 137, \"type\": \"UltralyticsDetectorProvider\", \"pos\": [940, 480], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 11, \"mode\": 2, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [254], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/face_yolov8n-seg2_60.pt\"]}, {\"id\": 132, \"type\": \"PreviewBridge\", \"pos\": [950, 350], \"size\": {\"0\": 320, \"1\": 290}, \"flags\": {\"collapsed\": true}, \"order\": 89, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 567}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"PreviewBridge\"}, \"widgets_values\": [\"$132-0\", false]}, {\"id\": 368, \"type\": \"LoraLoaderModelOnly\", \"pos\": [580, 610], \"size\": {\"0\": 300, \"1\": 80}, \"flags\": {}, \"order\": 60, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 576, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [577], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"REALISM\\\\add-detail-xl.safetensors\", 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 131, \"type\": \"FaceDetailer\", \"pos\": [960, 540], \"size\": {\"0\": 430, \"1\": 1320}, \"flags\": {\"collapsed\": true}, \"order\": 90, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 568}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 577}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 570}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 571}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 579}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 573}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 251, \"slot_index\": 6}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 253}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 254, \"slot_index\": 8}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [248, 262, 275, 460], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [], \"shape\": 6, \"slot_index\": 1}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [260], \"shape\": 6, \"slot_index\": 2}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": [], \"shape\": 3, \"slot_index\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3, \"slot_index\": 4}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": [], \"shape\": 6, \"slot_index\": 5}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [256, true, 768, 687183684917446, \"randomize\", 25, 7, \"euler_ancestral\", \"karras\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 369, \"type\": \"CLIPTextEncode\", \"pos\": [590, 760], \"size\": {\"0\": 300, \"1\": 220}, \"flags\": {\"collapsed\": true}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 578}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [579], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_9, score_8_up, score_7_up, score_6_up, drkdl, low key, dramatic lighting, dark theme, 1girl, perfecteyes, detailed, realistic, photorealistic\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 362, \"type\": \"UpscaleModelLoader\", \"pos\": [-320, 830], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"remacri_original.pt\"]}, {\"id\": 333, \"type\": \"KSampler\", \"pos\": [-960, 640], \"size\": {\"0\": 210, \"1\": 470}, \"flags\": {\"pinned\": false}, \"order\": 70, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 502, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 508, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 509, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 504, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [505], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [2519, \"increment\", 25, 7, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 337, \"type\": \"KSampler\", \"pos\": [-1330, 640], \"size\": {\"0\": 210, \"1\": 470}, \"flags\": {\"pinned\": false}, \"order\": 71, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 510, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 514, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 515, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 516, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [512], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [4897, \"increment\", 25, 7, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 338, \"type\": \"SaveImage\", \"pos\": [-1330, 40], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 94, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 511}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 117, \"type\": \"Reroute\", \"pos\": [-50, 700], \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 580, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [206, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 314, \"type\": \"VAEDecode\", \"pos\": [-250, 660], \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": false, \"pinned\": false}, \"order\": 79, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 484}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 486, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [567, 568, 581, 583], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 359, \"type\": \"Save Image w/Metadata\", \"pos\": [50, 850], \"size\": {\"0\": 400, \"1\": 710}, \"flags\": {}, \"order\": 91, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 581}], \"properties\": {\"Node name for S&R\": \"Save Image w/Metadata\"}, \"widgets_values\": [\"xXx_\", \"\", \"png\", 25, 7, \"ponyRealism_v21MainVAE.safetensors\", \"euler_ancestral\", \"karras\", \"score_9, score_8_up, score_7_up, score_6_up, flmgr, film grain, cinematic, cinematic light, photorealistic, a girl, Gith, pointed ears, spots on skin, red nose, green skin, fantasy, dungeon background, bangs, long eyelashes, long white hair\", \"score_5, score_4, score_3, score_2, score_1, fat, ugly\", 793002077594482, 833, 1217, true, 100, 0, \"%Y-%m-%d-%H%M%S\"]}, {\"id\": 95, \"type\": \"CLIPSetLastLayer\", \"pos\": [420, -590], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": false}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 157, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [338], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPSetLastLayer\"}, \"widgets_values\": [-2]}, {\"id\": 334, \"type\": \"SaveImage\", \"pos\": [-1340, 40], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 93, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 506}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 122, \"type\": \"Reroute\", \"pos\": [750, 210], \"size\": [140.8, 26], \"flags\": {}, \"order\": 66, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 229, \"pos\": [70.4, 0]}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [350, 352], \"slot_index\": 0}], \"properties\": {\"showOutputText\": true, \"horizontal\": true}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 367, \"type\": \"LoraLoaderModelOnly\", \"pos\": [130, 630], \"size\": {\"0\": 300, \"1\": 80}, \"flags\": {}, \"order\": 54, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 574, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [576, 582], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"REALISM\\\\FLMGR\\\\FLMGR-R.safetensors\", 0.5], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 36, \"type\": \"EmptyLatentImage\", \"pos\": [80, -670], \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {\"collapsed\": false}, \"order\": 13, \"mode\": 0, \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [171, 491, 504, 516, 525, 532], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 351, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-760, -250], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 41, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 545, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [544, 548, 549], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"REALISM\\\\add-detail-xl.safetensors\", 0.5], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 352, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-1210, -290], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 35, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 546, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [545], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"REALISM\\\\PerfectEyesXL.safetensors\", 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 320, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-1340, -530], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 27, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 539, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [498, 531, 533, 546], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"AliceInWonderlandXLPony_character-10V2.safetensors\", 0.4], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 350, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-670, -650], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 19, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 538, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [539], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"Expressive_H-000001.safetensors\", 0.5], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 311, \"type\": \"VAEDecode\", \"pos\": [-430, 760], \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 78, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 478}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 479, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [480], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 309, \"type\": \"SaveImage\", \"pos\": [-900, 60], \"size\": {\"0\": 450, \"1\": 520}, \"flags\": {\"pinned\": false}, \"order\": 88, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 480}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 388, \"type\": \"SaveImage\", \"pos\": [-410, 60], \"size\": {\"0\": 450, \"1\": 520}, \"flags\": {}, \"order\": 92, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 583}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 92, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-700, -80], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 46, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 544}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [547], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"MyLoRas\\\\GLSHS_-_V3N-000003.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 310, \"type\": \"KSampler\", \"pos\": [-680, 690], \"size\": [210, 470], \"flags\": {\"pinned\": false}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 547, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 481, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 482, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 532, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [478], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [769, \"increment\", 25, 6.5, \"dpmpp_2m_alt\", \"karras\", 1]}, {\"id\": 35, \"type\": \"CLIPTextEncode\", \"pos\": [130, 480], \"size\": {\"0\": 300, \"1\": 110}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 343}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [229, 482, 490, 509, 515, 527, 573], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_5, score_4, score_3, ugly, fat\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 33, \"type\": \"CheckpointLoaderSimple\", \"pos\": [80, -540], \"size\": {\"0\": 320, \"1\": 100}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [302, 305, 538], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [157, 570, 578], \"shape\": 3, \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [308, 479, 486, 507, 517, 524, 571], \"shape\": 3, \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"ponyDiffusionV6XL_v6StartWithThisOne.safetensors\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 315, \"type\": \"LoraLoaderModelOnly\", \"pos\": [130, 360], \"size\": {\"0\": 300, \"1\": 80}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 548, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [574], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"MyLoRas\\\\GTHAN2.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 313, \"type\": \"KSampler\", \"pos\": [470, 70], \"size\": [210, 470], \"flags\": {\"pinned\": false, \"collapsed\": false}, \"order\": 69, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 582, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 489, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 490, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 491, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [484], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [749, \"increment\", 25, 7, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 41, \"type\": \"CLIPTextEncode\", \"pos\": [130, 70], \"size\": {\"0\": 300, \"1\": 250}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 344}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [348, 481, 489, 508, 514, 526], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_9, score_8_up, score_7_up, flat color, gthan, gothic, 1girl, blood, solo, long hair, blood on face, looking at viewer, white hair, nosebleed, pink eyes, hair between eyes, portrait, lips, closed mouth, freckles, bangs\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}], \"links\": [[51, 40, 0, 42, 0, \"LATENT\"], [53, 42, 0, 43, 0, \"IMAGE\"], [157, 33, 1, 95, 0, \"CLIP\"], [171, 36, 0, 101, 0, \"*\"], [197, 113, 0, 112, 0, \"*\"], [206, 117, 0, 110, 0, \"*\"], [209, 118, 0, 109, 0, \"*\"], [213, 119, 0, 111, 0, \"*\"], [215, 108, 0, 40, 3, \"LATENT\"], [216, 109, 0, 40, 2, \"CONDITIONING\"], [229, 35, 0, 122, 0, \"*\"], [231, 93, 0, 126, 0, \"MODEL\"], [235, 126, 0, 128, 0, \"MODEL\"], [237, 128, 0, 129, 0, \"MODEL\"], [238, 129, 0, 127, 0, \"MODEL\"], [239, 127, 0, 130, 0, \"MODEL\"], [240, 130, 0, 94, 0, \"MODEL\"], [248, 131, 0, 133, 0, \"IMAGE\"], [251, 134, 0, 131, 6, \"BBOX_DETECTOR\"], [253, 136, 0, 131, 7, \"SAM_MODEL\"], [254, 137, 1, 131, 8, \"SEGM_DETECTOR\"], [260, 131, 2, 147, 0, \"IMAGE\"], [262, 131, 0, 150, 0, \"IMAGE\"], [264, 154, 0, 153, 2, \"CONTROL_NET\"], [267, 150, 0, 153, 3, \"IMAGE\"], [268, 153, 0, 155, 1, \"CONDITIONING\"], [269, 153, 1, 155, 2, \"CONDITIONING\"], [274, 170, 0, 156, 0, \"LATENT\"], [275, 131, 0, 167, 0, \"*\"], [276, 167, 0, 170, 0, \"IMAGE\"], [278, 150, 1, 156, 1, \"MASK\"], [279, 156, 0, 155, 3, \"LATENT\"], [281, 172, 0, 173, 0, \"IMAGE\"], [284, 110, 0, 174, 0, \"*\"], [302, 33, 0, 180, 0, \"*\"], [303, 155, 0, 172, 0, \"LATENT\"], [305, 33, 0, 176, 0, \"*\"], [306, 176, 0, 181, 0, \"*\"], [308, 33, 2, 182, 0, \"*\"], [309, 182, 0, 120, 0, \"*\"], [310, 117, 0, 42, 1, \"VAE\"], [311, 110, 0, 183, 0, \"*\"], [313, 174, 0, 184, 0, \"*\"], [316, 184, 0, 185, 0, \"*\"], [317, 185, 0, 170, 1, \"VAE\"], [318, 185, 0, 172, 1, \"VAE\"], [319, 180, 0, 186, 0, \"*\"], [323, 186, 0, 187, 0, \"*\"], [325, 188, 0, 138, 0, \"MODEL\"], [328, 189, 0, 190, 0, \"*\"], [329, 190, 0, 113, 0, \"*\"], [330, 112, 0, 191, 0, \"*\"], [332, 191, 0, 193, 0, \"*\"], [333, 193, 0, 192, 0, \"*\"], [334, 192, 0, 194, 0, \"*\"], [336, 195, 0, 155, 0, \"MODEL\"], [337, 194, 0, 195, 0, \"*\"], [338, 95, 0, 196, 0, \"*\"], [339, 196, 0, 197, 0, \"*\"], [340, 197, 0, 198, 0, \"*\"], [341, 198, 0, 199, 0, \"*\"], [342, 199, 0, 200, 0, \"*\"], [343, 200, 0, 35, 0, \"CLIP\"], [344, 200, 0, 41, 0, \"CLIP\"], [345, 121, 0, 201, 0, \"*\"], [346, 201, 0, 119, 0, \"*\"], [347, 199, 0, 121, 0, \"*\"], [348, 41, 0, 202, 0, \"*\"], [349, 202, 0, 40, 1, \"CONDITIONING\"], [350, 122, 0, 203, 0, \"*\"], [351, 203, 0, 118, 0, \"*\"], [352, 122, 0, 204, 0, \"*\"], [353, 204, 0, 205, 0, \"*\"], [354, 205, 0, 206, 0, \"*\"], [356, 206, 0, 153, 1, \"CONDITIONING\"], [357, 202, 0, 207, 0, \"*\"], [358, 207, 0, 208, 0, \"*\"], [360, 208, 0, 209, 0, \"*\"], [361, 209, 0, 210, 0, \"*\"], [362, 210, 0, 211, 0, \"*\"], [363, 211, 0, 153, 0, \"CONDITIONING\"], [372, 94, 0, 220, 0, \"*\"], [452, 281, 0, 279, 5, \"UPSCALE_MODEL\"], [453, 279, 0, 280, 0, \"IMAGE\"], [455, 220, 0, 279, 1, \"MODEL\"], [456, 204, 0, 279, 3, \"CONDITIONING\"], [457, 210, 0, 279, 2, \"CONDITIONING\"], [458, 184, 0, 279, 4, \"VAE\"], [460, 131, 0, 279, 0, \"IMAGE\"], [463, 138, 0, 292, 0, \"MODEL\"], [464, 292, 0, 220, 1, \"*\"], [465, 295, 0, 292, 1, \"IPADAPTER\"], [466, 296, 0, 292, 5, \"CLIP_VISION\"], [467, 298, 0, 292, 6, \"INSIGHTFACE\"], [470, 94, 0, 306, 0, \"MODEL\"], [471, 306, 0, 189, 0, \"*\"], [472, 187, 0, 188, 0, \"*\"], [473, 308, 0, 292, 2, \"IMAGE\"], [474, 101, 0, 108, 0, \"*\"], [475, 91, 0, 40, 0, \"MODEL\"], [478, 310, 0, 311, 0, \"LATENT\"], [479, 33, 2, 311, 1, \"VAE\"], [480, 311, 0, 309, 0, \"IMAGE\"], [481, 41, 0, 310, 1, \"CONDITIONING\"], [482, 35, 0, 310, 2, \"CONDITIONING\"], [484, 313, 0, 314, 0, \"LATENT\"], [486, 33, 2, 314, 1, \"VAE\"], [489, 41, 0, 313, 1, \"CONDITIONING\"], [490, 35, 0, 313, 2, \"CONDITIONING\"], [491, 36, 0, 313, 3, \"LATENT\"], [498, 320, 0, 91, 0, \"MODEL\"], [502, 335, 0, 333, 0, \"MODEL\"], [504, 36, 0, 333, 3, \"LATENT\"], [505, 333, 0, 336, 0, \"LATENT\"], [506, 336, 0, 334, 0, \"IMAGE\"], [507, 33, 2, 336, 1, \"VAE\"], [508, 41, 0, 333, 1, \"CONDITIONING\"], [509, 35, 0, 333, 2, \"CONDITIONING\"], [510, 339, 0, 337, 0, \"MODEL\"], [511, 340, 0, 338, 0, \"IMAGE\"], [512, 337, 0, 340, 0, \"LATENT\"], [514, 41, 0, 337, 1, \"CONDITIONING\"], [515, 35, 0, 337, 2, \"CONDITIONING\"], [516, 36, 0, 337, 3, \"LATENT\"], [517, 33, 2, 340, 1, \"VAE\"], [521, 344, 0, 345, 0, \"MODEL\"], [522, 346, 0, 343, 0, \"IMAGE\"], [523, 345, 0, 346, 0, \"LATENT\"], [524, 33, 2, 346, 1, \"VAE\"], [525, 36, 0, 345, 3, \"LATENT\"], [526, 41, 0, 345, 1, \"CONDITIONING\"], [527, 35, 0, 345, 2, \"CONDITIONING\"], [531, 320, 0, 344, 0, \"MODEL\"], [532, 36, 0, 310, 3, \"LATENT\"], [533, 320, 0, 349, 0, \"MODEL\"], [538, 33, 0, 350, 0, \"MODEL\"], [539, 350, 0, 320, 0, \"MODEL\"], [544, 351, 0, 92, 0, \"MODEL\"], [545, 352, 0, 351, 0, \"MODEL\"], [546, 320, 0, 352, 0, \"MODEL\"], [547, 92, 0, 310, 0, \"MODEL\"], [548, 351, 0, 315, 0, \"MODEL\"], [549, 351, 0, 335, 0, \"MODEL\"], [550, 349, 0, 339, 0, \"MODEL\"], [567, 314, 0, 132, 0, \"IMAGE\"], [568, 314, 0, 131, 0, \"IMAGE\"], [570, 33, 1, 131, 2, \"CLIP\"], [571, 33, 2, 131, 3, \"VAE\"], [573, 35, 0, 131, 5, \"CONDITIONING\"], [574, 315, 0, 367, 0, \"MODEL\"], [576, 367, 0, 368, 0, \"MODEL\"], [577, 368, 0, 131, 1, \"MODEL\"], [578, 33, 1, 369, 0, \"CLIP\"], [579, 369, 0, 131, 4, \"CONDITIONING\"], [580, 120, 0, 117, 0, \"*\"], [581, 314, 0, 359, 0, \"IMAGE\"], [582, 367, 0, 313, 0, \"MODEL\"], [583, 314, 0, 388, 0, \"IMAGE\"]], \"groups\": [{\"title\": \"Start\", \"bounding\": [60, -680, 715, 254], \"color\": \"#88A\", \"font_size\": 24, \"locked\": false}, {\"title\": \"Loras\", \"bounding\": [50, -390, 1714, 348], \"color\": \"#a1309b\", \"font_size\": 24, \"locked\": false}, {\"title\": \"StartImage\", \"bounding\": [80, -10, 835, 977], \"color\": \"#8A8\", \"font_size\": 24, \"locked\": true}, {\"title\": \"LorasFace\", \"bounding\": [920, 0, 872, 233], \"color\": \"#a1309b\", \"font_size\": 24, \"locked\": false}, {\"title\": \"FaceFix\", \"bounding\": [930, 280, 874, 687], \"color\": \"#8A8\", \"font_size\": 24, \"locked\": false}, {\"title\": \"HandsFaceResult\", \"bounding\": [1809, -420, 1367, 1399], \"color\": \"#b58b2a\", \"font_size\": 24, \"locked\": false}, {\"title\": \"Upscale\", \"bounding\": [670, 1210, 684, 404], \"color\": \"#3f789e\", \"font_size\": 24, \"locked\": false}, {\"title\": \"face\", \"bounding\": [830, -1100, 840, 690], \"color\": \"#3f789e\", \"font_size\": 24, \"locked\": false}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.7088742511246044, \"offset\": [472.56683339150203, -55.3442857123553]}}, \"version\": 0.4, \"widget_idx_map\": {\"40\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"131\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}, \"155\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"279\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"310\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"313\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"333\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"337\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"345\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"359\": {\"sampler_name\": 6, \"scheduler\": 7}}, \"seed_widgets\": {\"40\": 0, \"131\": 3, \"155\": 0, \"279\": 1, \"310\": 0, \"313\": 0, \"333\": 0, \"337\": 0, \"345\": 0}}}",
            "steps": 25,
            "width": 832,
            "height": 1216,
            "models": [
                "ponyDiffusionV6XL_v6StartWithThisOne.safetensors"
            ],
            "prompt": "score_9, score_8_up, score_7_up, flat color, gthan, gothic, 1girl, blood, solo, long hair, blood on face, looking at viewer, white hair, nosebleed, pink eyes, hair between eyes, portrait, lips, closed mouth, freckles, bangs",
            "denoise": 1,
            "sampler": "Euler a",
            "cfgScale": 7,
            "modelIds": [],
            "scheduler": "karras",
            "upscalers": [
                "remacri_original.pt"
            ],
            "versionIds": [],
            "controlNets": [],
            "negativePrompt": "score_5, score_4, score_3, ugly, fat",
            "additionalResources": [
                {
                    "name": "MyLoRas\\GTHAN2.safetensors",
                    "type": "lora",
                    "strength": 0.8
                }
            ]
        },
        "username": "blacksnowskill",
        "baseModel": null
    },
    {
        "id": 33381369,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/05027c5e-9213-406b-a68c-fdbbad6bc697/width=832/05027c5e-9213-406b-a68c-fdbbad6bc697.jpeg",
        "hash": "UAF#C0}[5N#P4UI9^SwN^Hxs-E;}Q.I;Ino#",
        "width": 832,
        "height": 1248,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-07T22:00:00.000Z",
        "postId": 7636657,
        "stats": {
            "cryCount": 0,
            "laughCount": 3,
            "likeCount": 163,
            "dislikeCount": 0,
            "heartCount": 69,
            "commentCount": 0
        },
        "meta": {
            "RNG": "CPU",
            "VAE": "sdxl_vae.safetensors",
            "Size": "832x1248",
            "seed": 1664607089,
            "Model": "snowpony_v10",
            "steps": 28,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "d6f941b46b",
                "lora:sailormars-pdxl-nvwls-v1-000005": "4ba9829d46c4"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime, 1girl, solo, <lora:sailormars-pdxl-nvwls-v1-000005:1> slrmars, black hair, long hair, purple eyes, circlet, earrings, choker, red sailor collar, white shirt, sleeveless, white leotard, purple bowtie, red skirt, pleated skirt, white gloves, elbow gloves, kneeling, wince, red sky, torn clothes, scratched face, holding own arm, red high heels, looking at you, city",
            "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
            "sampler": "Euler a",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "4ba9829d46c4",
                    "name": "sailormars-pdxl-nvwls-v1-000005",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "d6f941b46b",
                    "name": "snowpony_v10",
                    "type": "model"
                }
            ],
            "Model hash": "d6f941b46b",
            "Schedule type": "Automatic",
            "negativePrompt": "monochrome, greyscale",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.4.2",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "novowels",
        "baseModel": "Pony"
    },
    {
        "id": 32426813,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a3619b19-6ef0-47c1-b393-2bc115d95f4f/width=1664/a3619b19-6ef0-47c1-b393-2bc115d95f4f.jpeg",
        "hash": "UAB:1;~AeRI:_3xaH?WB0+EfVE%1AII;VXjF",
        "width": 1664,
        "height": 2432,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-02T14:11:41.566Z",
        "postId": 7424020,
        "stats": {
            "cryCount": 9,
            "laughCount": 28,
            "likeCount": 110,
            "dislikeCount": 0,
            "heartCount": 88,
            "commentCount": 0
        },
        "meta": {
            "VAE": "sdxl.vae.safetensors",
            "Size": "832x1216",
            "seed": 416868742,
            "Model": "PonyRealism_v2.2_VAE",
            "steps": 30,
            "hashes": {
                "vae": "235745af8d",
                "model": "7c97ecf786"
            },
            "prompt": "score_9, score_8_up, score_7_up, draenei, chubby, skimpy, fat, glowing eyes, glowing tattoos, gold ornaments, princess, temple, sit in throne, crossed legs, depth of field, highly detailed, high contrast, film grain, Rim Lighting, Rays of Shimmering Light",
            "Version": "v1.10.1",
            "sampler": "DPM++ SDE",
            "Template": {},
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "7c97ecf786",
                    "name": "PonyRealism_v2.2_VAE",
                    "type": "model"
                }
            ],
            "Model hash": "7c97ecf786",
            "Schedule type": "Karras",
            "negativePrompt": "score_6, score_5, score_4, text, censored, deformed, bad hand",
            "ADetailer model": "mediapipe_face_full",
            "ADetailer version": "24.8.0",
            "Negative Template": {},
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "Downcast alphas_cumprod": "True",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "ZyloO",
        "baseModel": "Pony"
    },
    {
        "id": 31613086,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3b90bdc1-3ffc-4da5-8d80-12c01cc1dc68/width=1248/3b90bdc1-3ffc-4da5-8d80-12c01cc1dc68.jpeg",
        "hash": "UdHeOVNHE1%L~pIpNIxYVrRPo#M{adRjoMoe",
        "width": 1248,
        "height": 1824,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-04T16:08:18.242Z",
        "postId": 7118529,
        "stats": {
            "cryCount": 0,
            "laughCount": 6,
            "likeCount": 156,
            "dislikeCount": 0,
            "heartCount": 73,
            "commentCount": 0
        },
        "meta": {
            "vae": "sdxl_vae",
            "Size": "832x1216",
            "seed": 2140186492,
            "Model": "XL\\mfcgSquishMix_v20.safetensors",
            "steps": 24,
            "hashes": {
                "model": "5c5e64e0d48d",
                "lora:tekken_emiliederochefort_ponyXL-ORIGINAL": "ef868799e18a"
            },
            "prompt": "score_9, score_8_up, score_7_up, <break> solo, 1girl, emilieog, light smile, looking at you, sitting, swivel chair, long hair, blonde hair, blunt bangs, hime cut, blue eyes, white shirt, collared shirt, black skirt, pencil skirt, black pantyhose, indoors, office\n<segment:yolo-face_yolov8m.pt,0.4,0.5//cid=1>",
            "sampler": "euler_ancestral",
            "cfgScale": 6,
            "resources": [
                {
                    "hash": "ef868799e18a",
                    "name": "tekken_emiliederochefort_ponyXL-ORIGINAL",
                    "type": "lora"
                },
                {
                    "hash": "5c5e64e0d48d",
                    "name": "XL\\mfcgSquishMix_v20.safetensors",
                    "type": "model"
                }
            ],
            "Model hash": "5c5e64e0d48d",
            "aspectratio": "Custom",
            "loraweights": "1",
            "refinersteps": "12",
            "Schedule type": "align_your_steps",
            "refinermethod": "PostApply",
            "negativePrompt": "holding pencil",
            "refinerupscale": "1.5",
            "refinerupscalemethod": "model-4xNomos8kDAT.pth",
            "refinercontrolpercentage": "0.4"
        },
        "username": "justTNP",
        "baseModel": "Pony"
    },
    {
        "id": 31200327,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2371c55a-ad02-4c11-a321-5e7133d2bf31/width=1024/2371c55a-ad02-4c11-a321-5e7133d2bf31.jpeg",
        "hash": "U6AJpXHq00T1PWMd%1bbFpMI?dXSEcRk-Wt7",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-25T01:25:14.458Z",
        "postId": 6974048,
        "stats": {
            "cryCount": 10,
            "laughCount": 30,
            "likeCount": 140,
            "dislikeCount": 0,
            "heartCount": 55,
            "commentCount": 0
        },
        "meta": {
            "Size": "1024x1024",
            "seed": 3683076071,
            "extra": {
                "remixOfId": 14896660
            },
            "steps": 36,
            "prompt": "A beautiful translucent pale orb containing glowing lightning bolt symbol, crystal clear, Fancy stand, time distortion, high quality, extreme detail, ultra hd,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-25T0117:50.2410716Z",
            "negativePrompt": "blurry, bad quality, poor quality,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 782002,
                    "modelVersionName": "Jugg_XI_by_RunDiffusion"
                },
                {
                    "type": "lora",
                    "weight": 0.65,
                    "modelVersionId": 135867,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 348189,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "shadowcat133600",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 31093547,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bb32ab51-93b2-49d0-b7f6-8b994278b4b2/width=1800/bb32ab51-93b2-49d0-b7f6-8b994278b4b2.jpeg",
        "hash": "U38fTS{JKj,@XTS~R*W;TJ$5#,63xaadW;R%",
        "width": 1920,
        "height": 3360,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-24T09:53:13.581Z",
        "postId": 6950165,
        "stats": {
            "cryCount": 6,
            "laughCount": 2,
            "likeCount": 165,
            "dislikeCount": 0,
            "heartCount": 62,
            "commentCount": 1
        },
        "meta": {
            "prompt": "A fearsome, jet-black cyborg looms, its body a labyrinth of gears, wires, and intricate mechanical parts. Red eyes glow ominously from within its demonic form, casting an eerie light as it moves with precision, a terrifying blend of machine and malevolence."
        },
        "username": "Clear_Note",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 29341485,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9489d3bc-e10b-4e52-8e74-060be7045df4/width=1024/9489d3bc-e10b-4e52-8e74-060be7045df4.jpeg",
        "hash": "U66S8cD4yVIoL4R3ben+00?vH;xT*wtmn;S%",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-14T07:05:00.000Z",
        "postId": 6565024,
        "stats": {
            "cryCount": 0,
            "laughCount": 17,
            "likeCount": 186,
            "dislikeCount": 0,
            "heartCount": 32,
            "commentCount": 0
        },
        "meta": {
            "Size": "1024x1024",
            "seed": 2665788205,
            "Model": "flux1-dev-fp8",
            "steps": 20,
            "hashes": {
                "model": "1be961341b",
                "lora:artilands": "182873e6365a"
            },
            "prompt": "The futuristic bar building located on a distant planet. The blue neon sign reads \"SPACE BAR\".\n<lora:artilands:0.8>",
            "Version": "f2.0.1v1.10.1-1.10.1",
            "sampler": "Euler",
            "Module 1": "flux1_vae",
            "Module 2": "t5xxl_fp8_e4m3fn",
            "Module 3": "ViT-L-14-BEST-smooth-GmP-TE-only-HF-format",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "182873e6365a",
                    "name": "artilands",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "1be961341b",
                    "name": "flux1-dev-fp8",
                    "type": "model"
                }
            ],
            "Model hash": "1be961341b",
            "Schedule type": "Simple",
            "Distilled CFG Scale": "3.5",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)"
        },
        "username": "PalmtopTiger",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 29097019,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8b3b0834-10ab-46a9-a7e7-664881db395e/width=832/8b3b0834-10ab-46a9-a7e7-664881db395e.jpeg",
        "hash": "U24eNJxDE2-:~oj?E2-o-:R*E2xtt7WBM|a}",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-12T20:46:10.391Z",
        "postId": 6510293,
        "stats": {
            "cryCount": 0,
            "laughCount": 11,
            "likeCount": 175,
            "dislikeCount": 0,
            "heartCount": 49,
            "commentCount": 4
        },
        "meta": null,
        "username": "Carcamagnu",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 28716993,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8debaf77-e298-4ed1-964c-0fc67acff77a/width=832/8debaf77-e298-4ed1-964c-0fc67acff77a.jpeg",
        "hash": "UHEe#w5YOX,.~VNKIpjFO@t6aKI=k=xDV@S4",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-10T13:28:11.112Z",
        "postId": 6423535,
        "stats": {
            "cryCount": 6,
            "laughCount": 18,
            "likeCount": 146,
            "dislikeCount": 0,
            "heartCount": 65,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3073113815,
            "extra": {
                "remixOfId": 25703245
            },
            "steps": 22,
            "prompt": "\"A majestic girl blonde emerges from the evening light, surrounded by a landscape bathed in a warm blend of golden and teal tones. Bold palette knife strokes create textured, elegant brushstrokes on the canvas. The subject, a commanding teacher, stands tall, radiating mythical power and timeless wisdom. The image focuses on a close-up shot, capturing the fine details of their expression, as they dominate a modern, minimalist environment.\"",
            "sampler": "Undefined",
            "cfgScale": 2.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-10T1326:13.9803175Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 720252,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.15,
                    "modelVersionId": 753642,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 751486,
                    "modelVersionName": "v1.0 Flux"
                },
                {
                    "type": "lora",
                    "weight": 0.05,
                    "modelVersionId": 793412,
                    "modelVersionName": "Flux"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 767132,
                    "modelVersionName": "Flux"
                }
            ]
        },
        "username": "FenixDX7",
        "baseModel": "Flux.1 D"
    }
]