[
    {
        "id": 32426766,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f31fde4b-6e95-435d-9b30-36086e07aa68/width=1664/f31fde4b-6e95-435d-9b30-36086e07aa68.jpeg",
        "hash": "U8Ac_500_NIAtRIB.89F9G%2M{RjD%-;V@t7",
        "width": 1664,
        "height": 2432,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-02T14:11:41.566Z",
        "postId": 7424020,
        "stats": {
            "cryCount": 58,
            "laughCount": 147,
            "likeCount": 1246,
            "dislikeCount": 0,
            "heartCount": 572,
            "commentCount": 3
        },
        "meta": {
            "VAE": "sdxl.vae.safetensors",
            "Size": "832x1216",
            "seed": 369587939,
            "Model": "PonyRealism_v2.2_VAE",
            "steps": 30,
            "hashes": {
                "vae": "235745af8d",
                "model": "7c97ecf786"
            },
            "prompt": "score_9, score_8_up, score_7_up, asian girl, makeup, goth, emo, portrait, close-up, messy bedroom, supported on bedside table, clutter tattoos, solo, sexy curves, revealing outfit, a latex minidress, depth of field, highly detailed, high contrast, film grain, Rim Lighting",
            "Version": "v1.10.1",
            "sampler": "DPM++ SDE",
            "Template": {},
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "7c97ecf786",
                    "name": "PonyRealism_v2.2_VAE",
                    "type": "model"
                }
            ],
            "Model hash": "7c97ecf786",
            "Schedule type": "Karras",
            "negativePrompt": "score_6, score_5, score_4, text, censored, deformed, bad hand",
            "ADetailer model": "mediapipe_face_full",
            "ADetailer version": "24.8.0",
            "Negative Template": {},
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "Downcast alphas_cumprod": "True",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "ZyloO",
        "baseModel": "Pony"
    },
    {
        "id": 27020233,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/21b594d5-1f3c-4b3b-981c-9dc2cefda346/width=1664/21b594d5-1f3c-4b3b-981c-9dc2cefda346.jpeg",
        "hash": "UTG+UF02%N$f~qDio}ofOBnlVYOCxabvV[WB",
        "width": 1664,
        "height": 2432,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-31T08:43:40.810Z",
        "postId": 6044059,
        "stats": {
            "cryCount": 67,
            "laughCount": 136,
            "likeCount": 1332,
            "dislikeCount": 0,
            "heartCount": 488,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 4048478875,
            "Model": "zavychromaxl_v80",
            "steps": 25,
            "hashes": {
                "model": "1dadb39e40"
            },
            "Version": "f2.0.1v1.10.1-previous-480-g3b9b2f65",
            "sampler": "DDPM",
            "Module 1": "sdxl_vae",
            "cfgScale": 5,
            "resources": [
                {
                    "hash": "1dadb39e40",
                    "name": "zavychromaxl_v80",
                    "type": "model"
                }
            ],
            "Model hash": "1dadb39e40",
            "Schedule type": "Automatic",
            "Denoising strength": "0.02",
            "SD upscale overlap": "64",
            "SD upscale upscaler": "DAT_x4",
            "Style Selector Style": "base",
            "Style Selector Enabled": "True",
            "Style Selector Randomize": "False"
        },
        "username": "fagnardsecours426",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 29107240,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6fffeb86-e673-4699-bc47-22e5ec508ce1/width=832/6fffeb86-e673-4699-bc47-22e5ec508ce1.jpeg",
        "hash": "UBD,AkX900D%YRozrqRj~BxuD%WBK6t7MxWB",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-13T08:00:00.000Z",
        "postId": 6512941,
        "stats": {
            "cryCount": 119,
            "laughCount": 156,
            "likeCount": 1338,
            "dislikeCount": 0,
            "heartCount": 409,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3495086304,
            "extra": {
                "remixOfId": 28897705
            },
            "steps": 25,
            "prompt": "Rene Magritte , (tilt-shift lens:1.6), draconian jaw, fantasy ambience, anime style,  woman contemplating, immersive-inspired art deco, inside and out landscape,showing the giant lighting maximalist.  award-winning, professional, In the midst of a darkened room, swinging its club and the warriors charging forward.",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-12T0309:29.7496050Z",
            "negativePrompt": "easynegative, bad proportions, low resolution, bad, ugly, terrible, painting, 3d, render, comic, anime, manga, unrealistic, flat, watermark, signature, worst quality, low quality, normal quality, lowres, simple background, inaccurate limb, extra fingers, fewer fingers, missing fingers, extra arms, (extra legs:1.3), inaccurate eyes, bad composition, bad anatomy, error, extra digit, fewer digits, cropped, low res, worst quality, low quality, normal quality, jpeg artifacts, extra digit, fewer digits, trademark, watermark, artist's name, username, signature, text, words, human,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 155870,
                    "modelVersionName": "v1"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208,
                    "modelVersionName": "EasyNegative"
                },
                {
                    "type": "lora",
                    "weight": 0.45,
                    "modelVersionId": 152309,
                    "modelVersionName": "xl_more_art-full-v1"
                },
                {
                    "type": "lora",
                    "weight": 0.3,
                    "modelVersionId": 258687,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.45,
                    "modelVersionId": 332071,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": -0.2,
                    "modelVersionId": 369959,
                    "modelVersionName": "Sword"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "funkstroke",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 19291691,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2ae76a07-f4d0-4680-880e-c4bb80ee65cc/width=1248/2ae76a07-f4d0-4680-880e-c4bb80ee65cc.jpeg",
        "hash": "UFCis:~WNHf+t7WVRjj[M|fks:ayxat7j[Rj",
        "width": 1248,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-10T23:34:37.707Z",
        "postId": 4311082,
        "stats": {
            "cryCount": 64,
            "laughCount": 188,
            "likeCount": 1345,
            "dislikeCount": 0,
            "heartCount": 424,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1152",
            "seed": 408711323,
            "Model": "ultraspice_v23",
            "steps": 10,
            "hashes": {
                "model": "cfd51d0cb5"
            },
            "prompt": "old piece of bark that looks like a face of creature, John Paul Caponigro,",
            "Version": "v1.9.3",
            "sampler": "Euler",
            "cfgScale": 2,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "cfd51d0cb5",
                    "name": "ultraspice_v23",
                    "type": "model"
                }
            ],
            "Model hash": "cfd51d0cb5",
            "Hires steps": "18",
            "Hires upscale": "1.5",
            "Schedule type": "Automatic",
            "Hires upscaler": "4x-UltraSharp",
            "Denoising strength": "0.2",
            "Style Selector Style": "base",
            "Style Selector Enabled": "True",
            "Style Selector Randomize": "False"
        },
        "username": "Jogging",
        "baseModel": "SDXL Turbo"
    },
    {
        "id": 14089708,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/68db6451-1d6c-45be-9cc3-b590ba292813/width=832/68db6451-1d6c-45be-9cc3-b590ba292813.jpeg",
        "hash": "UEK9rjaKDi~VxbxD01t7AFRjIpIp-oxtWBxt",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-31T01:35:37.119Z",
        "postId": 3125334,
        "stats": {
            "cryCount": 60,
            "laughCount": 185,
            "likeCount": 1234,
            "dislikeCount": 0,
            "heartCount": 542,
            "commentCount": 3
        },
        "meta": {
            "Size": "832x1216",
            "seed": 309751857,
            "steps": 8,
            "prompt": "35mm photograph, film, bokeh, professional, beautiful, in the background sits an adorable cute plushie orange tabby cat, sitting in a sunbeam, inside antelope canyon, beautiful curvy water carved rock walls, hyperrealistic, super realistic, sharp focus, 32k, (((masterpiece))) (((ultimate quality))), exquisite beauty, highiest texture resolution, photorealistic, fantasy setting, epic composition, ral-smlvltnpls",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 2,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-05-31T0128:32.4294399Z",
            "negativePrompt": "low quality, normal quality, worst quality, signature, watermark, logo, text, error, draft, grainy, noisy, url, website, patreon username, username, out of focus, ugly, ugly face, lowres, poor effort, low image quality, bad composition, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, missing fingers, 4 fingers, 6 fingers, too many fingers,blurry, blurred",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 346399,
                    "modelVersionName": "\ud83d\udc41\u200d\ud83d\udde8V7 (BakedVAE)\ud83d\udc41\u200d\ud83d\udde8"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 421065,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 343491,
                    "modelVersionName": "SDXL"
                },
                {
                    "type": "vae",
                    "weight": 1,
                    "modelVersionId": 333245,
                    "modelVersionName": "SDXL-VAE"
                }
            ]
        },
        "username": "jollyjack",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 37776764,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e50ccef8-99b2-4b45-8252-e559837aea16/width=832/e50ccef8-99b2-4b45-8252-e559837aea16.jpeg",
        "hash": "U36@KF|^zVi{G[635Rt75RW=tk%Mvh=y=xjv",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-01T17:55:47.059Z",
        "postId": 8627219,
        "stats": {
            "cryCount": 78,
            "laughCount": 155,
            "likeCount": 1302,
            "dislikeCount": 0,
            "heartCount": 485,
            "commentCount": 5
        },
        "meta": null,
        "username": "DoreenAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 31807092,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/42f2ee52-99b3-42ab-a814-c76a19fd3b27/width=896/42f2ee52-99b3-42ab-a814-c76a19fd3b27.jpeg",
        "hash": "UKBzg?t9IBtj_N%MRjS5%4-:WTMz-:t8M{V@",
        "width": 896,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-28T21:29:19.256Z",
        "postId": 7207334,
        "stats": {
            "cryCount": 89,
            "laughCount": 165,
            "likeCount": 1274,
            "dislikeCount": 0,
            "heartCount": 493,
            "commentCount": 1
        },
        "meta": {
            "Size": "896x1152",
            "seed": 2773119006,
            "Model": "flux1-dev-fp8",
            "steps": 25,
            "hashes": {
                "model": "275ef623d3"
            },
            "prompt": "d1st0p14 ,   An alien botanist, with delicate, bioluminescent skin and large, inquisitive eyes, studies a glowing plant on a distant, unexplored planet. The botanist\u00e2\u0080\u0099s tools are advanced, with floating drones that analyze the plant\u00e2\u0080\u0099s properties. The landscape around them is lush with strange, colorful vegetation and floating, jellyfish-like creatures\n<lora:dystopia:0.8>",
            "Version": "f2.0.1v1.10.1-previous-519-g44eb4ea8",
            "sampler": "Euler",
            "cfgScale": 1,
            "resources": [
                {
                    "name": "dystopia",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "275ef623d3",
                    "name": "flux1-dev-fp8",
                    "type": "model"
                }
            ],
            "Model hash": "275ef623d3",
            "Schedule type": "Simple",
            "Distilled CFG Scale": "4",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)"
        },
        "username": "andreac75",
        "baseModel": null
    },
    {
        "id": 10589920,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/826525bd-51f2-4f64-97d6-1bafbb7fa3e2/width=1800/826525bd-51f2-4f64-97d6-1bafbb7fa3e2.jpeg",
        "hash": "U75s1OOYD5wuy?n+MxkVXmnjR5bE$xSgQ.iw",
        "width": 2664,
        "height": 3416,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-24T00:34:32.493Z",
        "postId": 2321136,
        "stats": {
            "cryCount": 70,
            "laughCount": 198,
            "likeCount": 1278,
            "dislikeCount": 0,
            "heartCount": 474,
            "commentCount": 0
        },
        "meta": {
            "Size": "896x1152",
            "seed": 1068448421107322,
            "steps": 40,
            "hashes": {
                "model": "588d3efe35"
            },
            "prompt": "(zavy-mthcl:1.3), alien landscape ,Spectacular auroras dancing across the heavens, Quaint villages nestled in verdant valleys , alien flora, Chiaroscuro,,, surrealist, horror, trending on artstation, digital painting, painterly, concept art, smooth, illustration, clean ink detailed line drawings, cell shaded, 4k, tone mapping, doll, akihiko yoshida, james jean, andrei riabovitchev, marc sim",
            "sampler": "dpmpp_3m_sde_exponential",
            "cfgScale": 6,
            "resources": [],
            "Model hash": "588d3efe35",
            "zavychromaxl_v60 Version": "ComfyUI"
        },
        "username": "Zavy",
        "baseModel": null
    },
    {
        "id": 10576577,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2847f7e5-bd48-43b2-8d6a-a4313d3f3f30/width=1344/2847f7e5-bd48-43b2-8d6a-a4313d3f3f30.jpeg",
        "hash": "U8D]ezXTD%xu~pD%NH~q0KxtRjfi00IUxuR*",
        "width": 1344,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-23T20:05:37.285Z",
        "postId": 2318015,
        "stats": {
            "cryCount": 69,
            "laughCount": 183,
            "likeCount": 1247,
            "dislikeCount": 0,
            "heartCount": 521,
            "commentCount": 3
        },
        "meta": {
            "Size": "896x1152",
            "seed": 697818409,
            "Model": "wildcardxXLFusion_fusionOG",
            "steps": 30,
            "hashes": {
                "model": "22ebc61141"
            },
            "prompt": "fleeting, ethereal, alluring, sparkling, artistic, mysterious, delicate, complex, black-and-white, twisted, by Graham Sutherland, Dan Mumford, Massimo Vitali, Hikari Shimoda, Xanti Schawinsky",
            "Version": "v1.8.0",
            "sampler": "Euler",
            "cfgScale": 4,
            "Mask blur": "4",
            "resources": [
                {
                    "hash": "22ebc61141",
                    "name": "wildcardxXLFusion_fusionOG",
                    "type": "model"
                }
            ],
            "Model hash": "22ebc61141",
            "Hires steps": "20",
            "Inpaint area": "Only masked",
            "Hires upscale": "1.5",
            "Hires upscaler": "4x_UniversalUpscalerV2-Sharp_101000_G",
            "negativePrompt": "(worst quality, greyscale, jpeg artifacts, spots and lines on skin:2)",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer steps": "30",
            "ADetailer version": "24.3.5",
            "Denoising strength": "0.4",
            "ADetailer CFG scale": "7.0",
            "ADetailer mask blur": "4",
            "Masked area padding": "32",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer use separate steps": "True",
            "ADetailer inpaint only masked": "True",
            "ADetailer use separate CFG scale": "True",
            "ADetailer mask only top k largest": "3"
        },
        "username": "ArtifyAI",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 37546817,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6b8b98a7-a4b9-4c44-a80f-c35fea395c18/width=1536/6b8b98a7-a4b9-4c44-a80f-c35fea395c18.jpeg",
        "hash": "UHBo%Lv~0fog|wxGFKsAQ.Natk$*9^K3s,#T",
        "width": 1536,
        "height": 2312,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-31T10:41:51.098Z",
        "postId": 8576764,
        "stats": {
            "cryCount": 90,
            "laughCount": 145,
            "likeCount": 1388,
            "dislikeCount": 0,
            "heartCount": 395,
            "commentCount": 5
        },
        "meta": {
            "Size": "1024x1544",
            "seed": 4217318335,
            "Model": "flux_dev",
            "steps": 25,
            "hashes": {
                "model": "2eda627c8a",
                "lora:aidmaMJ6.1_v0.3": "3b1b4c38ecee"
            },
            "Version": "v1.10.1",
            "sampler": "Euler",
            "cfgScale": 1,
            "Mask blur": "4",
            "resources": [
                {
                    "hash": "3b1b4c38ecee",
                    "name": "aidmaMJ6.1_v0.3",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "2eda627c8a",
                    "name": "flux_dev",
                    "type": "model"
                }
            ],
            "Model hash": "2eda627c8a",
            "Schedule type": "Automatic",
            "Denoising strength": "0"
        },
        "username": "Castr0",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 26472405,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/004a1dc5-eef5-4cef-ab53-d6fe2cf6d637/width=832/004a1dc5-eef5-4cef-ab53-d6fe2cf6d637.jpeg",
        "hash": "UHByUrn,byxw|NjZJPRizrsWEIRi#ZW=K0tR",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-27T23:06:20.968Z",
        "postId": 5917380,
        "stats": {
            "cryCount": 57,
            "laughCount": 166,
            "likeCount": 1308,
            "dislikeCount": 0,
            "heartCount": 487,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 4192490954,
            "steps": 19,
            "prompt": "cat,",
            "sampler": "DDIM",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-08-23T0642:35.6160174Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 686204,
                    "modelVersionName": "V7"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 60938,
                    "modelVersionName": "negative_hand"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 491102,
                    "modelVersionName": "SDXL"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "montana_fox",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 12309249,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/09f695b4-68d5-47b1-8165-29f7c12b3ece/width=1224/09f695b4-68d5-47b1-8165-29f7c12b3ece.jpeg",
        "hash": "UaD,1,-=D$V[^-xtR*ogNHof%MxaJDbwxZjE",
        "width": 1224,
        "height": 2048,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-13T03:11:24.943Z",
        "postId": 2718320,
        "stats": {
            "cryCount": 83,
            "laughCount": 152,
            "likeCount": 1267,
            "dislikeCount": 0,
            "heartCount": 516,
            "commentCount": 2
        },
        "meta": {
            "Size": "768x1280",
            "seed": 4280568602,
            "Model": "TamarinXL_v10",
            "steps": 30,
            "hashes": {
                "model": "2d1805f294",
                "lora:MJ52": "000c96b6bd08",
                "lora:last": "b1ba0aeaf1e5",
                "lora:xl_more_art-full_v1": "fe3b4816be83"
            },
            "prompt": "Generate an enchanting and surreal depiction of a world locked in perpetual twilight. Picture a captivating landscape where the boundaries between day and night blur into an everlasting twilight. The sky should be a mesmerizing blend of deep blues and soft purples, with a faint, ethereal glow on the horizon. Show a mystical terrain, featuring delicate, bioluminescent flora and fauna that illuminate the landscape with gentle, otherworldly radiance. Let the scene emanate a sense of tranquility, mystery, and a touch of magic. Focus on intricate details and realism to create an image that transports viewers to this captivating twilight realm<lora:xl_more_art-full_v1:0.3> <lora:MJ52:0.4> <lora:last:0.8>",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ 3M SDE Karras",
            "cfgScale": 5,
            "resources": [
                {
                    "hash": "fe3b4816be83",
                    "name": "xl_more_art-full_v1",
                    "type": "lora",
                    "weight": 0.3
                },
                {
                    "hash": "000c96b6bd08",
                    "name": "MJ52",
                    "type": "lora",
                    "weight": 0.4
                },
                {
                    "hash": "b1ba0aeaf1e5",
                    "name": "last",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "2d1805f294",
                    "name": "TamarinXL_v10",
                    "type": "model"
                }
            ],
            "Model hash": "2d1805f294",
            "Hires steps": "15",
            "Hires upscale": "1.6",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "NSFW, nude, naked, porn, ugly, cleavage, extra hands, (deformed iris, deformed pupils), text, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, (extra fingers), (mutated hands), poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, (fused fingers), (too many fingers), long neck, camera, name, signature, watermark, logo, autograph, trademark, cut off, censored, bad anatomy, bad body, bad face, bad teeth, deformities, (boring, uninteresting:1.1)",
            "Denoising strength": "0.45"
        },
        "username": "kunge",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 38558800,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c9d41e23-d04e-40bb-9181-2ab38a582669/width=896/c9d41e23-d04e-40bb-9181-2ab38a582669.jpeg",
        "hash": "UEFiDK00~pRkIUIUE1IUxtf5s:-pD*bb%2NG",
        "width": 896,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-10T13:47:11.032Z",
        "postId": 8799847,
        "stats": {
            "cryCount": 76,
            "laughCount": 138,
            "likeCount": 1424,
            "dislikeCount": 0,
            "heartCount": 378,
            "commentCount": 0
        },
        "meta": {
            "Size": "896x1152",
            "seed": 1737776244,
            "Model": "iNiverseMix_F1D_fp8_real_NSFW_V21",
            "steps": 20,
            "hashes": {
                "model": "15ab0381d1"
            },
            "prompt": "hanfu girl,Cinematic Lighting,kongfu,with a chinese dagger,rain,soaked to the surface,portrait,dynamic posture of sword swing,chinese characters,Ink wash painting,",
            "Version": "f2.0.1v1.10.1-previous-581-ge4ad1140",
            "sampler": "Euler",
            "Module 1": "ae",
            "Module 2": "clip_l",
            "Module 3": "t5xxl_fp8_e4m3fn",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "15ab0381d1",
                    "name": "iNiverseMix_F1D_fp8_real_NSFW_V21",
                    "type": "model"
                }
            ],
            "Model hash": "15ab0381d1",
            "Schedule type": "Simple",
            "Distilled CFG Scale": "3.5"
        },
        "username": "JinnGames",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 38361815,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3dfe5e6e-cf23-4df1-86b7-83f27436d08e/width=1248/3dfe5e6e-cf23-4df1-86b7-83f27436d08e.jpeg",
        "hash": "UEC645~W={M{r=R*t6-pE2xGNbxttSxGS4Rk",
        "width": 1248,
        "height": 1824,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-05T00:36:23.592Z",
        "postId": 8758004,
        "stats": {
            "cryCount": 72,
            "laughCount": 153,
            "likeCount": 1316,
            "dislikeCount": 0,
            "heartCount": 473,
            "commentCount": 1
        },
        "meta": {
            "seed": 1068140337,
            "Model": "OfficialStableDiffusion/oneFORALLReality_vPony",
            "steps": 50,
            "width": 832,
            "height": 1216,
            "prompt": "kftenhance, safe_pos, score_9, score_8_up, score_7_up, upper body, score_9, score_8_up, score_7_up, solo, Dragonborn, furry dragon, red eyes, black scales, metallic shine, Throne room background, dark, dark clothes, lawful neutral alignment, dungeons and dragons character, highly detailed, dnd, cowboy shot, evil, evil grin, <lora:KFT_FSSE_V6.3-000005:0.6>",
            "sampler": "dpmpp_3m_sde_gpu",
            "cfgScale": 4,
            "scheduler": "sgm_uniform",
            "negativePrompt": "signature, watermark,  (human:2), eyes",
            "originalSampler": "dpmpp_3m_sde_gpu"
        },
        "username": "kftiger",
        "baseModel": null
    },
    {
        "id": 36268294,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/969d705c-8b88-487e-8723-fe1e5580b4f3/width=832/969d705c-8b88-487e-8723-fe1e5580b4f3.jpeg",
        "hash": "U7I}bV00.lqu2|+ro#Si03V=00O[0.Ql=s?w",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-24T09:20:00.000Z",
        "postId": 8285151,
        "stats": {
            "cryCount": 98,
            "laughCount": 189,
            "likeCount": 1290,
            "dislikeCount": 0,
            "heartCount": 433,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3397141043,
            "extra": {
                "remixOfId": 33335341
            },
            "steps": 25,
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime. zPDXL3, 1girl, solo, Mafuyu, Sofia maid outfit, Sofia maid headdress, Sofia maid gloves, looking at viewer, smile, leaning forward, bed sheet, window, sunlight, sunny, blue sky, cloud, pov, from below, backlighting",
            "sampler": "Euler a",
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-13T1828:43.0260447Z",
            "negativePrompt": "score_5, score_4, score_3, score_2, score_1,low quality, bad hands, (3d, COM3D2:0.3)",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 931577,
                    "modelVersionName": "v9.0"
                },
                {
                    "type": "lycoris",
                    "weight": 1,
                    "modelVersionId": 948390,
                    "modelVersionName": "pony_v5_16epochs"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 720175,
                    "modelVersionName": "High Quality V3"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 333590,
                    "modelVersionName": "Anime 2"
                }
            ]
        },
        "username": "Dajiejiekong",
        "baseModel": "Pony"
    },
    {
        "id": 30641999,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a5670b5c-5f03-4ed5-8417-c49ae1ed2b34/width=832/a5670b5c-5f03-4ed5-8417-c49ae1ed2b34.jpeg",
        "hash": "U69Z[mNHKk~UbFM{00bb%#-o$*S$R5M{4:M{",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-21T22:23:44.767Z",
        "postId": 6855536,
        "stats": {
            "cryCount": 64,
            "laughCount": 120,
            "likeCount": 1278,
            "dislikeCount": 0,
            "heartCount": 548,
            "commentCount": 3
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1936631162,
            "steps": 34,
            "prompt": "The goddess of war, Extreme Upper Body Closeup Portrait, Vibrant Amber and golden-black color graded, Face and eyes shaded By the oversized Linen hood, AmanoER, analog Photo of a eerie armored bedouin Warrior witch with a staff full of crystals, the crystals are round translucent black-red, hknature ninja-goddess, action pose, featuring a stylized, a ninja with translucent dark-red ice-based powers. He is depicted standing in a snowy, shadowy background., giving an action pose, Casting a spear Made of ICE and frost. The glowing dark outlines defines the character's muscular physique, ornate suit of armor. The armor includes a translucent amber and black chest piece with intricate Design.",
            "sampler": "Undefined",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-21T1301:12.8723938Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 856921,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 746484,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 762381,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 751598,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.25,
                    "modelVersionId": 827048,
                    "modelVersionName": "Flux"
                }
            ]
        },
        "username": "Ajuro",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 28180588,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/76c5e8b7-1597-477f-9d1b-b643fffb3dcd/width=832/76c5e8b7-1597-477f-9d1b-b643fffb3dcd.jpeg",
        "hash": "UA7w?FH=I:%NT}I9%1o#xBjcNxWUR4kXt7r=",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-07T08:14:32.222Z",
        "postId": 6303911,
        "stats": {
            "cryCount": 103,
            "laughCount": 152,
            "likeCount": 1320,
            "dislikeCount": 0,
            "heartCount": 435,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3960492514,
            "extra": {
                "remixOfId": 27631665
            },
            "steps": 25,
            "prompt": "A large medieval fantasy city, night, the moon is shining brightly, glare from the moon, a castle with fortresses on a hill, a huge dragon flies over the city and pours fire on the city, there is a fire in the city and the castle MythP0rt\n<lora:FredFraiStyle-FLUX-Share:0.5>  <lora:FluxMythP0rtr4itStyle:0.7>   <lora:dark_fantasy_flux:0.9>",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [
                {
                    "name": "FredFraiStyle-FLUX-Share",
                    "type": "lora",
                    "weight": 0.5
                },
                {
                    "name": "FluxMythP0rtr4itStyle",
                    "type": "lora",
                    "weight": 0.7
                },
                {
                    "name": "dark_fantasy_flux",
                    "type": "lora",
                    "weight": 0.9
                }
            ],
            "Created Date": "2024-09-06T2304:39.5507651Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.9,
                    "modelVersionId": 738658,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 753053,
                    "modelVersionName": "Flux"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 759600,
                    "modelVersionName": "FredFraiche!"
                }
            ]
        },
        "username": "KuroBlack",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 21195392,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b9e18aac-8ec1-4de1-ade1-e21a95ace304/width=832/b9e18aac-8ec1-4de1-ade1-e21a95ace304.jpeg",
        "hash": "U7CG6#R803_Jy=^iIBEl02Tc^IDQ015n^%ml",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-24T16:58:37.483Z",
        "postId": 4727264,
        "stats": {
            "cryCount": 44,
            "laughCount": 149,
            "likeCount": 1428,
            "dislikeCount": 0,
            "heartCount": 388,
            "commentCount": 6
        },
        "meta": {
            "Size": "832x1216",
            "seed": 663344632,
            "steps": 25,
            "prompt": "a cute salamander sitting on an apple. made out of potato chips, p1nkch1ps, enhanced textures, creative, beautiful, vibrant, masterpiece, 8k, Ultra HD, amazing details, amazing quality, amazing artist, sharp edges, detailed textures, full view, atmospheric lighting, amazing visuals",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-07-24T1646:40.4304470Z",
            "negativePrompt": "ImgFixerPre0.3, bad artist, bad eyes, blurry, low resolution, bad, ugly, bad composition, watermark, signature, worst quality, low quality, simple background, inaccurate limb, extra fingers, fewer fingers, missing fingers, extra arms, extra legs, inaccurate eyes, bad anatomy, error, extra digit, fewer digits, cinnadust, cropped, jpeg artifacts, trademark, artist's name, username, signature, blurry foreground, blurry background",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 462564,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 667768,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 159184,
                    "modelVersionName": "ImgFixer PreV0.3"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "Cinnadust",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 16084900,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2c273437-5a7f-4b2f-99b5-ae4889cb09cf/width=832/2c273437-5a7f-4b2f-99b5-ae4889cb09cf.jpeg",
        "hash": "U14KtSsuD|x9A6oOjCR~4,Np-sw,wSjubwWQ",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-17T04:20:47.391Z",
        "postId": 3594252,
        "stats": {
            "cryCount": 54,
            "laughCount": 128,
            "likeCount": 1324,
            "dislikeCount": 0,
            "heartCount": 504,
            "commentCount": 4
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3938263557,
            "steps": 28,
            "prompt": "zPDXL2, score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, Score_9, score_8_up, score_7_up, score_6_up, , , black silhouette, galaxy, glowing white eyes, no mouth",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-06-17T0420:05.2030091Z",
            "negativePrompt": "worst quality, low quality, lowres, blurry, white background",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 290640,
                    "modelVersionName": "V6 (start with this one)"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208,
                    "modelVersionName": "EasyNegative"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 578019,
                    "modelVersionName": "BG A."
                },
                {
                    "type": "lora",
                    "weight": 0.9,
                    "modelVersionId": 484099,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "Quit_acc",
        "baseModel": "Pony"
    },
    {
        "id": 28342086,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/35a15181-9bb5-42fe-90df-21d18f582555/width=800/35a15181-9bb5-42fe-90df-21d18f582555.jpeg",
        "hash": "U98F.EP:00-TdBIqWA.7^QZh8{yYx]R5NGyX",
        "width": 800,
        "height": 1200,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-08T07:45:01.288Z",
        "postId": 6340754,
        "stats": {
            "cryCount": 94,
            "laughCount": 132,
            "likeCount": 1298,
            "dislikeCount": 0,
            "heartCount": 483,
            "commentCount": 0
        },
        "meta": {
            "Size": "800x1200",
            "seed": 294263537,
            "Model": "svsn001_v10",
            "steps": 50,
            "hashes": {
                "model": "0662af5f19",
                "lora:Cosine_freck": "455da7a6be47",
                "lora:add-detail-xl": "9c783c8ce46c"
            },
            "prompt": "(((a forgotten crypt, where cobwebs hang heavy and the atmosphere is thick with the scent of old bones and dust))), Vivid Teals, Tropical Vibe: vibrant lighting, teal tones, sharp focus, lively ambiance, tropical elements, rich textures, vibrant look, lively atmosphere, tropical aesthetics, capturing nature's beauty, joyful emotions, vibrant scenes, artistic feel, storytelling through colors, professional technique, striking visuals, tropical concept, lively styling, vibrant environment, surreal aesthetics, captivating narratives, intricate details, tropical landscape, editorial storytelling, vibrant glows, evoking joy, pushing creative vision <lora:add-detail-xl:2> <lora:Cosine_freck:1>",
            "Version": "v1.10.1",
            "sampler": "DPM++ 3M SDE",
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "9c783c8ce46c",
                    "name": "add-detail-xl",
                    "type": "lora",
                    "weight": 2
                },
                {
                    "hash": "455da7a6be47",
                    "name": "Cosine_freck",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "0662af5f19",
                    "name": "svsn001_v10",
                    "type": "model"
                }
            ],
            "Model hash": "0662af5f19",
            "Schedule type": "Exponential",
            "negativePrompt": "score_6, score_5, score_4, fcNeg, simple background, blur, low quality,  fairy wings, elf ears, censored , cross-eyed, (lazy eye), bucktooth, mature, cartoon, ugly, anime, whore, makeup, burned, sunburned, ghostly, deformed, dismembered, disembodied, detached, fat, chubby, polydactyl, amputated, contorted, flat-chested, fingers"
        },
        "username": "VisualVisions",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 14967804,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9a60a101-a4f2-49a5-b2d9-cea8f9516660/width=1024/9a60a101-a4f2-49a5-b2d9-cea8f9516660.jpeg",
        "hash": "U33vX6V[8wo~IMjYt0kD8woe%~e.?=axIDbH",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-07T18:11:47.351Z",
        "postId": 3318761,
        "stats": {
            "cryCount": 66,
            "laughCount": 144,
            "likeCount": 1367,
            "dislikeCount": 0,
            "heartCount": 430,
            "commentCount": 1
        },
        "meta": {
            "Size": "1024x1024",
            "seed": 1068492753,
            "steps": 30,
            "prompt": "Ultra realistic color pencil  image of \na man standing in the middle of a field on a cloudy night, watching a city-sized spaceship descending in the background. Only light comes from the spaceship. silhouette style,\nBREAK\nDeep dark intense midnight blue misty background ,\nDark theme, dynamic lighting, (soft shadows), (soft focus), (photo realistic), uhd, 8k",
            "sampler": "Euler a",
            "cfgScale": 9,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-06-07T1740:18.2231720Z",
            "negativePrompt": "ng_deepnegative_v1_75t,  blurry, text, watermark,  (headdress), borders, washed out, documentary, candid, plain, FingerInside ass, car, journalistic, watermark, pens, pencils, drawing tools, brushes, (pubic hair:1.7),",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 344487,
                    "modelVersionName": "V4.0 (BakedVAE)"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 5637,
                    "modelVersionName": "V1 75T"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 293991,
                    "modelVersionName": "v24"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 383563,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 445047,
                    "modelVersionName": "Silhouette v1.1"
                },
                {
                    "type": "vae",
                    "weight": 1,
                    "modelVersionId": 333245,
                    "modelVersionName": "SDXL-VAE"
                }
            ]
        },
        "username": "hypnochristian701",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 9998658,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/521ccac3-8b6d-4213-afea-6de521d465ae/width=896/521ccac3-8b6d-4213-afea-6de521d465ae.jpeg",
        "hash": "U85i]7yEL#H?RhV?M{S$dVoKcbpJt-bvZ#aL",
        "width": 896,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-16T07:34:35.711Z",
        "postId": 2176604,
        "stats": {
            "cryCount": 62,
            "laughCount": 208,
            "likeCount": 1214,
            "dislikeCount": 0,
            "heartCount": 523,
            "commentCount": 5
        },
        "meta": {
            "Size": "896x1152",
            "seed": 357940592962759800,
            "Model": "openxlVersion21_v21",
            "steps": 60,
            "hashes": {
                "model": "cfd71bb3ec"
            },
            "prompt": "Telography Cognivore Hydralized Caves of Chaos Adventurer astralglassmic Mihoko Ogaki Vaporizer, Telography Cognivore Hydralized Caves of Chaos Adventurer astralglassmic Mihoko Ogaki Vaporizer, detailed, high quality, dynamic, fluid, realistic, intricate, shiny, glowing, rich deep vivid, crystal, sharp, complex, fine contrast, reflective, striking, brilliant, polished, sparkling, clear, crisp, resolution,,, impressive",
            "Version": "Fooocus v2.3.1",
            "sampler": "dpmpp_3m_sde_gpu",
            "cfgScale": 6.66,
            "Scheduler": "exponential",
            "Sharpness": "1",
            "resources": [
                {
                    "hash": "cfd71bb3ec",
                    "name": "openxlVersion21_v21",
                    "type": "model"
                }
            ],
            "Model hash": "cfd71bb3ec",
            "Raw prompt": "Telography Cognivore Hydralized Caves of Chaos Adventurer astralglassmic Mihoko Ogaki Vaporizer",
            "Performance": "Quality",
            "ADM Guidance": {},
            "Raw negative prompt": ""
        },
        "username": "DeepDemiurge",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 29791893,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5d79c936-32a0-451b-a3f1-63c67c80cdc7/width=1800/5d79c936-32a0-451b-a3f1-63c67c80cdc7.jpeg",
        "hash": "UVEWm}RjyDV@tljFRjog?wtSIAV@xvozt7of",
        "width": 2496,
        "height": 3648,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-17T00:02:01.799Z",
        "postId": 6666160,
        "stats": {
            "cryCount": 70,
            "laughCount": 195,
            "likeCount": 1213,
            "dislikeCount": 0,
            "heartCount": 528,
            "commentCount": 3
        },
        "meta": {
            "Size": "832x1216",
            "seed": 126510547,
            "Model": "flux1-dev-Q4_0",
            "steps": 22,
            "hashes": {
                "model": "e9c9d702d0",
                "lora:FluxBlackT40k": "9496a38cdc0f"
            },
            "prompt": "An atmospheric and powerful dark fantasy image, classical style painting of a beautiful female BlackT40k space marine dressed in intricate power armor. She crouches with her head down and her dirty blonde hair falls over her face. She holds a powerful sword of dark steel. There is blood in the snow around her from a fallen enemy. Cinematic shot in a snowy mountainous region. <lora:FluxBlackT40k:1>",
            "Version": "f2.0.1v1.10.1-previous-519-g44eb4ea8",
            "sampler": "Euler",
            "Module 1": "ae",
            "Module 2": "t5xxl_fp16",
            "Module 3": "clip_l",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "9496a38cdc0f",
                    "name": "FluxBlackT40k",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "e9c9d702d0",
                    "name": "flux1-dev-Q4_0",
                    "type": "model"
                }
            ],
            "Model hash": "e9c9d702d0",
            "Hires steps": "15",
            "Hires upscale": "1.5",
            "Original Size": "832x1216",
            "Schedule type": "Simple",
            "Hires upscaler": "4x_foolhardy_Remacri",
            "Denoising strength": "0.5",
            "Distilled CFG Scale": "3.5",
            "Hires schedule type": "Simple",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)"
        },
        "username": "VelvetS",
        "baseModel": null
    },
    {
        "id": 26037114,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/647c62d5-a261-4fad-aa1a-857b560b60fb/width=832/647c62d5-a261-4fad-aa1a-857b560b60fb.jpeg",
        "hash": "UKI}CI%1D%oc,loKE3js~VR+$ds.9GfPs;az",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-25T07:07:43.862Z",
        "postId": 5820416,
        "stats": {
            "cryCount": 62,
            "laughCount": 209,
            "likeCount": 1254,
            "dislikeCount": 0,
            "heartCount": 481,
            "commentCount": 6
        },
        "meta": null,
        "username": "cobrecht",
        "baseModel": ""
    },
    {
        "id": 11344630,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/11d33c4e-0cb1-41e8-87b5-cdb9019d0638/width=768/11d33c4e-0cb1-41e8-87b5-cdb9019d0638.jpeg",
        "hash": "UIF#?w?c0gIV~Dg59|a#VaD*E2%L,IRQNGxu",
        "width": 768,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-02T15:25:08.212Z",
        "postId": 2493249,
        "stats": {
            "cryCount": 81,
            "laughCount": 180,
            "likeCount": 1233,
            "dislikeCount": 0,
            "heartCount": 511,
            "commentCount": 2
        },
        "meta": {
            "Size": "768x1024",
            "seed": 2625339907,
            "Model": "ponyFaetality_v10",
            "steps": 20,
            "hashes": {
                "model": "90d594fd01",
                "lora:ral-fntsyrlms-sdxl": "98195fff6d5c"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, Magical Forest scenery,looking at the viewer, ultra realistic extremely detailed, meadow, castle crystal clear lake, trees, realistic highly detailed colorful field of flowers, (soft particles of fractal energy:1.3), depth of filed, (neon light particles:1.1), ultra-detailed,extremely delicate cute and beautiful,masterpiece,best quality, cinematic angle, cinematic lights, vibrant, vivid color,movie lens,movie special effects,detailed details,HDR,UHD,32K,concept art, magical scenery at daylight, (colorful butterflies:1.6), (full body:1.9), sharp focus, intricate details, iluminated by bright colors, (colorful flowers:1.3), (colorful particles:1.3), soft skin, (adorable look:1.8)(glowing tones:1.6),(glitter tones:1.2), beautiful,  <lora:ral-fntsyrlms-sdxl:1> ral-fntsyrlms",
            "Version": "v1.9.0",
            "sampler": "DPM++ 2M",
            "cfgScale": 8,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "98195fff6d5c",
                    "name": "ral-fntsyrlms-sdxl",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "90d594fd01",
                    "name": "ponyFaetality_v10",
                    "type": "model"
                }
            ],
            "Model hash": "90d594fd01",
            "Schedule type": "Karras",
            "negativePrompt": "worst quality, low quality, normal quality,bad X,bad-hands-5,EasyNegativeV2,ng_deepnegative_v1_75t,myself-badhand-v5,verybadimagenegative_v1.3,SuperNeg-Test,bad_prompt_version2-neg,text,signature, watermark"
        },
        "username": "GrumpyFurball",
        "baseModel": "PonyPony"
    },
    {
        "id": 12337514,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c55dd28c-7718-42b9-ba9c-4498d754fe0e/width=832/c55dd28c-7718-42b9-ba9c-4498d754fe0e.jpeg",
        "hash": "U9ELHg$*0OOE%7Rk5r={:NR*GHo~9XJm%1r?",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-13T11:17:56.715Z",
        "postId": 2724955,
        "stats": {
            "cryCount": 72,
            "laughCount": 164,
            "likeCount": 1258,
            "dislikeCount": 0,
            "heartCount": 510,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2098123672,
            "Model": "WildcardX-XL-Lightning",
            "steps": 6,
            "hashes": {
                "model": "f53945ec37"
            },
            "prompt": "masterpiece, An oil painting of an alien planet, Van Gogh, galaxy in background, vibrant colors, best quality, highly detailed",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ SDE Karras",
            "cfgScale": 2,
            "resources": [
                {
                    "hash": "f53945ec37",
                    "name": "WildcardX-XL-Lightning",
                    "type": "model"
                }
            ],
            "Model hash": "f53945ec37",
            "negativePrompt": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (mutated hands, poorly drawn hands, poorly drawn face, extra limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, extra fingers, deformed iris, deformed pupils, long neck), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated, malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (bad hands, bad anatomy, bad proportions, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3), (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D, 3D Game, 3D Game Scene, 3D Character:1.1)"
        },
        "username": "isr431",
        "baseModel": "SDXL Lightning"
    },
    {
        "id": 39178506,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ae524913-fdac-48bf-81c0-468833e900ef/width=832/ae524913-fdac-48bf-81c0-468833e900ef.jpeg",
        "hash": "U46uR@%~G^7h.SNweSMx02K6=E]#4owJR5-6",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-09T15:48:00.362Z",
        "postId": 8939634,
        "stats": {
            "cryCount": 111,
            "laughCount": 145,
            "likeCount": 1351,
            "dislikeCount": 0,
            "heartCount": 396,
            "commentCount": 2
        },
        "meta": {
            "prompt": "A Ghostly Sailor, spectral mariner with tattered uniform, glowing white eyes, holding a spectral lantern, haunted ship deck, misty sea background, dim lanterns, atmosphere of lost voyages and ghostly tales."
        },
        "username": "Adel_AI",
        "baseModel": null
    },
    {
        "id": 37100669,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/407ef953-b447-4f23-9e50-9a81e6e0a91f/width=1536/407ef953-b447-4f23-9e50-9a81e6e0a91f.jpeg",
        "hash": "U7AI_V57{e^P?bxZMx%LY5oJ66tQ}@Egt7t7",
        "width": 1536,
        "height": 2560,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-28T23:08:36.170Z",
        "postId": 8473204,
        "stats": {
            "cryCount": 59,
            "laughCount": 124,
            "likeCount": 1274,
            "dislikeCount": 0,
            "heartCount": 544,
            "commentCount": 2
        },
        "meta": {
            "vaes": [
                "sd3-5vae.safetensors"
            ],
            "Model": "sd3.5_large",
            "comfy": "{\"prompt\": {\"6\": {\"inputs\": {\"text\": \"A magical woodland scene, soft fantasy lighting, ethereal glow; a fluffy, young sheep with large, expressive eyes, clothed in leaves and moss, small antlers adorned with delicate green foliage, soft white wool blending with warm earthy tones; a gentle drizzle falls around, casting glistening droplets on its fur; surrounded by glowing fireflies, lush forest plants, and a misty, dimly lit background that shifts from deep blues to vibrant greens; rays of golden light break through the trees above, illuminating the sheep\\u2019s face, creating a calm and enchanting atmosphere.\", \"clip\": [\"182\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Positive Prompt)\"}}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"361\", 0]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"13\": {\"inputs\": {\"noise\": [\"50\", 0], \"guider\": [\"183\", 0], \"sampler\": [\"334\", 0], \"sigmas\": [\"302\", 1], \"latent_image\": [\"45\", 0]}, \"class_type\": \"SamplerCustomAdvanced\", \"_meta\": {\"title\": \"SamplerCustomAdvanced\"}}, \"38\": {\"inputs\": {\"text\": \"\", \"clip\": [\"182\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode\"}}, \"41\": {\"inputs\": {\"pixels\": [\"359\", 0], \"vae\": [\"361\", 0]}, \"class_type\": \"VAEEncode\", \"_meta\": {\"title\": \"VAE Encode\"}}, \"45\": {\"inputs\": {\"noise\": [\"50\", 0], \"guider\": [\"46\", 0], \"sampler\": [\"335\", 0], \"sigmas\": [\"302\", 0], \"latent_image\": [\"287\", 3]}, \"class_type\": \"SamplerCustomAdvanced\", \"_meta\": {\"title\": \"SamplerCustomAdvanced\"}}, \"46\": {\"inputs\": {\"model\": [\"280\", 0], \"conditioning\": [\"356\", 0]}, \"class_type\": \"BasicGuider\", \"_meta\": {\"title\": \"BasicGuider\"}}, \"50\": {\"inputs\": {}, \"class_type\": \"DisableNoise\", \"_meta\": {\"title\": \"DisableNoise\"}}, \"182\": {\"inputs\": {\"clip_name1\": \"OPENAIclip_g.safetensors\", \"clip_name2\": \"OPENAIclip_l.safetensors\", \"clip_name3\": \"t5xxl_fp16.safetensors\"}, \"class_type\": \"TripleCLIPLoader\", \"_meta\": {\"title\": \"TripleCLIPLoader\"}}, \"183\": {\"inputs\": {\"cfg\": 5.0, \"model\": [\"280\", 0], \"positive\": [\"356\", 0], \"negative\": [\"288\", 0]}, \"class_type\": \"CFGGuider\", \"_meta\": {\"title\": \"CFGGuider\"}}, \"191\": {\"inputs\": {\"steps\": 40, \"alpha\": 0.5, \"beta\": 0.7, \"model\": [\"280\", 0]}, \"class_type\": \"BetaSamplingScheduler\", \"_meta\": {\"title\": \"BetaSamplingScheduler\"}}, \"280\": {\"inputs\": {\"scaling\": \"exponential\", \"shift\": 3.0, \"model\": [\"369\", 0]}, \"class_type\": \"SD35L_TimestepPatcher\", \"_meta\": {\"title\": \"SD35L_TimestepPatcher\"}}, \"287\": {\"inputs\": {\"precision\": \"fp64\", \"set_default\": false, \"cond_pos\": [\"398\", 0], \"cond_neg\": [\"288\", 0], \"sigmas\": [\"353\", 0], \"latent_image\": [\"41\", 0]}, \"class_type\": \"Set Precision Universal\", \"_meta\": {\"title\": \"Set Precision Universal\"}}, \"288\": {\"inputs\": {\"conditioning\": [\"38\", 0]}, \"class_type\": \"ConditioningZeroOut\", \"_meta\": {\"title\": \"ConditioningZeroOut\"}}, \"302\": {\"inputs\": {\"sigmas\": [\"287\", 2]}, \"class_type\": \"Sigmas Noise Inversion\", \"_meta\": {\"title\": \"Sigmas Noise Inversion\"}}, \"334\": {\"inputs\": {\"momentum\": 0.0, \"eta_value\": 0.5, \"eta\": 0.25, \"eta_var\": 0.0, \"s_noise\": 1.0, \"alpha\": 0.0, \"k\": 1.0, \"noise_sampler_type\": \"brownian\", \"noise_mode\": \"hard\", \"sde_seed\": 6, \"order\": 3, \"cfgpp\": 1.0, \"latent_guide_weight\": 1.0, \"model\": [\"280\", 0], \"eta_values\": [\"337\", 0], \"latent_guide\": [\"41\", 0]}, \"class_type\": \"SamplerNoiseInversion\", \"_meta\": {\"title\": \"SamplerNoiseInversion\"}}, \"335\": {\"inputs\": {\"momentum\": 0.0, \"eta_value\": 0.5, \"eta\": 0.25, \"eta_var\": 0.0, \"s_noise\": 1.0, \"alpha\": 0.0, \"k\": 1.0, \"noise_sampler_type\": \"gaussian\", \"noise_mode\": \"hard\", \"sde_seed\": 1003, \"order\": 2, \"cfgpp\": 0.0, \"latent_guide_weight\": 1.0, \"model\": [\"280\", 0]}, \"class_type\": \"SamplerNoiseInversion\", \"_meta\": {\"title\": \"SamplerNoiseInversion\"}}, \"337\": {\"inputs\": {\"steps\": 13, \"alpha\": 0.5, \"beta\": 0.7, \"model\": [\"280\", 0]}, \"class_type\": \"BetaSamplingScheduler\", \"_meta\": {\"title\": \"BetaSamplingScheduler\"}}, \"344\": {\"inputs\": {\"image\": \"36009593.jpeg\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"_meta\": {\"title\": \"Load Image\"}, \"is_changed\": [\"23b87b7b8fbef8e44c26c5f421b31e7a8db80db2a2af5510d39df248351034e0\"]}, \"353\": {\"inputs\": {\"start\": 0.8999999999999999, \"end\": 0.0, \"sigmas\": [\"191\", 0]}, \"class_type\": \"Sigmas Rescale\", \"_meta\": {\"title\": \"Sigmas Rescale\"}}, \"356\": {\"inputs\": {\"precision\": \"fp64\", \"set_default\": false, \"cond_pos\": [\"398\", 0]}, \"class_type\": \"Set Precision Universal\", \"_meta\": {\"title\": \"Set Precision Universal\"}}, \"359\": {\"inputs\": {\"width\": [\"370\", 1], \"height\": [\"370\", 2], \"interpolation\": \"nearest\", \"method\": \"fill / crop\", \"condition\": \"always\", \"multiple_of\": 0, \"image\": [\"344\", 0]}, \"class_type\": \"ImageResize+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Image Resize\"}}, \"361\": {\"inputs\": {\"vae_name\": \"sd3-5vae.safetensors\"}, \"class_type\": \"VAELoader\", \"_meta\": {\"title\": \"Load VAE\"}}, \"362\": {\"inputs\": {\"VAE\": [\"361\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"369\": {\"inputs\": {\"ckpt_name\": \"sd3.5_large.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\", \"_meta\": {\"title\": \"Load Checkpoint\"}}, \"370\": {\"inputs\": {\"resolution\": \"768x1280 (0.6)\", \"batch_size\": 1, \"width_override\": 0, \"height_override\": 0}, \"class_type\": \"SDXLEmptyLatentSizePicker+\", \"_meta\": {\"title\": \"\\ud83d\\udd27 Empty Latent Size Picker\"}}, \"371\": {\"inputs\": {\"mode\": \"Repeat last selection\", \"count\": 1, \"images\": [\"8\", 0]}, \"class_type\": \"Preview Chooser\", \"_meta\": {\"title\": \"Preview Chooser\"}, \"is_changed\": [0.6566568114562574]}, \"372\": {\"inputs\": {\"filename_prefix\": \"sd3/clowninv/comfyui\", \"images\": [\"373\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}, \"373\": {\"inputs\": {\"upscale_by\": [\"375\", 3], \"seed\": 1000122408342704, \"steps\": 20, \"cfg\": 1.0, \"sampler_name\": \"dpmpp_2m\", \"scheduler\": \"sgm_uniform\", \"denoise\": 0.2, \"mode_type\": \"Linear\", \"tile_width\": [\"375\", 1], \"tile_height\": [\"375\", 2], \"mask_blur\": 16, \"tile_padding\": 32, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 0.25, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 16, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"375\", 0], \"model\": [\"369\", 0], \"positive\": [\"356\", 0], \"negative\": [\"288\", 0], \"upscale_model\": [\"374\", 0], \"vae\": [\"361\", 0]}, \"class_type\": \"UltimateSDUpscale\", \"_meta\": {\"title\": \"Ultimate SD Upscale\"}}, \"374\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"UpscaleModelLoader\", \"_meta\": {\"title\": \"Load Upscale Model\"}}, \"375\": {\"inputs\": {\"slicing\": \"2x2\", \"multiplier\": 2.0, \"image\": [\"371\", 0]}, \"class_type\": \"FL_SDUltimate_Slices\", \"_meta\": {\"title\": \"FL SDUltimate Slices\"}, \"is_changed\": [NaN]}, \"376\": {\"inputs\": {\"rgthree_comparer\": {\"images\": [{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rdlzx_00003_.png&type=temp&subfolder=&rand=0.44207854617154263\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rdlzx_00004_.png&type=temp&subfolder=&rand=0.7183029369810923\"}]}, \"image_a\": [\"8\", 0], \"image_b\": [\"373\", 0]}, \"class_type\": \"Image Comparer (rgthree)\", \"_meta\": {\"title\": \"Image Comparer (rgthree)\"}}, \"377\": {\"inputs\": {\"text\": \"4k, detailed\", \"clip\": [\"182\", 0]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Prompt)\"}}, \"378\": {\"inputs\": {\"text\": [\"389\", 0], \"text2\": \"Digital painting, hyperrealistic style, close-up shot. The composition heavily focuses on the subject\\u2019s face, creating an intimate, intense feel. The lighting emphasizes the shiny, slightly oily texture of the skin, casting soft highlights on the cheek and nose. The subject is a young woman with piercing, reflective eyes, gazing sideways with a serious expression. Her choppy black hair falls loosely around her face, partially obscured by a dark, tactical outfit accented with worn, red paint splatters. The background is a neutral, desaturated gray, keeping the focus entirely on the subject. The image employs the rule of thirds, with her face positioned on the left side, drawing the viewer\\u2019s eye directly to her intense gaze. The weapon resting on her shoulder, a large, rugged, metallic object, is partially visible and adds an element of danger. The overall mood is gritty, with subtle textures of wear and tear adding to the realism.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"LLM Prompt\"}}, \"379\": {\"inputs\": {\"text\": [\"389\", 2], \"text2\": \"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Troubleshooting\"}}, \"380\": {\"inputs\": {\"text\": \"oil painting, impasto, low-angle shot, soft, ethereal lighting. A skeletal queen stands regally, adorned in intricate golden armor laced with blue gemstones. Her ribcage is exposed but beautifully crafted, embedded with glowing jewels. She holds an ornate, towering scythe, bedecked with skulls and decorated with delicate, metallic flourishes. Her long, flowing veil, embroidered with gold and blue, trails behind her, cascading down like a river of fabric. She wears a crown of skeletal motifs, with flowers and bones intertwined. The background depicts a serene, reflective lake nestled between massive, misty mountains under a clear, soft cloud-streaked sky. The mountains and trees are reflected perfectly in the water, with the image framed symmetrically. Hints of warm sunlight peek through, casting a gentle glow on the scene, while the queen's figure contrasts against the peaceful landscape, creating an otherworldly, yet serene atmosphere.\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Examples\"}}, \"381\": {\"inputs\": {\"text\": \"Act as a creative agent who generates highly creative detailed, comma-delimited formatted prompt of up to 150 words for the image. Begin each prompt by specifying an art style (for example, cartoon, impasto, absurdres, oil or acrylic or watercolor painting, or charcoal drawing or engraving or sculpture, etc.)  Include information about lighting. Include information about camera angle. Include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.Do NOT mention any text that is in the image.Specify the depth of field and whether the background is in focus or blurred.Do NOT use any ambiguous language. Include the pose of the subject. Then, continue with descriptive visual elements of the subject, surroundings, and background. Please do not omit any details, especially objects, lighting, colors, and textures, even subtle ones hidden in the background! It is imperative that you carefully consider every aspect of the image, and provide satisfactory descriptions! Also, please be very careful when considering whether the image really is a photograph or actually a detailed painting or illustration.\\n\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"System: Instructions\"}}, \"382\": {\"inputs\": {\"text\": \"Create an image prompt from the image provided, be sure to include all details, emphasis on art style, camera angle and composition\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"User: Prompt\"}}, \"383\": {\"inputs\": {\"image\": \"37074063.jpeg\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"_meta\": {\"title\": \"Load Image\"}, \"is_changed\": [\"2367ac12339f0ac597f7de83fc5250038a922bfc6b3f7f94aa51b89ec8967947\"]}, \"384\": {\"inputs\": {\"text\": [\"390\", 0], \"text2\": \"digital painting, close-up portrait, girl, dark hair, intense gaze, red and black palette, hooded jacket, sci-fi, post-apocalyptic, gritty texture, reflective skin, weapon, cinematic lighting, detailed illustration, dramatic expression, moody atmosphere\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"LLM Prompt\"}}, \"385\": {\"inputs\": {\"text\": [\"390\", 2], \"text2\": \"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Troubleshooting\"}}, \"386\": {\"inputs\": {\"text\": \"Traditional Chinese motifs, Chinese paper cut art, color red and blue, festive, cultural celebration, winter scene, snowflakes, lanterns, snowman, silhouetted cut-out art, intricate cut designs, layered compositions, Chinese ornaments,\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Examples\"}}, \"387\": {\"inputs\": {\"text\": \"Describe the image\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\\nEmphasize key information about the subject, scene, details, effects as needed. Stick with short comma-delimited prompts. start with the art style, then subject, then details like pose, camera angle.\\n\\nNote that Clip-L focuses on specific visual elements and technical details. It lists concrete objects, visual attributes, and effects. Use for specific visual elements and attributes.\\n\\n\\n\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"System: Instructions\"}}, \"388\": {\"inputs\": {\"text\": \"Provide comma-separated keywords as a direct string for the provided image\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"User: Prompt\"}}, \"389\": {\"inputs\": {\"AI_service\": \"ChatGPT\", \"ChatGPT_model\": \"chatgpt-4o-latest\", \"Groq_model\": \"none\", \"Anthropic_model\": \"none\", \"Ollama_model\": \"none\", \"Optional_model\": \"none\", \"creative_latitude\": 0.7, \"tokens\": 300, \"seed\": 353162164338036, \"examples_delimiter\": \"Two newlines\", \"LLM_URL\": \"https://api.groq.com/openai/v1\", \"Instruction\": [\"381\", 0], \"Examples_or_Context\": [\"380\", 0], \"Prompt\": [\"382\", 0], \"image\": [\"383\", 0]}, \"class_type\": \"AdvPromptEnhancer\", \"_meta\": {\"title\": \"Advanced Prompt Enhancer\"}}, \"390\": {\"inputs\": {\"AI_service\": \"ChatGPT\", \"ChatGPT_model\": \"chatgpt-4o-latest\", \"Groq_model\": \"none\", \"Anthropic_model\": \"none\", \"Ollama_model\": \"none\", \"Optional_model\": \"none\", \"creative_latitude\": 0.7, \"tokens\": 100, \"seed\": 285692465375160, \"examples_delimiter\": \"Two newlines\", \"LLM_URL\": \"https://api.groq.com/openai/v1\", \"Instruction\": [\"387\", 0], \"Examples_or_Context\": [\"386\", 0], \"Prompt\": [\"388\", 0], \"image\": [\"383\", 0]}, \"class_type\": \"AdvPromptEnhancer\", \"_meta\": {\"title\": \"Advanced Prompt Enhancer\"}}, \"391\": {\"inputs\": {\"text\": [\"396\", 0], \"text2\": \"A digital painting of a young person with intense eyes, wearing a dark hooded jacket with red accents, and holding a sword on their shoulder.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"LLM Prompt\"}}, \"392\": {\"inputs\": {\"text\": [\"396\", 2], \"text2\": \"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Troubleshooting\"}}, \"393\": {\"inputs\": {\"text\": \"Beautiful Chinese Paper Cutting winter scene with intricately cut Matroshka dolls and snow-covered ornaments, presented in a warm, traditional setting\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"Examples\"}}, \"394\": {\"inputs\": {\"text\": \"Describe the image, in one sentence\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"System: Instructions\"}}, \"395\": {\"inputs\": {\"text\": \"provide a single-sentence description of the provided image\"}, \"class_type\": \"Text Multiline\", \"_meta\": {\"title\": \"User: Prompt\"}}, \"396\": {\"inputs\": {\"AI_service\": \"ChatGPT\", \"ChatGPT_model\": \"chatgpt-4o-latest\", \"Groq_model\": \"none\", \"Anthropic_model\": \"none\", \"Ollama_model\": \"none\", \"Optional_model\": \"none\", \"creative_latitude\": 0.7, \"tokens\": 100, \"seed\": 263716373364502, \"examples_delimiter\": \"Two newlines\", \"LLM_URL\": \"https://api.groq.com/openai/v1\", \"Instruction\": [\"394\", 0], \"Examples_or_Context\": [\"393\", 0], \"Prompt\": [\"395\", 0], \"image\": [\"383\", 0]}, \"class_type\": \"AdvPromptEnhancer\", \"_meta\": {\"title\": \"Advanced Prompt Enhancer\"}}, \"398\": {\"inputs\": {\"clip_l\": [\"401\", 0], \"clip_g\": [\"402\", 0], \"t5xxl\": [\"403\", 0], \"empty_padding\": \"none\", \"clip\": [\"182\", 0]}, \"class_type\": \"CLIPTextEncodeSD3\", \"_meta\": {\"title\": \"CLIPTextEncodeSD3\"}}, \"401\": {\"inputs\": {\"text\": [\"390\", 0], \"text2\": \"digital painting, close-up portrait, girl, dark hair, intense gaze, red and black palette, hooded jacket, sci-fi, post-apocalyptic, gritty texture, reflective skin, weapon, cinematic lighting, detailed illustration, dramatic expression, moody atmosphere\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Clip-L Prompt\"}}, \"402\": {\"inputs\": {\"text\": [\"396\", 0], \"text2\": \"A digital painting of a young person with intense eyes, wearing a dark hooded jacket with red accents, and holding a sword on their shoulder.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"Clip-G Prompt\"}}, \"403\": {\"inputs\": {\"text\": [\"389\", 0], \"text2\": \"Digital painting, hyperrealistic style, close-up shot. The composition heavily focuses on the subject\\u2019s face, creating an intimate, intense feel. The lighting emphasizes the shiny, slightly oily texture of the skin, casting soft highlights on the cheek and nose. The subject is a young woman with piercing, reflective eyes, gazing sideways with a serious expression. Her choppy black hair falls loosely around her face, partially obscured by a dark, tactical outfit accented with worn, red paint splatters. The background is a neutral, desaturated gray, keeping the focus entirely on the subject. The image employs the rule of thirds, with her face positioned on the left side, drawing the viewer\\u2019s eye directly to her intense gaze. The weapon resting on her shoulder, a large, rugged, metallic object, is partially visible and adds an element of danger. The overall mood is gritty, with subtle textures of wear and tear adding to the realism.\"}, \"class_type\": \"ShowText|pysssss\", \"_meta\": {\"title\": \"T5 Prompt\"}}, \"404\": {\"inputs\": {\"CLIP\": [\"182\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}}, \"workflow\": {\"last_node_id\": 404, \"last_link_id\": 1000, \"nodes\": [{\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1330, \"1\": 330}, \"size\": {\"0\": 240, \"1\": 330}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 844, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 368, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 862, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 843, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 890, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 41, \"type\": \"VAEEncode\", \"pos\": {\"0\": 330, \"1\": 370}, \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 933}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [676, 896], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 45, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 750, \"1\": 350}, \"size\": {\"0\": 240, \"1\": 330}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 128, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 386, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 898, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 842, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 677, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [890], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 46, \"type\": \"BasicGuider\", \"pos\": {\"0\": 529, \"1\": 294}, \"size\": {\"0\": 161.1999969482422, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 856, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 930, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [386], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 50, \"type\": \"DisableNoise\", \"pos\": {\"0\": 528, \"1\": 351}, \"size\": {\"0\": 140, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [128, 844], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DisableNoise\"}, \"widgets_values\": []}, {\"id\": 183, \"type\": \"CFGGuider\", \"pos\": {\"0\": 1043, \"1\": 285}, \"size\": {\"0\": 210, \"1\": 100}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 855}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 921}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 918}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [368], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CFGGuider\"}, \"widgets_values\": [5]}, {\"id\": 302, \"type\": \"Sigmas Noise Inversion\", \"pos\": {\"0\": 480, \"1\": 420}, \"size\": {\"0\": 184.8000030517578, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 841}], \"outputs\": [{\"name\": \"sigmas_fwd\", \"type\": \"SIGMAS\", \"links\": [842], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"sigmas_rev\", \"type\": \"SIGMAS\", \"links\": [843], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Sigmas Noise Inversion\"}, \"widgets_values\": []}, {\"id\": 353, \"type\": \"Sigmas Rescale\", \"pos\": {\"0\": 492, \"1\": 153}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 913}], \"outputs\": [{\"name\": \"sigmas_rescaled\", \"type\": \"SIGMAS\", \"links\": [914], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Sigmas Rescale\"}, \"widgets_values\": [0.8999999999999999, 0]}, {\"id\": 359, \"type\": \"ImageResize+\", \"pos\": {\"0\": 37, \"1\": 495}, \"size\": [210, 220], \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 927}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 947, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 948, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [933], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"width\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageResize+\"}, \"widgets_values\": [768, 1280, \"nearest\", \"fill / crop\", \"always\", 0]}, {\"id\": 334, \"type\": \"SamplerNoiseInversion\", \"pos\": {\"0\": 1030, \"1\": 460}, \"size\": {\"0\": 250, \"1\": 530}, \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 859}, {\"name\": \"momentums\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"eta_values\", \"type\": \"SIGMAS\", \"link\": 902, \"shape\": 7}, {\"name\": \"t_is\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"etas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"s_noises\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"alphas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide\", \"type\": \"LATENT\", \"link\": 896, \"shape\": 7}, {\"name\": \"latent_guide_weights\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"sampler\", \"type\": \"SAMPLER\", \"links\": [862], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerNoiseInversion\"}, \"widgets_values\": [0, 0.5, 0.25, 0, 1, 0, 1, \"brownian\", \"hard\", 6, 3, 1, 1]}, {\"id\": 191, \"type\": \"BetaSamplingScheduler\", \"pos\": {\"0\": 260, \"1\": 190}, \"size\": {\"0\": 210, \"1\": 110}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 852}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [913], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BetaSamplingScheduler\"}, \"widgets_values\": [40, 0.5, 0.7]}, {\"id\": 287, \"type\": \"Set Precision Universal\", \"pos\": {\"0\": 730, \"1\": 120}, \"size\": {\"0\": 211.60000610351562, \"1\": 142}, \"flags\": {\"collapsed\": false}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"cond_pos\", \"type\": \"CONDITIONING\", \"link\": 990, \"shape\": 7}, {\"name\": \"cond_neg\", \"type\": \"CONDITIONING\", \"link\": 845, \"shape\": 7}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 914, \"shape\": 7}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 676, \"shape\": 7}], \"outputs\": [{\"name\": \"cond_pos\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cond_neg\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"links\": [841], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"links\": [677], \"slot_index\": 3, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Set Precision Universal\"}, \"widgets_values\": [\"fp64\", false]}, {\"id\": 288, \"type\": \"ConditioningZeroOut\", \"pos\": {\"0\": 420, \"1\": 64}, \"size\": {\"0\": 211.60000610351562, \"1\": 30}, \"flags\": {\"collapsed\": false}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 671}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [845, 918, 960], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ConditioningZeroOut\"}, \"widgets_values\": []}, {\"id\": 356, \"type\": \"Set Precision Universal\", \"pos\": {\"0\": 790, \"1\": -80}, \"size\": {\"0\": 211.60000610351562, \"1\": 142}, \"flags\": {\"collapsed\": false}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"cond_pos\", \"type\": \"CONDITIONING\", \"link\": 989, \"shape\": 7}, {\"name\": \"cond_neg\", \"type\": \"CONDITIONING\", \"link\": null, \"shape\": 7}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"cond_pos\", \"type\": \"CONDITIONING\", \"links\": [921, 930, 961], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cond_neg\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"links\": [], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 3, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Set Precision Universal\"}, \"widgets_values\": [\"fp64\", false]}, {\"id\": 372, \"type\": \"SaveImage\", \"pos\": {\"0\": 3303, \"1\": 132}, \"size\": {\"0\": 356.5569152832031, \"1\": 281.8731384277344}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 949, \"slot_index\": 0}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"sd3/clowninv/comfyui\"]}, {\"id\": 376, \"type\": \"Image Comparer (rgthree)\", \"pos\": {\"0\": 3222, \"1\": 552}, \"size\": {\"0\": 639.7817993164062, \"1\": 506.23114013671875}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"link\": 962, \"dir\": 3}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"link\": 956, \"dir\": 3}], \"outputs\": [], \"properties\": {\"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rdlzx_00003_.png&type=temp&subfolder=&rand=0.44207854617154263\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_rdlzx_00004_.png&type=temp&subfolder=&rand=0.7183029369810923\"}]]}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1502, \"1\": 213}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [958, 962], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 375, \"type\": \"FL_SDUltimate_Slices\", \"pos\": {\"0\": 2406, \"1\": 170}, \"size\": {\"0\": 210, \"1\": 142}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 955}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [950], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"slice_width\", \"type\": \"INT\", \"links\": [953], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"slice_height\", \"type\": \"INT\", \"links\": [954], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"multiplier\", \"type\": \"FLOAT\", \"links\": [952], \"slot_index\": 3, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FL_SDUltimate_Slices\"}, \"widgets_values\": [\"2x2\", 2], \"color\": \"#16727c\", \"bgcolor\": \"#4F0074\"}, {\"id\": 374, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 2416, \"1\": 377}, \"size\": {\"0\": 210, \"1\": 60}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [951], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"]}, {\"id\": 377, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 2430, \"1\": 524}, \"size\": {\"0\": 210, \"1\": 201.48159790039062}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"4k, detailed\"]}, {\"id\": 373, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2711, \"1\": 254}, \"size\": {\"0\": 320, \"1\": 830}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 950}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 959}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 961}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 960}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 951, \"slot_index\": 5}, {\"name\": \"upscale_by\", \"type\": \"FLOAT\", \"link\": 952, \"slot_index\": 6, \"widget\": {\"name\": \"upscale_by\"}}, {\"name\": \"tile_width\", \"type\": \"INT\", \"link\": 953, \"widget\": {\"name\": \"tile_width\"}}, {\"name\": \"tile_height\", \"type\": \"INT\", \"link\": 954, \"widget\": {\"name\": \"tile_height\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [949, 956], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 1000122408342704, \"fixed\", 20, 1, \"dpmpp_2m\", \"sgm_uniform\", 0.2, \"Linear\", 1024, 1024, 16, 32, \"None\", 0.25, 64, 16, 16, true, false]}, {\"id\": 370, \"type\": \"SDXLEmptyLatentSizePicker+\", \"pos\": {\"0\": 41, \"1\": 781}, \"size\": {\"0\": 340.20001220703125, \"1\": 170}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null}, {\"name\": \"width\", \"type\": \"INT\", \"links\": [947], \"slot_index\": 1}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [948], \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"SDXLEmptyLatentSizePicker+\"}, \"widgets_values\": [\"768x1280 (0.6)\", 1, 0, 0]}, {\"id\": 378, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1724.1240234375, \"1\": -823.2809448242188}, \"size\": [414.07562255859375, 249.64144897460938], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 963, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 6}], \"title\": \"LLM Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"Hyperrealistic portrait, extreme close-up shot, soft, diffused lighting. The image showcases a marble-skinned figure, with cracks running through the face, accentuated with veins of gold leaf. The figure's strikingly red, glowing eyes are framed by dark, smoky makeup that intensifies the gaze. The lips are painted matte black, with a delicate golden chain hanging from the lower lip, adding an intricate, metallic detail. The figure is wrapped in a luxurious, cream-colored fabric adorned with golden embroidery, draped elegantly around the head and neck. The texture of the fabric contrasts the smooth, cold marble-like skin. The shallow depth of field keeps the background softly blurred, allowing the detailed focus on the subject's face and the delicate interplay of light on the gold and fabric. The composition uses symmetry to center the face, enhancing the serene yet haunting atmosphere of the image.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 379, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1697.546142578125, \"1\": -502.4762878417969}, \"size\": [330, 240], \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 964, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"title\": \"Troubleshooting\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 380, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2599.12451171875, \"1\": -257.2809143066406}, \"size\": {\"0\": 390, \"1\": 220}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [969], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Examples\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"oil painting, impasto, low-angle shot, soft, ethereal lighting. A skeletal queen stands regally, adorned in intricate golden armor laced with blue gemstones. Her ribcage is exposed but beautifully crafted, embedded with glowing jewels. She holds an ornate, towering scythe, bedecked with skulls and decorated with delicate, metallic flourishes. Her long, flowing veil, embroidered with gold and blue, trails behind her, cascading down like a river of fabric. She wears a crown of skeletal motifs, with flowers and bones intertwined. The background depicts a serene, reflective lake nestled between massive, misty mountains under a clear, soft cloud-streaked sky. The mountains and trees are reflected perfectly in the water, with the image framed symmetrically. Hints of warm sunlight peek through, casting a gentle glow on the scene, while the queen's figure contrasts against the peaceful landscape, creating an otherworldly, yet serene atmosphere.\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 382, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2594.7265625, \"1\": -417.03814697265625}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [970], \"slot_index\": 0, \"shape\": 3}], \"title\": \"User: Prompt\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Create an image prompt from the image provided, be sure to include all details, emphasis on art style, camera angle and composition\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 384, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1724.5750732421875, \"1\": 171.2557373046875}, \"size\": [396.9629211425781, 178.00289916992188], \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 965, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 6}], \"title\": \"LLM Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"surreal portrait, cracked porcelain skin, gold accents, red glowing eyes, black lipstick, dark eye makeup, kintsugi art style, intricate patterns, white scarf, gold embroidery, ethereal, haunting beauty, close-up face, detailed textures, elegance, mysterious expression\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 385, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1704.9300537109375, \"1\": 414.7872314453125}, \"size\": [330, 240], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 966, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"title\": \"Troubleshooting\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 386, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2602.010498046875, \"1\": 471.8555603027344}, \"size\": {\"0\": 390, \"1\": 220}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [973], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Examples\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Traditional Chinese motifs, Chinese paper cut art, color red and blue, festive, cultural celebration, winter scene, snowflakes, lanterns, snowman, silhouetted cut-out art, intricate cut designs, layered compositions, Chinese ornaments,\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 387, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2595.021240234375, \"1\": 92.58341979980469}, \"size\": {\"0\": 390.9617004394531, \"1\": 174.10166931152344}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [972], \"slot_index\": 0, \"shape\": 3}], \"title\": \"System: Instructions\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Describe the image\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\\nEmphasize key information about the subject, scene, details, effects as needed. Stick with short comma-delimited prompts. start with the art style, then subject, then details like pose, camera angle.\\n\\nNote that Clip-L focuses on specific visual elements and technical details. It lists concrete objects, visual attributes, and effects. Use for specific visual elements and attributes.\\n\\n\\n\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 388, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2611.285400390625, \"1\": 327.2838439941406}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [974], \"slot_index\": 0, \"shape\": 3}], \"title\": \"User: Prompt\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Provide comma-separated keywords as a direct string for the provided image\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 391, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1732.5263671875, \"1\": 885.6227416992188}, \"size\": [396.9629211425781, 178.00289916992188], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 975, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 0, \"shape\": 6}], \"title\": \"LLM Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"A hauntingly beautiful figure with pale, cracked skin adorned with gold detailing, wearing a headscarf and possessing glowing red eyes and dark makeup.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 392, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1712.88134765625, \"1\": 1129.154541015625}, \"size\": [330, 240], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 976, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 6}], \"title\": \"Troubleshooting\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"\\u2022 Advanced Prompt Enhancer (APE) uses AI Models to generate text output from any combination of: Instruction, Example_or_Context, Image and Prompt you provide. No API key is needed for Open source Models.  This node can use various remote models, ChatGPT, Groq and Anthropic Claude if you have an API key and have stored it in an environment variable (see ReadMe file).  With or without a key it can also connect to various local apps and models e.g.: LM Studio, Oobabooga, Koboldcpp, etc.\\n\\n\\u2022 image input: Advanced Prompt Enhancer can send image data (in the form of a b64 image file) to AI vision capable models.  If you're sending an image to an AI model be sure both the model and the app or remote service have vision capabilities and can handle image files.\\n\\n\\u2022 Examples_or_Context: APE can send example(s) and/or context along with your instructions to the LLM.  Examples and Context *always* need to be in the form of: User input, then the delimiter, followed by the model's response.  Delimited text entered in this field will automatically create alternatating input to the model for each delimited segment using this pattern.  If you want to explicitly tag your text as being user or model input you can preface each delimited segment with <<user>> or <<model>>}. (There's an workflow file: 'How_To_Use_Examples.png' in the 'Example_Worflows' folder with details about using the Examples_or_Context input.)\\n\\n\\u2022Context (output): The 'Context' output is an accumulation of the 'Examples_or_Context' input plus the current 'Prompt' and 'LLM_response'.  It can be fed directly into the 'Examples_or_Context' input of a second APE node.  Before passing this information between nodes, make sure all the Context linked nodes have the same 'example_delimiter' setting. Each node linked in this way will accumulate all of the conversations of the nodes before it.\\n\\n\\u2022 API Keys:  API keys need to be kept in environment variables.  The Environment Variable names that Advanced Prompt Enhancer looks for are: \\u2726ChatGPT: OPENAI_API_KEY or OAI_KEY;  \\u2726Groq: GROQ_API_KEY;  \\u2726Anthropic: ANTHROPIC_API_KEY.  Find instructions on how to create the Enviroment Variable here: https://github.com/glibsonoran/Plush-for-ComfyUI?tab=readme-ov-file#requirements .  \\n\\n**************\\n\\n\\u2022  AI_service: This indicates the type of AI service and connection you're going to send your data to.  If you're using a local AI app you'll need to provide a valid URL in the LLM_URL field near the bottom of the node.  If you're using 'Oobabooga API' make sure you read the LLM_URL help below.  'OpenAI compatible http POST' uses a web POST action rather than the OpenAI API Object to communicate with the local or remote AI server, typically this requires a 'v1/chat/completions' path in the URL. 'http POST Simplified Data' also uses a web POST action and presents a simplified data structure. Try this if the other AI service methods don't work, it will also require a: 'v1/chat/completions' path.  \\n\\n\\u2022 GPTmodel: This field only applies when the LLM field is set to 'ChatGPT'.  Select the specific OpenAI ChatGPT model you want to use.  If you're inputting an image, make sure the model you choose is vision capable.\\n\\n\\u2022 Groq_model: This only applies when you select 'Groq' in the AI_service field. Choose the Groq model you want to use. \\n\\n\\u2022 Anthropic_model: This only applies when you select 'Anthropic' from the AI_service field.  Choose the Anthopic model you want to use. \\n\\n\\u2022 Ollama_model: This will display the model(s) currently loaded in the Ollama front end. In order for models to show up in the drop down Ollama will have to be running with the models you intend to use loaded *before* starting ComfyUI. Note that APE looks for the standard url: http://localhost:11434/api/tags when retrieving the model names.  If you've setup Ollama with another url (e.g. different port), you'll need to modify the 'urls.json' file. \\n\\n\\u2022 Optional_model: This is a list of models extracted from the text file: '/custom_nodes/Plush-for-ComfyUI/Opt_models.txt'.  This is a user configurable file that's initially empty.  It's meant to hold model names for unique remote or local AI services that require a model name to be included with the inference request.  These model names only apply to AI_Services that end in '(URL)'. If you enter or remove model names from this file, the changes will only show up after you reboot ComfyUI. Instructions on how to enter these model names is in the comments header of the 'Opt_models.txt' text file. \\n\\n\\u2022 creative_latitude: (Temperature)  This will set how strictly the LLM adheres to common word relationships and how closely it will follow your instruction and prompt.  Setting this value higher allows more creative freedom in interpreting your input and generating its ouptput.\\n\\n\\u2022 tokens:  The maximum number of tokens that the LLM can use in processing your prompt and return text.  This is not the number of tokens  it 'will' use, it's the number available that it 'can' use.\\n\\n\\u2022 seed: This is a pseudo or mock seed, it has no effect on the text generated, and it's not passed to the LLM.  It's used here solely to control when the node will run.  It works the same as a KSampler, set it to 'fixed' if you want the node to run only once each time you change your inputs, set it to random or increment/decrement if you want it run with each Queue.\\n\\n\\u2022 example_delimiter: You can provide multiple examples or context to the LLM.  Providing multiple examples for a given instruction is a type of 'Few Shot Prompting', which can be effective with some LLM's. This field indicates how the node will distinguish each separate example, each separate example or context item will be presented as originating from the User then the Model alternating in that order for as many as you enter.  You can choose to separate your examples with a pipe '|' character, two newlines (i.e.: carriage returns) or two colons '::', these are called delimiters and they denote where these separations will occur.\\n\\n\\u2022 LLM_URL: When using an LLM other than ChatGPT, Anthropic or Groq you'll need to provide a URL in this field.  Typically the AI application you're using (e.g. LM Studio, Oobabooga), will indicate the URL to use after you startup its server. It may be in the terminal output or in the UI. Some local AI apps will specify that a particular URL is OpenAI compatible, if so this is the one you want to use.  Typically the URLs for local apps have this general format: http://localhost:5001/v1 where '5001' is the port and 'localhost' is interchangable with '127.0.0.1'.  If you're using the Oobabooga API or 'OpenAI compatible http POST' selection your url will need to have /chat/completions appended as part of the url: http://127.0.0.1:5000/v1/chat/completions\\n\\n**************\\n\\n\\u2022 Use the troubleshooting output if you have issues with model connections, or if you want to see exactly which model was used to produce your output (some ChatGPT model names are actually only pointers to the latest specific model in that category) and how many tokens were used.\"]], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 393, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2602.923095703125, \"1\": 1196.686279296875}, \"size\": {\"0\": 390, \"1\": 220}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [979], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Examples\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Beautiful Chinese Paper Cutting winter scene with intricately cut Matroshka dolls and snow-covered ornaments, presented in a warm, traditional setting\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 394, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2602.974365234375, \"1\": 806.9500732421875}, \"size\": {\"0\": 390.9617004394531, \"1\": 174.10166931152344}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [978], \"slot_index\": 0, \"shape\": 3}], \"title\": \"System: Instructions\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Describe the image, in one sentence\\n\\nProvide ONLY the prompt. Do not add any narrative or exposition or intro or closing statement. Do not discuss how you've rewritten the prompt. \\n\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 395, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2619.238525390625, \"1\": 1041.651123046875}, \"size\": {\"0\": 390, \"1\": 90}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [980], \"slot_index\": 0, \"shape\": 3}], \"title\": \"User: Prompt\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"provide a single-sentence description of the provided image\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 381, \"type\": \"Text Multiline\", \"pos\": {\"0\": -2621.3154296875, \"1\": -838.0553588867188}, \"size\": {\"0\": 425.0143127441406, \"1\": 360.5466613769531}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [968], \"slot_index\": 0, \"shape\": 3}], \"title\": \"System: Instructions\", \"properties\": {\"Node name for S&R\": \"Text Multiline\"}, \"widgets_values\": [\"Act as a creative agent who generates highly creative detailed, comma-delimited formatted prompt of up to 150 words for the image. Begin each prompt by specifying an art style (for example, cartoon, impasto, absurdres, oil or acrylic or watercolor painting, or charcoal drawing or engraving or sculpture, etc.)  Include information about lighting. Include information about camera angle. Include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.Do NOT mention any text that is in the image.Specify the depth of field and whether the background is in focus or blurred.Do NOT use any ambiguous language. Include the pose of the subject. Then, continue with descriptive visual elements of the subject, surroundings, and background. Please do not omit any details, especially objects, lighting, colors, and textures, even subtle ones hidden in the background! It is imperative that you carefully consider every aspect of the image, and provide satisfactory descriptions! Also, please be very careful when considering whether the image really is a photograph or actually a detailed painting or illustration.\\n\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 397, \"type\": \"Reroute\", \"pos\": {\"0\": -1220, \"1\": -410}, \"size\": [75, 26], \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 991, \"widget\": {\"name\": \"value\"}}], \"outputs\": [{\"name\": \"\", \"type\": \"STRING\", \"links\": [987]}], \"title\": \"t5\", \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 399, \"type\": \"Reroute\", \"pos\": {\"0\": -1210, \"1\": -60}, \"size\": [75, 26], \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 992, \"widget\": {\"name\": \"value\"}}], \"outputs\": [{\"name\": \"\", \"type\": \"STRING\", \"links\": [985]}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 400, \"type\": \"Reroute\", \"pos\": {\"0\": -1240, \"1\": 330}, \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 993, \"widget\": {\"name\": \"value\"}}], \"outputs\": [{\"name\": \"\", \"type\": \"STRING\", \"links\": [986]}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 401, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1030, \"1\": -70}, \"size\": [350, 290], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 985, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [982], \"slot_index\": 0, \"shape\": 6}], \"title\": \"Clip-L Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"surreal portrait, cracked porcelain skin, gold accents, red glowing eyes, black lipstick, dark eye makeup, kintsugi art style, intricate patterns, white scarf, gold embroidery, ethereal, haunting beauty, close-up face, detailed textures, elegance, mysterious expression\"]], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 402, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1030, \"1\": 280}, \"size\": [350, 290], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 986, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [983], \"slot_index\": 0, \"shape\": 6}], \"title\": \"Clip-G Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"A hauntingly beautiful figure with pale, cracked skin adorned with gold detailing, wearing a headscarf and possessing glowing red eyes and dark makeup.\"]], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 403, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": -1030, \"1\": -390}, \"size\": [344.6795959472656, 255.9129638671875], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 987, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [984], \"slot_index\": 0, \"shape\": 6}], \"title\": \"T5 Prompt\", \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"Hyperrealistic portrait, extreme close-up shot, soft, diffused lighting. The image showcases a marble-skinned figure, with cracks running through the face, accentuated with veins of gold leaf. The figure's strikingly red, glowing eyes are framed by dark, smoky makeup that intensifies the gaze. The lips are painted matte black, with a delicate golden chain hanging from the lower lip, adding an intricate, metallic detail. The figure is wrapped in a luxurious, cream-colored fabric adorned with golden embroidery, draped elegantly around the head and neck. The texture of the fabric contrasts the smooth, cold marble-like skin. The shallow depth of field keeps the background softly blurred, allowing the detailed focus on the subject's face and the delicate interplay of light on the gold and fabric. The composition uses symmetry to center the face, enhancing the serene yet haunting atmosphere of the image.\"]], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 362, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 33, \"1\": 351}, \"size\": {\"0\": 180, \"1\": 80}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"VAE\", \"type\": \"*\", \"link\": 981, \"shape\": 7, \"color_on\": \"#FF6E6E\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 334, \"1\": -434}, \"size\": {\"0\": 350, \"1\": 190}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"title\": \"CLIP Text Encode (Positive Prompt)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"A magical woodland scene, soft fantasy lighting, ethereal glow; a fluffy, young sheep with large, expressive eyes, clothed in leaves and moss, small antlers adorned with delicate green foliage, soft white wool blending with warm earthy tones; a gentle drizzle falls around, casting glistening droplets on its fur; surrounded by glowing fireflies, lush forest plants, and a misty, dimly lit background that shifts from deep blues to vibrant greens; rays of golden light break through the trees above, illuminating the sheep\\u2019s face, creating a calm and enchanting atmosphere.\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 38, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 90, \"1\": 58}, \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {\"collapsed\": false}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [671], \"slot_index\": 0}], \"title\": \"CLIP Text Encode\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 398, \"type\": \"CLIPTextEncodeSD3\", \"pos\": {\"0\": -527, \"1\": -293}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}, {\"name\": \"clip_l\", \"type\": \"STRING\", \"link\": 982, \"widget\": {\"name\": \"clip_l\"}}, {\"name\": \"clip_g\", \"type\": \"STRING\", \"link\": 983, \"widget\": {\"name\": \"clip_g\"}}, {\"name\": \"t5xxl\", \"type\": \"STRING\", \"link\": 984, \"widget\": {\"name\": \"t5xxl\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [989, 990], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncodeSD3\"}, \"widgets_values\": [\"\", \"\", \"\", \"none\"]}, {\"id\": 390, \"type\": \"AdvPromptEnhancer\", \"pos\": {\"0\": -2137.970703125, \"1\": 142.31881713867188}, \"size\": [400, 434], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"Add_Parameter\", \"type\": \"LIST\", \"link\": null, \"shape\": 7}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 971, \"shape\": 7}, {\"name\": \"Instruction\", \"type\": \"STRING\", \"link\": 972, \"widget\": {\"name\": \"Instruction\"}, \"shape\": 7}, {\"name\": \"Examples_or_Context\", \"type\": \"STRING\", \"link\": 973, \"widget\": {\"name\": \"Examples_or_Context\"}, \"shape\": 7}, {\"name\": \"Prompt\", \"type\": \"STRING\", \"link\": 974, \"widget\": {\"name\": \"Prompt\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"LLMprompt\", \"type\": \"STRING\", \"links\": [965, 992], \"slot_index\": 0}, {\"name\": \"Context\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"Help\", \"type\": \"STRING\", \"links\": [966]}, {\"name\": \"Troubleshooting\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"AdvPromptEnhancer\"}, \"widgets_values\": [\"ChatGPT\", \"chatgpt-4o-latest\", \"none\", \"none\", \"none\", \"none\", 0.7, 100, 285692465375160, \"randomize\", \"Two newlines\", \"https://api.groq.com/openai/v1\", \"\", \"\", \"\"]}, {\"id\": 396, \"type\": \"AdvPromptEnhancer\", \"pos\": {\"0\": -2145.9228515625, \"1\": 856.685546875}, \"size\": [400, 434], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"Add_Parameter\", \"type\": \"LIST\", \"link\": null, \"shape\": 7}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 977, \"shape\": 7}, {\"name\": \"Instruction\", \"type\": \"STRING\", \"link\": 978, \"widget\": {\"name\": \"Instruction\"}, \"shape\": 7}, {\"name\": \"Examples_or_Context\", \"type\": \"STRING\", \"link\": 979, \"widget\": {\"name\": \"Examples_or_Context\"}, \"shape\": 7}, {\"name\": \"Prompt\", \"type\": \"STRING\", \"link\": 980, \"widget\": {\"name\": \"Prompt\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"LLMprompt\", \"type\": \"STRING\", \"links\": [975, 993], \"slot_index\": 0}, {\"name\": \"Context\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"Help\", \"type\": \"STRING\", \"links\": [976]}, {\"name\": \"Troubleshooting\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"AdvPromptEnhancer\"}, \"widgets_values\": [\"ChatGPT\", \"chatgpt-4o-latest\", \"none\", \"none\", \"none\", \"none\", 0.7, 100, 263716373364502, \"randomize\", \"Two newlines\", \"https://api.groq.com/openai/v1\", \"\", \"\", \"\"]}, {\"id\": 389, \"type\": \"AdvPromptEnhancer\", \"pos\": {\"0\": -2164.725830078125, \"1\": -853.0382080078125}, \"size\": [400, 434], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"Add_Parameter\", \"type\": \"LIST\", \"link\": null, \"shape\": 7}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 967, \"shape\": 7}, {\"name\": \"Instruction\", \"type\": \"STRING\", \"link\": 968, \"widget\": {\"name\": \"Instruction\"}, \"shape\": 7}, {\"name\": \"Examples_or_Context\", \"type\": \"STRING\", \"link\": 969, \"widget\": {\"name\": \"Examples_or_Context\"}, \"shape\": 7}, {\"name\": \"Prompt\", \"type\": \"STRING\", \"link\": 970, \"widget\": {\"name\": \"Prompt\"}, \"shape\": 7}], \"outputs\": [{\"name\": \"LLMprompt\", \"type\": \"STRING\", \"links\": [963, 991], \"slot_index\": 0}, {\"name\": \"Context\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"Help\", \"type\": \"STRING\", \"links\": [964]}, {\"name\": \"Troubleshooting\", \"type\": \"STRING\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"AdvPromptEnhancer\"}, \"widgets_values\": [\"ChatGPT\", \"chatgpt-4o-latest\", \"none\", \"none\", \"none\", \"none\", 0.7, 300, 353162164338036, \"randomize\", \"Two newlines\", \"https://api.groq.com/openai/v1\", \"\", \"\", \"\"]}, {\"id\": 182, \"type\": \"TripleCLIPLoader\", \"pos\": {\"0\": -518, \"1\": -28}, \"size\": {\"0\": 340, \"1\": 110}, \"flags\": {\"collapsed\": false}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [988], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"TripleCLIPLoader\"}, \"widgets_values\": [\"OPENAIclip_g.safetensors\", \"OPENAIclip_l.safetensors\", \"t5xxl_fp16.safetensors\"]}, {\"id\": 369, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": -508, \"1\": 145}, \"size\": {\"0\": 315, \"1\": 98}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [946, 959], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": null}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [], \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"sd3.5_large.safetensors\"]}, {\"id\": 361, \"type\": \"VAELoader\", \"pos\": {\"0\": -508, \"1\": 313}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [981], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"sd3-5vae.safetensors\"]}, {\"id\": 404, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": -124, \"1\": -32}, \"size\": [159.60000610351562, 38.09176869571644], \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"CLIP\", \"type\": \"*\", \"link\": 988, \"shape\": 7, \"color_on\": \"#FFD500\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 280, \"type\": \"SD35L_TimestepPatcher\", \"pos\": {\"0\": -125, \"1\": 190}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 946}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [852, 855, 856, 859, 863, 867], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SD35L_TimestepPatcher\"}, \"widgets_values\": [\"exponential\", 3]}, {\"id\": 371, \"type\": \"Preview Chooser\", \"pos\": {\"0\": 1643, \"1\": 346}, \"size\": {\"0\": 692.0098266601562, \"1\": 498.26287841796875}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 958, \"shape\": 7}, {\"name\": \"latents\", \"type\": \"LATENT\", \"link\": null, \"shape\": 7}, {\"name\": \"masks\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}, {\"name\": \"segs\", \"type\": \"SEGS\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"links\": [955], \"slot_index\": 0}, {\"name\": \"latents\", \"type\": \"LATENT\", \"links\": null}, {\"name\": \"masks\", \"type\": \"MASK\", \"links\": null}, {\"name\": \"selected\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"segs\", \"type\": \"SEGS\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"Preview Chooser\"}, \"widgets_values\": [\"Always pause\", 1, \"\", \"\"]}, {\"id\": 335, \"type\": \"SamplerNoiseInversion\", \"pos\": {\"0\": 455, \"1\": 532}, \"size\": {\"0\": 250, \"1\": 530}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 863}, {\"name\": \"momentums\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"eta_values\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"t_is\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"etas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"s_noises\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"alphas\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide\", \"type\": \"LATENT\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_weights\", \"type\": \"SIGMAS\", \"link\": null, \"shape\": 7}, {\"name\": \"latent_guide_mask\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"sampler\", \"type\": \"SAMPLER\", \"links\": [898], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerNoiseInversion\"}, \"widgets_values\": [0, 0.5, 0.25, 0, 1, 0, 1, \"gaussian\", \"hard\", 1003, 2, 0, 1]}, {\"id\": 337, \"type\": \"BetaSamplingScheduler\", \"pos\": {\"0\": 760, \"1\": 740}, \"size\": {\"0\": 210, \"1\": 110}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 867}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [902], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BetaSamplingScheduler\"}, \"widgets_values\": [13, 0.5, 0.7]}, {\"id\": 383, \"type\": \"LoadImage\", \"pos\": {\"0\": -2136.123779296875, \"1\": -349.2808837890625}, \"size\": {\"0\": 320, \"1\": 314}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [967, 971, 977], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"37074063.jpeg\", \"image\"], \"color\": \"#155588\", \"bgcolor\": \"#29699c\"}, {\"id\": 344, \"type\": \"LoadImage\", \"pos\": {\"0\": -514, \"1\": 434}, \"size\": {\"0\": 320, \"1\": 314}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [927], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"36009593.jpeg\", \"image\"]}], \"links\": [[24, 13, 0, 8, 0, \"LATENT\"], [128, 50, 0, 45, 0, \"NOISE\"], [368, 183, 0, 13, 1, \"GUIDER\"], [386, 46, 0, 45, 1, \"GUIDER\"], [671, 38, 0, 288, 0, \"CONDITIONING\"], [676, 41, 0, 287, 3, \"LATENT\"], [677, 287, 3, 45, 4, \"LATENT\"], [841, 287, 2, 302, 0, \"SIGMAS\"], [842, 302, 0, 45, 3, \"SIGMAS\"], [843, 302, 1, 13, 3, \"SIGMAS\"], [844, 50, 0, 13, 0, \"NOISE\"], [845, 288, 0, 287, 1, \"CONDITIONING\"], [852, 280, 0, 191, 0, \"MODEL\"], [855, 280, 0, 183, 0, \"MODEL\"], [856, 280, 0, 46, 0, \"MODEL\"], [859, 280, 0, 334, 0, \"MODEL\"], [862, 334, 0, 13, 2, \"SAMPLER\"], [863, 280, 0, 335, 0, \"MODEL\"], [867, 280, 0, 337, 0, \"MODEL\"], [890, 45, 0, 13, 4, \"LATENT\"], [896, 41, 0, 334, 7, \"LATENT\"], [898, 335, 0, 45, 2, \"SAMPLER\"], [902, 337, 0, 334, 2, \"SIGMAS\"], [913, 191, 0, 353, 0, \"SIGMAS\"], [914, 353, 0, 287, 2, \"SIGMAS\"], [918, 288, 0, 183, 2, \"CONDITIONING\"], [921, 356, 0, 183, 1, \"CONDITIONING\"], [927, 344, 0, 359, 0, \"IMAGE\"], [930, 356, 0, 46, 1, \"CONDITIONING\"], [933, 359, 0, 41, 0, \"IMAGE\"], [946, 369, 0, 280, 0, \"MODEL\"], [947, 370, 1, 359, 1, \"INT\"], [948, 370, 2, 359, 2, \"INT\"], [949, 373, 0, 372, 0, \"IMAGE\"], [950, 375, 0, 373, 0, \"IMAGE\"], [951, 374, 0, 373, 5, \"UPSCALE_MODEL\"], [952, 375, 3, 373, 6, \"FLOAT\"], [953, 375, 1, 373, 7, \"INT\"], [954, 375, 2, 373, 8, \"INT\"], [955, 371, 0, 375, 0, \"IMAGE\"], [956, 373, 0, 376, 1, \"IMAGE\"], [958, 8, 0, 371, 0, \"IMAGE\"], [959, 369, 0, 373, 1, \"MODEL\"], [960, 288, 0, 373, 3, \"CONDITIONING\"], [961, 356, 0, 373, 2, \"CONDITIONING\"], [962, 8, 0, 376, 0, \"IMAGE\"], [963, 389, 0, 378, 0, \"STRING\"], [964, 389, 2, 379, 0, \"STRING\"], [965, 390, 0, 384, 0, \"STRING\"], [966, 390, 2, 385, 0, \"STRING\"], [967, 383, 0, 389, 1, \"IMAGE\"], [968, 381, 0, 389, 2, \"STRING\"], [969, 380, 0, 389, 3, \"STRING\"], [970, 382, 0, 389, 4, \"STRING\"], [971, 383, 0, 390, 1, \"IMAGE\"], [972, 387, 0, 390, 2, \"STRING\"], [973, 386, 0, 390, 3, \"STRING\"], [974, 388, 0, 390, 4, \"STRING\"], [975, 396, 0, 391, 0, \"STRING\"], [976, 396, 2, 392, 0, \"STRING\"], [977, 383, 0, 396, 1, \"IMAGE\"], [978, 394, 0, 396, 2, \"STRING\"], [979, 393, 0, 396, 3, \"STRING\"], [980, 395, 0, 396, 4, \"STRING\"], [981, 361, 0, 362, 0, \"VAE\"], [982, 401, 0, 398, 1, \"STRING\"], [983, 402, 0, 398, 2, \"STRING\"], [984, 403, 0, 398, 3, \"STRING\"], [985, 399, 0, 401, 0, \"STRING\"], [986, 400, 0, 402, 0, \"STRING\"], [987, 397, 0, 403, 0, \"STRING\"], [988, 182, 0, 404, 0, \"CLIP\"], [989, 398, 0, 356, 0, \"CONDITIONING\"], [990, 398, 0, 287, 0, \"CONDITIONING\"], [991, 389, 0, 397, 0, \"*\"], [992, 390, 0, 399, 0, \"*\"], [993, 396, 0, 400, 0, \"*\"], [994, 361, 0, 41, 1, \"VAE\"], [995, 361, 0, 8, 1, \"VAE\"], [996, 182, 0, 377, 0, \"CLIP\"], [997, 361, 0, 373, 4, \"VAE\"], [998, 182, 0, 6, 0, \"CLIP\"], [999, 182, 0, 38, 0, \"CLIP\"], [1000, 182, 0, 398, 0, \"CLIP\"]], \"groups\": [{\"title\": \"Clip\", \"bounding\": [-1250, -464, 580, 1044], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"clip l\", \"bounding\": [-2621, 18, 1329, 680], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"t5\", \"bounding\": [-2631, -927, 1331, 902], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"clip g\", \"bounding\": [-2628, 733, 1346, 694], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.5989500000000083, \"offset\": [1434.591450370974, 411.21593092161913]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"373\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"389\": {\"seed\": 8}, \"390\": {\"seed\": 8}, \"396\": {\"seed\": 8}}, \"seed_widgets\": {\"373\": 1, \"389\": 8, \"390\": 8, \"396\": 8}}}",
            "models": [
                "sd3.5_large.safetensors"
            ],
            "modelIds": [],
            "upscalers": [
                "4x-UltraSharp.pth"
            ],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": []
        },
        "username": "NaomiVK",
        "baseModel": "SD 3.5"
    },
    {
        "id": 12838529,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2188ac67-dd8d-402e-ba4b-b69125bbb5ca/width=832/2188ac67-dd8d-402e-ba4b-b69125bbb5ca.jpeg",
        "hash": "UCIYE%iyJK$.ClVVo;-qKFz-#YPWCTMI,mpd",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-18T10:10:32.455Z",
        "postId": 2837978,
        "stats": {
            "cryCount": 83,
            "laughCount": 189,
            "likeCount": 1258,
            "dislikeCount": 0,
            "heartCount": 471,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 43765999,
            "steps": 25,
            "prompt": "ral-vxl bob Ross, painter, easel, landscape painting",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-05-18T1001:16.8058121Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 128078,
                    "modelVersionName": "v1.0 VAE fix"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 513975,
                    "modelVersionName": "SDXL"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "inkrose115605",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 28171413,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/905dad9e-efa4-4ec4-9b50-4674eadb262a/width=1536/905dad9e-efa4-4ec4-9b50-4674eadb262a.jpeg",
        "hash": "ULBDvvnm4-o}uPWrZgobwGoJM{WBi]kCR+V@",
        "width": 1536,
        "height": 2688,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-07T06:43:00.999Z",
        "postId": 6301531,
        "stats": {
            "cryCount": 54,
            "laughCount": 135,
            "likeCount": 1343,
            "dislikeCount": 0,
            "heartCount": 467,
            "commentCount": 3
        },
        "meta": {
            "seed": 759511682542531,
            "vaes": [],
            "Model": "SDXL\\Copaxanime_vs_Tamarin_50-50",
            "comfy": "{\"prompt\": {\"27\": {\"inputs\": {\"width\": 768, \"height\": 1344, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"55\": {\"inputs\": {\"images\": [\"127\", 0]}, \"class_type\": \"PreviewImage\"}, \"57\": {\"inputs\": {\"filename_prefix\": \"Flux XL FInal\", \"images\": [\"185\", 0]}, \"class_type\": \"SaveImage\"}, \"94\": {\"inputs\": {\"seed\": 776176199102788, \"steps\": 30, \"cfg\": 7.0, \"sampler_name\": \"dpmpp_2m_sde_gpu\", \"scheduler\": \"karras\", \"denoise\": 0.4, \"preview_method\": \"auto\", \"vae_decode\": \"true\", \"model\": [\"141\", 0], \"positive\": [\"238\", 0], \"negative\": [\"238\", 1], \"latent_image\": [\"162\", 0], \"optional_vae\": [\"139\", 2]}, \"class_type\": \"KSampler (Efficient)\"}, \"103\": {\"inputs\": {\"filename_prefix\": \"Flux XL Small\", \"images\": [\"94\", 5]}, \"class_type\": \"SaveImage\"}, \"127\": {\"inputs\": {\"upscale_by\": [\"130\", 2], \"seed\": 639296840369093, \"steps\": 5, \"cfg\": 7.0, \"sampler_name\": \"dpmpp_2m_sde_gpu\", \"scheduler\": \"karras\", \"denoise\": 0.25, \"mode_type\": \"Linear\", \"tile_width\": 1024, \"tile_height\": 1024, \"mask_blur\": 8, \"tile_padding\": 32, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 8, \"seam_fix_padding\": 16, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"94\", 5], \"model\": [\"94\", 0], \"positive\": [\"94\", 1], \"negative\": [\"94\", 2], \"vae\": [\"94\", 4], \"upscale_model\": [\"128\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"128\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"129\": {\"inputs\": {\"image\": [\"94\", 5]}, \"class_type\": \"CM_NearestSDXLResolution\"}, \"130\": {\"inputs\": {\"desiredXSIZE\": [\"134\", 0], \"desiredYSIZE\": [\"131\", 0]}, \"class_type\": \"RecommendedResCalc\"}, \"131\": {\"inputs\": {\"op\": \"Mul\", \"a\": 2, \"b\": [\"129\", 1]}, \"class_type\": \"CM_IntBinaryOperation\"}, \"134\": {\"inputs\": {\"op\": \"Mul\", \"a\": 2, \"b\": [\"129\", 0]}, \"class_type\": \"CM_IntBinaryOperation\"}, \"138\": {\"inputs\": {\"model\": [\"150\", 0], \"conditioning\": [\"202\", 0]}, \"class_type\": \"BasicGuider\"}, \"139\": {\"inputs\": {\"ckpt_name\": \"SDXL\\\\Copaxanime_vs_Tamarin_50-50.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"141\": {\"inputs\": {\"model\": [\"139\", 0], \"clip\": [\"139\", 1], \"lora_stack\": [\"142\", 0]}, \"class_type\": \"CR Apply LoRA Stack\"}, \"142\": {\"inputs\": {\"switch_1\": \"On\", \"lora_name_1\": \"add-detail-xl.safetensors\", \"model_weight_1\": 1.0, \"clip_weight_1\": 1.0, \"switch_2\": \"On\", \"lora_name_2\": \"RMSDXL_Enhance.safetensors\", \"model_weight_2\": 0.8, \"clip_weight_2\": 0.8, \"switch_3\": \"On\", \"lora_name_3\": \"RMSDXL_Enhance.safetensors\", \"model_weight_3\": 0.8, \"clip_weight_3\": 0.8, \"lora_stack\": [\"169\", 0]}, \"class_type\": \"CR LoRA Stack\"}, \"143\": {\"inputs\": {\"text\": [\"148\", 0], \"clip\": [\"144\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"144\": {\"inputs\": {\"stop_at_clip_layer\": -2, \"clip\": [\"141\", 1]}, \"class_type\": \"CLIPSetLastLayer\"}, \"146\": {\"inputs\": {\"text\": \"(stgl2023:1.2),An elegant woman with a slender silhouette stands poised in a cyberpunk cityscape, her form adorned with a dress crafted from a mosaic of vibrant stained glass. The glass captures the essence of the neon city lights, casting a prismatic array of colors that dance upon her dress and spill onto the surrounding architecture. Gone is the halo, replaced with a crown of complex, gothic-styled stained glass that weaves religious and symbolic motifs into a narrative that contrasts starkly against the backdrop of the future.\\n\\nBehind her, the scene is framed by a grand, cathedral-like window, its panes a patchwork of urban glow, marrying the sanctity of the past with the pulse of technology. Intricate, geometric patterns are embedded in the stained glass of her dress, each segment a canvas telling tales as old as time, echoing the stories once told in ancient church windows.\\n\\nShe stands bathed in internal light, an ethereal glow that emanates from within, casting the translucent and reflective beauty of her stained glass attire in soft radiance. Her presence is magnetic, pulling the gaze of passersby and commanding the attention of the city. As she moves, her dress comes to life, the patterns of stained glass shifting gracefully, giving the impression of a living artwork with a rhythm akin to a slow, steady heartbeat.\\n\\nIn this vision, the figure stands as a fusion of two realms: the vibrant artistry of stained glass from a time of faith and the technological marvels of the coming future. She is a nexus of art and circuitry, an icon of the digital age, representing the potential for beauty and inspiration in the era of artificial intelligence.(reflection:1.1), (cyber Stained glass window:1.15),backlighting\"}, \"class_type\": \"Text Prompt (JPS)\"}, \"148\": {\"inputs\": {\"string\": [\"146\", 0], \"old\": \"\", \"new\": \"\"}, \"class_type\": \"String Replace (mtb)\"}, \"150\": {\"inputs\": {\"ckpt_name\": \"flux\\\\flux.1_dev_16x16-marduk191.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"157\": {\"inputs\": {\"noise\": [\"158\", 0], \"guider\": [\"138\", 0], \"sampler\": [\"159\", 0], \"sigmas\": [\"160\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"158\": {\"inputs\": {\"noise_seed\": 759511682542531}, \"class_type\": \"RandomNoise\"}, \"159\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"160\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 10, \"denoise\": 1.0, \"model\": [\"232\", 0]}, \"class_type\": \"BasicScheduler\"}, \"161\": {\"inputs\": {\"samples\": [\"157\", 0], \"vae\": [\"150\", 2]}, \"class_type\": \"VAEDecode\"}, \"162\": {\"inputs\": {\"pixels\": [\"161\", 0], \"vae\": [\"139\", 2]}, \"class_type\": \"VAEEncode\"}, \"163\": {\"inputs\": {\"text\": [\"164\", 0], \"clip\": [\"144\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"164\": {\"inputs\": {\"text\": \"bad hands, deformed hands, anime, watermark, signature, string, holding fabric, holding bag, drawn by bad-artist, sketch by bad-artist-anime, artist name, signature, watermark, (ugly:1.2), (worst quality, poor details:1.4), blurry, child, loli, kids, oil paint\"}, \"class_type\": \"Text Prompt (JPS)\"}, \"165\": {\"inputs\": {\"images\": [\"161\", 0]}, \"class_type\": \"PreviewImage\"}, \"168\": {\"inputs\": {\"filename_prefix\": \"Flux Small\", \"images\": [\"161\", 0]}, \"class_type\": \"SaveImage\"}, \"169\": {\"inputs\": {\"switch_1\": \"On\", \"lora_name_1\": \"PerfectEyesXL.safetensors\", \"model_weight_1\": 1.0, \"clip_weight_1\": 1.0, \"switch_2\": \"On\", \"lora_name_2\": \"EpicF4nta5yXL.safetensors\", \"model_weight_2\": 0.8, \"clip_weight_2\": 1.0, \"switch_3\": \"Off\", \"lora_name_3\": \"hand 4.safetensors\", \"model_weight_3\": 1.0, \"clip_weight_3\": 1.0}, \"class_type\": \"CR LoRA Stack\"}, \"171\": {\"inputs\": {\"guide_size\": 512.0, \"guide_size_for\": true, \"max_size\": 1024.0, \"seed\": 803941750574846, \"steps\": 5, \"cfg\": 7.0, \"sampler_name\": \"dpmpp_2m_sde_gpu\", \"scheduler\": \"karras\", \"denoise\": 0.25, \"feather\": 7, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.5, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3.0, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"Small\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"image\": [\"127\", 0], \"model\": [\"94\", 0], \"clip\": [\"139\", 1], \"vae\": [\"94\", 4], \"positive\": [\"94\", 1], \"negative\": [\"94\", 2], \"bbox_detector\": [\"175\", 0], \"sam_model_opt\": [\"176\", 0], \"segm_detector_opt\": [\"177\", 1]}, \"class_type\": \"FaceDetailer\"}, \"173\": {\"inputs\": {\"guide_size\": 512.0, \"guide_size_for\": true, \"max_size\": 1024.0, \"seed\": 948255715188256, \"steps\": 5, \"cfg\": 7.0, \"sampler_name\": \"dpmpp_2m_sde_gpu\", \"scheduler\": \"karras\", \"denoise\": 0.25, \"feather\": 7, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.5, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3.0, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"wildcard\": \"\", \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"image\": [\"171\", 0], \"model\": [\"94\", 0], \"clip\": [\"139\", 1], \"vae\": [\"94\", 4], \"positive\": [\"94\", 1], \"negative\": [\"94\", 2], \"bbox_detector\": [\"178\", 0], \"sam_model_opt\": [\"179\", 0], \"segm_detector_opt\": [\"180\", 1]}, \"class_type\": \"FaceDetailer\"}, \"174\": {\"inputs\": {\"filename_prefix\": \"Upscaled\", \"images\": [\"127\", 0]}, \"class_type\": \"SaveImage\"}, \"175\": {\"inputs\": {\"model_name\": \"segm/person_yolov8m-seg.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"176\": {\"inputs\": {\"model_name\": \"sam_vit_b_01ec64.pth\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\"}, \"177\": {\"inputs\": {\"model_name\": \"segm/person_yolov8m-seg.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"178\": {\"inputs\": {\"model_name\": \"bbox/hand_yolov8s.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"179\": {\"inputs\": {\"model_name\": \"sam_vit_b_01ec64.pth\", \"device_mode\": \"AUTO\"}, \"class_type\": \"SAMLoader\"}, \"180\": {\"inputs\": {\"model_name\": \"bbox/face_yolov8m.pt\"}, \"class_type\": \"UltralyticsDetectorProvider\"}, \"185\": {\"inputs\": {\"guide_size\": 512.0, \"guide_size_for\": true, \"max_size\": 1024.0, \"seed\": 256432644423343, \"steps\": 5, \"cfg\": 7.0, \"sampler_name\": \"dpmpp_2m_sde_gpu\", \"scheduler\": \"karras\", \"denoise\": 0.25, \"feather\": 7, \"noise_mask\": true, \"force_inpaint\": true, \"bbox_threshold\": 0.35000000000000003, \"bbox_dilation\": 10, \"bbox_crop_factor\": 3.0, \"sam_detection_hint\": \"center-1\", \"sam_dilation\": 0, \"sam_threshold\": 0.93, \"sam_bbox_expansion\": 0, \"sam_mask_hint_threshold\": 0.7, \"sam_mask_hint_use_negative\": \"False\", \"drop_size\": 10, \"refiner_ratio\": 0.2, \"cycle\": 1, \"inpaint_model\": false, \"noise_mask_feather\": 20, \"image\": [\"173\", 0], \"detailer_pipe\": [\"173\", 4]}, \"class_type\": \"FaceDetailerPipe\"}, \"202\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"203\", 0]}, \"class_type\": \"FluxGuidance\"}, \"203\": {\"inputs\": {\"text\": [\"148\", 0], \"clip\": [\"232\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"209\": {\"inputs\": {\"control_net_name\": \"diffusion_pytorch_model.safetensors\"}, \"class_type\": \"ControlNetLoader\"}, \"231\": {\"inputs\": {\"strength\": 1.0, \"start_percent\": 0.0, \"end_percent\": 0.9, \"positive\": [\"143\", 0], \"negative\": [\"163\", 0], \"control_net\": [\"209\", 0], \"image\": [\"161\", 0]}, \"class_type\": \"ControlNetApplyAdvanced\"}, \"232\": {\"inputs\": {\"model\": [\"150\", 0], \"clip\": [\"150\", 1], \"lora_stack\": [\"234\", 0]}, \"class_type\": \"CR Apply LoRA Stack\"}, \"233\": {\"inputs\": {\"switch_1\": \"Off\", \"lora_name_1\": \"add-detail-xl.safetensors\", \"model_weight_1\": 1.0, \"clip_weight_1\": 1.0, \"switch_2\": \"Off\", \"lora_name_2\": \"RMSDXL_Creative.safetensors\", \"model_weight_2\": 2.0, \"clip_weight_2\": 1.0, \"switch_3\": \"Off\", \"lora_name_3\": \"RMSDXL_Enhance.safetensors\", \"model_weight_3\": 2.0, \"clip_weight_3\": 1.0}, \"class_type\": \"CR LoRA Stack\"}, \"234\": {\"inputs\": {\"switch_1\": \"On\", \"lora_name_1\": \"Flux\\\\Cinematic_style.safetensors\", \"model_weight_1\": 2.0, \"clip_weight_1\": 1.0, \"switch_2\": \"On\", \"lora_name_2\": \"Flux\\\\julie bell flux D-GMR.safetensors\", \"model_weight_2\": 1.0, \"clip_weight_2\": 1.5, \"switch_3\": \"On\", \"lora_name_3\": \"Flux\\\\FLUXEnh4nce.safetensors\", \"model_weight_3\": 0.8, \"clip_weight_3\": 1.0, \"lora_stack\": [\"233\", 0]}, \"class_type\": \"CR LoRA Stack\"}, \"237\": {\"inputs\": {\"control_net_name\": \"diffusion_pytorch_model.safetensors\"}, \"class_type\": \"ControlNetLoader\"}, \"238\": {\"inputs\": {\"strength\": 0.8, \"start_percent\": 0.0, \"end_percent\": 0.9, \"positive\": [\"241\", 0], \"negative\": [\"241\", 1], \"control_net\": [\"243\", 0], \"image\": [\"161\", 0]}, \"class_type\": \"ControlNetApplyAdvanced\"}, \"240\": {\"inputs\": {\"control_net_name\": \"diffusion_pytorch_model.safetensors\"}, \"class_type\": \"ControlNetLoader\"}, \"241\": {\"inputs\": {\"strength\": 0.8, \"start_percent\": 0.0, \"end_percent\": 0.9, \"positive\": [\"244\", 0], \"negative\": [\"244\", 1], \"control_net\": [\"240\", 0], \"image\": [\"161\", 0]}, \"class_type\": \"ControlNetApplyAdvanced\"}, \"243\": {\"inputs\": {\"control_net_name\": \"diffusion_pytorch_model.safetensors\"}, \"class_type\": \"ControlNetLoader\"}, \"244\": {\"inputs\": {\"strength\": 0.8, \"start_percent\": 0.0, \"end_percent\": 0.9, \"positive\": [\"231\", 0], \"negative\": [\"231\", 1], \"control_net\": [\"237\", 0], \"image\": [\"161\", 0]}, \"class_type\": \"ControlNetApplyAdvanced\"}, \"250\": {\"inputs\": {\"image\": \"2024-09-05 112402_00001_.png\", \"upload\": \"image\", \"parameter_index\": 0, \"positive\": \"\", \"negative\": \"\", \"setting\": \"The workflow is overly complex, or unsupported custom nodes have been used. Please see the README for more details.\\nhttps://github.com/receyuki/comfyui-prompt-reader-node#prompt-reader-node\"}, \"class_type\": \"SDPromptReader\", \"is_changed\": [\"{\\\"positive\\\": \\\"\\\", \\\"negative\\\": \\\"\\\", \\\"positive_sdxl\\\": {}, \\\"negative_sdxl\\\": {}, \\\"is_sdxl\\\": false, \\\"model\\\": \\\"\\\", \\\"sampler\\\": \\\"\\\", \\\"seed\\\": \\\"\\\", \\\"cfg\\\": \\\"\\\", \\\"steps\\\": \\\"\\\", \\\"size\\\": \\\"\\\", \\\"height\\\": \\\"1024\\\", \\\"width\\\": \\\"768\\\", \\\"setting\\\": \\\"\\\"}\"]}}, \"workflow\": {\"last_node_id\": 250, \"last_link_id\": 544, \"nodes\": [{\"id\": 130, \"type\": \"RecommendedResCalc\", \"pos\": {\"0\": 5828.08544921875, \"1\": -629.8947143554688, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 295.6000061035156, \"1\": 114}, \"flags\": {\"collapsed\": true}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"desiredXSIZE\", \"type\": \"INT\", \"link\": 306, \"widget\": {\"name\": \"desiredXSIZE\"}}, {\"name\": \"desiredYSIZE\", \"type\": \"INT\", \"link\": 307, \"widget\": {\"name\": \"desiredYSIZE\"}}], \"outputs\": [{\"name\": \"recomm width\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"recomm height\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"upscale factor\", \"type\": \"FLOAT\", \"links\": [308], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"reverse upscale for 4x\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}, {\"name\": \"reverse upscale for 2x\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RecommendedResCalc\"}, \"widgets_values\": [1024, 1024]}, {\"id\": 148, \"type\": \"String Replace (mtb)\", \"pos\": {\"0\": 2750.196044921875, \"1\": -986.9423217773438, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"string\", \"type\": \"STRING\", \"link\": 483, \"widget\": {\"name\": \"string\"}}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [326, 438], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"String Replace (mtb)\"}, \"widgets_values\": [\"\", \"\", \"\"]}, {\"id\": 168, \"type\": \"SaveImage\", \"pos\": {\"0\": 6387.31689453125, \"1\": -1000.0228881835938, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 525.0610961914062, \"1\": 582.182373046875}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 366}], \"outputs\": [], \"title\": \"Flux Generated Before SDXL\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"Flux Small\"]}, {\"id\": 103, \"type\": \"SaveImage\", \"pos\": {\"0\": 6949.31689453125, \"1\": -1007.0228881835938, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 525.0610961914062, \"1\": 582.182373046875}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 238}], \"outputs\": [], \"title\": \"SDXL Before Detailing and Upscaling Image\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"Flux XL Small\"]}, {\"id\": 174, \"type\": \"SaveImage\", \"pos\": {\"0\": 6374.31689453125, \"1\": -364.02288818359375, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 525.0610961914062, \"1\": 582.182373046875}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 484}], \"outputs\": [], \"title\": \"Upscaled Before Detailing\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"Upscaled\"]}, {\"id\": 57, \"type\": \"SaveImage\", \"pos\": {\"0\": 6942.64794921875, \"1\": -362.7694396972656, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 525.0610961914062, \"1\": 582.182373046875}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 485, \"slot_index\": 0}], \"outputs\": [], \"title\": \"Final Image\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"Flux XL FInal\"]}, {\"id\": 141, \"type\": \"CR Apply LoRA Stack\", \"pos\": {\"0\": 3868.7333984375, \"1\": -142.97654724121094, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 254.40000915527344, \"1\": 66}, \"flags\": {\"collapsed\": true}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 315}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 319}, {\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": 408, \"slot_index\": 2}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [344], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [323], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR Apply LoRA Stack\"}}, {\"id\": 232, \"type\": \"CR Apply LoRA Stack\", \"pos\": {\"0\": 3229.5546875, \"1\": -1083.9420166015625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 254.40000915527344, \"1\": 66}, \"flags\": {\"collapsed\": false}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 503}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 504}, {\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": 507, \"slot_index\": 2}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [505], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [506], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR Apply LoRA Stack\"}}, {\"id\": 164, \"type\": \"Text Prompt (JPS)\", \"pos\": {\"0\": 2666.6572265625, \"1\": -633.4291381835938, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 497.4541931152344, \"1\": 204.72251892089844}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"links\": [347], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Negative Prompt \", \"properties\": {\"Node name for S&R\": \"Text Prompt (JPS)\"}, \"widgets_values\": [\"bad hands, deformed hands, anime, watermark, signature, string, holding fabric, holding bag, drawn by bad-artist, sketch by bad-artist-anime, artist name, signature, watermark, (ugly:1.2), (worst quality, poor details:1.4), blurry, child, loli, kids, oil paint\"]}, {\"id\": 162, \"type\": \"VAEEncode\", \"pos\": {\"0\": 3589.47900390625, \"1\": -1046.0225830078125, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {\"collapsed\": true}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 341}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 365}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [343], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}}, {\"id\": 55, \"type\": \"PreviewImage\", \"pos\": {\"0\": 5808.9482421875, \"1\": -1316.85693359375, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 525.734619140625, \"1\": 700.7864990234375}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 294}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 176, \"type\": \"SAMLoader\", \"pos\": {\"0\": 5268.81396484375, \"1\": 826.2299194335938, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 349.4730529785156, \"1\": 82}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [389], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 179, \"type\": \"SAMLoader\", \"pos\": {\"0\": 5626.81396484375, \"1\": 824.2299194335938, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 339.2709655761719, \"1\": 84.23072814941406}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [393], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 233, \"type\": \"CR LoRA Stack\", \"pos\": {\"0\": 3186.5546875, \"1\": -764.9419555664062, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 316.0473327636719, \"1\": 351.2866516113281}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [{\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": null}], \"outputs\": [{\"name\": \"LORA_STACK\", \"type\": \"LORA_STACK\", \"links\": [508], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR LoRA Stack\"}, \"widgets_values\": [\"Off\", \"add-detail-xl.safetensors\", 1, 1, \"Off\", \"RMSDXL_Creative.safetensors\", 2, 1, \"Off\", \"RMSDXL_Enhance.safetensors\", 2, 1]}, {\"id\": 202, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 3528.650390625, \"1\": -750.7078247070312, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 342.93072509765625, \"1\": 66.43536376953125}, \"flags\": {\"collapsed\": false}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 468, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [462], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 129, \"type\": \"CM_NearestSDXLResolution\", \"pos\": {\"0\": 5387, \"1\": -517.513427734375, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {\"collapsed\": false}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 301}], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [312], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CM_NearestSDXLResolution\"}}, {\"id\": 131, \"type\": \"CM_IntBinaryOperation\", \"pos\": {\"0\": 5618, \"1\": -511.5133972167969, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {\"collapsed\": false}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"b\", \"type\": \"INT\", \"link\": 312, \"widget\": {\"name\": \"b\"}}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [307], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Height Multiplier\", \"properties\": {\"Node name for S&R\": \"CM_IntBinaryOperation\"}, \"widgets_values\": [\"Mul\", 2, 0]}, {\"id\": 134, \"type\": \"CM_IntBinaryOperation\", \"pos\": {\"0\": 5840, \"1\": -513.513427734375, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {\"collapsed\": false}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"b\", \"type\": \"INT\", \"link\": 311, \"widget\": {\"name\": \"b\"}}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [306], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Width Multiplier\", \"properties\": {\"Node name for S&R\": \"CM_IntBinaryOperation\"}, \"widgets_values\": [\"Mul\", 2, 0]}, {\"id\": 157, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 3554.082275390625, \"1\": -1060.3387451171875, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 236.8000030517578, \"1\": 148.19093322753906}, \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 334, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 333}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 335, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 337, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 458}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [339], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 144, \"type\": \"CLIPSetLastLayer\", \"pos\": {\"0\": 4207, \"1\": -190.29376220703125, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 224.3109130859375, \"1\": 58}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 323}], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [320, 346], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPSetLastLayer\"}, \"widgets_values\": [-2]}, {\"id\": 138, \"type\": \"BasicGuider\", \"pos\": {\"0\": 3531.082275390625, \"1\": -1133.3387451171875, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 226.98257446289062, \"1\": 58.645484924316406}, \"flags\": {\"collapsed\": true}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 416}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 462}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [333], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 203, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 3513.082275390625, \"1\": -1164.3387451171875, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 222.98257446289062, \"1\": 67.73639678955078}, \"flags\": {\"collapsed\": true}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 506}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 438, \"slot_index\": 1, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [468], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 161, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3573.082275390625, \"1\": -1133.3387451171875, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {\"collapsed\": false}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 339}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 340}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [341, 352, 366, 541, 542, 543, 544], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 238, \"type\": \"ControlNetApplyAdvanced\", \"pos\": {\"0\": 5130.76171875, \"1\": -592.244140625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 226.8000030517578, \"1\": 166}, \"flags\": {\"collapsed\": false}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 534}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 535}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 538}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 542, \"slot_index\": 3}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [536], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [537], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetApplyAdvanced\"}, \"widgets_values\": [0.8, 0, 0.9]}, {\"id\": 241, \"type\": \"ControlNetApplyAdvanced\", \"pos\": {\"0\": 5130.76171875, \"1\": -815.244140625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 226.8000030517578, \"1\": 166}, \"flags\": {\"collapsed\": false}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 532}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 533}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 539}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 541}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [534], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [535], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetApplyAdvanced\"}, \"widgets_values\": [0.8, 0, 0.9]}, {\"id\": 244, \"type\": \"ControlNetApplyAdvanced\", \"pos\": {\"0\": 5129.76171875, \"1\": -1047.244140625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 226.8000030517578, \"1\": 166}, \"flags\": {\"collapsed\": false}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 530}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 531}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 540}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 544, \"slot_index\": 3}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [532], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [533], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetApplyAdvanced\"}, \"widgets_values\": [0.8, 0, 0.9]}, {\"id\": 231, \"type\": \"ControlNetApplyAdvanced\", \"pos\": {\"0\": 5128.76171875, \"1\": -1266.244140625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 226.8000030517578, \"1\": 166}, \"flags\": {\"collapsed\": false}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 498}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 501}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 497}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 543}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [530], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [531], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetApplyAdvanced\"}, \"widgets_values\": [1, 0, 0.9]}, {\"id\": 163, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 4243.08203125, \"1\": -1141.3387451171875, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 210, \"1\": 59.249393463134766}, \"flags\": {\"collapsed\": true}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 346}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 347, \"slot_index\": 1, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [501], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 165, \"type\": \"PreviewImage\", \"pos\": {\"0\": 3882.082275390625, \"1\": -1158.3387451171875, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 791.8395385742188, \"1\": 711.39501953125}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 352}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 185, \"type\": \"FaceDetailerPipe\", \"pos\": {\"0\": 5977.81396484375, \"1\": -338.77008056640625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 346, \"1\": 782}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 406}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"link\": 407}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [485], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"slot_index\": 4, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailerPipe\"}, \"widgets_values\": [512, true, 1024, 256432644423343, \"randomize\", 5, 7, \"dpmpp_2m_sde_gpu\", \"karras\", 0.25, 7, true, true, 0.35000000000000003, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, 0.2, 1, false, 20]}, {\"id\": 173, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 5620.81396484375, \"1\": -340.77008056640625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 346, \"1\": 900}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 405}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 384}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 395}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 387}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 385}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 386}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 391}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 393}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 392}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [406], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"slot_index\": 3, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": [407], \"slot_index\": 4, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [512, true, 1024, 948255715188256, \"randomize\", 5, 7, \"dpmpp_2m_sde_gpu\", \"karras\", 0.25, 7, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 171, \"type\": \"FaceDetailer\", \"pos\": {\"0\": 5267.81396484375, \"1\": -340.77008056640625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 346, \"1\": 900}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 374}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 378}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 394}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 381}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 379}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 380}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 409, \"slot_index\": 6}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 389, \"slot_index\": 7}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 390, \"slot_index\": 8}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [405], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": [], \"slot_index\": 4, \"shape\": 3}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 6}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [512, true, 1024, 803941750574846, \"randomize\", 5, 7, \"dpmpp_2m_sde_gpu\", \"karras\", 0.25, 7, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"Small\", 10, \"\", 1, false, 20]}, {\"id\": 127, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 5381, \"1\": -1201.513427734375, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 421.5822448730469, \"1\": 642.752685546875}, \"flags\": {\"collapsed\": false}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 293}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 296}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 297}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 298}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 360}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 300}, {\"name\": \"upscale_by\", \"type\": \"FLOAT\", \"link\": 308, \"widget\": {\"name\": \"upscale_by\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [294, 374, 484], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [4, 639296840369093, \"randomize\", 5, 7, \"dpmpp_2m_sde_gpu\", \"karras\", 0.25, \"Linear\", 1024, 1024, 8, 32, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 169, \"type\": \"CR LoRA Stack\", \"pos\": {\"0\": 3765.7333984375, \"1\": 72.0234603881836, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 322.1335754394531, \"1\": 342}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": null}], \"outputs\": [{\"name\": \"LORA_STACK\", \"type\": \"LORA_STACK\", \"links\": [514], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR LoRA Stack\"}, \"widgets_values\": [\"On\", \"PerfectEyesXL.safetensors\", 1, 1, \"On\", \"EpicF4nta5yXL.safetensors\", 0.8, 1, \"Off\", \"hand 4.safetensors\", 1, 1]}, {\"id\": 209, \"type\": \"ControlNetLoader\", \"pos\": {\"0\": 4702.1875, \"1\": -1262.541259765625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 410.8729553222656, \"1\": 74.46261596679688}, \"flags\": {\"collapsed\": false}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [497], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"diffusion_pytorch_model.safetensors\"]}, {\"id\": 237, \"type\": \"ControlNetLoader\", \"pos\": {\"0\": 4695.1875, \"1\": -1040.541259765625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 420.2330627441406, \"1\": 68.04086303710938}, \"flags\": {\"collapsed\": false}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [540], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"diffusion_pytorch_model.safetensors\"]}, {\"id\": 240, \"type\": \"ControlNetLoader\", \"pos\": {\"0\": 4697.76171875, \"1\": -807.244140625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 420.2330627441406, \"1\": 68.04086303710938}, \"flags\": {\"collapsed\": false}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [539], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"diffusion_pytorch_model.safetensors\"]}, {\"id\": 243, \"type\": \"ControlNetLoader\", \"pos\": {\"0\": 4700.76171875, \"1\": -583.244140625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 420.2330627441406, \"1\": 68.04086303710938}, \"flags\": {\"collapsed\": false}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [538], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"diffusion_pytorch_model.safetensors\"]}, {\"id\": 175, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 5268, \"1\": 594, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 349.56396484375, \"1\": 79.22269439697266}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [409], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/person_yolov8m-seg.pt\"]}, {\"id\": 177, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 5268.81396484375, \"1\": 710.2299194335938, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 348.56396484375, \"1\": 82.3135986328125}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [390], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/person_yolov8m-seg.pt\"]}, {\"id\": 178, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 5623.81396484375, \"1\": 590.2299194335938, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 341.2669372558594, \"1\": 78}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [391], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/hand_yolov8s.pt\"]}, {\"id\": 180, \"type\": \"UltralyticsDetectorProvider\", \"pos\": {\"0\": 5625.81396484375, \"1\": 709.2299194335938, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 339.1709899902344, \"1\": 78.23072814941406}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [392], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 158, \"type\": \"RandomNoise\", \"pos\": {\"0\": 3530.140869140625, \"1\": -1027.098388671875, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 342.5567932128906, \"1\": 109.1871109008789}, \"flags\": {\"collapsed\": false}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [334], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [759511682542531, \"randomize\"]}, {\"id\": 160, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 3528.650390625, \"1\": -566.7078247070312, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 342.59832763671875, \"1\": 115.4333724975586}, \"flags\": {\"collapsed\": false}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 505}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [337], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 10, 1]}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 3528.650390625, \"1\": -887.7078247070312, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 343.54571533203125, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [458], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [768, 1344, 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 128, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 5383, \"1\": -1319.513427734375, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 441.69189453125, \"1\": 81.40042877197266}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"]}, {\"id\": 142, \"type\": \"CR LoRA Stack\", \"pos\": {\"0\": 3766.610107421875, \"1\": -319.1896667480469, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 316.0473327636719, \"1\": 351.2866516113281}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": 514}], \"outputs\": [{\"name\": \"LORA_STACK\", \"type\": \"LORA_STACK\", \"links\": [408], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR LoRA Stack\"}, \"widgets_values\": [\"On\", \"add-detail-xl.safetensors\", 1, 1, \"On\", \"RMSDXL_Enhance.safetensors\", 0.8, 0.8, \"On\", \"RMSDXL_Enhance.safetensors\", 0.8, 0.8]}, {\"id\": 94, \"type\": \"KSampler (Efficient)\", \"pos\": {\"0\": 4444, \"1\": -337, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 785.263671875, \"1\": 1244.8709716796875}, \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 344}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 536}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 537}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 343}, {\"name\": \"optional_vae\", \"type\": \"VAE\", \"link\": 364}, {\"name\": \"script\", \"type\": \"SCRIPT\", \"link\": null}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [296, 378, 384], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CONDITIONING+\", \"type\": \"CONDITIONING\", \"links\": [297, 379, 385], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"CONDITIONING-\", \"type\": \"CONDITIONING\", \"links\": [298, 380, 386], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [360, 381, 387], \"slot_index\": 4, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [238, 293, 301], \"slot_index\": 5, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler (Efficient)\"}, \"widgets_values\": [776176199102788, null, 30, 7, \"dpmpp_2m_sde_gpu\", \"karras\", 0.4, \"auto\", \"true\"], \"color\": \"#222233\", \"bgcolor\": \"#333355\", \"shape\": 1}, {\"id\": 150, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": 3527.082275390625, \"1\": -1164.3387451171875, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 340.9234924316406, \"1\": 101.91331481933594}, \"flags\": {\"collapsed\": true}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [416, 503], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [504], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [340], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"flux\\\\flux.1_dev_16x16-marduk191.safetensors\"]}, {\"id\": 139, \"type\": \"CheckpointLoaderSimple\", \"pos\": {\"0\": 4098, \"1\": -329, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 328.0381774902344, \"1\": 100.56018829345703}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [315], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [319, 394, 395], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [364, 365], \"slot_index\": 2, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"SDXL\\\\Copaxanime_vs_Tamarin_50-50.safetensors\"]}, {\"id\": 143, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 3567, \"1\": -1112, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 210, \"1\": 59.249393463134766}, \"flags\": {\"collapsed\": true}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 320}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 326, \"slot_index\": 1, \"widget\": {\"name\": \"text\"}}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [498], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 159, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 3528.650390625, \"1\": -654.7078247070312, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 342.82794189453125, \"1\": 58}, \"flags\": {\"collapsed\": false}, \"order\": 18, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [335], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 250, \"type\": \"SDPromptReader\", \"pos\": {\"0\": 2234, \"1\": -1211, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 315, \"1\": 978}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"POSITIVE\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}, {\"name\": \"NEGATIVE\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}, {\"name\": \"SEED\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"STEPS\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"CFG\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3}, {\"name\": \"WIDTH\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"HEIGHT\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"MODEL_NAME\", \"type\": \"*\", \"links\": null, \"shape\": 3}, {\"name\": \"FILENAME\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}, {\"name\": \"SETTINGS\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SDPromptReader\"}, \"widgets_values\": [\"2024-09-05 112402_00001_.png\", \"image\", 0, \"\", \"\", \"The workflow is overly complex, or unsupported custom nodes have been used. Please see the README for more details.\\nhttps://github.com/receyuki/comfyui-prompt-reader-node#prompt-reader-node\"]}, {\"id\": 234, \"type\": \"CR LoRA Stack\", \"pos\": {\"0\": 3186.75927734375, \"1\": -1146.9384765625, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 322.1335754394531, \"1\": 342}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"lora_stack\", \"type\": \"LORA_STACK\", \"link\": 508}], \"outputs\": [{\"name\": \"LORA_STACK\", \"type\": \"LORA_STACK\", \"links\": [507], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR LoRA Stack\"}, \"widgets_values\": [\"On\", \"Flux\\\\Cinematic_style.safetensors\", 2, 1, \"On\", \"Flux\\\\julie bell flux D-GMR.safetensors\", 1, 1.5, \"On\", \"Flux\\\\FLUXEnh4nce.safetensors\", 0.8, 1]}, {\"id\": 146, \"type\": \"Text Prompt (JPS)\", \"pos\": {\"0\": 2668, \"1\": -1148, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0, \"6\": 0, \"7\": 0, \"8\": 0, \"9\": 0}, \"size\": {\"0\": 492.9900817871094, \"1\": 487.0024108886719}, \"flags\": {\"collapsed\": false}, \"order\": 20, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"links\": [483], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Positive Prompt \", \"properties\": {\"Node name for S&R\": \"Text Prompt (JPS)\"}, \"widgets_values\": [\"(stgl2023:1.2),An elegant woman with a slender silhouette stands poised in a cyberpunk cityscape, her form adorned with a dress crafted from a mosaic of vibrant stained glass. The glass captures the essence of the neon city lights, casting a prismatic array of colors that dance upon her dress and spill onto the surrounding architecture. Gone is the halo, replaced with a crown of complex, gothic-styled stained glass that weaves religious and symbolic motifs into a narrative that contrasts starkly against the backdrop of the future.\\n\\nBehind her, the scene is framed by a grand, cathedral-like window, its panes a patchwork of urban glow, marrying the sanctity of the past with the pulse of technology. Intricate, geometric patterns are embedded in the stained glass of her dress, each segment a canvas telling tales as old as time, echoing the stories once told in ancient church windows.\\n\\nShe stands bathed in internal light, an ethereal glow that emanates from within, casting the translucent and reflective beauty of her stained glass attire in soft radiance. Her presence is magnetic, pulling the gaze of passersby and commanding the attention of the city. As she moves, her dress comes to life, the patterns of stained glass shifting gracefully, giving the impression of a living artwork with a rhythm akin to a slow, steady heartbeat.\\n\\nIn this vision, the figure stands as a fusion of two realms: the vibrant artistry of stained glass from a time of faith and the technological marvels of the coming future. She is a nexus of art and circuitry, an icon of the digital age, representing the potential for beauty and inspiration in the era of artificial intelligence.(reflection:1.1), (cyber Stained glass window:1.15),backlighting\"]}], \"links\": [[238, 94, 5, 103, 0, \"IMAGE\"], [293, 94, 5, 127, 0, \"IMAGE\"], [294, 127, 0, 55, 0, \"IMAGE\"], [296, 94, 0, 127, 1, \"MODEL\"], [297, 94, 1, 127, 2, \"CONDITIONING\"], [298, 94, 2, 127, 3, \"CONDITIONING\"], [300, 128, 0, 127, 5, \"UPSCALE_MODEL\"], [301, 94, 5, 129, 0, \"IMAGE\"], [306, 134, 0, 130, 0, \"INT\"], [307, 131, 0, 130, 1, \"INT\"], [308, 130, 2, 127, 6, \"FLOAT\"], [311, 129, 0, 134, 0, \"INT\"], [312, 129, 1, 131, 0, \"INT\"], [315, 139, 0, 141, 0, \"MODEL\"], [319, 139, 1, 141, 1, \"CLIP\"], [320, 144, 0, 143, 0, \"CLIP\"], [323, 141, 1, 144, 0, \"CLIP\"], [326, 148, 0, 143, 1, \"STRING\"], [333, 138, 0, 157, 1, \"GUIDER\"], [334, 158, 0, 157, 0, \"NOISE\"], [335, 159, 0, 157, 2, \"SAMPLER\"], [337, 160, 0, 157, 3, \"SIGMAS\"], [339, 157, 0, 161, 0, \"LATENT\"], [340, 150, 2, 161, 1, \"VAE\"], [341, 161, 0, 162, 0, \"IMAGE\"], [343, 162, 0, 94, 3, \"LATENT\"], [344, 141, 0, 94, 0, \"MODEL\"], [346, 144, 0, 163, 0, \"CLIP\"], [347, 164, 0, 163, 1, \"STRING\"], [352, 161, 0, 165, 0, \"IMAGE\"], [360, 94, 4, 127, 4, \"VAE\"], [364, 139, 2, 94, 4, \"VAE\"], [365, 139, 2, 162, 1, \"VAE\"], [366, 161, 0, 168, 0, \"IMAGE\"], [374, 127, 0, 171, 0, \"IMAGE\"], [378, 94, 0, 171, 1, \"MODEL\"], [379, 94, 1, 171, 4, \"CONDITIONING\"], [380, 94, 2, 171, 5, \"CONDITIONING\"], [381, 94, 4, 171, 3, \"VAE\"], [384, 94, 0, 173, 1, \"MODEL\"], [385, 94, 1, 173, 4, \"CONDITIONING\"], [386, 94, 2, 173, 5, \"CONDITIONING\"], [387, 94, 4, 173, 3, \"VAE\"], [389, 176, 0, 171, 7, \"SAM_MODEL\"], [390, 177, 1, 171, 8, \"SEGM_DETECTOR\"], [391, 178, 0, 173, 6, \"BBOX_DETECTOR\"], [392, 180, 1, 173, 8, \"SEGM_DETECTOR\"], [393, 179, 0, 173, 7, \"SAM_MODEL\"], [394, 139, 1, 171, 2, \"CLIP\"], [395, 139, 1, 173, 2, \"CLIP\"], [405, 171, 0, 173, 0, \"IMAGE\"], [406, 173, 0, 185, 0, \"IMAGE\"], [407, 173, 4, 185, 1, \"DETAILER_PIPE\"], [408, 142, 0, 141, 2, \"LORA_STACK\"], [409, 175, 0, 171, 6, \"BBOX_DETECTOR\"], [416, 150, 0, 138, 0, \"MODEL\"], [438, 148, 0, 203, 1, \"STRING\"], [458, 27, 0, 157, 4, \"LATENT\"], [462, 202, 0, 138, 1, \"CONDITIONING\"], [468, 203, 0, 202, 0, \"CONDITIONING\"], [483, 146, 0, 148, 0, \"STRING\"], [484, 127, 0, 174, 0, \"IMAGE\"], [485, 185, 0, 57, 0, \"IMAGE\"], [497, 209, 0, 231, 2, \"CONTROL_NET\"], [498, 143, 0, 231, 0, \"CONDITIONING\"], [501, 163, 0, 231, 1, \"CONDITIONING\"], [503, 150, 0, 232, 0, \"MODEL\"], [504, 150, 1, 232, 1, \"CLIP\"], [505, 232, 0, 160, 0, \"MODEL\"], [506, 232, 1, 203, 0, \"CLIP\"], [507, 234, 0, 232, 2, \"LORA_STACK\"], [508, 233, 0, 234, 0, \"LORA_STACK\"], [514, 169, 0, 142, 0, \"LORA_STACK\"], [530, 231, 0, 244, 0, \"CONDITIONING\"], [531, 231, 1, 244, 1, \"CONDITIONING\"], [532, 244, 0, 241, 0, \"CONDITIONING\"], [533, 244, 1, 241, 1, \"CONDITIONING\"], [534, 241, 0, 238, 0, \"CONDITIONING\"], [535, 241, 1, 238, 1, \"CONDITIONING\"], [536, 238, 0, 94, 1, \"CONDITIONING\"], [537, 238, 1, 94, 2, \"CONDITIONING\"], [538, 243, 0, 238, 2, \"CONTROL_NET\"], [539, 240, 0, 241, 2, \"CONTROL_NET\"], [540, 237, 0, 244, 2, \"CONTROL_NET\"], [541, 161, 0, 241, 3, \"IMAGE\"], [542, 161, 0, 238, 3, \"IMAGE\"], [543, 161, 0, 231, 3, \"IMAGE\"], [544, 161, 0, 244, 3, \"IMAGE\"]], \"groups\": [{\"title\": \"FLUX\", \"bounding\": [3519, -1222, 1161, 805], \"color\": \"#b58b2a\", \"font_size\": 24, \"locked\": false}, {\"title\": \"UPSCALER\", \"bounding\": [5371, -1394, 974, 974], \"color\": \"#009c2c\", \"font_size\": 24, \"locked\": false}, {\"title\": \"Output\", \"bounding\": [6353, -1080, 1154, 1318], \"color\": \"#444\", \"font_size\": 24, \"locked\": false}, {\"title\": \"SD 1.5 or SDXL\", \"bounding\": [4101, -403, 1147, 1321], \"color\": \"#4f00d9\", \"font_size\": 30, \"locked\": false}, {\"title\": \"Detailers\", \"bounding\": [5255, -409, 1084, 1323], \"color\": \"#eb7400\", \"font_size\": 24, \"locked\": false}, {\"title\": \"ControlNet\", \"bounding\": [4685, -1340, 683, 924], \"color\": \"#009feb\", \"font_size\": 24, \"locked\": false}, {\"title\": \"Prompt\", \"bounding\": [2659, -1223, 509, 804], \"color\": \"#a1309b\", \"font_size\": 24, \"locked\": false}, {\"title\": \"SD 1.5 or SDXL Loras\", \"bounding\": [3754, -407, 342, 822], \"color\": \"#9b0000\", \"font_size\": 24, \"locked\": false}, {\"title\": \"Flux Loras\", \"bounding\": [3174, -1223, 341, 820], \"color\": \"#A88\", \"font_size\": 24, \"locked\": false}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.6588450000000071, \"offset\": [-1870.2411952296295, 1652.660635514753]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"94\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"127\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"158\": {\"noise_seed\": 0}, \"159\": {\"sampler_name\": 0}, \"160\": {\"scheduler\": 0}, \"171\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}, \"173\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}, \"185\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}}, \"seed_widgets\": {\"94\": 0, \"127\": 1, \"158\": 0, \"171\": 3, \"173\": 3, \"185\": 3}}}",
            "steps": 10,
            "models": [
                "SDXL\\Copaxanime_vs_Tamarin_50-50.safetensors",
                "flux\\flux.1_dev_16x16-marduk191.safetensors"
            ],
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 3.5,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [
                "4x-UltraSharp.pth"
            ],
            "versionIds": [],
            "controlNets": [
                "diffusion_pytorch_model.safetensors",
                "diffusion_pytorch_model.safetensors",
                "diffusion_pytorch_model.safetensors",
                "diffusion_pytorch_model.safetensors"
            ],
            "additionalResources": []
        },
        "username": "serget2",
        "baseModel": ""
    },
    {
        "id": 14525990,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8cadc4e9-744a-4253-91c0-6704f7e61aff/width=1152/8cadc4e9-744a-4253-91c0-6704f7e61aff.jpeg",
        "hash": "UEA,wK%L014;~U%LE39G%1xCIqJCxYsmIpR.",
        "width": 1152,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-04T01:49:24.998Z",
        "postId": 3225932,
        "stats": {
            "cryCount": 70,
            "laughCount": 172,
            "likeCount": 1342,
            "dislikeCount": 0,
            "heartCount": 412,
            "commentCount": 5
        },
        "meta": {
            "Size": "769x1153",
            "seed": 221,
            "Model": "LG\\FRT_MixModel_XL_Lightning",
            "steps": 6,
            "hashes": {
                "model": "8063854374"
            },
            "prompt": "surrealist art A surreal scene unfolding in the realm of dreams! . dreamlike, mysterious, provocative, symbolic, intricate, detailed",
            "Version": "ComfyUI",
            "sampler": "dpmpp_2s_ancestral_karras",
            "CFG Scale": "1.5",
            "resources": [
                {
                    "hash": "8063854374",
                    "name": "LG\\FRT_MixModel_XL_Lightning",
                    "type": "model"
                }
            ],
            "Model hash": "8063854374",
            "negativePrompt": "anime, photorealistic, realistic, deformed, glitch, noisy, low contrast,"
        },
        "username": "Komposto",
        "baseModel": "SDXL Lightning"
    },
    {
        "id": 11136821,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0a3a9256-e7f6-42ed-891a-fb2a2bb12766/width=1152/0a3a9256-e7f6-42ed-891a-fb2a2bb12766.jpeg",
        "hash": "U2HoB{_3fQ_3?bkCfikCfQfQfQfQ?bkCfikC",
        "width": 1152,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-30T04:26:49.188Z",
        "postId": 2444106,
        "stats": {
            "cryCount": 71,
            "laughCount": 179,
            "likeCount": 1269,
            "dislikeCount": 0,
            "heartCount": 477,
            "commentCount": 4
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "768x1152",
            "seed": 1100775980,
            "Model": "Artex_XL",
            "steps": 50,
            "hashes": {
                "vae": "b3165c12ca",
                "model": "44f0cc14be"
            },
            "prompt": "best quality, high quality, detailed schematic, (realistic, photorealistic, absurdres:1.2), complex, <lora:l30_1___XL2400_lora_f32:5>, (chaos:1.3), dark water, deep ocean, macabre, darkness, creature, shadows",
            "Version": "v1.9.3",
            "sampler": "Euler",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "name": "l30_1___XL2400_lora_f32",
                    "type": "lora",
                    "weight": 5
                },
                {
                    "hash": "44f0cc14be",
                    "name": "Artex_XL",
                    "type": "model"
                }
            ],
            "Model hash": "44f0cc14be",
            "Hires steps": "70",
            "Hires upscale": "1.5",
            "Schedule type": "Automatic",
            "Hires upscaler": "4x_NMKD-Siax_200k",
            "negativePrompt": "text, watermark, low-quality, signature, monochrome, 3d, censored, muscles, furry, animal, lores, worst quality, female pubic hair, censored, mosaic,  unaestheticXL_Alb2",
            "Denoising strength": "0.2"
        },
        "username": null,
        "baseModel": null
    },
    {
        "id": 34809981,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/332aa871-c3a8-46c1-a8cc-6bf4e5212fcf/width=832/332aa871-c3a8-46c1-a8cc-6bf4e5212fcf.jpeg",
        "hash": "UQHUU$MyNGI:_NIUSgkC.8WVD%%1x]xaaea{",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-16T00:03:47.520Z",
        "postId": 7955384,
        "stats": {
            "cryCount": 70,
            "laughCount": 161,
            "likeCount": 1310,
            "dislikeCount": 0,
            "heartCount": 454,
            "commentCount": 44
        },
        "meta": null,
        "username": null,
        "baseModel": "Flux.1 D"
    },
    {
        "id": 33546090,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2db7b132-8114-48b2-bb1f-8cb78d79d8b7/width=832/2db7b132-8114-48b2-bb1f-8cb78d79d8b7.jpeg",
        "hash": "UVEW5iRjD%f+IUxuxut79Fxut7t6~qR%RiWC",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-08T20:35:41.195Z",
        "postId": 7672895,
        "stats": {
            "cryCount": 143,
            "laughCount": 340,
            "likeCount": 1210,
            "dislikeCount": 0,
            "heartCount": 301,
            "commentCount": 3
        },
        "meta": {
            "Size": "832x1216",
            "steps": 25,
            "prompt": "A very blurred, epic image of a dragon in the background, obscured by a cartoonish pop-up window. The pop-up shows a small toy-like droid/robot with its hand raised in a 'stop' gesture. Clear, large text at the bottom of the pop-up reads \"This Image Requires a CivitAi Platinum Membership.\" The android's expression is serious, and the background remains blurry, indistinct and vague, adding to the sense of being locked out. The android has the civitaiLogo on its forehead.",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-08T1930:08.6577567Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.35,
                    "modelVersionId": 863991,
                    "modelVersionName": "FLUX v0.2"
                },
                {
                    "type": "lora",
                    "weight": 0.65,
                    "modelVersionId": 737284,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 864939,
                    "modelVersionName": "Flux v1.0"
                }
            ]
        },
        "username": "UnstableGen",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 16664045,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5a999477-8af6-4de7-9ffe-8048918f97c5/width=864/5a999477-8af6-4de7-9ffe-8048918f97c5.jpeg",
        "hash": "UEC=#U-o9]IV0gw{M|Na~At6$%s.IUR*S$WX",
        "width": 864,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-21T23:29:12.892Z",
        "postId": 3738431,
        "stats": {
            "cryCount": 101,
            "laughCount": 158,
            "likeCount": 1204,
            "dislikeCount": 0,
            "heartCount": 531,
            "commentCount": 5
        },
        "meta": {
            "RNG": "NV",
            "VAE": "sdxl_vae.safetensors",
            "Size": "864x1152",
            "seed": 293459763,
            "Model": "autismmixSDXL_autismmixPony",
            "steps": 30,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "821aa5537f",
                "lora:ph4nt0m01lXLP": "2fad3070c8a2",
                "lora:oddities_shop_specimen": "1044d492e42d"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up,   <lora:oddities_shop_specimen:1> 0ddmag1c, curio, (in container:1.3), solo, no_humans, cork, label, , fetal_position, preserved, wet_specimen_container, dim, dark,<lora:ph4nt0m01lXLP:0.8> ph4nt0m01l, jar , bottle, on shelf, eyes_closed, full body, floating, limp, dragon, cute, feral, submerged, indoors, room",
            "Version": "v1.9.4",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "Pad conds": "True",
            "resources": [
                {
                    "hash": "1044d492e42d",
                    "name": "oddities_shop_specimen",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "2fad3070c8a2",
                    "name": "ph4nt0m01lXLP",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "821aa5537f",
                    "name": "autismmixSDXL_autismmixPony",
                    "type": "model"
                }
            ],
            "Model hash": "821aa5537f",
            "Schedule type": "Automatic",
            "negativePrompt": "watermark, signature, artist name, (3d), muscular, cum, ugly,",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.5.1",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.6",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "freckledvixon",
        "baseModel": "Pony"
    },
    {
        "id": 35331152,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b104b341-9066-4d28-99a4-119f4a7fccda/width=832/b104b341-9066-4d28-99a4-119f4a7fccda.jpeg",
        "hash": "UeJr?8};SctPENs.xDn$NaRkWXfkjFkBkCWC",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-19T01:00:00.000Z",
        "postId": 8074168,
        "stats": {
            "cryCount": 93,
            "laughCount": 164,
            "likeCount": 1262,
            "dislikeCount": 0,
            "heartCount": 474,
            "commentCount": 10
        },
        "meta": {
            "Size": "832x1216",
            "seed": 4186844782,
            "steps": 20,
            "prompt": "hyperrealistic digital painting by J. Scott Campbell and Thomas Saliot and Jeremiah Ketner and Lois van Baarle, lifelike anime, incredibly detailed, bokeh, ultra realistic, 8k, incredibly cute ginger girl",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-07T2125:33.7225665Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 922358,
                    "modelVersionName": "Pro 1.1"
                }
            ]
        },
        "username": "LordTerror",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 34948505,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/44cb97a0-73ed-404a-8c07-cff810adabd0/width=720/44cb97a0-73ed-404a-8c07-cff810adabd0.jpeg",
        "hash": "U6Bd,CFwn2I,AdF3$fEy;L,]6z$k|_wc,=-C",
        "width": 720,
        "height": 1008,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-16T18:51:51.255Z",
        "postId": 7987723,
        "stats": {
            "cryCount": 47,
            "laughCount": 73,
            "likeCount": 1549,
            "dislikeCount": 0,
            "heartCount": 324,
            "commentCount": 12
        },
        "meta": {
            "prompt": "A surreal journey through a kaleidoscopic dreamscape, where vibrant paint splatters come alive, swirling around a mesmerizing golden eye that holds secrets of another dimension. @HailuoAI"
        },
        "username": "jihaamies",
        "baseModel": ""
    },
    {
        "id": 28454765,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1cb64bf8-c802-4cf6-87ba-c17f390e0dd8/width=1800/1cb64bf8-c802-4cf6-87ba-c17f390e0dd8.jpeg",
        "hash": "U79ZZ#54j[;R2T,]n$9sNZJ6Ris;}vozV@xa",
        "width": 2688,
        "height": 3456,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-09T00:09:25.082Z",
        "postId": 6365942,
        "stats": {
            "cryCount": 73,
            "laughCount": 147,
            "likeCount": 1324,
            "dislikeCount": 0,
            "heartCount": 448,
            "commentCount": 2
        },
        "meta": {
            "Size": "896x1152",
            "seed": 2987306450,
            "steps": 25,
            "prompt": "<lora:artilands:0.8>   <lora:CPA:0.7> anime, cyberpunk   <lora:dark_fantasy_flux:0.7>",
            "sampler": "Euler",
            "cfgScale": 3,
            "resources": [
                {
                    "name": "artilands",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "name": "CPA",
                    "type": "lora",
                    "weight": 0.7
                },
                {
                    "name": "dark_fantasy_flux",
                    "type": "lora",
                    "weight": 0.7
                }
            ],
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 802003,
                    "modelVersionName": "artilands"
                },
                {
                    "type": "lora",
                    "weight": 0.9,
                    "modelVersionId": 738658,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 747534,
                    "modelVersionName": "Flux.1 D v1"
                }
            ]
        },
        "username": "ArtifyAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 30835523,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b6e55239-4ea4-4164-8f0e-afedee9a0689/width=832/b6e55239-4ea4-4164-8f0e-afedee9a0689.jpeg",
        "hash": "U89tGXjF02x[+ZSO5Yrr~9ae4=oz^gX89wnO",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-23T10:00:00.000Z",
        "postId": 6895611,
        "stats": {
            "cryCount": 71,
            "laughCount": 184,
            "likeCount": 1295,
            "dislikeCount": 0,
            "heartCount": 441,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1046817811,
            "extra": {
                "remixOfId": 30681772
            },
            "steps": 18,
            "prompt": "A beautiful blonde  deco pop artist, all pastel sleek futuristic outfit dress standing in a cave, high quality fantasy art, historic rendering of an old lighthouse, square spaceship , digital artwork by Beksinski, vibrant colors include cuware and births a house,picture shows water, expansive, the moon, with strange architecture and down on a suspended mid-air jet. create a sense of detailed, abstract, trippy, 60s style, op art,  cell shaded, 8k. The composition includes overlapping circles, sharp-edged polygons, and fluid lines, all interwoven to create a sense of rhythm and flow.",
            "sampler": "Euler a",
            "cfgScale": 2,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-22T2344:27.5297427Z",
            "negativePrompt": "(worst quality, low quality, poor quality, normal quality, low res, low details, over/under saturated, over/under exposed, grayscale, black and white, bad photo, bad art:1.4), (watermark, signature, text, font, logo, words, letters, digits, name:1.2), (blur, grain, morbid, ugly, asymmetrical, mutated, malformed, poorly lit, bad lighting, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate), (cartoon, anime, CGI, render, digital art, manga, amateur art:1.3), (3D, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad proportions, deformities:1.3), (incorrect white balance:1.2),bad quality, low resolution, image with artifacts",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 131960,
                    "modelVersionName": "v1.1-Beta"
                },
                {
                    "type": "lora",
                    "weight": 0.25,
                    "modelVersionId": 152309,
                    "modelVersionName": "xl_more_art-full-v1"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 246747,
                    "modelVersionName": "Euler a.fix"
                },
                {
                    "type": "lora",
                    "weight": 0.75,
                    "modelVersionId": 258416,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.25,
                    "modelVersionId": 309330,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.45,
                    "modelVersionId": 337278,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.15,
                    "modelVersionId": 383563,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 560995,
                    "modelVersionName": "SDXL"
                },
                {
                    "type": "lora",
                    "weight": 0.35,
                    "modelVersionId": 641523,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.65,
                    "modelVersionId": 678485,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "funkstroke",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 36613317,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3440c0f7-98b7-4d56-beb5-c3db33c2579d/width=864/3440c0f7-98b7-4d56-beb5-c3db33c2579d.jpeg",
        "hash": "UKJl=oFf~nyC3ENKi_Sh18OE9IIW#-s,=]jF",
        "width": 864,
        "height": 1440,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-26T08:30:00.000Z",
        "postId": 8362814,
        "stats": {
            "cryCount": 94,
            "laughCount": 162,
            "likeCount": 1303,
            "dislikeCount": 0,
            "heartCount": 431,
            "commentCount": 5
        },
        "meta": {
            "Size": "864x1440",
            "seed": 1580852300,
            "Model": "flux1-dev-fp8 16GB",
            "steps": 28,
            "hashes": {
                "model": "ca1385eb36",
                "lora:FLUX-daubrez-DB4RZ-v2": "9A6DFC274BBD"
            },
            "prompt": "A digital painting or illustration features a woman in a light teal or baby blue dress, seated on a swing suspended in a dreamlike, softly colored sky.\u00a0\nThe woman's back is to the viewer.\u00a0 Her hair is long and a light brown/ auburn, flowing freely around her shoulders and back, partly highlighted with a golden tone, suggesting sunlight or the warmth of a sunset.\u00a0She\u00a0appears to be wearing a simple, v-necked, sleeveless top. This style and color of the dress continue over into her skirt; the design of the skirt seems to be divided into\u00a0irregular geometric shapes.\u00a0\nThe sky/atmosphere surrounding the swing is a soft blend of cerulean blues, pale yellows, and hints of orange, reminiscent of a sunrise or sunset.\u00a0Soft,\u00a0stylized clouds are depicted in a palette of muted tones, creating a dreamy, ethereal atmosphere.  Several small, light-colored birds are depicted in flight amongst the clouds, creating a sense of movement and openness within the scene.\u00a0\nThe\u00a0swing ropes are simple lines that run vertically through the image, further emphasizing the sense of floating and weightlessness.\u00a0The overall style of the work is painterly, with visible brushstrokes or patterns that suggest a digital art process, adding a soft, textural quality to the image. The colors are light, soft, and blend seamlessly into one another; there isn't a hard or harsh transition from one color to another, creating a sense of peace.\n<lora:FLUX-daubrez-DB4RZ-v2:1> DB4RZ, DB4RZ style painting",
            "Version": "f2.0.1v1.10.1-previous-584-g9a698e26",
            "sampler": "DPM++ 2M",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "9A6DFC274BBD",
                    "name": "FLUX-daubrez-DB4RZ-v2",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "ca1385eb36",
                    "name": "flux1-dev-fp8 16GB",
                    "type": "model"
                }
            ],
            "Model hash": "ca1385eb36",
            "Schedule type": "SGM Uniform",
            "Distilled CFG Scale": "3.5"
        },
        "username": "NoobFromEgypt",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 29136612,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1b1d2267-ecbc-4668-aa4f-d2c467bfa543/width=512/1b1d2267-ecbc-4668-aa4f-d2c467bfa543.jpeg",
        "hash": "U5B:1,~B7KAt~VNb9[xt-:I;Q.^55RR%w{-V",
        "width": 512,
        "height": 912,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-13T01:54:41.506Z",
        "postId": 6519534,
        "stats": {
            "cryCount": 94,
            "laughCount": 245,
            "likeCount": 1227,
            "dislikeCount": 0,
            "heartCount": 423,
            "commentCount": 0
        },
        "meta": {
            "Size": "512x912",
            "seed": 1309517014,
            "Model": "8StepsCreartHyperFluxDev_hyperDevFp8Unet",
            "steps": 8,
            "hashes": {
                "model": "0f1a78539b"
            },
            "prompt": "mage of an eccentric figure, mixture of a hypopotamus with giraffe",
            "Version": "f2.0.1v1.10.1-previous-526-gc13b26ba",
            "sampler": "Euler",
            "Module 1": "ae",
            "Module 2": "clip_l",
            "Module 3": "t5xxl_fp16",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "0f1a78539b",
                    "name": "8StepsCreartHyperFluxDev_hyperDevFp8Unet",
                    "type": "model"
                }
            ],
            "Model hash": "0f1a78539b",
            "Schedule type": "Normal",
            "Distilled CFG Scale": "3.5",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)"
        },
        "username": "daniilomaia332908",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 25272655,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cfc3ea9b-7ce7-43fb-b563-f566d648b838/width=832/cfc3ea9b-7ce7-43fb-b563-f566d648b838.jpeg",
        "hash": "UCMZz0D%L~%K_MWBxsoJDPs.R.Ion$kCbIM|",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-20T14:03:55.147Z",
        "postId": 5647040,
        "stats": {
            "cryCount": 62,
            "laughCount": 295,
            "likeCount": 1216,
            "dislikeCount": 0,
            "heartCount": 416,
            "commentCount": 8
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2451479270,
            "steps": 50,
            "prompt": "A recipe card titled \"Recipe for Disaster,\" with steps that clearly lead to chaos. Ingredients include \"2 cups of poor planning,\" \"1 tablespoon of overconfidence,\" and \"a pinch of denial.\" The instructions would detail steps like \"Combine all ingredients in a haphazard manner\" and \"Bake at full speed ahead until everything falls apart.\"",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-08-20T1356:55.9710198Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 699332,
                    "modelVersionName": "Pro"
                }
            ]
        },
        "username": "kasparovabi",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 11294344,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8b0a1f17-d83f-4853-8952-3d0c414ca7a3/width=1288/8b0a1f17-d83f-4853-8952-3d0c414ca7a3.jpeg",
        "hash": "UAF5{gx^8wob7%-:ADog0L%N~AWU;KoyOutR",
        "width": 1288,
        "height": 1880,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-02T01:08:22.624Z",
        "postId": 2481352,
        "stats": {
            "cryCount": 66,
            "laughCount": 188,
            "likeCount": 1239,
            "dislikeCount": 0,
            "heartCount": 496,
            "commentCount": 3
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "832x1216",
            "seed": 1299769895,
            "Model": "SDXLFaetastic_v24",
            "steps": 85,
            "hashes": {
                "vae": "235745af8d",
                "model": "07b985d12f",
                "lora:MJ52": "000c96b6bd08",
                "lora:add-detail-xl": "9c783c8ce46c",
                "lora:dvr-lnds-sdxl": "a9bf748d0856",
                "lora:zavy-cntrst-sdxl": "1ac0c6cd4e92",
                "lora:zavy-rmlght-sdxl": "65db6b026942",
                "lora:SDXLFaeTastic2400": "e7da1e0c0933",
                "lora:ral-apoctvisn-sdxl": "04f9cdbb3aa2"
            },
            "prompt": "Adventurers race go-karts through a rainbow-colored racetrack suspended in the clouds. \nextremely detailed,\nmany details, extreme detailed, full of details,\nWide range of colors., Dramatic,Dynamic,Cinematic,Sharp details\n Insane quality. Insane resolution. Insane details. Masterpiece. 32k resolution.\n <lora:add-detail-xl:0.95> <lora:dvr-lnds-sdxl:0.3> dvr-lnds-sdxl <lora:MJ52:0.25> <lora:ral-apoctvisn-sdxl:0.3> ral-apoctvisn <lora:zavy-cntrst-sdxl:0.35> dark, chiaroscuro, low-key <lora:zavy-rmlght-sdxl:0.41> zavy-rmlght <lora:SDXLFaeTastic2400:0.225>",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4.5,
            "resources": [
                {
                    "hash": "9c783c8ce46c",
                    "name": "add-detail-xl",
                    "type": "lora",
                    "weight": 0.95
                },
                {
                    "hash": "a9bf748d0856",
                    "name": "dvr-lnds-sdxl",
                    "type": "lora",
                    "weight": 0.3
                },
                {
                    "hash": "000c96b6bd08",
                    "name": "MJ52",
                    "type": "lora",
                    "weight": 0.25
                },
                {
                    "hash": "04f9cdbb3aa2",
                    "name": "ral-apoctvisn-sdxl",
                    "type": "lora",
                    "weight": 0.3
                },
                {
                    "hash": "1ac0c6cd4e92",
                    "name": "zavy-cntrst-sdxl",
                    "type": "lora",
                    "weight": 0.35
                },
                {
                    "hash": "65db6b026942",
                    "name": "zavy-rmlght-sdxl",
                    "type": "lora",
                    "weight": 0.41
                },
                {
                    "hash": "e7da1e0c0933",
                    "name": "SDXLFaeTastic2400",
                    "type": "lora",
                    "weight": 0.225
                },
                {
                    "hash": "07b985d12f",
                    "name": "SDXLFaetastic_v24",
                    "type": "model"
                }
            ],
            "Model hash": "07b985d12f",
            "Hires steps": "15",
            "Hires upscale": "1.55",
            "Hires upscaler": "SwinIR_4x",
            "negativePrompt": "maks, borders, text, words, copyright, grotesque, unsightly, misshapen, deformed, mangled, awkward, distorted, twisted, contorted, misshapen, lopsided, malformed, asymmetrical, irregular, unnatural, botched, mangled, mutilated, disfigured, unsightly, ugly, repulsive, revolting, ghastly, hideous, unappealing, terrible, awful, frightful, odious, loathsome, revolting, obnoxious, detestable, hateful, repugnant, sickening, vile, abhorrent, contemptible, execrable, loathsome, detestable, repellent, disgusting, revolting, loathsome, distasteful, abominable, ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, blurry, bad anatomy, blurred, watermark, grainy, signature, cut off, draft, amateur, multiple, gross, weird, uneven, furnishing, decorating, decoration, furniture, text, poor, low, basic, worst, unprofessional, failure, crayon, oil, label, thousand (hands:1.1), straight stitch, monochromatic, plain, unpatterned",
            "Denoising strength": "0.25"
        },
        "username": "AIDigitalMediaAgency",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 31027020,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c41190c5-497f-4001-9af9-911e8da0418f/width=832/c41190c5-497f-4001-9af9-911e8da0418f.jpeg",
        "hash": "UWH2ZQxsEdt6pGs.%LoeEeoL%1oL~Vs:MyoL",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-24T00:40:46.468Z",
        "postId": 6935811,
        "stats": {
            "cryCount": 158,
            "laughCount": 480,
            "likeCount": 929,
            "dislikeCount": 0,
            "heartCount": 421,
            "commentCount": 13
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2690466396,
            "extra": {
                "remixOfId": 29163792
            },
            "steps": 31,
            "prompt": "photorealistic, shepherd cross, liathedog, outside, grass, holding up a sign with her paws that says \"My owner paid 10K Buzz to feature this instead of buying treats!\"",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-24T0037:05.5937869Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 1.4,
                    "modelVersionId": 769336,
                    "modelVersionName": "V1"
                }
            ]
        },
        "username": "kftiger",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 14896660,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b2af4a3a-3f14-4d00-baf1-58106eb62322/width=1024/b2af4a3a-3f14-4d00-baf1-58106eb62322.jpeg",
        "hash": "U88z7.,J4mE|EZJ}NEwgIEnm%jog-noIEHNt",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-07T03:25:01.432Z",
        "postId": 3304043,
        "stats": {
            "cryCount": 75,
            "laughCount": 148,
            "likeCount": 1299,
            "dislikeCount": 0,
            "heartCount": 466,
            "commentCount": 2
        },
        "meta": {
            "Size": "1024x1024",
            "seed": 149009056,
            "steps": 41,
            "prompt": "A beautiful translucent pale orb containing lightning, crystal clear, Fancey stand, time distortion, high quality, RGB the everything",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "blurry, bad quality, poor quality,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 240840
                }
            ]
        },
        "username": "shadowcat133600",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 23302357,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2d47b074-9013-42cb-9fee-ca9728d5234f/width=832/2d47b074-9013-42cb-9fee-ca9728d5234f.jpeg",
        "hash": "USC}^JNw5;$i}@a}E*oL#,jtJ9fREgsmwdNc",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-08T08:04:25.570Z",
        "postId": 5192229,
        "stats": {
            "cryCount": 66,
            "laughCount": 136,
            "likeCount": 1405,
            "dislikeCount": 0,
            "heartCount": 380,
            "commentCount": 1
        },
        "meta": null,
        "username": "LennMcL",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 34809381,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1a532ad0-a173-4a57-b91d-3c937c7ef665/width=1248/1a532ad0-a173-4a57-b91d-3c937c7ef665.jpeg",
        "hash": "UDBV,~E29bIo~B9bt6WB0gE3?Fxa02%1-nf+",
        "width": 1248,
        "height": 1824,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-16T00:15:00.000Z",
        "postId": 7955232,
        "stats": {
            "cryCount": 49,
            "laughCount": 128,
            "likeCount": 1405,
            "dislikeCount": 0,
            "heartCount": 405,
            "commentCount": 4
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2411150303,
            "Model": "flux1-dev-bnb-nf4-v2",
            "steps": 30,
            "hashes": {
                "model": "bea01d51bd",
                "lora:ImageUpgraderV2": "e5598e0ef11d",
                "lora:flux_dev_flmft5": "1C835C0967",
                "lora:artisketchyfs-v02": "2097f7b0e740",
                "lora:dark_fantasy_flux": "6E5F580C0E",
                "lora:FredFraiStyle-FLUX-Share": "63BFAA1CF9",
                "lora:flux.1_lora_flyway_Epic-Characters_v1": "B73E077D02BF"
            },
            "Version": "",
            "sampler": "Euler",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "63BFAA1CF9",
                    "name": "FredFraiStyle-FLUX-Share",
                    "type": "lora"
                },
                {
                    "hash": "6E5F580C0E",
                    "name": "dark_fantasy_flux",
                    "type": "lora"
                },
                {
                    "hash": "e5598e0ef11d",
                    "name": "ImageUpgraderV2",
                    "type": "lora"
                },
                {
                    "hash": "2097f7b0e740",
                    "name": "artisketchyfs-v02",
                    "type": "lora"
                },
                {
                    "hash": "1C835C0967",
                    "name": "flux_dev_flmft5",
                    "type": "lora"
                },
                {
                    "hash": "B73E077D02BF",
                    "name": "flux.1_lora_flyway_Epic-Characters_v1",
                    "type": "lora"
                },
                {
                    "hash": "bea01d51bd",
                    "name": "flux1-dev-bnb-nf4-v2",
                    "type": "model"
                }
            ],
            "Model hash": "bea01d51bd",
            "Hires steps": "20",
            "Hires upscale": "1.5",
            "Schedule type": "Normal",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "f2.0.1v1.10.1-previous-450-gdb6448df, Diffusion in Low Bits: Automatic (fp16 LoRA)",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.9.0",
            "Denoising strength": "0.35",
            "ADetailer mask blur": "8",
            "Distilled CFG Scale": "3",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint width": "1024",
            "ADetailer inpaint height": "1280",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.35",
            "ADetailer inpaint only masked": "True",
            "ADetailer use inpaint width height": "True"
        },
        "username": "ArtifyAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 18989234,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/40eef5c5-75d3-43a4-bf99-210fcd87033e/width=1800/40eef5c5-75d3-43a4-bf99-210fcd87033e.jpeg",
        "hash": "U78;12W=00nhKQs.IAR*iuS5t8a$}TnhF}of",
        "width": 1872,
        "height": 2736,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-08T17:38:00.722Z",
        "postId": 4239836,
        "stats": {
            "cryCount": 54,
            "laughCount": 150,
            "likeCount": 1342,
            "dislikeCount": 0,
            "heartCount": 440,
            "commentCount": 7
        },
        "meta": null,
        "username": "Pinkielicious",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 11320088,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ebde529a-da3c-40c9-a4b6-d8c5a51d08c0/width=832/ebde529a-da3c-40c9-a4b6-d8c5a51d08c0.jpeg",
        "hash": "UWFa2lx^t-WBY8V@RiozIXs8VYkDWXadjEbH",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-05-02T09:05:00.677Z",
        "postId": 2487537,
        "stats": {
            "cryCount": 49,
            "laughCount": 230,
            "likeCount": 1184,
            "dislikeCount": 0,
            "heartCount": 523,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 185608514,
            "steps": 50,
            "prompt": "otherworldly, Hyper-Realism, Capturing the essence of summer serenity, a breathtaking Busty redhead beauty, adorned with delicate freckles, graces the seaside and throwing a Pokemon Ball, Wrapped in a translucent pastel blue scarf, gently billowing in the breeze, her radiant smile and laughing eyes reveal the joy of the moment against the backdrop of the endless blue sky.r., Radiating with Neon Brightness. With Ultra Detailed Anatomy and Perfect Lighting, Every Detail Shines. From a Bright Sideview, the Scene Pops with Cinematic Atmosphere and black sand. Shot in UHD Quality, This Candid Moment Captures the Epicness and Vibrancy of the Moment. Explore the Depth of Field for an Eye-Catching Experience, Where Imperfections Add to the Natural Beauty.surrounded by a detailed monochrome spacescape with translucent dark-scarlet Highlights, hyper-detailed, sharp, high resolution, high quality, 32K, Ultra realistic, HD, super detailed, line art, abstract style",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 5,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "bad proportions, low resolution, bad, ugly, terrible, female, girl, painting, 3d, render, comic, anime, manga, unrealistic, flat, FastNegativeV2, watermark, signature, worst quality, low quality, normal quality, lowres, simple background, inaccurate limb, extra fingers, fewer fingers, missing fingers, extra arms, (extra legs:1.3), inaccurate eyes, bad composition, bad anatomy, error, extra digit, fewer digits, cropped, low res, worst quality, low quality, normal quality, jpeg artifacts, extra digit, fewer digits, trademark, watermark, artist's name, username, signature, text, words,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 343830
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208
                },
                {
                    "type": "ImageJobNetworkParams { Strength = 0.4, TriggerWord = , Type = lora }",
                    "weight": 0.4,
                    "modelVersionId": 258687
                },
                {
                    "type": "ImageJobNetworkParams { Strength = 0.5, TriggerWord = , Type = lora }",
                    "weight": 0.5,
                    "modelVersionId": 296637
                },
                {
                    "type": "ImageJobNetworkParams { Strength = 0.75, TriggerWord = , Type = lora }",
                    "weight": 0.75,
                    "modelVersionId": 405924
                },
                {
                    "type": "ImageJobNetworkParams { Strength = 0.85, TriggerWord = , Type = lora }",
                    "weight": 0.85,
                    "modelVersionId": 413566
                },
                {
                    "type": "ImageJobNetworkParams { Strength = 0.4, TriggerWord = , Type = lora }",
                    "weight": 0.4,
                    "modelVersionId": 446308
                },
                {
                    "type": "ImageJobNetworkParams { Strength = 1, TriggerWord = , Type = vae }",
                    "weight": 1,
                    "modelVersionId": 333245
                }
            ]
        },
        "username": "Ajuro",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 33246906,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/91527282-0727-4670-9e9e-d458d873f111/width=832/91527282-0727-4670-9e9e-d458d873f111.jpeg",
        "hash": "UJMQL=NIADnO{geoQnTINKE2U_%L*}V@TdtQ",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-07T03:44:52.316Z",
        "postId": 7606542,
        "stats": {
            "cryCount": 102,
            "laughCount": 193,
            "likeCount": 1304,
            "dislikeCount": 0,
            "heartCount": 386,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2045551462,
            "extra": {
                "remixOfId": 32290947
            },
            "steps": 28,
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, watercolor painting, cat in a kimono, soft colors, falling cherry blossoms",
            "sampler": "Euler a",
            "cfgScale": 8.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-07T0344:12.3076700Z",
            "negativePrompt": "Score_6, score_5, score_4, 3d, bad quality, bad anatomy, worst quality, low quality, low resolution, extra fingers, blur, blurry, ugly, wrong proportions, watermark, image artifacts, lowres, ugly, jpeg artifacts, deformed, noisy image, deformation, duplicate horns, head wings,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 290640,
                    "modelVersionName": "V6 (start with this one)"
                },
                {
                    "type": "lora",
                    "weight": 0.85,
                    "modelVersionId": 486869,
                    "modelVersionName": "Organic Sauce"
                }
            ]
        },
        "username": "Meower2024",
        "baseModel": "Pony"
    },
    {
        "id": 22493645,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/01456943-35d3-4939-9151-fc9b1725e0b5/width=1664/01456943-35d3-4939-9151-fc9b1725e0b5.jpeg",
        "hash": "UBE:G2Dh00xu%$9G8_-;00R*em_N?GxtWXx[",
        "width": 1664,
        "height": 2432,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-02T23:31:48.144Z",
        "postId": 5011517,
        "stats": {
            "cryCount": 56,
            "laughCount": 93,
            "likeCount": 898,
            "dislikeCount": 0,
            "heartCount": 288,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 942154536,
            "Model": "XL_DeverDivineDiffusion_v11",
            "steps": 30,
            "hashes": {
                "model": "505966774f",
                "lora:dvr-bnz": "cb8d19021083"
            },
            "prompt": "large mist monster with glowing demon eye emerging from the darkness and ectoplasmic mist behind a small boat passing on the cam water, barely visible glowing scales and spikes, ethereal, volumetric lighting\n<lora:dvr-bnz:0.8> dvr-bnz",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ 3M SDE Exponential",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "cb8d19021083",
                    "name": "dvr-bnz",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "505966774f",
                    "name": "XL_DeverDivineDiffusion_v11",
                    "type": "model"
                }
            ],
            "Model hash": "505966774f",
            "Hires steps": "20",
            "Hires upscale": "2",
            "Hires upscaler": "4x_foolhardy_Remacri",
            "Denoising strength": "0.4",
            "Old prompt editing timelines": "True"
        },
        "username": "Dever",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 31354908,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/42e93749-9c27-47dc-888e-da4f265d214b/width=1160/42e93749-9c27-47dc-888e-da4f265d214b.jpeg",
        "hash": "ULEw~rs,?Eox}=oeI;oexYS4V]s.NHs,WCod",
        "width": 1160,
        "height": 1696,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-26T01:07:32.014Z",
        "postId": 7008985,
        "stats": {
            "cryCount": 33,
            "laughCount": 122,
            "likeCount": 875,
            "dislikeCount": 0,
            "heartCount": 304,
            "commentCount": 0
        },
        "meta": {
            "seed": 1608,
            "vaes": [
                "FLUX1\\ae.sft"
            ],
            "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux_dev.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 25, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 1608}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 0.5, \"base_shift\": 0.3, \"width\": 832, \"height\": 1216, \"model\": [\"161\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.5, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.05, \"scale\": 100.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"161\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 1], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"71\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.3, \"alpha\": 0.3, \"image\": [\"69\", 0]}, \"class_type\": \"ImageSharpen\"}, \"73\": {\"inputs\": {\"intensity\": 0.08, \"scale\": 100.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"71\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.35000000000000003, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 20, \"denoise\": 0.3, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"A photorealistic image of supergirl sabcarp based on fictional characters from DC Comics  enveloped in a digital nexus, her costume infused with binary code that flickers with energy the backdrop of intersecting geometric shapes that seem to pulse with a golden glow, representing her power over both the digital and physical realms.\\n\\ngeometric armor plating to her shoulders and chest, with sharp, angular designs that mirror the background aesthetics.Integrate glowing binary code patterns into Supergirl's suit, running along the seams and edges, highlighting her connection to the digital realm.\\n\\nShe stands with one hand raised, palm facing outwards as if signaling to calm down, her expression firm but gentle.\\n\", \"clip\": [\"161\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"141\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"144\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"147\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"149\": {\"inputs\": {\"scale_method\": \"nearest-exact\", \"scale_factor\": 1.5, \"use_tiled_vae\": false}, \"class_type\": \"LatentPixelScale\"}, \"156\": {\"inputs\": {\"lora_name\": \"flux1\\\\Flux__Semi-realistic_art_style-000004.safetensors\", \"strength_model\": 0.25, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"161\": {\"inputs\": {\"lora_name\": \"flux1\\\\sabrina_carpenter.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"156\", 0], \"clip\": [\"156\", 1]}, \"class_type\": \"LoraLoader\"}, \"162\": {\"inputs\": {\"text_input\": \"\", \"task\": \"region_caption\", \"fill_mask\": true, \"keep_model_loaded\": false, \"max_new_tokens\": 1024, \"num_beams\": 3, \"do_sample\": true, \"output_mask_select\": \"\", \"seed\": 779714526819826, \"florence2_model\": [\"163\", 0]}, \"class_type\": \"Florence2Run\"}, \"163\": {\"inputs\": {\"model\": null, \"precision\": \"fp32\", \"attention\": \"sdpa\"}, \"class_type\": \"Florence2ModelLoader\"}, \"164\": {\"inputs\": {\"control_net_name\": \"Flux1\\\\flux-canny-controlnet.safetensors\"}, \"class_type\": \"ControlNetLoader\"}, \"165\": {\"inputs\": {\"strength\": 1}, \"class_type\": \"ControlNetApply\"}}, \"workflow\": {\"last_node_id\": 165, \"last_link_id\": 350, \"nodes\": [{\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1300, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 892, \"1\": 13}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 450, \"1\": 1353}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 289}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 141, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2036, \"1\": 41}, \"size\": {\"0\": 428.9556884765625, \"1\": 78}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": 2156, \"1\": 435}, \"size\": {\"0\": 504.7402648925781, \"1\": 472.86358642578125}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [294, 305], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [295, 306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [296, 307], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186, 297, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3079, \"1\": -575}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 311}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 148, \"type\": \"SaveImage\", \"pos\": {\"0\": 3061, \"1\": -483}, \"size\": {\"0\": 281.4468078613281, \"1\": 480.5931091308594}, \"flags\": {}, \"order\": 69, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 313}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 149, \"type\": \"LatentPixelScale\", \"pos\": {\"0\": 445.9807434082031, \"1\": 1519.1585693359375}, \"size\": {\"0\": 365.4000244140625, \"1\": 146}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model_opt\", \"type\": \"UPSCALE_MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentPixelScale\"}, \"widgets_values\": [\"nearest-exact\", 1.5, false]}, {\"id\": 146, \"type\": \"DZ_Face_Detailer\", \"pos\": {\"0\": 2658, \"1\": -843}, \"size\": {\"0\": 309.8262939453125, \"1\": 842.9425659179688}, \"flags\": {}, \"order\": 65, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 305}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 306}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 307}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DZ_Face_Detailer\"}, \"widgets_values\": [1, \"fixed\", 20, 4, \"euler\", \"sgm_uniform\", 0.25, 32, \"face\", \"dilate\", 3, 3]}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": 14, \"1\": 1284}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 301, \"1\": -171}, \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 325}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1813, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [260, 299], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.75, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 142, \"type\": \"SaveImage\", \"pos\": {\"0\": 3181, \"1\": 87}, \"size\": {\"0\": 813.5270385742188, \"1\": 1236.560546875}, \"flags\": {}, \"order\": 73, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 300}], \"outputs\": [], \"title\": \"FinalPass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 140, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2769, \"1\": 86}, \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 71, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 294}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 295}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 296}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 297}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 298}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.25, 1, \"fixed\", 25, 3, \"euler\", \"sgm_uniform\", 0.2, \"Linear\", 832, 1216, 24, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 2233, \"1\": 955}, \"size\": {\"0\": 848.405029296875, \"1\": 898.4495849609375}, \"flags\": {}, \"order\": 74, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 117, \"type\": \"SaveImagePlus\", \"pos\": {\"0\": 4366, \"1\": 456}, \"size\": {\"0\": 832.2413940429688, \"1\": 1183.025634765625}, \"flags\": {}, \"order\": 75, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 282}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImagePlus\"}, \"widgets_values\": [\"ComfyUI\", \"JPEG\", true]}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 258, \"1\": 793}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 342, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 884, \"1\": 975}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 100, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 162, \"type\": \"Florence2Run\", \"pos\": {\"0\": -9, \"1\": -1313}, \"size\": {\"0\": 400, \"1\": 352}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"link\": 349}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}, {\"name\": \"caption\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}, {\"name\": \"data\", \"type\": \"JSON\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Florence2Run\"}, \"widgets_values\": [\"\", \"region_caption\", true, false, 1024, 3, true, \"\", 779714526819826, \"randomize\"]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 511, \"1\": -87}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1801, \"1\": 21}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 66, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 350}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 869, \"1\": 622}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 163, \"type\": \"Florence2ModelLoader\", \"pos\": {\"0\": -430, \"1\": -1290}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"lora\", \"type\": \"PEFTLORA\", \"link\": null}], \"outputs\": [{\"name\": \"florence2_model\", \"type\": \"FL2MODEL\", \"links\": [349], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Florence2ModelLoader\"}, \"widgets_values\": [null, \"fp32\", \"sdpa\"]}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 876, \"1\": 785}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 289], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 165, \"type\": \"ControlNetApply\", \"pos\": {\"0\": -407, \"1\": 189}, \"size\": {\"0\": 317.4000244140625, \"1\": 98}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": null}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": null}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetApply\"}, \"widgets_values\": [1]}, {\"id\": 164, \"type\": \"ControlNetLoader\", \"pos\": {\"0\": -408, \"1\": 84}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"Flux1\\\\flux-canny-controlnet.safetensors\"]}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1197, \"1\": 34}, \"size\": {\"0\": 245.11636352539062, \"1\": 82}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1513, \"1\": 38}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 63, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1215, \"1\": 172}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [287], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 19, \"1\": 308}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 154, \"type\": \"LoraLoader\", \"pos\": {\"0\": -390, \"1\": 408}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 34, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 347}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 348}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [326], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [327], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Flux__Semi-realistic_art_style-000004.safetensors\", 0.35000000000000003, 1]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -29, \"1\": 159}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [333], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 324, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [0.5, 0.3, 832, 1216]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -37, \"1\": 33}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux_dev.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 493, \"1\": 12}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1326, \"1\": 965}, \"size\": {\"0\": 848.655029296875, \"1\": 899.4495849609375}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": -404, \"1\": 781}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 155, \"type\": \"LoraLoader\", \"pos\": {\"0\": -22, \"1\": 601}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 23, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 332}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 333}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [330], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [331], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\detailed_skin_portraits-000005.safetensors\", 0.25, 1]}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 837, \"1\": 1291}, \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1809, \"1\": 365}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 72, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168, 282], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.08, 100, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 2061, \"1\": 273}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 70, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 260}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.3, 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1829, \"1\": 554}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 20, 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [1608, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1454, \"1\": 131}, \"size\": {\"0\": 334.8955383300781, \"1\": 535.3447265625}, \"flags\": {}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 287, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [308], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [350], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 153, \"type\": \"LoraLoader\", \"pos\": {\"0\": -36, \"1\": 410}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 35, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 326}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 327}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [324], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [325], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\XT404.BOOBS-Bastic.XXL.safetensors\", 0.3, 1]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 474, \"1\": 893}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 617, \"1\": 645}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1216, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 386, \"1\": 647}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 342], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [832, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 883, \"1\": 1143}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 160, \"type\": \"LoraLoader\", \"pos\": {\"0\": -768, \"1\": 597}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 30, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 346}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 345}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [343], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [344], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\realism_lora_comfy flux_converted.safetensors\", 0.35000000000000003, 1]}, {\"id\": 156, \"type\": \"LoraLoader\", \"pos\": {\"0\": -399, \"1\": 593}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 330}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 331}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [346], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [345], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Flux__Semi-realistic_art_style-000004.safetensors\", 0.25, 1]}, {\"id\": 161, \"type\": \"LoraLoader\", \"pos\": {\"0\": -755, \"1\": 406}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 343}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 344}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [347], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [348], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\sabrina_carpenter.safetensors\", 1, 1]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 487, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 25, 1]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 883, \"1\": 0}, \"size\": {\"0\": 318.1961975097656, \"1\": 569.048095703125}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 310, \"1\": 77}, \"size\": {\"0\": 499.79559326171875, \"1\": 484.8913879394531}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"A photorealistic image of supergirl sabcarp based on fictional characters from DC Comics  enveloped in a digital nexus, her costume infused with binary code that flickers with energy the backdrop of intersecting geometric shapes that seem to pulse with a golden glow, representing her power over both the digital and physical realms.\\n\\ngeometric armor plating to her shoulders and chest, with sharp, angular designs that mirror the background aesthetics.Integrate glowing binary code patterns into Supergirl's suit, running along the seams and edges, highlighting her connection to the digital realm.\\n\\nShe stands with one hand raised, palm facing outwards as if signaling to calm down, her expression firm but gentle.\\n\"]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [260, 72, 0, 71, 0, \"IMAGE\"], [282, 73, 0, 117, 0, \"IMAGE\"], [285, 75, 0, 59, 0, \"IMAGE\"], [287, 134, 0, 42, 2, \"SAMPLER\"], [288, 62, 0, 41, 0, \"IMAGE\"], [289, 61, 0, 77, 1, \"IMAGE\"], [294, 96, 0, 140, 1, \"MODEL\"], [295, 64, 0, 140, 2, \"CONDITIONING\"], [296, 65, 0, 140, 3, \"CONDITIONING\"], [297, 70, 0, 140, 4, \"VAE\"], [298, 141, 0, 140, 5, \"UPSCALE_MODEL\"], [299, 72, 0, 140, 0, \"IMAGE\"], [300, 140, 0, 142, 0, \"IMAGE\"], [305, 96, 0, 146, 0, \"MODEL\"], [306, 64, 0, 146, 1, \"CONDITIONING\"], [307, 65, 0, 146, 2, \"CONDITIONING\"], [308, 42, 0, 146, 3, \"LATENT\"], [310, 70, 0, 146, 4, \"VAE\"], [311, 146, 0, 147, 0, \"LATENT\"], [312, 81, 0, 147, 1, \"VAE\"], [313, 147, 0, 148, 0, \"IMAGE\"], [324, 153, 0, 30, 0, \"MODEL\"], [325, 153, 1, 49, 0, \"*\"], [326, 154, 0, 153, 0, \"MODEL\"], [327, 154, 1, 153, 1, \"CLIP\"], [330, 155, 0, 156, 0, \"MODEL\"], [331, 155, 1, 156, 1, \"CLIP\"], [332, 12, 0, 155, 0, \"MODEL\"], [333, 11, 0, 155, 1, \"CLIP\"], [342, 34, 0, 27, 0, \"INT\"], [343, 160, 0, 161, 0, \"MODEL\"], [344, 160, 1, 161, 1, \"CLIP\"], [345, 156, 1, 160, 1, \"CLIP\"], [346, 156, 0, 160, 0, \"MODEL\"], [347, 161, 0, 154, 0, \"MODEL\"], [348, 161, 1, 154, 1, \"CLIP\"], [349, 163, 0, 162, 1, \"FL2MODEL\"], [350, 42, 1, 69, 0, \"LATENT\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.3310000000000004, \"offset\": [-335.9548212118677, 66.12688372251269]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}, \"140\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"146\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"162\": {\"seed\": 8}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"140\": 1, \"146\": 0, \"162\": 8}}}",
            "steps": 25,
            "models": [],
            "prompt": "A photorealistic image of supergirl sabcarp based on fictional characters from DC Comics  enveloped in a digital nexus, her costume infused with binary code that flickers with energy the backdrop of intersecting geometric shapes that seem to pulse with a golden glow, representing her power over both the digital and physical realms.\n\ngeometric armor plating to her shoulders and chest, with sharp, angular designs that mirror the background aesthetics.Integrate glowing binary code patterns into Supergirl's suit, running along the seams and edges, highlighting her connection to the digital realm.\n\nShe stands with one hand raised, palm facing outwards as if signaling to calm down, her expression firm but gentle.\n",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 3.5,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [
                "Flux1\\flux-canny-controlnet.safetensors"
            ],
            "additionalResources": [
                {
                    "name": "flux1\\Flux__Semi-realistic_art_style-000004.safetensors",
                    "type": "lora",
                    "strength": 0.25,
                    "strengthClip": 1
                },
                {
                    "name": "flux1\\sabrina_carpenter.safetensors",
                    "type": "lora",
                    "strength": 1,
                    "strengthClip": 1
                }
            ]
        },
        "username": "salammy",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 40921678,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/78e15dc4-f03d-4f87-96c2-ef34f425296b/width=832/78e15dc4-f03d-4f87-96c2-ef34f425296b.jpeg",
        "hash": "UDDl+sDOt7T1CAxD%LNI00T1X9MxxGs+E1jY",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-19T08:38:49.569Z",
        "postId": 9322846,
        "stats": {
            "cryCount": 36,
            "laughCount": 69,
            "likeCount": 980,
            "dislikeCount": 0,
            "heartCount": 252,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "nsfw": true,
            "seed": 1376106839,
            "draft": false,
            "steps": 28,
            "width": 832,
            "height": 1216,
            "prompt": "an astronaut standing sideways on with his head raised. Small bright yellow butterflies flutter above it, it stands on an unknown planet, but with very contra vegetation, beautiful flowers",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "fluxMode": "urn:air:flux1:checkpoint:civitai:618692@691639",
            "quantity": 1,
            "workflow": "txt2img",
            "baseModel": "Flux1",
            "resources": [],
            "Created Date": "2024-11-19T0801:42.9900471Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 863655,
                    "modelVersionName": "Balance_v2.0"
                },
                {
                    "type": "lora",
                    "weight": 0.65,
                    "modelVersionId": 753053,
                    "modelVersionName": "Flux Original"
                },
                {
                    "type": "lora",
                    "weight": 0.29,
                    "modelVersionId": 778925,
                    "modelVersionName": "Henry Daubrez FLUX v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.15,
                    "modelVersionId": 1060845,
                    "modelVersionName": "v2.0"
                }
            ]
        },
        "username": "AtomGirl",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 21311135,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4c586034-2e3d-4693-bca7-400911cf5b1e/width=1280/4c586034-2e3d-4693-bca7-400911cf5b1e.jpeg",
        "hash": "ULD0T0%MD%aK~p%ggOROIoxvsSRjIUoLjEbc",
        "width": 1280,
        "height": 1856,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-07-25T13:07:25.721Z",
        "postId": 4751762,
        "stats": {
            "cryCount": 48,
            "laughCount": 86,
            "likeCount": 816,
            "dislikeCount": 0,
            "heartCount": 383,
            "commentCount": 0
        },
        "meta": null,
        "username": "CappAI",
        "baseModel": "Pony"
    },
    {
        "id": 13953360,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6175cf34-5be1-4456-af65-444c20f199e5/width=1800/6175cf34-5be1-4456-af65-444c20f199e5.jpeg",
        "hash": "UAEx;OIV00~UPCM}IURk00s:t,IV#5OStmK5",
        "width": 2160,
        "height": 3152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-29T16:29:44.592Z",
        "postId": 3094421,
        "stats": {
            "cryCount": 27,
            "laughCount": 87,
            "likeCount": 894,
            "dislikeCount": 0,
            "heartCount": 325,
            "commentCount": 3
        },
        "meta": null,
        "username": "Pinkielicious",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 32582449,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4b819550-9c96-435a-9de0-f1b0282d8c8b/width=832/4b819550-9c96-435a-9de0-f1b0282d8c8b.jpeg",
        "hash": "UFI48[0159?u~9#*9}9}59RkXSNHsqRk%0%K",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-03T11:11:45.232Z",
        "postId": 7457839,
        "stats": {
            "cryCount": 69,
            "laughCount": 58,
            "likeCount": 981,
            "dislikeCount": 0,
            "heartCount": 224,
            "commentCount": 3
        },
        "meta": null,
        "username": "shhdejong302",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 39434251,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/87b73234-bd49-45b7-a1f6-3ab050786be8/width=832/87b73234-bd49-45b7-a1f6-3ab050786be8.jpeg",
        "hash": "UAAJQ%o#0JN]G1R$,-kEbbwHROEf=}RjE1$*",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-10T23:30:00.000Z",
        "postId": 8995740,
        "stats": {
            "cryCount": 49,
            "laughCount": 70,
            "likeCount": 945,
            "dislikeCount": 0,
            "heartCount": 266,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1209256874,
            "steps": 30,
            "prompt": "In a mesmerizing digital painting, A large space and below there is a fire in a open forest and a giant storm  emerges, radiating vibrant bioluminescent hues against the dark expanse of space. Its otherworldly form is a symphony of colors, with scales that shimmer like precious gems and intricate patterns that seem to dance with life. Luminescent tendrils extend from its body, illuminating its surroundings with an ethereal glow. showcasing its celestial beauty in stunning high-definition.",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-09T2030:37.0107154Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 753053,
                    "modelVersionName": "Flux Original"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 823881,
                    "modelVersionName": "character_flux_v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.33,
                    "modelVersionId": 746484,
                    "modelVersionName": "V1"
                }
            ]
        },
        "username": "VelvetS",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 36854673,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/963e0d65-c490-4f97-9ed6-1b1f46fb91f6/width=832/963e0d65-c490-4f97-9ed6-1b1f46fb91f6.jpeg",
        "hash": "UQD,ZOWV4os,_NX8IUWAoMkDM{V[-:s:IUs:",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-27T15:01:36.404Z",
        "postId": 8417560,
        "stats": {
            "cryCount": 41,
            "laughCount": 86,
            "likeCount": 931,
            "dislikeCount": 0,
            "heartCount": 272,
            "commentCount": 2
        },
        "meta": {
            "seed": 648735154039594,
            "vaes": [
                "ae.sft"
            ],
            "comfy": "{\"prompt\": {\"5\": {\"inputs\": {\"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\", \"_meta\": {\"title\": \"Empty Latent Image\"}}, \"10\": {\"inputs\": {\"vae_name\": \"ae.sft\"}, \"class_type\": \"VAELoader\", \"_meta\": {\"title\": \"Load VAE\"}}, \"11\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\", \"_meta\": {\"title\": \"DualCLIPLoader\"}}, \"12\": {\"inputs\": {\"unet_name\": \"flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\", \"_meta\": {\"title\": \"Load Diffusion Model\"}}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\", \"_meta\": {\"title\": \"KSamplerSelect\"}}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 20, \"denoise\": 1, \"model\": [\"61\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"22\": {\"inputs\": {\"model\": [\"61\", 0], \"conditioning\": [\"60\", 0]}, \"class_type\": \"BasicGuider\", \"_meta\": {\"title\": \"BasicGuider\"}}, \"25\": {\"inputs\": {\"noise_seed\": 842399517107390}, \"class_type\": \"RandomNoise\", \"_meta\": {\"title\": \"RandomNoise\"}}, \"60\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"225\", 0]}, \"class_type\": \"FluxGuidance\", \"_meta\": {\"title\": \"FluxGuidance\"}}, \"61\": {\"inputs\": {\"max_shift\": 0.7000000000000001, \"base_shift\": 0.5, \"width\": [\"220\", 0], \"height\": [\"220\", 1], \"model\": [\"309\", 0]}, \"class_type\": \"ModelSamplingFlux\", \"_meta\": {\"title\": \"ModelSamplingFlux\"}}, \"70\": {\"inputs\": {\"int\": 896}, \"class_type\": \"Int Literal\", \"_meta\": {\"title\": \"Width\"}}, \"71\": {\"inputs\": {\"int\": 1216}, \"class_type\": \"Int Literal\", \"_meta\": {\"title\": \"Height\"}}, \"161\": {\"inputs\": {\"scheduler\": \"beta\", \"steps\": 5, \"denoise\": 0.5, \"model\": [\"61\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"207\": {\"inputs\": {\"scheduler\": \"beta\", \"steps\": 5, \"denoise\": 0.5, \"model\": [\"61\", 0]}, \"class_type\": \"BasicScheduler\", \"_meta\": {\"title\": \"BasicScheduler\"}}, \"216\": {\"inputs\": {\"VAE\": [\"10\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"220\": {\"inputs\": {\"width\": 672, \"height\": 1496, \"aspect_ratio\": \"5:8 portrait 832x1216\", \"swap_dimensions\": \"Off\", \"upscale_factor\": 2.0, \"batch_size\": 1}, \"class_type\": \"CR SDXL Aspect Ratio\", \"_meta\": {\"title\": \"\\ud83d\\udd33 CR SDXL Aspect Ratio\"}}, \"222\": {\"inputs\": {\"SAMPLER\": [\"16\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"223\": {\"inputs\": {\"GUIDER\": [\"22\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"224\": {\"inputs\": {\"MODEL\": [\"61\", 0]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"225\": {\"inputs\": {\"text\": \"\\u3000\\u3000In the aftermath of the massive explosion that ripped through the futuristic cityscape, time is fractured and a haunting moment is trapped. The shining shards of chrome plating and neon signs that once symbolised a vibrant, technologically advanced society now pour down like an eerie shower of broken dreams. Twisted metal girders and fragments of sophisticated futuristic architecture are suspended in mid-air, defying gravity as the echoes of the blast echo through the smoke-filled air.\\n\\nIn the midst of this desolate technological ruin, a woman stands frozen in place. Her silhouette is a stark reminder of human fragility against the backdrop of a shattered future. Her cybernetically enhanced body, once a testament to human ingenuity and progress, now bears the scars of a devastating explosion, wires sparking and circuitry exposed. Her hair, once vibrant, is now covered in soot and dust, framing her face in a mixture of shock and defiance.\\n\\nBehind her, the giant geometric angel, a symbol of artificial intelligence and the pinnacle of technological progress, is scattered and broken. Its very presence illustrates the destructive power of ambition and technological hubris.\\n\\nThe scene poignantly expresses the transience of progress and the potential consequences of unstoppable technological progress. Cold, desaturated colours, high contrast and an emphasis on fragmentation amplify the sense of loss and despair, while elements of frozen time and a futuristic setting add a layer of chilling surrealism. The images evoke a powerful and emotionally resonant warning about the possibility of a dystopian future in which the dream of human progress is shattered in the ruins of its own creation.\", \"clip\": [\"309\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Positive Prompt)\"}}, \"227\": {\"inputs\": {\"model_name\": \"4x_NMKD-Siax_200k.pth\"}, \"class_type\": \"UpscaleModelLoader\", \"_meta\": {\"title\": \"Load Upscale Model\"}}, \"230\": {\"inputs\": {\"value\": [\"220\", 2]}, \"class_type\": \"easy float\", \"_meta\": {\"title\": \"upscale by\"}}, \"231\": {\"inputs\": {\"expression\": \"a * b * c / 2 + 32\", \"a\": [\"230\", 0], \"b\": [\"235\", 0], \"c\": [\"247\", 0]}, \"class_type\": \"MathExpression|pysssss\", \"_meta\": {\"title\": \"tile height (Math Expression \\ud83d\\udc0d)\"}, \"is_changed\": [\"a * b * c / 2 + 32\"]}, \"232\": {\"inputs\": {\"expression\": \"a * b * c / 2 + 32\", \"a\": [\"230\", 0], \"b\": [\"236\", 0], \"c\": [\"247\", 0]}, \"class_type\": \"MathExpression|pysssss\", \"_meta\": {\"title\": \"tile height (Math Expression \\ud83d\\udc0d)\"}, \"is_changed\": [\"a * b * c / 2 + 32\"]}, \"235\": {\"inputs\": {\"a\": [\"220\", 0]}, \"class_type\": \"CM_IntToFloat\", \"_meta\": {\"title\": \"IntToFloat\"}}, \"236\": {\"inputs\": {\"a\": [\"220\", 1]}, \"class_type\": \"CM_IntToFloat\", \"_meta\": {\"title\": \"IntToFloat\"}}, \"238\": {\"inputs\": {}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"239\": {\"inputs\": {}, \"class_type\": \"EmptySegs\", \"_meta\": {\"title\": \"EmptySegs\"}}, \"241\": {\"inputs\": {\"CLIP\": [\"309\", 1]}, \"class_type\": \"Anything Everywhere\", \"_meta\": {\"title\": \"Anything Everywhere\"}}, \"247\": {\"inputs\": {\"Number\": \"1.05\"}, \"class_type\": \"Float\", \"_meta\": {\"title\": \"Float\"}}, \"252\": {\"inputs\": {\"filename_prefix\": \"flux/ComfyUI2\", \"images\": [\"296\", 0]}, \"class_type\": \"SaveImage\", \"_meta\": {\"title\": \"Save Image\"}}, \"258\": {\"inputs\": {\"seed\": 648735154039594, \"steps\": 15, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"beta\", \"denoise\": 1.0, \"positive\": [\"60\", 0], \"negative\": [\"259\", 0], \"latent_image\": [\"220\", 4], \"model\": [\"61\", 0]}, \"class_type\": \"KSampler\", \"_meta\": {\"title\": \"KSampler\"}}, \"259\": {\"inputs\": {\"text\": \"\", \"clip\": [\"309\", 1]}, \"class_type\": \"CLIPTextEncode\", \"_meta\": {\"title\": \"CLIP Text Encode (Negative Prompt)\"}}, \"270\": {\"inputs\": {\"samples\": [\"220\", 4], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\", \"_meta\": {\"title\": \"VAE Decode\"}}, \"285\": {\"inputs\": {\"width\": 821, \"height\": 1502, \"aspect_ratio\": \"5:8 portrait 832x1216\", \"swap_dimensions\": \"Off\", \"upscale_factor\": 1.5, \"batch_size\": 1}, \"class_type\": \"CR SDXL Aspect Ratio\", \"_meta\": {\"title\": \"\\ud83d\\udd33 CR SDXL Aspect Ratio\"}}, \"296\": {\"inputs\": {\"tile_size\": 512, \"samples\": [\"258\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecodeTiled\", \"_meta\": {\"title\": \"VAE Decode (Tiled)\"}}, \"309\": {\"inputs\": {\"PowerLoraLoaderHeaderWidget\": {\"type\": \"PowerLoraLoaderHeaderWidget\"}, \"lora_1\": {\"on\": true, \"lora\": \"Lora\\\\flux\\\\flux_realism_lora.safetensors\", \"strength\": 0.36}, \"lora_2\": {\"on\": true, \"lora\": \"Lora\\\\flux\\\\ancient.safetensors\", \"strength\": 0.85}, \"lora_3\": {\"on\": true, \"lora\": \"Lora\\\\flux\\\\aidmaFLUXpro1.1-FLUX-V0.1.safetensors\", \"strength\": 0.16}, \"lora_4\": {\"on\": true, \"lora\": \"Lora\\\\flux\\\\flux_turbo.safetensors\", \"strength\": 0.25}, \"lora_5\": {\"on\": false, \"lora\": \"Lora\\\\flux\\\\Analog_Photo_Style.safetensors\", \"strength\": 0.6}, \"\\u2795 Add Lora\": \"\", \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"Power Lora Loader (rgthree)\", \"_meta\": {\"title\": \"Power Lora Loader (rgthree)\"}}, \"312\": {\"inputs\": {\"model_name\": \"4x_NMKD-Siax_200k.pth\"}, \"class_type\": \"UpscaleModelLoader\", \"_meta\": {\"title\": \"Load Upscale Model\"}}, \"332\": {\"inputs\": {\"unet_name\": null, \"dequant_dtype\": \"default\", \"patch_dtype\": \"default\", \"patch_on_device\": false}, \"class_type\": \"UnetLoaderGGUFAdvanced\", \"_meta\": {\"title\": \"Unet Loader (GGUF/Advanced)\"}}}, \"workflow\": {\"last_node_id\": 347, \"last_link_id\": 1600, \"nodes\": [{\"id\": 71, \"type\": \"Int Literal\", \"pos\": {\"0\": -10, \"1\": 190}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": true}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Height\", \"properties\": {\"Node name for S&R\": \"Int Literal\"}, \"widgets_values\": [1216]}, {\"id\": 216, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 170, \"1\": 150}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"VAE\", \"type\": \"*\", \"link\": 309, \"color_on\": \"#FF6E6E\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 271, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": -236.1959991455078, \"1\": -186.1042938232422}, \"size\": {\"0\": 203.1999969482422, \"1\": 26}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"connect to widget input\", \"type\": \"*\", \"links\": null}], \"properties\": {\"Run widget replace on values\": false}}, {\"id\": 281, \"type\": \"GetNode\", \"pos\": {\"0\": -480, \"1\": 2390}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": [537], \"slot_index\": 0}], \"title\": \"Get_us\", \"properties\": {}, \"widgets_values\": [\"us\"]}, {\"id\": 282, \"type\": \"GetNode\", \"pos\": {\"0\": -580, \"1\": 2610}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [538], \"slot_index\": 0}], \"title\": \"Get_w\", \"properties\": {}, \"widgets_values\": [\"w\"]}, {\"id\": 283, \"type\": \"GetNode\", \"pos\": {\"0\": -560, \"1\": 2820}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [539], \"slot_index\": 0}], \"title\": \"Get_h\", \"properties\": {}, \"widgets_values\": [\"h\"]}, {\"id\": 285, \"type\": \"CR SDXL Aspect Ratio\", \"pos\": {\"0\": -570, \"1\": 1260}, \"size\": {\"0\": 320, \"1\": 280}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"upscale_factor\", \"type\": \"FLOAT\", \"links\": [], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"batch_size\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"empty_latent\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 4, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"slot_index\": 5, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR SDXL Aspect Ratio\"}, \"widgets_values\": [821, 1502, \"5:8 portrait 832x1216\", \"Off\", 1.5, 1]}, {\"id\": 70, \"type\": \"Int Literal\", \"pos\": {\"0\": -10, \"1\": 110}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": true}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Width\", \"properties\": {\"Node name for S&R\": \"Int Literal\"}, \"widgets_values\": [896]}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 20, \"1\": 260}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": false}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [309], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.sft\"]}, {\"id\": 60, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 490, \"1\": 330}, \"size\": {\"0\": 210, \"1\": 60}, \"flags\": {\"collapsed\": false}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 319}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [87, 280, 335, 384, 1528], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 235, \"type\": \"CM_IntToFloat\", \"pos\": {\"0\": -100, \"1\": 3120}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": false}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"a\", \"type\": \"INT\", \"link\": 538, \"widget\": {\"name\": \"a\"}}], \"outputs\": [{\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": [329], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CM_IntToFloat\"}, \"widgets_values\": [0]}, {\"id\": 236, \"type\": \"CM_IntToFloat\", \"pos\": {\"0\": -190, \"1\": 3360}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": false}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"a\", \"type\": \"INT\", \"link\": 539, \"widget\": {\"name\": \"a\"}}], \"outputs\": [{\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": [331], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CM_IntToFloat\"}, \"widgets_values\": [0]}, {\"id\": 230, \"type\": \"easy float\", \"pos\": {\"0\": -50, \"1\": 2590}, \"size\": {\"0\": 210, \"1\": 60}, \"flags\": {\"collapsed\": false}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"value\", \"type\": \"FLOAT\", \"link\": 537, \"widget\": {\"name\": \"value\"}}], \"outputs\": [{\"name\": \"float\", \"type\": \"FLOAT\", \"links\": [322, 328, 330, 1267, 1531], \"slot_index\": 0, \"shape\": 3}], \"title\": \"upscale by\", \"properties\": {\"Node name for S&R\": \"easy float\"}, \"widgets_values\": [2]}, {\"id\": 222, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1200, \"1\": -140}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": false}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"SAMPLER\", \"type\": \"*\", \"link\": 314, \"color_on\": \"#ECB4B4\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 223, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1310, \"1\": 370}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"GUIDER\", \"type\": \"*\", \"link\": 315, \"color_on\": \"#66FFFF\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 910, \"1\": 320}, \"size\": {\"0\": 200, \"1\": 60}, \"flags\": {\"collapsed\": false}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 94, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 87, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [315], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 247, \"type\": \"Float\", \"pos\": {\"0\": -80, \"1\": 2360}, \"size\": {\"0\": 210, \"1\": 60}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": [1183, 1273, 1274], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Float\"}, \"widgets_values\": [\"1.05\"]}, {\"id\": 231, \"type\": \"MathExpression|pysssss\", \"pos\": {\"0\": 170, \"1\": 3040}, \"size\": {\"0\": 270, \"1\": 120}, \"flags\": {\"collapsed\": false}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"a\", \"type\": \"INT,FLOAT,IMAGE,LATENT\", \"link\": 328, \"shape\": 7}, {\"name\": \"b\", \"type\": \"INT,FLOAT,IMAGE,LATENT\", \"link\": 329, \"shape\": 7}, {\"name\": \"c\", \"type\": \"INT,FLOAT,IMAGE,LATENT\", \"link\": 1273, \"shape\": 7}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [323, 1268, 1532], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"title\": \"tile height (Math Expression \\ud83d\\udc0d)\", \"properties\": {\"Node name for S&R\": \"MathExpression|pysssss\"}, \"widgets_values\": [\"a * b * c / 2 + 32\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 232, \"type\": \"MathExpression|pysssss\", \"pos\": {\"0\": 180, \"1\": 3260}, \"size\": {\"0\": 270, \"1\": 120}, \"flags\": {\"collapsed\": false}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"a\", \"type\": \"INT,FLOAT,IMAGE,LATENT\", \"link\": 330, \"shape\": 7}, {\"name\": \"b\", \"type\": \"INT,FLOAT,IMAGE,LATENT\", \"link\": 331, \"shape\": 7}, {\"name\": \"c\", \"type\": \"INT,FLOAT,IMAGE,LATENT\", \"link\": 1274, \"shape\": 7}], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [324, 1269, 1533], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"title\": \"tile height (Math Expression \\ud83d\\udc0d)\", \"properties\": {\"Node name for S&R\": \"MathExpression|pysssss\"}, \"widgets_values\": [\"a * b * c / 2 + 32\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 5, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 440, \"1\": -230}, \"size\": {\"0\": 330, \"1\": 80}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 220, \"type\": \"CR SDXL Aspect Ratio\", \"pos\": {\"0\": -540, \"1\": 860}, \"size\": {\"0\": 320, \"1\": 280}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [317, 534], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [318, 1380], \"slot_index\": 1, \"shape\": 3}, {\"name\": \"upscale_factor\", \"type\": \"FLOAT\", \"links\": [536], \"slot_index\": 2, \"shape\": 3}, {\"name\": \"batch_size\", \"type\": \"INT\", \"links\": null, \"shape\": 3}, {\"name\": \"empty_latent\", \"type\": \"LATENT\", \"links\": [313, 386, 1413], \"slot_index\": 4, \"shape\": 3}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"slot_index\": 5, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CR SDXL Aspect Ratio\"}, \"widgets_values\": [672, 1496, \"5:8 portrait 832x1216\", \"Off\", 2, 1]}, {\"id\": 229, \"type\": \"Image Comparer (rgthree)\", \"pos\": {\"0\": 1870, \"1\": 3880}, \"size\": {\"0\": 930, \"1\": 1430}, \"flags\": {}, \"order\": 84, \"mode\": 2, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"link\": 374, \"dir\": 3}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"link\": 1315, \"dir\": 3}], \"outputs\": [], \"properties\": {\"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_unmaf_00007_.png&type=temp&subfolder=&rand=0.21909797616058957\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_unmaf_00008_.png&type=temp&subfolder=&rand=0.19841163623657798\"}]]}, {\"id\": 241, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1410, \"1\": -620}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"CLIP\", \"type\": \"*\", \"link\": 1158, \"color_on\": \"#FFD500\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 224, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1200, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"MODEL\", \"type\": \"*\", \"link\": 316, \"color_on\": \"#B39DDB\", \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 313, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 1980, \"1\": 470}, \"size\": {\"0\": 320, \"1\": 830}, \"flags\": {\"collapsed\": true}, \"order\": 60, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1246}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 1247}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 1244}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 1245}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 1243}, {\"name\": \"upscale_by\", \"type\": \"FLOAT\", \"link\": 1267, \"widget\": {\"name\": \"upscale_by\"}}, {\"name\": \"tile_width\", \"type\": \"INT\", \"link\": 1268, \"widget\": {\"name\": \"tile_width\"}}, {\"name\": \"tile_height\", \"type\": \"INT\", \"link\": 1269, \"widget\": {\"name\": \"tile_height\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1248], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 708466383031613, \"randomize\", 8, 1, \"euler\", \"beta\", 0.34, \"Linear\", 832, 1216, 16, 32, \"None\", 1, 64, 16, 16, true, false]}, {\"id\": 314, \"type\": \"SaveImage\", \"pos\": {\"0\": 2230, \"1\": 470}, \"size\": {\"0\": 320, \"1\": 270}, \"flags\": {\"collapsed\": true}, \"order\": 65, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 1248}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux/ComfyUI2_Up\"]}, {\"id\": 251, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1410, \"1\": 2180}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 62, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1314}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [375], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.06, 50, 0, 0]}, {\"id\": 250, \"type\": \"ImageApplyLUT+\", \"pos\": {\"0\": 1680, \"1\": 2170}, \"size\": {\"0\": 220, \"1\": 130}, \"flags\": {}, \"order\": 67, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 375}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [382, 383, 1339], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageApplyLUT+\"}, \"widgets_values\": [\"Presetpro  - Kodacrome 64.cube\", true, true, 0.2]}, {\"id\": 323, \"type\": \"VAEEncode\", \"pos\": {\"0\": 3160, \"1\": 2440}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 42, \"mode\": 4, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 1308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 326, \"type\": \"SaveImage\", \"pos\": {\"0\": 1450, \"1\": 2610}, \"size\": {\"0\": 320, \"1\": 270}, \"flags\": {}, \"order\": 73, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 1342}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux/ComfyUI\"]}, {\"id\": 325, \"type\": \"Image Levels Adjustment\", \"pos\": {\"0\": 1460, \"1\": 2400}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 71, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1339}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1342, 1343], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"Image Levels Adjustment\"}, \"widgets_values\": [0, 255, 227.3]}, {\"id\": 259, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -120, \"1\": 1100}, \"size\": {\"0\": 290, \"1\": 90}, \"flags\": {\"collapsed\": true}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [385, 1245], \"slot_index\": 0}], \"title\": \"CLIP Text Encode (Negative Prompt)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": -130, \"1\": 1480}, \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 48, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 156}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1272], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 315, \"type\": \"SaveImage\", \"pos\": {\"0\": -140, \"1\": 1600}, \"size\": {\"0\": 320, \"1\": 270}, \"flags\": {\"collapsed\": true}, \"order\": 53, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 1272}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux/ComfyUI2\"]}, {\"id\": 239, \"type\": \"EmptySegs\", \"pos\": {\"0\": -210, \"1\": 1740}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SEGS\", \"type\": \"SEGS\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySegs\"}, \"widgets_values\": []}, {\"id\": 279, \"type\": \"SetNode\", \"pos\": {\"0\": -190, \"1\": 740}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {\"collapsed\": true}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"link\": 1380}], \"outputs\": [{\"name\": \"*\", \"type\": \"*\", \"links\": null}], \"title\": \"Set_h\", \"properties\": {\"previousName\": \"h\"}, \"widgets_values\": [\"h\"]}, {\"id\": 280, \"type\": \"SetNode\", \"pos\": {\"0\": -200, \"1\": 800}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {\"collapsed\": true}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"FLOAT\", \"type\": \"FLOAT\", \"link\": 536}], \"outputs\": [{\"name\": \"*\", \"type\": \"*\", \"links\": null}], \"title\": \"Set_us\", \"properties\": {\"previousName\": \"us\"}, \"widgets_values\": [\"us\"]}, {\"id\": 278, \"type\": \"SetNode\", \"pos\": {\"0\": -200, \"1\": 700}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {\"collapsed\": true}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"link\": 534}], \"outputs\": [{\"name\": \"*\", \"type\": \"*\", \"links\": null}], \"title\": \"Set_w\", \"properties\": {\"previousName\": \"w\"}, \"widgets_values\": [\"w\"]}, {\"id\": 270, \"type\": \"VAEDecode\", \"pos\": {\"0\": -210, \"1\": 230}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 1413}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 332, \"type\": \"UnetLoaderGGUFAdvanced\", \"pos\": {\"0\": -410, \"1\": -530}, \"size\": {\"0\": 340, \"1\": 130}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"UnetLoaderGGUFAdvanced\"}, \"widgets_values\": [null, \"default\", \"default\", false]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -10, \"1\": -80}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [1156], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -20, \"1\": -220}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [1417], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": -50, \"1\": 670}, \"size\": {\"0\": 280, \"1\": 110}, \"flags\": {\"collapsed\": true}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 20, 1]}, {\"id\": 207, \"type\": \"BasicScheduler\", \"pos\": {\"0\": -190, \"1\": 1860}, \"size\": {\"0\": 270, \"1\": 110}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"beta\", 5, 0.5]}, {\"id\": 161, \"type\": \"BasicScheduler\", \"pos\": {\"0\": -180, \"1\": 2030}, \"size\": {\"0\": 250, \"1\": 110}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [191], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"beta\", 5, 0.5]}, {\"id\": 227, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 30, \"1\": 2850}, \"size\": {\"0\": 360, \"1\": 100}, \"flags\": {\"collapsed\": false}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [321, 1530], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x_NMKD-Siax_200k.pth\"]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": -40, \"1\": 740}, \"size\": {\"0\": 240, \"1\": 330}, \"flags\": {\"collapsed\": true}, \"order\": 39, \"mode\": 4, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": null, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": null, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 313, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [156], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 440, \"1\": -80}, \"size\": {\"0\": 330, \"1\": 90}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37, 186], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [842399517107390, \"randomize\"]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 820, \"1\": -60}, \"size\": {\"0\": 270, \"1\": 60}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [314], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 338, \"type\": \"Reroute\", \"pos\": {\"0\": 1140, \"1\": 2230}, \"size\": [75, 26], \"flags\": {}, \"order\": 76, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 1522}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [1524], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 249, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1030, \"1\": 3770}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 81, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 370}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [371], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.07, 29, 0, 0]}, {\"id\": 248, \"type\": \"ImageApplyLUT+\", \"pos\": {\"0\": 1330, \"1\": 3740}, \"size\": {\"0\": 380, \"1\": 130}, \"flags\": {}, \"order\": 82, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 371}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [372, 374], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageApplyLUT+\"}, \"widgets_values\": [\"Presetpro  - Kodacrome 64.cube\", true, true, 0.2]}, {\"id\": 240, \"type\": \"CLIPTextEncodeFlux\", \"pos\": {\"0\": 510, \"1\": 5050}, \"size\": {\"0\": 210, \"1\": 160}, \"flags\": {\"collapsed\": false}, \"order\": 22, \"mode\": 2, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [336, 1529], \"slot_index\": 0, \"shape\": 3}], \"title\": \"Empty Negative\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncodeFlux\"}, \"widgets_values\": [\"\", \"\", 3.4000000000000004]}, {\"id\": 228, \"type\": \"SaveImage\", \"pos\": {\"0\": 1200, \"1\": 3930}, \"size\": {\"0\": 600, \"1\": 670}, \"flags\": {}, \"order\": 83, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 372}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux/img_\"]}, {\"id\": 226, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 710, \"1\": 3960}, \"size\": {\"0\": 320, \"1\": 830}, \"flags\": {}, \"order\": 79, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1524}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 335}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 336}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 321, \"slot_index\": 5}, {\"name\": \"upscale_by\", \"type\": \"FLOAT\", \"link\": 322, \"slot_index\": 6, \"widget\": {\"name\": \"upscale_by\"}}, {\"name\": \"tile_width\", \"type\": \"INT\", \"link\": 323, \"widget\": {\"name\": \"tile_width\"}}, {\"name\": \"tile_height\", \"type\": \"INT\", \"link\": 324, \"widget\": {\"name\": \"tile_height\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [370], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 1000122408342527, \"fixed\", 10, 1, \"euler\", \"beta\", 0.3, \"Linear\", 1024, 1024, 16, 32, \"None\", 0.25, 64, 16, 16, true, true]}, {\"id\": 343, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 740, \"1\": 4930}, \"size\": {\"0\": 320, \"1\": 830}, \"flags\": {}, \"order\": 63, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1534}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 1528}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 1529}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 1530, \"slot_index\": 5}, {\"name\": \"upscale_by\", \"type\": \"FLOAT\", \"link\": 1531, \"slot_index\": 6, \"widget\": {\"name\": \"upscale_by\"}}, {\"name\": \"tile_width\", \"type\": \"INT\", \"link\": 1532, \"widget\": {\"name\": \"tile_width\"}}, {\"name\": \"tile_height\", \"type\": \"INT\", \"link\": 1533, \"widget\": {\"name\": \"tile_height\"}}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1535], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 1000122408342527, \"fixed\", 10, 1, \"euler\", \"beta\", 0.3, \"Linear\", 1024, 1024, 16, 32, \"None\", 0.25, 64, 16, 16, true, true]}, {\"id\": 344, \"type\": \"SaveImage\", \"pos\": {\"0\": 1190, \"1\": 4690}, \"size\": {\"0\": 600, \"1\": 670}, \"flags\": {}, \"order\": 68, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 1535}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux/img_\"]}, {\"id\": 309, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": {\"0\": 30, \"1\": 1360}, \"size\": {\"0\": 340, \"1\": 240}, \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 1417, \"dir\": 3}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 1156, \"dir\": 3}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [1157, 1247], \"slot_index\": 0, \"shape\": 3, \"dir\": 4}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [1158], \"slot_index\": 1, \"shape\": 3, \"dir\": 4}], \"properties\": {\"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": true, \"lora\": \"Lora\\\\flux\\\\flux_realism_lora.safetensors\", \"strength\": 0.36, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"Lora\\\\flux\\\\ancient.safetensors\", \"strength\": 0.85, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"Lora\\\\flux\\\\aidmaFLUXpro1.1-FLUX-V0.1.safetensors\", \"strength\": 0.16, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"Lora\\\\flux\\\\flux_turbo.safetensors\", \"strength\": 0.25, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"Lora\\\\flux\\\\Analog_Photo_Style.safetensors\", \"strength\": 0.6, \"strengthTwo\": null}, null, \"\"]}, {\"id\": 61, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 770, \"1\": 100}, \"size\": {\"0\": 320, \"1\": 120}, \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 1157}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 317, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 318, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [94, 316], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [0.7000000000000001, 0.5, 1024, 1024]}, {\"id\": 312, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 1180, \"1\": 500}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [1243], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x_NMKD-Siax_200k.pth\"]}, {\"id\": 311, \"type\": \"LatentUpscaleBy\", \"pos\": {\"0\": 1530, \"1\": 1870}, \"size\": {\"0\": 270, \"1\": 80}, \"flags\": {}, \"order\": 56, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 1313}, {\"name\": \"scale_by\", \"type\": \"FLOAT\", \"link\": 1183, \"widget\": {\"name\": \"scale_by\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [1184, 1185], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LatentUpscaleBy\"}, \"widgets_values\": [\"nearest-exact\", 1.5]}, {\"id\": 199, \"type\": \"CLIPTextEncodeFlux\", \"pos\": {\"0\": 1540, \"1\": 1810}, \"size\": {\"0\": 210, \"1\": 160}, \"flags\": {\"collapsed\": true}, \"order\": 24, \"mode\": 2, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [281], \"shape\": 3}], \"title\": \"Empty Negative\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncodeFlux\"}, \"widgets_values\": [\"\", \"\", 3.5]}, {\"id\": 198, \"type\": \"BNK_Unsampler\", \"pos\": {\"0\": 1570, \"1\": 1700}, \"size\": {\"0\": 240, \"1\": 240}, \"flags\": {\"collapsed\": true}, \"order\": 64, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 280}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 281}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 1185}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [292], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BNK_Unsampler\"}, \"widgets_values\": [25, 20, 1, \"euler\", \"beta\", \"disable\"]}, {\"id\": 201, \"type\": \"LatentInterpolate\", \"pos\": {\"0\": 1540, \"1\": 1550}, \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 69, \"mode\": 2, \"inputs\": [{\"name\": \"samples1\", \"type\": \"LATENT\", \"link\": 1184}, {\"name\": \"samples2\", \"type\": \"LATENT\", \"link\": 292}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentInterpolate\"}, \"widgets_values\": [0.02]}, {\"id\": 157, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1530, \"1\": 1120}, \"size\": {\"0\": 240, \"1\": 360}, \"flags\": {}, \"order\": 72, \"mode\": 2, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 186, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": null, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": null, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 191, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 288, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [1518], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 321, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1580, \"1\": 710}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {}, \"order\": 66, \"mode\": 4, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 1305}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": []}, {\"id\": 319, \"type\": \"Preview Chooser\", \"pos\": {\"0\": 1220, \"1\": 640}, \"size\": {\"0\": 210, \"1\": 420}, \"flags\": {}, \"order\": 61, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 1303, \"shape\": 7}, {\"name\": \"latents\", \"type\": \"LATENT\", \"link\": null, \"shape\": 7}, {\"name\": \"masks\", \"type\": \"MASK\", \"link\": null, \"shape\": 7}, {\"name\": \"segs\", \"type\": \"SEGS\", \"link\": null, \"shape\": 7}], \"outputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"links\": [1305], \"slot_index\": 0}, {\"name\": \"latents\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1}, {\"name\": \"masks\", \"type\": \"MASK\", \"links\": null}, {\"name\": \"selected\", \"type\": \"STRING\", \"links\": null}, {\"name\": \"segs\", \"type\": \"SEGS\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"Preview Chooser\"}, \"widgets_values\": [\"Always pause\", 2, \"\", \"\"]}, {\"id\": 238, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1860, \"1\": 680}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": null, \"shape\": 7}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 347, \"type\": \"Reroute\", \"pos\": {\"0\": 2268.6552734375, \"1\": 559.6874389648438}, \"size\": [75, 26], \"flags\": {}, \"order\": 78, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 1568}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [1567], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 334, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1500, \"1\": 1040}, \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 75, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 1518}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1522, 1564, 1568], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 345, \"type\": \"SaveImage\", \"pos\": {\"0\": 1830, \"1\": 1580}, \"size\": {\"0\": 250, \"1\": 410}, \"flags\": {}, \"order\": 77, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 1564}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux/ComfyUI2\"]}, {\"id\": 158, \"type\": \"VAEDecode\", \"pos\": {\"0\": 2140, \"1\": 1010}, \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": true}, \"order\": 26, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [254], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 165, \"type\": \"FilmGrain\", \"pos\": {\"0\": 2140, \"1\": 1080}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {\"collapsed\": true}, \"order\": 41, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 254}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [199], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 48, 0, 0]}, {\"id\": 166, \"type\": \"ImageApplyLUT+\", \"pos\": {\"0\": 2140, \"1\": 1140}, \"size\": {\"0\": 220, \"1\": 130}, \"flags\": {}, \"order\": 49, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 199}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1311], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageApplyLUT+\"}, \"widgets_values\": [\"Presetpro  - Kodacrome 64.cube\", true, true, 0.4]}, {\"id\": 324, \"type\": \"Image Levels Adjustment\", \"pos\": {\"0\": 2160, \"1\": 1340}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {\"collapsed\": true}, \"order\": 54, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 1311}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1312], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"Image Levels Adjustment\"}, \"widgets_values\": [0, 127.5, 230.9]}, {\"id\": 162, \"type\": \"SaveImage\", \"pos\": {\"0\": 2150, \"1\": 1390}, \"size\": {\"0\": 340, \"1\": 590}, \"flags\": {}, \"order\": 58, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 1312}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux/ComfyUI\"]}, {\"id\": 322, \"type\": \"LoadImage\", \"pos\": {\"0\": 2600, \"1\": 2510}, \"size\": {\"0\": 320, \"1\": 310}, \"flags\": {}, \"order\": 27, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [1308], \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ComfyUI2_04768_.png\", \"image\"]}, {\"id\": 213, \"type\": \"SaveImage\", \"pos\": {\"0\": 1430, \"1\": 3010}, \"size\": {\"0\": 380, \"1\": 490}, \"flags\": {}, \"order\": 70, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 383}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux/ComfyUI\"]}, {\"id\": 255, \"type\": \"Image Comparer (rgthree)\", \"pos\": {\"0\": 1860, \"1\": 2780}, \"size\": {\"0\": 450, \"1\": 760}, \"flags\": {}, \"order\": 74, \"mode\": 2, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"link\": 382, \"dir\": 3}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"link\": 1343, \"dir\": 3}], \"outputs\": [], \"properties\": {\"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_mfobb_00047_.png&type=temp&subfolder=&rand=0.6470248885458347\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_mfobb_00048_.png&type=temp&subfolder=&rand=0.22758385826713767\"}]]}, {\"id\": 346, \"type\": \"Image Comparer (rgthree)\", \"pos\": {\"0\": 480, \"1\": 2060}, \"size\": {\"0\": 830, \"1\": 1080}, \"flags\": {}, \"order\": 80, \"mode\": 4, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"link\": 1565, \"dir\": 3}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"link\": 1567, \"dir\": 3}], \"outputs\": [], \"properties\": {\"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_mfobb_00023_.png&type=temp&subfolder=&rand=0.355712449793276\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_mfobb_00024_.png&type=temp&subfolder=&rand=0.5405384896744105\"}]]}, {\"id\": 329, \"type\": \"Fast Groups Muter (rgthree)\", \"pos\": {\"0\": 170, \"1\": 1000}, \"size\": {\"0\": 230, \"1\": 270}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null}], \"properties\": {\"matchColors\": \"\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}, \"shape\": \"card\"}, {\"id\": 296, \"type\": \"VAEDecodeTiled\", \"pos\": {\"0\": 860, \"1\": 1320}, \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 911}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [912, 1246, 1303, 1314, 1315, 1534, 1565], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecodeTiled\"}, \"widgets_values\": [512]}, {\"id\": 252, \"type\": \"SaveImage\", \"pos\": {\"0\": 850, \"1\": 1370}, \"size\": {\"0\": 440, \"1\": 620}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 912}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"flux/ComfyUI2\"]}, {\"id\": 258, \"type\": \"KSampler\", \"pos\": {\"0\": 470, \"1\": 1330}, \"size\": {\"0\": 350, \"1\": 570}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 384}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 385}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 386}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [911, 1313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [648735154039594, \"randomize\", 15, 1, \"euler\", \"beta\", 1]}, {\"id\": 225, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 470, \"1\": 750}, \"size\": {\"0\": 680, \"1\": 410}, \"flags\": {\"collapsed\": false}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": null}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [319, 1244], \"slot_index\": 0}], \"title\": \"CLIP Text Encode (Positive Prompt)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\\u3000\\u3000In the aftermath of the massive explosion that ripped through the futuristic cityscape, time is fractured and a haunting moment is trapped. The shining shards of chrome plating and neon signs that once symbolised a vibrant, technologically advanced society now pour down like an eerie shower of broken dreams. Twisted metal girders and fragments of sophisticated futuristic architecture are suspended in mid-air, defying gravity as the echoes of the blast echo through the smoke-filled air.\\n\\nIn the midst of this desolate technological ruin, a woman stands frozen in place. Her silhouette is a stark reminder of human fragility against the backdrop of a shattered future. Her cybernetically enhanced body, once a testament to human ingenuity and progress, now bears the scars of a devastating explosion, wires sparking and circuitry exposed. Her hair, once vibrant, is now covered in soot and dust, framing her face in a mixture of shock and defiance.\\n\\nBehind her, the giant geometric angel, a symbol of artificial intelligence and the pinnacle of technological progress, is scattered and broken. Its very presence illustrates the destructive power of ambition and technological hubris.\\n\\nThe scene poignantly expresses the transience of progress and the potential consequences of unstoppable technological progress. Cold, desaturated colours, high contrast and an emphasis on fragmentation amplify the sense of loss and despair, while elements of frozen time and a futuristic setting add a layer of chilling surrealism. The images evoke a powerful and emotionally resonant warning about the possibility of a dystopian future in which the dream of human progress is shattered in the ruins of its own creation.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}], \"links\": [[20, 17, 0, 13, 3, \"SIGMAS\"], [37, 25, 0, 13, 0, \"NOISE\"], [87, 60, 0, 22, 1, \"CONDITIONING\"], [94, 61, 0, 22, 0, \"MODEL\"], [156, 13, 0, 147, 0, \"LATENT\"], [186, 25, 0, 157, 0, \"NOISE\"], [191, 161, 0, 157, 3, \"SIGMAS\"], [199, 165, 0, 166, 0, \"IMAGE\"], [254, 158, 0, 165, 0, \"IMAGE\"], [280, 60, 0, 198, 1, \"CONDITIONING\"], [281, 199, 0, 198, 2, \"CONDITIONING\"], [288, 201, 0, 157, 4, \"LATENT\"], [292, 198, 0, 201, 1, \"LATENT\"], [309, 10, 0, 216, 0, \"VAE\"], [313, 220, 4, 13, 4, \"LATENT\"], [314, 16, 0, 222, 0, \"SAMPLER\"], [315, 22, 0, 223, 0, \"GUIDER\"], [316, 61, 0, 224, 0, \"MODEL\"], [317, 220, 0, 61, 1, \"INT\"], [318, 220, 1, 61, 2, \"INT\"], [319, 225, 0, 60, 0, \"CONDITIONING\"], [321, 227, 0, 226, 5, \"UPSCALE_MODEL\"], [322, 230, 0, 226, 6, \"FLOAT\"], [323, 231, 0, 226, 7, \"INT\"], [324, 232, 0, 226, 8, \"INT\"], [328, 230, 0, 231, 0, \"INT,FLOAT,IMAGE,LATENT\"], [329, 235, 0, 231, 1, \"INT,FLOAT,IMAGE,LATENT\"], [330, 230, 0, 232, 0, \"INT,FLOAT,IMAGE,LATENT\"], [331, 236, 0, 232, 1, \"INT,FLOAT,IMAGE,LATENT\"], [335, 60, 0, 226, 2, \"CONDITIONING\"], [336, 240, 0, 226, 3, \"CONDITIONING\"], [338, 22, 0, 13, 1, \"GUIDER\"], [339, 16, 0, 13, 2, \"SAMPLER\"], [340, 61, 0, 161, 0, \"MODEL\"], [341, 61, 0, 207, 0, \"MODEL\"], [342, 61, 0, 17, 0, \"MODEL\"], [343, 147, 0, 229, 0, \"IMAGE\"], [344, 147, 0, 226, 0, \"IMAGE\"], [345, 61, 0, 226, 1, \"MODEL\"], [346, 10, 0, 226, 4, \"VAE\"], [347, 10, 0, 147, 1, \"VAE\"], [348, 147, 0, 213, 0, \"IMAGE\"], [349, 11, 0, 240, 0, \"CLIP\"], [350, 11, 0, 225, 0, \"CLIP\"], [351, 22, 0, 13, 1, \"GUIDER\"], [352, 16, 0, 13, 2, \"SAMPLER\"], [353, 61, 0, 161, 0, \"MODEL\"], [354, 61, 0, 207, 0, \"MODEL\"], [355, 61, 0, 17, 0, \"MODEL\"], [356, 147, 0, 229, 0, \"IMAGE\"], [357, 147, 0, 226, 0, \"IMAGE\"], [358, 61, 0, 226, 1, \"MODEL\"], [359, 10, 0, 226, 4, \"VAE\"], [360, 10, 0, 147, 1, \"VAE\"], [361, 147, 0, 213, 0, \"IMAGE\"], [362, 11, 0, 240, 0, \"CLIP\"], [363, 11, 0, 225, 0, \"CLIP\"], [370, 226, 0, 249, 0, \"IMAGE\"], [371, 249, 0, 248, 0, \"IMAGE\"], [372, 248, 0, 228, 0, \"IMAGE\"], [374, 248, 0, 229, 0, \"IMAGE\"], [375, 251, 0, 250, 0, \"IMAGE\"], [382, 250, 0, 255, 0, \"IMAGE\"], [383, 250, 0, 213, 0, \"IMAGE\"], [384, 60, 0, 258, 1, \"CONDITIONING\"], [385, 259, 0, 258, 2, \"CONDITIONING\"], [386, 220, 4, 258, 3, \"LATENT\"], [395, 61, 0, 161, 0, \"MODEL\"], [396, 61, 0, 207, 0, \"MODEL\"], [397, 61, 0, 17, 0, \"MODEL\"], [398, 11, 0, 259, 0, \"CLIP\"], [399, 10, 0, 260, 1, \"VAE\"], [400, 260, 0, 252, 0, \"IMAGE\"], [401, 260, 0, 255, 0, \"IMAGE\"], [402, 260, 0, 255, 1, \"IMAGE\"], [403, 61, 0, 258, 0, \"MODEL\"], [404, 11, 0, 225, 0, \"CLIP\"], [405, 61, 0, 161, 0, \"MODEL\"], [406, 61, 0, 207, 0, \"MODEL\"], [407, 61, 0, 17, 0, \"MODEL\"], [408, 11, 0, 259, 0, \"CLIP\"], [409, 10, 0, 260, 1, \"VAE\"], [410, 260, 0, 252, 0, \"IMAGE\"], [411, 260, 0, 255, 0, \"IMAGE\"], [412, 260, 0, 255, 1, \"IMAGE\"], [413, 61, 0, 258, 0, \"MODEL\"], [414, 11, 0, 225, 0, \"CLIP\"], [415, 61, 0, 161, 0, \"MODEL\"], [416, 61, 0, 207, 0, \"MODEL\"], [417, 61, 0, 17, 0, \"MODEL\"], [418, 11, 0, 259, 0, \"CLIP\"], [419, 10, 0, 260, 1, \"VAE\"], [420, 260, 0, 252, 0, \"IMAGE\"], [421, 260, 0, 255, 0, \"IMAGE\"], [422, 260, 0, 255, 1, \"IMAGE\"], [423, 61, 0, 258, 0, \"MODEL\"], [424, 11, 0, 225, 0, \"CLIP\"], [425, 61, 0, 161, 0, \"MODEL\"], [426, 61, 0, 207, 0, \"MODEL\"], [427, 61, 0, 17, 0, \"MODEL\"], [428, 11, 0, 259, 0, \"CLIP\"], [429, 10, 0, 260, 1, \"VAE\"], [430, 260, 0, 252, 0, \"IMAGE\"], [431, 260, 0, 255, 0, \"IMAGE\"], [432, 260, 0, 255, 1, \"IMAGE\"], [433, 61, 0, 258, 0, \"MODEL\"], [434, 11, 0, 225, 0, \"CLIP\"], [435, 61, 0, 161, 0, \"MODEL\"], [436, 61, 0, 207, 0, \"MODEL\"], [437, 61, 0, 17, 0, \"MODEL\"], [438, 11, 0, 259, 0, \"CLIP\"], [439, 10, 0, 260, 1, \"VAE\"], [440, 260, 0, 252, 0, \"IMAGE\"], [441, 260, 0, 255, 0, \"IMAGE\"], [442, 260, 0, 255, 1, \"IMAGE\"], [443, 61, 0, 258, 0, \"MODEL\"], [444, 11, 0, 225, 0, \"CLIP\"], [445, 61, 0, 161, 0, \"MODEL\"], [446, 61, 0, 207, 0, \"MODEL\"], [447, 61, 0, 17, 0, \"MODEL\"], [448, 11, 0, 259, 0, \"CLIP\"], [449, 10, 0, 260, 1, \"VAE\"], [450, 260, 0, 252, 0, \"IMAGE\"], [451, 260, 0, 255, 0, \"IMAGE\"], [452, 260, 0, 255, 1, \"IMAGE\"], [453, 61, 0, 258, 0, \"MODEL\"], [454, 11, 0, 225, 0, \"CLIP\"], [455, 61, 0, 161, 0, \"MODEL\"], [456, 61, 0, 207, 0, \"MODEL\"], [457, 61, 0, 17, 0, \"MODEL\"], [458, 11, 0, 259, 0, \"CLIP\"], [459, 10, 0, 260, 1, \"VAE\"], [460, 260, 0, 252, 0, \"IMAGE\"], [461, 260, 0, 255, 0, \"IMAGE\"], [462, 260, 0, 255, 1, \"IMAGE\"], [463, 61, 0, 258, 0, \"MODEL\"], [464, 11, 0, 225, 0, \"CLIP\"], [465, 61, 0, 161, 0, \"MODEL\"], [466, 61, 0, 207, 0, \"MODEL\"], [467, 61, 0, 17, 0, \"MODEL\"], [468, 11, 0, 259, 0, \"CLIP\"], [469, 10, 0, 260, 1, \"VAE\"], [470, 260, 0, 252, 0, \"IMAGE\"], [471, 260, 0, 255, 0, \"IMAGE\"], [472, 260, 0, 255, 1, \"IMAGE\"], [473, 61, 0, 258, 0, \"MODEL\"], [474, 11, 0, 225, 0, \"CLIP\"], [475, 61, 0, 161, 0, \"MODEL\"], [476, 61, 0, 207, 0, \"MODEL\"], [477, 61, 0, 17, 0, \"MODEL\"], [478, 11, 0, 259, 0, \"CLIP\"], [479, 10, 0, 260, 1, \"VAE\"], [480, 260, 0, 252, 0, \"IMAGE\"], [481, 260, 0, 255, 0, \"IMAGE\"], [482, 260, 0, 255, 1, \"IMAGE\"], [483, 61, 0, 258, 0, \"MODEL\"], [484, 11, 0, 225, 0, \"CLIP\"], [485, 61, 0, 161, 0, \"MODEL\"], [486, 61, 0, 207, 0, \"MODEL\"], [487, 61, 0, 17, 0, \"MODEL\"], [488, 11, 0, 259, 0, \"CLIP\"], [489, 10, 0, 260, 1, \"VAE\"], [490, 260, 0, 252, 0, \"IMAGE\"], [491, 260, 0, 255, 0, \"IMAGE\"], [492, 260, 0, 255, 1, \"IMAGE\"], [493, 61, 0, 258, 0, \"MODEL\"], [494, 11, 0, 225, 0, \"CLIP\"], [495, 61, 0, 161, 0, \"MODEL\"], [496, 61, 0, 207, 0, \"MODEL\"], [497, 61, 0, 17, 0, \"MODEL\"], [498, 11, 0, 259, 0, \"CLIP\"], [499, 10, 0, 260, 1, \"VAE\"], [500, 260, 0, 252, 0, \"IMAGE\"], [501, 260, 0, 255, 0, \"IMAGE\"], [502, 260, 0, 255, 1, \"IMAGE\"], [503, 61, 0, 258, 0, \"MODEL\"], [504, 10, 0, 270, 1, \"VAE\"], [505, 11, 0, 225, 0, \"CLIP\"], [509, 61, 0, 161, 0, \"MODEL\"], [510, 61, 0, 207, 0, \"MODEL\"], [511, 61, 0, 17, 0, \"MODEL\"], [512, 11, 0, 259, 0, \"CLIP\"], [513, 10, 0, 260, 1, \"VAE\"], [514, 260, 0, 252, 0, \"IMAGE\"], [515, 260, 0, 255, 0, \"IMAGE\"], [516, 260, 0, 255, 1, \"IMAGE\"], [517, 10, 0, 270, 1, \"VAE\"], [518, 61, 0, 258, 0, \"MODEL\"], [519, 11, 0, 225, 0, \"CLIP\"], [523, 61, 0, 161, 0, \"MODEL\"], [524, 61, 0, 207, 0, \"MODEL\"], [525, 61, 0, 17, 0, \"MODEL\"], [526, 11, 0, 259, 0, \"CLIP\"], [527, 10, 0, 260, 1, \"VAE\"], [528, 260, 0, 252, 0, \"IMAGE\"], [529, 260, 0, 255, 0, \"IMAGE\"], [530, 260, 0, 255, 1, \"IMAGE\"], [531, 10, 0, 270, 1, \"VAE\"], [532, 61, 0, 258, 0, \"MODEL\"], [533, 11, 0, 225, 0, \"CLIP\"], [534, 220, 0, 278, 0, \"*\"], [536, 220, 2, 280, 0, \"*\"], [537, 281, 0, 230, 0, \"FLOAT\"], [538, 282, 0, 235, 0, \"INT\"], [539, 283, 0, 236, 0, \"INT\"], [540, 61, 0, 161, 0, \"MODEL\"], [541, 61, 0, 207, 0, \"MODEL\"], [542, 61, 0, 17, 0, \"MODEL\"], [543, 11, 0, 259, 0, \"CLIP\"], [544, 10, 0, 260, 1, \"VAE\"], [545, 260, 0, 252, 0, \"IMAGE\"], [546, 260, 0, 255, 0, \"IMAGE\"], [547, 260, 0, 255, 1, \"IMAGE\"], [548, 10, 0, 270, 1, \"VAE\"], [549, 61, 0, 258, 0, \"MODEL\"], [550, 11, 0, 225, 0, \"CLIP\"], [551, 61, 0, 161, 0, \"MODEL\"], [552, 61, 0, 207, 0, \"MODEL\"], [553, 61, 0, 17, 0, \"MODEL\"], [554, 11, 0, 259, 0, \"CLIP\"], [555, 10, 0, 260, 1, \"VAE\"], [556, 260, 0, 252, 0, \"IMAGE\"], [557, 260, 0, 255, 0, \"IMAGE\"], [558, 260, 0, 255, 1, \"IMAGE\"], [559, 10, 0, 270, 1, \"VAE\"], [560, 61, 0, 258, 0, \"MODEL\"], [561, 61, 0, 284, 0, \"MODEL\"], [562, 11, 0, 225, 0, \"CLIP\"], [563, 61, 0, 161, 0, \"MODEL\"], [564, 61, 0, 207, 0, \"MODEL\"], [565, 61, 0, 17, 0, \"MODEL\"], [566, 11, 0, 259, 0, \"CLIP\"], [567, 10, 0, 260, 1, \"VAE\"], [568, 260, 0, 252, 0, \"IMAGE\"], [569, 260, 0, 255, 0, \"IMAGE\"], [570, 260, 0, 255, 1, \"IMAGE\"], [571, 10, 0, 270, 1, \"VAE\"], [572, 61, 0, 284, 0, \"MODEL\"], [573, 11, 0, 225, 0, \"CLIP\"], [574, 61, 0, 258, 0, \"MODEL\"], [582, 61, 0, 161, 0, \"MODEL\"], [583, 61, 0, 207, 0, \"MODEL\"], [584, 61, 0, 17, 0, \"MODEL\"], [585, 11, 0, 259, 0, \"CLIP\"], [586, 10, 0, 260, 1, \"VAE\"], [587, 260, 0, 252, 0, \"IMAGE\"], [588, 260, 0, 255, 0, \"IMAGE\"], [589, 260, 0, 255, 1, \"IMAGE\"], [590, 10, 0, 270, 1, \"VAE\"], [591, 61, 0, 258, 0, \"MODEL\"], [592, 11, 0, 225, 0, \"CLIP\"], [593, 61, 0, 161, 0, \"MODEL\"], [594, 61, 0, 207, 0, \"MODEL\"], [595, 61, 0, 17, 0, \"MODEL\"], [596, 11, 0, 259, 0, \"CLIP\"], [597, 10, 0, 260, 1, \"VAE\"], [598, 260, 0, 252, 0, \"IMAGE\"], [599, 260, 0, 255, 0, \"IMAGE\"], [600, 260, 0, 255, 1, \"IMAGE\"], [601, 10, 0, 270, 1, \"VAE\"], [602, 61, 0, 258, 0, \"MODEL\"], [603, 11, 0, 225, 0, \"CLIP\"], [604, 61, 0, 161, 0, \"MODEL\"], [605, 61, 0, 207, 0, \"MODEL\"], [606, 61, 0, 17, 0, \"MODEL\"], [607, 11, 0, 259, 0, \"CLIP\"], [608, 10, 0, 260, 1, \"VAE\"], [609, 260, 0, 252, 0, \"IMAGE\"], [610, 260, 0, 255, 0, \"IMAGE\"], [611, 260, 0, 255, 1, \"IMAGE\"], [612, 10, 0, 270, 1, \"VAE\"], [613, 11, 0, 225, 0, \"CLIP\"], [614, 61, 0, 258, 0, \"MODEL\"], [615, 61, 0, 161, 0, \"MODEL\"], [616, 61, 0, 207, 0, \"MODEL\"], [617, 61, 0, 17, 0, \"MODEL\"], [618, 11, 0, 259, 0, \"CLIP\"], [619, 10, 0, 260, 1, \"VAE\"], [620, 260, 0, 252, 0, \"IMAGE\"], [621, 260, 0, 255, 0, \"IMAGE\"], [622, 260, 0, 255, 1, \"IMAGE\"], [623, 10, 0, 270, 1, \"VAE\"], [624, 61, 0, 258, 0, \"MODEL\"], [625, 11, 0, 225, 0, \"CLIP\"], [626, 61, 0, 161, 0, \"MODEL\"], [627, 61, 0, 207, 0, \"MODEL\"], [628, 61, 0, 17, 0, \"MODEL\"], [629, 11, 0, 259, 0, \"CLIP\"], [630, 10, 0, 260, 1, \"VAE\"], [631, 260, 0, 252, 0, \"IMAGE\"], [632, 260, 0, 255, 0, \"IMAGE\"], [633, 260, 0, 255, 1, \"IMAGE\"], [634, 10, 0, 270, 1, \"VAE\"], [635, 61, 0, 258, 0, \"MODEL\"], [636, 11, 0, 225, 0, \"CLIP\"], [637, 61, 0, 161, 0, \"MODEL\"], [638, 61, 0, 207, 0, \"MODEL\"], [639, 61, 0, 17, 0, \"MODEL\"], [640, 11, 0, 259, 0, \"CLIP\"], [641, 10, 0, 260, 1, \"VAE\"], [642, 260, 0, 252, 0, \"IMAGE\"], [643, 260, 0, 255, 0, \"IMAGE\"], [644, 260, 0, 255, 1, \"IMAGE\"], [645, 10, 0, 270, 1, \"VAE\"], [646, 11, 0, 225, 0, \"CLIP\"], [647, 61, 0, 258, 0, \"MODEL\"], [648, 61, 0, 161, 0, \"MODEL\"], [649, 61, 0, 207, 0, \"MODEL\"], [650, 61, 0, 17, 0, \"MODEL\"], [651, 11, 0, 259, 0, \"CLIP\"], [652, 10, 0, 260, 1, \"VAE\"], [653, 260, 0, 252, 0, \"IMAGE\"], [654, 260, 0, 255, 0, \"IMAGE\"], [655, 260, 0, 255, 1, \"IMAGE\"], [656, 10, 0, 270, 1, \"VAE\"], [657, 61, 0, 258, 0, \"MODEL\"], [658, 11, 0, 225, 0, \"CLIP\"], [659, 61, 0, 161, 0, \"MODEL\"], [660, 61, 0, 207, 0, \"MODEL\"], [661, 61, 0, 17, 0, \"MODEL\"], [662, 11, 0, 259, 0, \"CLIP\"], [663, 10, 0, 260, 1, \"VAE\"], [664, 260, 0, 252, 0, \"IMAGE\"], [665, 260, 0, 255, 0, \"IMAGE\"], [666, 260, 0, 255, 1, \"IMAGE\"], [667, 10, 0, 270, 1, \"VAE\"], [668, 61, 0, 258, 0, \"MODEL\"], [669, 11, 0, 225, 0, \"CLIP\"], [670, 61, 0, 161, 0, \"MODEL\"], [671, 61, 0, 207, 0, \"MODEL\"], [672, 61, 0, 17, 0, \"MODEL\"], [673, 11, 0, 259, 0, \"CLIP\"], [674, 10, 0, 260, 1, \"VAE\"], [675, 260, 0, 252, 0, \"IMAGE\"], [676, 260, 0, 255, 0, \"IMAGE\"], [677, 260, 0, 255, 1, \"IMAGE\"], [678, 10, 0, 270, 1, \"VAE\"], [679, 61, 0, 258, 0, \"MODEL\"], [680, 11, 0, 225, 0, \"CLIP\"], [681, 61, 0, 161, 0, \"MODEL\"], [682, 61, 0, 207, 0, \"MODEL\"], [683, 61, 0, 17, 0, \"MODEL\"], [684, 11, 0, 259, 0, \"CLIP\"], [685, 10, 0, 260, 1, \"VAE\"], [686, 260, 0, 252, 0, \"IMAGE\"], [687, 260, 0, 255, 0, \"IMAGE\"], [688, 260, 0, 255, 1, \"IMAGE\"], [689, 10, 0, 270, 1, \"VAE\"], [690, 61, 0, 258, 0, \"MODEL\"], [691, 11, 0, 225, 0, \"CLIP\"], [694, 61, 0, 161, 0, \"MODEL\"], [695, 61, 0, 207, 0, \"MODEL\"], [696, 61, 0, 17, 0, \"MODEL\"], [697, 11, 0, 259, 0, \"CLIP\"], [698, 10, 0, 260, 1, \"VAE\"], [699, 260, 0, 252, 0, \"IMAGE\"], [700, 260, 0, 255, 0, \"IMAGE\"], [701, 260, 0, 255, 1, \"IMAGE\"], [702, 10, 0, 270, 1, \"VAE\"], [703, 61, 0, 258, 0, \"MODEL\"], [704, 11, 0, 225, 0, \"CLIP\"], [705, 61, 0, 161, 0, \"MODEL\"], [706, 61, 0, 207, 0, \"MODEL\"], [707, 61, 0, 17, 0, \"MODEL\"], [708, 11, 0, 259, 0, \"CLIP\"], [709, 10, 0, 260, 1, \"VAE\"], [710, 260, 0, 252, 0, \"IMAGE\"], [711, 260, 0, 255, 0, \"IMAGE\"], [712, 260, 0, 255, 1, \"IMAGE\"], [713, 10, 0, 270, 1, \"VAE\"], [714, 61, 0, 258, 0, \"MODEL\"], [715, 11, 0, 225, 0, \"CLIP\"], [718, 61, 0, 161, 0, \"MODEL\"], [719, 61, 0, 207, 0, \"MODEL\"], [720, 61, 0, 17, 0, \"MODEL\"], [721, 290, 0, 252, 0, \"IMAGE\"], [722, 290, 0, 255, 0, \"IMAGE\"], [723, 290, 0, 255, 1, \"IMAGE\"], [724, 10, 0, 270, 1, \"VAE\"], [725, 11, 0, 259, 0, \"CLIP\"], [726, 61, 0, 258, 0, \"MODEL\"], [727, 10, 0, 290, 1, \"VAE\"], [728, 11, 0, 225, 0, \"CLIP\"], [729, 61, 0, 161, 0, \"MODEL\"], [730, 61, 0, 207, 0, \"MODEL\"], [731, 61, 0, 17, 0, \"MODEL\"], [732, 290, 0, 252, 0, \"IMAGE\"], [733, 290, 0, 255, 0, \"IMAGE\"], [734, 290, 0, 255, 1, \"IMAGE\"], [735, 10, 0, 270, 1, \"VAE\"], [736, 11, 0, 259, 0, \"CLIP\"], [737, 61, 0, 258, 0, \"MODEL\"], [738, 10, 0, 290, 1, \"VAE\"], [739, 11, 0, 225, 0, \"CLIP\"], [740, 61, 0, 161, 0, \"MODEL\"], [741, 61, 0, 207, 0, \"MODEL\"], [742, 61, 0, 17, 0, \"MODEL\"], [743, 290, 0, 252, 0, \"IMAGE\"], [744, 290, 0, 255, 0, \"IMAGE\"], [745, 290, 0, 255, 1, \"IMAGE\"], [746, 10, 0, 270, 1, \"VAE\"], [747, 61, 0, 258, 0, \"MODEL\"], [748, 11, 0, 259, 0, \"CLIP\"], [749, 10, 0, 290, 1, \"VAE\"], [750, 11, 0, 225, 0, \"CLIP\"], [751, 61, 0, 161, 0, \"MODEL\"], [752, 61, 0, 207, 0, \"MODEL\"], [753, 61, 0, 17, 0, \"MODEL\"], [754, 290, 0, 252, 0, \"IMAGE\"], [755, 290, 0, 255, 0, \"IMAGE\"], [756, 290, 0, 255, 1, \"IMAGE\"], [757, 10, 0, 270, 1, \"VAE\"], [758, 61, 0, 258, 0, \"MODEL\"], [759, 11, 0, 259, 0, \"CLIP\"], [760, 10, 0, 290, 1, \"VAE\"], [761, 11, 0, 225, 0, \"CLIP\"], [762, 61, 0, 161, 0, \"MODEL\"], [763, 61, 0, 207, 0, \"MODEL\"], [764, 61, 0, 17, 0, \"MODEL\"], [765, 290, 0, 252, 0, \"IMAGE\"], [766, 290, 0, 255, 0, \"IMAGE\"], [767, 290, 0, 255, 1, \"IMAGE\"], [768, 10, 0, 270, 1, \"VAE\"], [769, 11, 0, 259, 0, \"CLIP\"], [770, 10, 0, 290, 1, \"VAE\"], [771, 11, 0, 225, 0, \"CLIP\"], [772, 61, 0, 258, 0, \"MODEL\"], [773, 61, 0, 161, 0, \"MODEL\"], [774, 61, 0, 207, 0, \"MODEL\"], [775, 61, 0, 17, 0, \"MODEL\"], [776, 290, 0, 252, 0, \"IMAGE\"], [777, 290, 0, 255, 0, \"IMAGE\"], [778, 290, 0, 255, 1, \"IMAGE\"], [779, 10, 0, 270, 1, \"VAE\"], [780, 11, 0, 259, 0, \"CLIP\"], [781, 10, 0, 290, 1, \"VAE\"], [782, 61, 0, 258, 0, \"MODEL\"], [783, 11, 0, 225, 0, \"CLIP\"], [784, 61, 0, 161, 0, \"MODEL\"], [785, 61, 0, 207, 0, \"MODEL\"], [786, 61, 0, 17, 0, \"MODEL\"], [787, 290, 0, 252, 0, \"IMAGE\"], [788, 290, 0, 255, 0, \"IMAGE\"], [789, 290, 0, 255, 1, \"IMAGE\"], [790, 10, 0, 270, 1, \"VAE\"], [791, 11, 0, 259, 0, \"CLIP\"], [792, 10, 0, 290, 1, \"VAE\"], [793, 61, 0, 258, 0, \"MODEL\"], [794, 11, 0, 225, 0, \"CLIP\"], [795, 61, 0, 161, 0, \"MODEL\"], [796, 61, 0, 207, 0, \"MODEL\"], [797, 61, 0, 17, 0, \"MODEL\"], [798, 290, 0, 252, 0, \"IMAGE\"], [799, 290, 0, 255, 0, \"IMAGE\"], [800, 290, 0, 255, 1, \"IMAGE\"], [801, 10, 0, 270, 1, \"VAE\"], [802, 11, 0, 259, 0, \"CLIP\"], [803, 10, 0, 290, 1, \"VAE\"], [804, 11, 0, 225, 0, \"CLIP\"], [805, 61, 0, 258, 0, \"MODEL\"], [806, 290, 0, 252, 0, \"IMAGE\"], [807, 290, 0, 255, 0, \"IMAGE\"], [808, 290, 0, 255, 1, \"IMAGE\"], [809, 10, 0, 270, 1, \"VAE\"], [810, 11, 0, 259, 0, \"CLIP\"], [811, 10, 0, 290, 1, \"VAE\"], [812, 61, 0, 258, 0, \"MODEL\"], [813, 61, 0, 161, 0, \"MODEL\"], [814, 61, 0, 207, 0, \"MODEL\"], [815, 61, 0, 17, 0, \"MODEL\"], [816, 11, 0, 225, 0, \"CLIP\"], [817, 290, 0, 252, 0, \"IMAGE\"], [818, 290, 0, 255, 0, \"IMAGE\"], [819, 290, 0, 255, 1, \"IMAGE\"], [820, 10, 0, 270, 1, \"VAE\"], [821, 11, 0, 259, 0, \"CLIP\"], [822, 10, 0, 290, 1, \"VAE\"], [823, 61, 0, 161, 0, \"MODEL\"], [824, 61, 0, 207, 0, \"MODEL\"], [825, 61, 0, 17, 0, \"MODEL\"], [826, 61, 0, 258, 0, \"MODEL\"], [827, 11, 0, 225, 0, \"CLIP\"], [828, 290, 0, 252, 0, \"IMAGE\"], [829, 10, 0, 270, 1, \"VAE\"], [830, 11, 0, 259, 0, \"CLIP\"], [831, 10, 0, 290, 1, \"VAE\"], [832, 61, 0, 161, 0, \"MODEL\"], [833, 61, 0, 207, 0, \"MODEL\"], [834, 61, 0, 17, 0, \"MODEL\"], [835, 61, 0, 258, 0, \"MODEL\"], [836, 11, 0, 225, 0, \"CLIP\"], [837, 290, 0, 252, 0, \"IMAGE\"], [838, 10, 0, 270, 1, \"VAE\"], [839, 11, 0, 259, 0, \"CLIP\"], [840, 10, 0, 290, 1, \"VAE\"], [841, 61, 0, 161, 0, \"MODEL\"], [842, 61, 0, 207, 0, \"MODEL\"], [843, 61, 0, 17, 0, \"MODEL\"], [844, 61, 0, 258, 0, \"MODEL\"], [845, 11, 0, 225, 0, \"CLIP\"], [846, 290, 0, 252, 0, \"IMAGE\"], [847, 10, 0, 270, 1, \"VAE\"], [848, 11, 0, 259, 0, \"CLIP\"], [849, 10, 0, 290, 1, \"VAE\"], [850, 61, 0, 161, 0, \"MODEL\"], [851, 61, 0, 207, 0, \"MODEL\"], [852, 61, 0, 17, 0, \"MODEL\"], [853, 61, 0, 258, 0, \"MODEL\"], [854, 11, 0, 225, 0, \"CLIP\"], [855, 290, 0, 252, 0, \"IMAGE\"], [856, 10, 0, 270, 1, \"VAE\"], [857, 11, 0, 259, 0, \"CLIP\"], [858, 10, 0, 290, 1, \"VAE\"], [859, 61, 0, 161, 0, \"MODEL\"], [860, 61, 0, 207, 0, \"MODEL\"], [861, 61, 0, 17, 0, \"MODEL\"], [862, 61, 0, 258, 0, \"MODEL\"], [863, 11, 0, 225, 0, \"CLIP\"], [864, 290, 0, 252, 0, \"IMAGE\"], [865, 10, 0, 270, 1, \"VAE\"], [866, 11, 0, 259, 0, \"CLIP\"], [867, 10, 0, 290, 1, \"VAE\"], [868, 61, 0, 161, 0, \"MODEL\"], [869, 61, 0, 207, 0, \"MODEL\"], [870, 61, 0, 17, 0, \"MODEL\"], [871, 61, 0, 258, 0, \"MODEL\"], [872, 11, 0, 225, 0, \"CLIP\"], [873, 290, 0, 252, 0, \"IMAGE\"], [874, 10, 0, 270, 1, \"VAE\"], [875, 11, 0, 259, 0, \"CLIP\"], [876, 10, 0, 290, 1, \"VAE\"], [877, 61, 0, 161, 0, \"MODEL\"], [878, 61, 0, 207, 0, \"MODEL\"], [879, 61, 0, 17, 0, \"MODEL\"], [880, 61, 0, 258, 0, \"MODEL\"], [881, 11, 0, 225, 0, \"CLIP\"], [882, 290, 0, 252, 0, \"IMAGE\"], [883, 10, 0, 270, 1, \"VAE\"], [884, 11, 0, 259, 0, \"CLIP\"], [885, 10, 0, 290, 1, \"VAE\"], [886, 61, 0, 161, 0, \"MODEL\"], [887, 61, 0, 207, 0, \"MODEL\"], [888, 61, 0, 17, 0, \"MODEL\"], [889, 61, 0, 258, 0, \"MODEL\"], [890, 11, 0, 225, 0, \"CLIP\"], [891, 290, 0, 252, 0, \"IMAGE\"], [892, 10, 0, 270, 1, \"VAE\"], [893, 11, 0, 259, 0, \"CLIP\"], [894, 10, 0, 290, 1, \"VAE\"], [895, 61, 0, 161, 0, \"MODEL\"], [896, 61, 0, 207, 0, \"MODEL\"], [897, 61, 0, 17, 0, \"MODEL\"], [898, 61, 0, 258, 0, \"MODEL\"], [899, 11, 0, 225, 0, \"CLIP\"], [900, 290, 0, 252, 0, \"IMAGE\"], [901, 10, 0, 270, 1, \"VAE\"], [902, 11, 0, 259, 0, \"CLIP\"], [903, 10, 0, 290, 1, \"VAE\"], [904, 61, 0, 161, 0, \"MODEL\"], [905, 61, 0, 207, 0, \"MODEL\"], [906, 61, 0, 17, 0, \"MODEL\"], [907, 61, 0, 258, 0, \"MODEL\"], [908, 11, 0, 225, 0, \"CLIP\"], [911, 258, 0, 296, 0, \"LATENT\"], [912, 296, 0, 252, 0, \"IMAGE\"], [913, 10, 0, 270, 1, \"VAE\"], [914, 61, 0, 161, 0, \"MODEL\"], [915, 61, 0, 207, 0, \"MODEL\"], [916, 61, 0, 17, 0, \"MODEL\"], [917, 11, 0, 259, 0, \"CLIP\"], [918, 10, 0, 296, 1, \"VAE\"], [919, 11, 0, 225, 0, \"CLIP\"], [920, 61, 0, 258, 0, \"MODEL\"], [921, 10, 0, 270, 1, \"VAE\"], [922, 61, 0, 161, 0, \"MODEL\"], [923, 61, 0, 207, 0, \"MODEL\"], [924, 61, 0, 17, 0, \"MODEL\"], [925, 11, 0, 259, 0, \"CLIP\"], [926, 10, 0, 296, 1, \"VAE\"], [927, 61, 0, 258, 0, \"MODEL\"], [928, 11, 0, 225, 0, \"CLIP\"], [929, 10, 0, 270, 1, \"VAE\"], [930, 61, 0, 161, 0, \"MODEL\"], [931, 61, 0, 207, 0, \"MODEL\"], [932, 61, 0, 17, 0, \"MODEL\"], [933, 11, 0, 259, 0, \"CLIP\"], [934, 10, 0, 296, 1, \"VAE\"], [935, 61, 0, 258, 0, \"MODEL\"], [936, 11, 0, 225, 0, \"CLIP\"], [937, 10, 0, 270, 1, \"VAE\"], [938, 61, 0, 161, 0, \"MODEL\"], [939, 61, 0, 207, 0, \"MODEL\"], [940, 61, 0, 17, 0, \"MODEL\"], [941, 11, 0, 259, 0, \"CLIP\"], [942, 10, 0, 296, 1, \"VAE\"], [943, 61, 0, 258, 0, \"MODEL\"], [944, 11, 0, 225, 0, \"CLIP\"], [945, 10, 0, 270, 1, \"VAE\"], [946, 61, 0, 161, 0, \"MODEL\"], [947, 61, 0, 207, 0, \"MODEL\"], [948, 61, 0, 17, 0, \"MODEL\"], [949, 11, 0, 259, 0, \"CLIP\"], [950, 10, 0, 296, 1, \"VAE\"], [951, 11, 0, 225, 0, \"CLIP\"], [952, 61, 0, 258, 0, \"MODEL\"], [953, 10, 0, 270, 1, \"VAE\"], [954, 61, 0, 161, 0, \"MODEL\"], [955, 61, 0, 207, 0, \"MODEL\"], [956, 61, 0, 17, 0, \"MODEL\"], [957, 11, 0, 259, 0, \"CLIP\"], [958, 10, 0, 296, 1, \"VAE\"], [959, 61, 0, 258, 0, \"MODEL\"], [960, 11, 0, 225, 0, \"CLIP\"], [961, 10, 0, 270, 1, \"VAE\"], [962, 61, 0, 161, 0, \"MODEL\"], [963, 61, 0, 207, 0, \"MODEL\"], [964, 61, 0, 17, 0, \"MODEL\"], [965, 11, 0, 259, 0, \"CLIP\"], [966, 10, 0, 296, 1, \"VAE\"], [967, 61, 0, 258, 0, \"MODEL\"], [968, 11, 0, 225, 0, \"CLIP\"], [969, 10, 0, 270, 1, \"VAE\"], [970, 61, 0, 161, 0, \"MODEL\"], [971, 61, 0, 207, 0, \"MODEL\"], [972, 61, 0, 17, 0, \"MODEL\"], [973, 11, 0, 259, 0, \"CLIP\"], [974, 10, 0, 296, 1, \"VAE\"], [975, 11, 0, 225, 0, \"CLIP\"], [976, 61, 0, 258, 0, \"MODEL\"], [977, 10, 0, 270, 1, \"VAE\"], [978, 61, 0, 161, 0, \"MODEL\"], [979, 61, 0, 207, 0, \"MODEL\"], [980, 61, 0, 17, 0, \"MODEL\"], [981, 11, 0, 259, 0, \"CLIP\"], [982, 10, 0, 296, 1, \"VAE\"], [983, 61, 0, 258, 0, \"MODEL\"], [984, 11, 0, 225, 0, \"CLIP\"], [985, 10, 0, 270, 1, \"VAE\"], [986, 61, 0, 161, 0, \"MODEL\"], [987, 61, 0, 207, 0, \"MODEL\"], [988, 61, 0, 17, 0, \"MODEL\"], [989, 11, 0, 259, 0, \"CLIP\"], [990, 10, 0, 296, 1, \"VAE\"], [991, 11, 0, 225, 0, \"CLIP\"], [992, 61, 0, 258, 0, \"MODEL\"], [993, 10, 0, 270, 1, \"VAE\"], [994, 61, 0, 161, 0, \"MODEL\"], [995, 61, 0, 207, 0, \"MODEL\"], [996, 61, 0, 17, 0, \"MODEL\"], [997, 11, 0, 259, 0, \"CLIP\"], [998, 10, 0, 296, 1, \"VAE\"], [999, 61, 0, 258, 0, \"MODEL\"], [1000, 11, 0, 225, 0, \"CLIP\"], [1001, 10, 0, 270, 1, \"VAE\"], [1002, 61, 0, 161, 0, \"MODEL\"], [1003, 61, 0, 207, 0, \"MODEL\"], [1004, 61, 0, 17, 0, \"MODEL\"], [1005, 11, 0, 259, 0, \"CLIP\"], [1006, 10, 0, 296, 1, \"VAE\"], [1007, 61, 0, 258, 0, \"MODEL\"], [1008, 11, 0, 225, 0, \"CLIP\"], [1009, 10, 0, 270, 1, \"VAE\"], [1010, 61, 0, 161, 0, \"MODEL\"], [1011, 61, 0, 207, 0, \"MODEL\"], [1012, 61, 0, 17, 0, \"MODEL\"], [1013, 11, 0, 259, 0, \"CLIP\"], [1014, 10, 0, 296, 1, \"VAE\"], [1015, 61, 0, 258, 0, \"MODEL\"], [1016, 11, 0, 225, 0, \"CLIP\"], [1017, 10, 0, 270, 1, \"VAE\"], [1018, 61, 0, 161, 0, \"MODEL\"], [1019, 61, 0, 207, 0, \"MODEL\"], [1020, 61, 0, 17, 0, \"MODEL\"], [1021, 11, 0, 259, 0, \"CLIP\"], [1022, 10, 0, 296, 1, \"VAE\"], [1023, 11, 0, 225, 0, \"CLIP\"], [1024, 61, 0, 258, 0, \"MODEL\"], [1030, 10, 0, 270, 1, \"VAE\"], [1031, 61, 0, 161, 0, \"MODEL\"], [1032, 61, 0, 207, 0, \"MODEL\"], [1033, 61, 0, 17, 0, \"MODEL\"], [1034, 11, 0, 259, 0, \"CLIP\"], [1035, 10, 0, 296, 1, \"VAE\"], [1036, 61, 0, 258, 0, \"MODEL\"], [1037, 11, 0, 225, 0, \"CLIP\"], [1043, 10, 0, 270, 1, \"VAE\"], [1044, 61, 0, 161, 0, \"MODEL\"], [1045, 61, 0, 207, 0, \"MODEL\"], [1046, 61, 0, 17, 0, \"MODEL\"], [1047, 11, 0, 259, 0, \"CLIP\"], [1048, 10, 0, 296, 1, \"VAE\"], [1049, 61, 0, 258, 0, \"MODEL\"], [1050, 11, 0, 225, 0, \"CLIP\"], [1051, 10, 0, 270, 1, \"VAE\"], [1052, 61, 0, 161, 0, \"MODEL\"], [1053, 61, 0, 207, 0, \"MODEL\"], [1054, 61, 0, 17, 0, \"MODEL\"], [1055, 11, 0, 259, 0, \"CLIP\"], [1056, 10, 0, 296, 1, \"VAE\"], [1057, 61, 0, 258, 0, \"MODEL\"], [1058, 11, 0, 225, 0, \"CLIP\"], [1059, 10, 0, 270, 1, \"VAE\"], [1060, 61, 0, 161, 0, \"MODEL\"], [1061, 61, 0, 207, 0, \"MODEL\"], [1062, 61, 0, 17, 0, \"MODEL\"], [1063, 11, 0, 259, 0, \"CLIP\"], [1064, 10, 0, 296, 1, \"VAE\"], [1065, 11, 0, 225, 0, \"CLIP\"], [1066, 61, 0, 258, 0, \"MODEL\"], [1067, 10, 0, 270, 1, \"VAE\"], [1068, 61, 0, 161, 0, \"MODEL\"], [1069, 61, 0, 207, 0, \"MODEL\"], [1070, 61, 0, 17, 0, \"MODEL\"], [1071, 11, 0, 259, 0, \"CLIP\"], [1072, 10, 0, 296, 1, \"VAE\"], [1073, 11, 0, 225, 0, \"CLIP\"], [1074, 61, 0, 258, 0, \"MODEL\"], [1075, 10, 0, 270, 1, \"VAE\"], [1076, 61, 0, 161, 0, \"MODEL\"], [1077, 61, 0, 207, 0, \"MODEL\"], [1078, 61, 0, 17, 0, \"MODEL\"], [1079, 11, 0, 259, 0, \"CLIP\"], [1080, 10, 0, 296, 1, \"VAE\"], [1081, 11, 0, 225, 0, \"CLIP\"], [1082, 61, 0, 258, 0, \"MODEL\"], [1083, 10, 0, 270, 1, \"VAE\"], [1084, 61, 0, 161, 0, \"MODEL\"], [1085, 61, 0, 207, 0, \"MODEL\"], [1086, 61, 0, 17, 0, \"MODEL\"], [1087, 11, 0, 259, 0, \"CLIP\"], [1088, 10, 0, 296, 1, \"VAE\"], [1089, 61, 0, 258, 0, \"MODEL\"], [1090, 11, 0, 225, 0, \"CLIP\"], [1091, 10, 0, 270, 1, \"VAE\"], [1092, 61, 0, 161, 0, \"MODEL\"], [1093, 61, 0, 207, 0, \"MODEL\"], [1094, 61, 0, 17, 0, \"MODEL\"], [1095, 11, 0, 259, 0, \"CLIP\"], [1096, 10, 0, 296, 1, \"VAE\"], [1097, 61, 0, 258, 0, \"MODEL\"], [1098, 11, 0, 225, 0, \"CLIP\"], [1099, 10, 0, 270, 1, \"VAE\"], [1100, 61, 0, 161, 0, \"MODEL\"], [1101, 61, 0, 207, 0, \"MODEL\"], [1102, 61, 0, 17, 0, \"MODEL\"], [1103, 11, 0, 259, 0, \"CLIP\"], [1104, 10, 0, 296, 1, \"VAE\"], [1105, 61, 0, 258, 0, \"MODEL\"], [1106, 11, 0, 225, 0, \"CLIP\"], [1107, 10, 0, 270, 1, \"VAE\"], [1108, 61, 0, 161, 0, \"MODEL\"], [1109, 61, 0, 207, 0, \"MODEL\"], [1110, 61, 0, 17, 0, \"MODEL\"], [1111, 11, 0, 259, 0, \"CLIP\"], [1112, 10, 0, 296, 1, \"VAE\"], [1113, 61, 0, 258, 0, \"MODEL\"], [1114, 11, 0, 225, 0, \"CLIP\"], [1115, 10, 0, 270, 1, \"VAE\"], [1116, 61, 0, 161, 0, \"MODEL\"], [1117, 61, 0, 207, 0, \"MODEL\"], [1118, 61, 0, 17, 0, \"MODEL\"], [1119, 11, 0, 259, 0, \"CLIP\"], [1120, 10, 0, 296, 1, \"VAE\"], [1121, 61, 0, 258, 0, \"MODEL\"], [1122, 11, 0, 225, 0, \"CLIP\"], [1123, 10, 0, 270, 1, \"VAE\"], [1124, 61, 0, 161, 0, \"MODEL\"], [1125, 61, 0, 207, 0, \"MODEL\"], [1126, 61, 0, 17, 0, \"MODEL\"], [1127, 11, 0, 259, 0, \"CLIP\"], [1128, 10, 0, 296, 1, \"VAE\"], [1129, 61, 0, 258, 0, \"MODEL\"], [1130, 11, 0, 225, 0, \"CLIP\"], [1131, 10, 0, 270, 1, \"VAE\"], [1132, 61, 0, 161, 0, \"MODEL\"], [1133, 61, 0, 207, 0, \"MODEL\"], [1134, 61, 0, 17, 0, \"MODEL\"], [1135, 11, 0, 259, 0, \"CLIP\"], [1136, 10, 0, 296, 1, \"VAE\"], [1137, 61, 0, 258, 0, \"MODEL\"], [1138, 11, 0, 225, 0, \"CLIP\"], [1139, 10, 0, 270, 1, \"VAE\"], [1140, 61, 0, 161, 0, \"MODEL\"], [1141, 61, 0, 207, 0, \"MODEL\"], [1142, 61, 0, 17, 0, \"MODEL\"], [1143, 11, 0, 259, 0, \"CLIP\"], [1144, 10, 0, 296, 1, \"VAE\"], [1145, 11, 0, 225, 0, \"CLIP\"], [1146, 61, 0, 258, 0, \"MODEL\"], [1147, 10, 0, 270, 1, \"VAE\"], [1148, 61, 0, 161, 0, \"MODEL\"], [1149, 61, 0, 207, 0, \"MODEL\"], [1150, 61, 0, 17, 0, \"MODEL\"], [1151, 11, 0, 259, 0, \"CLIP\"], [1152, 10, 0, 296, 1, \"VAE\"], [1153, 61, 0, 258, 0, \"MODEL\"], [1154, 11, 0, 225, 0, \"CLIP\"], [1156, 11, 0, 309, 1, \"CLIP\"], [1157, 309, 0, 61, 0, \"MODEL\"], [1158, 309, 1, 241, 0, \"CLIP\"], [1159, 10, 0, 270, 1, \"VAE\"], [1160, 61, 0, 161, 0, \"MODEL\"], [1161, 309, 1, 259, 0, \"CLIP\"], [1162, 10, 0, 296, 1, \"VAE\"], [1163, 61, 0, 207, 0, \"MODEL\"], [1164, 61, 0, 17, 0, \"MODEL\"], [1165, 61, 0, 258, 0, \"MODEL\"], [1166, 309, 1, 225, 0, \"CLIP\"], [1167, 10, 0, 270, 1, \"VAE\"], [1168, 61, 0, 161, 0, \"MODEL\"], [1169, 309, 1, 259, 0, \"CLIP\"], [1170, 10, 0, 296, 1, \"VAE\"], [1171, 61, 0, 207, 0, \"MODEL\"], [1172, 61, 0, 17, 0, \"MODEL\"], [1173, 61, 0, 258, 0, \"MODEL\"], [1174, 309, 1, 225, 0, \"CLIP\"], [1175, 10, 0, 270, 1, \"VAE\"], [1176, 61, 0, 161, 0, \"MODEL\"], [1177, 309, 1, 259, 0, \"CLIP\"], [1178, 10, 0, 296, 1, \"VAE\"], [1179, 61, 0, 207, 0, \"MODEL\"], [1180, 61, 0, 17, 0, \"MODEL\"], [1181, 61, 0, 258, 0, \"MODEL\"], [1182, 309, 1, 225, 0, \"CLIP\"], [1183, 247, 0, 311, 1, \"FLOAT\"], [1184, 311, 0, 201, 0, \"LATENT\"], [1185, 311, 0, 198, 3, \"LATENT\"], [1187, 10, 0, 270, 1, \"VAE\"], [1188, 61, 0, 161, 0, \"MODEL\"], [1189, 309, 1, 259, 0, \"CLIP\"], [1190, 61, 0, 207, 0, \"MODEL\"], [1191, 61, 0, 17, 0, \"MODEL\"], [1192, 10, 0, 296, 1, \"VAE\"], [1193, 61, 0, 258, 0, \"MODEL\"], [1194, 309, 1, 225, 0, \"CLIP\"], [1195, 10, 0, 270, 1, \"VAE\"], [1196, 61, 0, 161, 0, \"MODEL\"], [1197, 309, 1, 259, 0, \"CLIP\"], [1198, 61, 0, 207, 0, \"MODEL\"], [1199, 61, 0, 17, 0, \"MODEL\"], [1200, 10, 0, 296, 1, \"VAE\"], [1201, 61, 0, 258, 0, \"MODEL\"], [1202, 309, 1, 225, 0, \"CLIP\"], [1203, 10, 0, 270, 1, \"VAE\"], [1204, 61, 0, 161, 0, \"MODEL\"], [1205, 309, 1, 259, 0, \"CLIP\"], [1206, 61, 0, 207, 0, \"MODEL\"], [1207, 61, 0, 17, 0, \"MODEL\"], [1208, 10, 0, 296, 1, \"VAE\"], [1209, 61, 0, 258, 0, \"MODEL\"], [1210, 309, 1, 225, 0, \"CLIP\"], [1211, 10, 0, 270, 1, \"VAE\"], [1212, 61, 0, 161, 0, \"MODEL\"], [1213, 309, 1, 259, 0, \"CLIP\"], [1214, 61, 0, 207, 0, \"MODEL\"], [1215, 61, 0, 17, 0, \"MODEL\"], [1216, 10, 0, 296, 1, \"VAE\"], [1217, 61, 0, 258, 0, \"MODEL\"], [1218, 309, 1, 225, 0, \"CLIP\"], [1219, 10, 0, 270, 1, \"VAE\"], [1220, 61, 0, 161, 0, \"MODEL\"], [1221, 309, 1, 259, 0, \"CLIP\"], [1222, 61, 0, 207, 0, \"MODEL\"], [1223, 61, 0, 17, 0, \"MODEL\"], [1224, 10, 0, 296, 1, \"VAE\"], [1225, 61, 0, 258, 0, \"MODEL\"], [1226, 309, 1, 225, 0, \"CLIP\"], [1227, 10, 0, 270, 1, \"VAE\"], [1228, 61, 0, 161, 0, \"MODEL\"], [1229, 309, 1, 259, 0, \"CLIP\"], [1230, 61, 0, 207, 0, \"MODEL\"], [1231, 61, 0, 17, 0, \"MODEL\"], [1232, 10, 0, 296, 1, \"VAE\"], [1233, 309, 1, 225, 0, \"CLIP\"], [1234, 61, 0, 258, 0, \"MODEL\"], [1235, 10, 0, 270, 1, \"VAE\"], [1236, 61, 0, 161, 0, \"MODEL\"], [1237, 309, 1, 259, 0, \"CLIP\"], [1238, 61, 0, 207, 0, \"MODEL\"], [1239, 61, 0, 17, 0, \"MODEL\"], [1240, 10, 0, 296, 1, \"VAE\"], [1241, 61, 0, 258, 0, \"MODEL\"], [1242, 309, 1, 225, 0, \"CLIP\"], [1243, 312, 0, 313, 5, \"UPSCALE_MODEL\"], [1244, 225, 0, 313, 2, \"CONDITIONING\"], [1245, 259, 0, 313, 3, \"CONDITIONING\"], [1246, 296, 0, 313, 0, \"IMAGE\"], [1247, 309, 0, 313, 1, \"MODEL\"], [1248, 313, 0, 314, 0, \"IMAGE\"], [1249, 10, 0, 270, 1, \"VAE\"], [1250, 61, 0, 161, 0, \"MODEL\"], [1251, 61, 0, 207, 0, \"MODEL\"], [1252, 61, 0, 17, 0, \"MODEL\"], [1253, 61, 0, 258, 0, \"MODEL\"], [1254, 309, 1, 259, 0, \"CLIP\"], [1255, 10, 0, 296, 1, \"VAE\"], [1256, 309, 1, 225, 0, \"CLIP\"], [1257, 10, 0, 313, 4, \"VAE\"], [1258, 10, 0, 270, 1, \"VAE\"], [1259, 61, 0, 161, 0, \"MODEL\"], [1260, 61, 0, 207, 0, \"MODEL\"], [1261, 61, 0, 17, 0, \"MODEL\"], [1262, 309, 1, 259, 0, \"CLIP\"], [1263, 10, 0, 296, 1, \"VAE\"], [1264, 309, 1, 225, 0, \"CLIP\"], [1265, 61, 0, 258, 0, \"MODEL\"], [1266, 10, 0, 313, 4, \"VAE\"], [1267, 230, 0, 313, 6, \"FLOAT\"], [1268, 231, 0, 313, 7, \"INT\"], [1269, 232, 0, 313, 8, \"INT\"], [1272, 147, 0, 315, 0, \"IMAGE\"], [1273, 247, 0, 231, 2, \"INT,FLOAT,IMAGE,LATENT\"], [1274, 247, 0, 232, 2, \"INT,FLOAT,IMAGE,LATENT\"], [1276, 10, 0, 158, 1, \"VAE\"], [1277, 309, 1, 199, 0, \"CLIP\"], [1278, 10, 0, 270, 1, \"VAE\"], [1279, 309, 1, 259, 0, \"CLIP\"], [1280, 309, 1, 240, 0, \"CLIP\"], [1281, 10, 0, 202, 1, \"VAE\"], [1282, 22, 0, 157, 1, \"GUIDER\"], [1283, 16, 0, 157, 2, \"SAMPLER\"], [1284, 22, 0, 206, 1, \"GUIDER\"], [1285, 16, 0, 206, 2, \"SAMPLER\"], [1286, 61, 0, 207, 0, \"MODEL\"], [1287, 61, 0, 161, 0, \"MODEL\"], [1288, 61, 0, 17, 0, \"MODEL\"], [1289, 61, 0, 198, 0, \"MODEL\"], [1290, 61, 0, 226, 1, \"MODEL\"], [1291, 10, 0, 226, 4, \"VAE\"], [1292, 309, 1, 225, 0, \"CLIP\"], [1293, 61, 0, 258, 0, \"MODEL\"], [1294, 10, 0, 296, 1, \"VAE\"], [1295, 10, 0, 147, 1, \"VAE\"], [1296, 22, 0, 13, 1, \"GUIDER\"], [1297, 16, 0, 13, 2, \"SAMPLER\"], [1303, 296, 0, 319, 0, \"IMAGE\"], [1305, 319, 0, 321, 0, \"IMAGE\"], [1308, 322, 0, 323, 0, \"IMAGE\"], [1311, 166, 0, 324, 0, \"IMAGE\"], [1312, 324, 0, 162, 0, \"IMAGE\"], [1313, 258, 0, 311, 0, \"LATENT\"], [1314, 296, 0, 251, 0, \"IMAGE\"], [1315, 296, 0, 229, 1, \"IMAGE\"], [1317, 10, 0, 270, 1, \"VAE\"], [1318, 309, 1, 240, 0, \"CLIP\"], [1319, 61, 0, 207, 0, \"MODEL\"], [1320, 61, 0, 161, 0, \"MODEL\"], [1321, 61, 0, 17, 0, \"MODEL\"], [1322, 10, 0, 147, 1, \"VAE\"], [1323, 22, 0, 13, 1, \"GUIDER\"], [1324, 16, 0, 13, 2, \"SAMPLER\"], [1325, 309, 1, 259, 0, \"CLIP\"], [1326, 61, 0, 226, 1, \"MODEL\"], [1327, 10, 0, 226, 4, \"VAE\"], [1328, 22, 0, 157, 1, \"GUIDER\"], [1329, 16, 0, 157, 2, \"SAMPLER\"], [1330, 22, 0, 206, 1, \"GUIDER\"], [1331, 16, 0, 206, 2, \"SAMPLER\"], [1332, 309, 1, 199, 0, \"CLIP\"], [1333, 10, 0, 158, 1, \"VAE\"], [1334, 61, 0, 258, 0, \"MODEL\"], [1335, 10, 0, 296, 1, \"VAE\"], [1336, 61, 0, 198, 0, \"MODEL\"], [1337, 10, 0, 323, 1, \"VAE\"], [1338, 309, 1, 225, 0, \"CLIP\"], [1339, 250, 0, 325, 0, \"IMAGE\"], [1342, 325, 0, 326, 0, \"IMAGE\"], [1343, 325, 0, 255, 1, \"IMAGE\"], [1345, 10, 0, 270, 1, \"VAE\"], [1346, 61, 0, 207, 0, \"MODEL\"], [1347, 61, 0, 161, 0, \"MODEL\"], [1348, 61, 0, 17, 0, \"MODEL\"], [1349, 309, 1, 259, 0, \"CLIP\"], [1350, 10, 0, 296, 1, \"VAE\"], [1351, 309, 1, 225, 0, \"CLIP\"], [1352, 61, 0, 258, 0, \"MODEL\"], [1353, 10, 0, 270, 1, \"VAE\"], [1354, 61, 0, 207, 0, \"MODEL\"], [1355, 61, 0, 161, 0, \"MODEL\"], [1356, 61, 0, 17, 0, \"MODEL\"], [1357, 309, 1, 259, 0, \"CLIP\"], [1358, 10, 0, 296, 1, \"VAE\"], [1359, 309, 1, 225, 0, \"CLIP\"], [1360, 61, 0, 258, 0, \"MODEL\"], [1361, 10, 0, 270, 1, \"VAE\"], [1362, 309, 1, 240, 0, \"CLIP\"], [1363, 61, 0, 207, 0, \"MODEL\"], [1364, 61, 0, 161, 0, \"MODEL\"], [1365, 61, 0, 17, 0, \"MODEL\"], [1366, 309, 1, 259, 0, \"CLIP\"], [1367, 22, 0, 157, 1, \"GUIDER\"], [1368, 16, 0, 157, 2, \"SAMPLER\"], [1369, 22, 0, 206, 1, \"GUIDER\"], [1370, 16, 0, 206, 2, \"SAMPLER\"], [1371, 309, 1, 199, 0, \"CLIP\"], [1372, 10, 0, 158, 1, \"VAE\"], [1373, 61, 0, 198, 0, \"MODEL\"], [1374, 10, 0, 296, 1, \"VAE\"], [1375, 309, 1, 225, 0, \"CLIP\"], [1376, 61, 0, 258, 0, \"MODEL\"], [1377, 61, 0, 226, 1, \"MODEL\"], [1378, 10, 0, 226, 4, \"VAE\"], [1380, 220, 1, 279, 0, \"INT\"], [1381, 10, 0, 270, 1, \"VAE\"], [1382, 61, 0, 207, 0, \"MODEL\"], [1383, 61, 0, 161, 0, \"MODEL\"], [1384, 309, 1, 259, 0, \"CLIP\"], [1385, 10, 0, 296, 1, \"VAE\"], [1386, 61, 0, 258, 0, \"MODEL\"], [1387, 61, 0, 17, 0, \"MODEL\"], [1388, 309, 1, 225, 0, \"CLIP\"], [1389, 10, 0, 270, 1, \"VAE\"], [1390, 61, 0, 207, 0, \"MODEL\"], [1391, 61, 0, 161, 0, \"MODEL\"], [1392, 309, 1, 259, 0, \"CLIP\"], [1393, 10, 0, 296, 1, \"VAE\"], [1394, 61, 0, 258, 0, \"MODEL\"], [1395, 61, 0, 17, 0, \"MODEL\"], [1396, 309, 1, 225, 0, \"CLIP\"], [1397, 10, 0, 270, 1, \"VAE\"], [1398, 61, 0, 207, 0, \"MODEL\"], [1399, 61, 0, 161, 0, \"MODEL\"], [1400, 309, 1, 259, 0, \"CLIP\"], [1401, 10, 0, 296, 1, \"VAE\"], [1402, 61, 0, 17, 0, \"MODEL\"], [1403, 61, 0, 258, 0, \"MODEL\"], [1404, 309, 1, 225, 0, \"CLIP\"], [1405, 10, 0, 270, 1, \"VAE\"], [1406, 61, 0, 207, 0, \"MODEL\"], [1407, 61, 0, 161, 0, \"MODEL\"], [1408, 309, 1, 259, 0, \"CLIP\"], [1409, 10, 0, 296, 1, \"VAE\"], [1410, 61, 0, 17, 0, \"MODEL\"], [1411, 309, 1, 225, 0, \"CLIP\"], [1412, 61, 0, 258, 0, \"MODEL\"], [1413, 220, 4, 270, 0, \"LATENT\"], [1417, 12, 0, 309, 0, \"MODEL\"], [1418, 309, 1, 259, 0, \"CLIP\"], [1419, 10, 0, 296, 1, \"VAE\"], [1420, 10, 0, 270, 1, \"VAE\"], [1421, 61, 0, 17, 0, \"MODEL\"], [1422, 61, 0, 258, 0, \"MODEL\"], [1423, 61, 0, 207, 0, \"MODEL\"], [1424, 61, 0, 161, 0, \"MODEL\"], [1425, 309, 1, 225, 0, \"CLIP\"], [1426, 309, 1, 259, 0, \"CLIP\"], [1427, 10, 0, 296, 1, \"VAE\"], [1428, 10, 0, 270, 1, \"VAE\"], [1429, 61, 0, 17, 0, \"MODEL\"], [1430, 61, 0, 207, 0, \"MODEL\"], [1431, 61, 0, 161, 0, \"MODEL\"], [1432, 61, 0, 258, 0, \"MODEL\"], [1433, 309, 1, 225, 0, \"CLIP\"], [1434, 309, 1, 259, 0, \"CLIP\"], [1435, 10, 0, 296, 1, \"VAE\"], [1436, 10, 0, 270, 1, \"VAE\"], [1437, 61, 0, 17, 0, \"MODEL\"], [1438, 61, 0, 207, 0, \"MODEL\"], [1439, 61, 0, 161, 0, \"MODEL\"], [1440, 61, 0, 258, 0, \"MODEL\"], [1441, 309, 1, 225, 0, \"CLIP\"], [1442, 309, 1, 259, 0, \"CLIP\"], [1443, 10, 0, 296, 1, \"VAE\"], [1444, 10, 0, 270, 1, \"VAE\"], [1445, 61, 0, 17, 0, \"MODEL\"], [1446, 61, 0, 207, 0, \"MODEL\"], [1447, 61, 0, 161, 0, \"MODEL\"], [1448, 309, 1, 225, 0, \"CLIP\"], [1449, 61, 0, 258, 0, \"MODEL\"], [1450, 309, 1, 240, 0, \"CLIP\"], [1451, 22, 0, 157, 1, \"GUIDER\"], [1452, 16, 0, 157, 2, \"SAMPLER\"], [1453, 309, 1, 199, 0, \"CLIP\"], [1454, 61, 0, 198, 0, \"MODEL\"], [1455, 22, 0, 206, 1, \"GUIDER\"], [1456, 16, 0, 206, 2, \"SAMPLER\"], [1457, 61, 0, 226, 1, \"MODEL\"], [1458, 10, 0, 226, 4, \"VAE\"], [1459, 309, 1, 259, 0, \"CLIP\"], [1460, 10, 0, 296, 1, \"VAE\"], [1461, 10, 0, 270, 1, \"VAE\"], [1462, 61, 0, 17, 0, \"MODEL\"], [1463, 61, 0, 207, 0, \"MODEL\"], [1464, 61, 0, 161, 0, \"MODEL\"], [1465, 309, 1, 225, 0, \"CLIP\"], [1466, 61, 0, 258, 0, \"MODEL\"], [1467, 10, 0, 158, 1, \"VAE\"], [1468, 309, 1, 240, 0, \"CLIP\"], [1469, 22, 0, 157, 1, \"GUIDER\"], [1470, 16, 0, 157, 2, \"SAMPLER\"], [1471, 309, 1, 199, 0, \"CLIP\"], [1472, 61, 0, 198, 0, \"MODEL\"], [1473, 22, 0, 206, 1, \"GUIDER\"], [1474, 16, 0, 206, 2, \"SAMPLER\"], [1475, 61, 0, 226, 1, \"MODEL\"], [1476, 10, 0, 226, 4, \"VAE\"], [1477, 309, 1, 259, 0, \"CLIP\"], [1478, 10, 0, 296, 1, \"VAE\"], [1479, 10, 0, 270, 1, \"VAE\"], [1480, 61, 0, 17, 0, \"MODEL\"], [1481, 61, 0, 207, 0, \"MODEL\"], [1482, 61, 0, 161, 0, \"MODEL\"], [1483, 309, 1, 225, 0, \"CLIP\"], [1484, 61, 0, 258, 0, \"MODEL\"], [1485, 10, 0, 158, 1, \"VAE\"], [1487, 309, 1, 240, 0, \"CLIP\"], [1488, 309, 1, 259, 0, \"CLIP\"], [1489, 10, 0, 270, 1, \"VAE\"], [1490, 61, 0, 17, 0, \"MODEL\"], [1491, 61, 0, 207, 0, \"MODEL\"], [1492, 61, 0, 161, 0, \"MODEL\"], [1493, 309, 1, 225, 0, \"CLIP\"], [1494, 61, 0, 226, 1, \"MODEL\"], [1495, 10, 0, 226, 4, \"VAE\"], [1496, 10, 0, 296, 1, \"VAE\"], [1497, 61, 0, 258, 0, \"MODEL\"], [1498, 309, 1, 240, 0, \"CLIP\"], [1499, 22, 0, 157, 1, \"GUIDER\"], [1500, 16, 0, 157, 2, \"SAMPLER\"], [1501, 309, 1, 199, 0, \"CLIP\"], [1502, 22, 0, 206, 1, \"GUIDER\"], [1503, 16, 0, 206, 2, \"SAMPLER\"], [1504, 309, 1, 259, 0, \"CLIP\"], [1505, 10, 0, 270, 1, \"VAE\"], [1506, 61, 0, 17, 0, \"MODEL\"], [1507, 61, 0, 207, 0, \"MODEL\"], [1508, 61, 0, 161, 0, \"MODEL\"], [1509, 309, 1, 225, 0, \"CLIP\"], [1510, 61, 0, 226, 1, \"MODEL\"], [1511, 10, 0, 226, 4, \"VAE\"], [1512, 10, 0, 296, 1, \"VAE\"], [1513, 61, 0, 258, 0, \"MODEL\"], [1514, 61, 0, 198, 0, \"MODEL\"], [1515, 10, 0, 158, 1, \"VAE\"], [1518, 157, 0, 334, 0, \"LATENT\"], [1522, 334, 0, 338, 0, \"*\"], [1524, 338, 0, 226, 0, \"IMAGE\"], [1528, 60, 0, 343, 2, \"CONDITIONING\"], [1529, 240, 0, 343, 3, \"CONDITIONING\"], [1530, 227, 0, 343, 5, \"UPSCALE_MODEL\"], [1531, 230, 0, 343, 6, \"FLOAT\"], [1532, 231, 0, 343, 7, \"INT\"], [1533, 232, 0, 343, 8, \"INT\"], [1534, 296, 0, 343, 0, \"IMAGE\"], [1535, 343, 0, 344, 0, \"IMAGE\"], [1536, 309, 1, 199, 0, \"CLIP\"], [1537, 309, 1, 259, 0, \"CLIP\"], [1538, 10, 0, 270, 1, \"VAE\"], [1539, 61, 0, 17, 0, \"MODEL\"], [1540, 61, 0, 207, 0, \"MODEL\"], [1541, 61, 0, 161, 0, \"MODEL\"], [1542, 309, 1, 225, 0, \"CLIP\"], [1543, 22, 0, 157, 1, \"GUIDER\"], [1544, 16, 0, 157, 2, \"SAMPLER\"], [1545, 61, 0, 258, 0, \"MODEL\"], [1546, 61, 0, 198, 0, \"MODEL\"], [1547, 10, 0, 158, 1, \"VAE\"], [1548, 10, 0, 334, 1, \"VAE\"], [1549, 10, 0, 296, 1, \"VAE\"], [1550, 309, 1, 199, 0, \"CLIP\"], [1551, 309, 1, 259, 0, \"CLIP\"], [1552, 10, 0, 270, 1, \"VAE\"], [1553, 61, 0, 17, 0, \"MODEL\"], [1554, 61, 0, 207, 0, \"MODEL\"], [1555, 61, 0, 161, 0, \"MODEL\"], [1556, 22, 0, 157, 1, \"GUIDER\"], [1557, 16, 0, 157, 2, \"SAMPLER\"], [1558, 61, 0, 258, 0, \"MODEL\"], [1559, 61, 0, 198, 0, \"MODEL\"], [1560, 10, 0, 158, 1, \"VAE\"], [1561, 10, 0, 334, 1, \"VAE\"], [1562, 10, 0, 296, 1, \"VAE\"], [1563, 309, 1, 225, 0, \"CLIP\"], [1564, 334, 0, 345, 0, \"IMAGE\"], [1565, 296, 0, 346, 0, \"IMAGE\"], [1567, 347, 0, 346, 1, \"IMAGE\"], [1568, 334, 0, 347, 0, \"*\"], [1569, 309, 1, 259, 0, \"CLIP\"], [1570, 10, 0, 270, 1, \"VAE\"], [1571, 61, 0, 17, 0, \"MODEL\"], [1572, 61, 0, 207, 0, \"MODEL\"], [1573, 61, 0, 161, 0, \"MODEL\"], [1574, 61, 0, 258, 0, \"MODEL\"], [1575, 10, 0, 296, 1, \"VAE\"], [1576, 309, 1, 225, 0, \"CLIP\"], [1577, 309, 1, 259, 0, \"CLIP\"], [1578, 10, 0, 270, 1, \"VAE\"], [1579, 61, 0, 17, 0, \"MODEL\"], [1580, 61, 0, 207, 0, \"MODEL\"], [1581, 61, 0, 161, 0, \"MODEL\"], [1582, 10, 0, 296, 1, \"VAE\"], [1583, 309, 1, 225, 0, \"CLIP\"], [1584, 61, 0, 258, 0, \"MODEL\"], [1585, 309, 1, 259, 0, \"CLIP\"], [1586, 10, 0, 270, 1, \"VAE\"], [1587, 61, 0, 17, 0, \"MODEL\"], [1588, 61, 0, 207, 0, \"MODEL\"], [1589, 61, 0, 161, 0, \"MODEL\"], [1590, 10, 0, 296, 1, \"VAE\"], [1591, 61, 0, 258, 0, \"MODEL\"], [1592, 309, 1, 225, 0, \"CLIP\"], [1593, 309, 1, 259, 0, \"CLIP\"], [1594, 10, 0, 270, 1, \"VAE\"], [1595, 61, 0, 17, 0, \"MODEL\"], [1596, 61, 0, 207, 0, \"MODEL\"], [1597, 61, 0, 161, 0, \"MODEL\"], [1598, 10, 0, 296, 1, \"VAE\"], [1599, 61, 0, 258, 0, \"MODEL\"], [1600, 309, 1, 225, 0, \"CLIP\"]], \"groups\": [{\"title\": \"us\", \"bounding\": [550, 3640, 2320, 2010], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Post Processing\", \"bounding\": [5510, 410, 1110, 1250], \"color\": \"#8A8\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Pass\", \"bounding\": [1480, 880, 1073, 1140], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"1st Pass\", \"bounding\": [450, 1240, 870, 750], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Conditioning\", \"bounding\": [410, 250, 732, 159], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"FLUX Prompt\", \"bounding\": [430, 660, 754, 511], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Set Parameters\", \"bounding\": [400, -300, 733, 526], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"Load FLUX.1\", \"bounding\": [-20, -310, 369, 693], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"ia\", \"bounding\": [1400, 2050, 930, 1540], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.486436280241495, \"offset\": [-300.3939429896591, -426.04800023225357]}, \"workspace_info\": {\"id\": \"IBQmnKsuVAKWZxE4Fo76c\", \"saveLock\": false, \"cloudID\": null, \"coverMediaPath\": null}}, \"version\": 0.4, \"seed_widgets\": {\"25\": 0, \"226\": 1, \"258\": 0, \"313\": 1, \"343\": 1}}}",
            "steps": 15,
            "width": 672,
            "height": 1496,
            "models": [],
            "prompt": "\u3000\u3000In the aftermath of the massive explosion that ripped through the futuristic cityscape, time is fractured and a haunting moment is trapped. The shining shards of chrome plating and neon signs that once symbolised a vibrant, technologically advanced society now pour down like an eerie shower of broken dreams. Twisted metal girders and fragments of sophisticated futuristic architecture are suspended in mid-air, defying gravity as the echoes of the blast echo through the smoke-filled air.\n\nIn the midst of this desolate technological ruin, a woman stands frozen in place. Her silhouette is a stark reminder of human fragility against the backdrop of a shattered future. Her cybernetically enhanced body, once a testament to human ingenuity and progress, now bears the scars of a devastating explosion, wires sparking and circuitry exposed. Her hair, once vibrant, is now covered in soot and dust, framing her face in a mixture of shock and defiance.\n\nBehind her, the giant geometric angel, a symbol of artificial intelligence and the pinnacle of technological progress, is scattered and broken. Its very presence illustrates the destructive power of ambition and technological hubris.\n\nThe scene poignantly expresses the transience of progress and the potential consequences of unstoppable technological progress. Cold, desaturated colours, high contrast and an emphasis on fragmentation amplify the sense of loss and despair, while elements of frozen time and a futuristic setting add a layer of chilling surrealism. The images evoke a powerful and emotionally resonant warning about the possibility of a dystopian future in which the dream of human progress is shattered in the ruins of its own creation.",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 1,
            "modelIds": [],
            "scheduler": "beta",
            "upscalers": [
                "4x_NMKD-Siax_200k.pth",
                "4x_NMKD-Siax_200k.pth"
            ],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": []
        },
        "username": "okamuron",
        "baseModel": ""
    },
    {
        "id": 10350634,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/705f1f54-d6bd-49bb-9b37-3c59fc24ee38/width=1456/705f1f54-d6bd-49bb-9b37-3c59fc24ee38.jpeg",
        "hash": "UAC6cA~p?a4o4:M{9GjZ=rj=9GM|?Hxuj]Io",
        "width": 1456,
        "height": 2624,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-20T22:10:53.734Z",
        "postId": 2262419,
        "stats": {
            "cryCount": 26,
            "laughCount": 134,
            "likeCount": 804,
            "dislikeCount": 0,
            "heartCount": 366,
            "commentCount": 4
        },
        "meta": null,
        "username": "patz65",
        "baseModel": null
    },
    {
        "id": 36996261,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4c8caa4d-ec4f-4ba6-baf3-51f0f3508447/width=1536/4c8caa4d-ec4f-4ba6-baf3-51f0f3508447.jpeg",
        "hash": "UtF?Rs%Lx[Rj_NoftQWB%MRkWBoft7aeRjof",
        "width": 1536,
        "height": 2312,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-28T08:26:17.883Z",
        "postId": 8448487,
        "stats": {
            "cryCount": 37,
            "laughCount": 78,
            "likeCount": 946,
            "dislikeCount": 0,
            "heartCount": 267,
            "commentCount": 2
        },
        "meta": null,
        "username": "Castr0",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 29715042,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8efe7ff5-8747-4ecb-bff1-7fd49ec10e67/width=832/8efe7ff5-8747-4ecb-bff1-7fd49ec10e67.jpeg",
        "hash": "UNDlG??Gx[r=~oxttQV@%fofaeIoozjZaKM|",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-16T13:08:08.476Z",
        "postId": 6648698,
        "stats": {
            "cryCount": 32,
            "laughCount": 90,
            "likeCount": 881,
            "dislikeCount": 0,
            "heartCount": 325,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 373749487,
            "steps": 41,
            "prompt": "Extreme Face Closeup, FredFraiStyle, old grainy analog photo, bad image quality, heavy film grain, monochrome with low key color spots, Create an action scene featuring a intricately wired and mechanical robot wizard with Female head and Long hair in a broad outworn hooded cape shading her eyes, standing in the midst of an DARK desert forest. SHe is executing a powerful spell with her Long orb-staff with a translucent Amber Sphere head that carves a furrow through the sand and enemies on the ground, scattering them away or disintegrating them with the force of the blow. The focus is on the intricate designed luminous orbstaff of the robot in motion, showcasing the reddish blur of light that eye trails with the swift motion of the spell, capturing the dynamic speed of the Magic force. Pressure Wave, floating particles, the Closeup of her face silhouette visible against the backdrop of the setting sun, which shines through parts of her metallic body. Her billowing Linen cape adding to the dramatic effect. The scene is vibrant with atmospheric lighting and cinematic composition. Super Face Closeup",
            "sampler": "Undefined",
            "cfgScale": 5.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-13T1034:33.6854631Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.35,
                    "modelVersionId": 748318,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 756311,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.45,
                    "modelVersionId": 781667,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 816800,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.75,
                    "modelVersionId": 827048,
                    "modelVersionName": "Flux"
                },
                {
                    "type": "lora",
                    "weight": 0.3,
                    "modelVersionId": 814994,
                    "modelVersionName": "FLUX-v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 751598,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.55,
                    "modelVersionId": 766903,
                    "modelVersionName": "V1"
                }
            ]
        },
        "username": "Ajuro",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 40469327,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c6b00ec4-ede4-4684-924a-0d440bddadaa/width=1624/c6b00ec4-ede4-4684-924a-0d440bddadaa.jpeg",
        "hash": "UHBDZ?q[+Z?v.TZ#ITyDo~IoNFS~KjW?R5S3",
        "width": 1624,
        "height": 2368,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-16T17:50:33.071Z",
        "postId": 9221116,
        "stats": {
            "cryCount": 51,
            "laughCount": 73,
            "likeCount": 964,
            "dislikeCount": 0,
            "heartCount": 239,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 13938369098277,
            "Model": "flux_dev",
            "steps": 20,
            "hashes": {
                "model": "2eda627c8a",
                "LORA:FLUX\\Anime v1.3": "0d061b16de",
                "LORA:FLUX\\VividlyReal": "bd3bf33631",
                "LORA:FLUX\\FLUX-daubrez-DB4RZ": "82acd43214"
            },
            "prompt": "(in Otomo Katsuhiro style:1.2), masterpiece, high-quality, A futuristic scout in a sleek angular suit embedded with pulsating circuits, Theyre framed in a glowing urban sprawl of vertical megastructures and floating drones, their visor reflecting a fragmented digital skyline, One hand grips a small high-tech device scanning the area for unseen threats, urban sprawl, circuit suit, digital skyline, (Stylized in neon cyberpunk anime with a sharp high-contrast aesthetic:1.1), (elaborate fine details:1.1), (hyperdetailed:1.1), (intricate details:1.0), (Refined details:1.1), (best quality:1.1), (high resolution:1.2), <lora:FLUX\\Anime v1.3:0.6> <lora:FLUX\\VividlyReal:0.6> <lora:FLUX\\FLUX-daubrez-DB4RZ:0.4>",
            "Version": "ComfyUI",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 3.5,
            "resources": [
                {
                    "hash": "2eda627c8a",
                    "name": "flux_dev",
                    "type": "model"
                }
            ],
            "Model hash": "2eda627c8a"
        },
        "username": "RIDD",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 39157890,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9bf9ad34-d559-44a4-a87b-b7d7538ce4db/width=832/9bf9ad34-d559-44a4-a87b-b7d7538ce4db.jpeg",
        "hash": "U6CGVvWY00-myG-:9ERPo}IuD%MxyYS5DhMy",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-09T11:11:00.000Z",
        "postId": 8935049,
        "stats": {
            "cryCount": 64,
            "laughCount": 87,
            "likeCount": 904,
            "dislikeCount": 0,
            "heartCount": 272,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3239916463,
            "steps": 32,
            "prompt": "(beautiful fantasy landscape), sharp focus, no blur background, ((very detailed)), small rock, (water ripples) reflections, magic castle,  river (pond), elven fairies forest, ((elven fairies village)), stunning nature aquatic environment , enchanted land, (bright sunny sky), (high contrast), cinematic (lights), backlight, (shadows), lens flare, vibrant colors, colorful, [Kelly Green flowers] and leaves, (pretty), (beautiful), loving,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 1,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-09T0734:19.9615359Z",
            "negativePrompt": "(blurry), out of focus, undetailed, (worst quality, low quality, normal quality:2), saturated colors",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 345685,
                    "modelVersionName": "FUSION OG"
                }
            ]
        },
        "username": "ShallowS",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 38082754,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c5f2b34d-2890-4f76-b7d4-475d27ee59a0/width=1152/c5f2b34d-2890-4f76-b7d4-475d27ee59a0.jpeg",
        "hash": "U4O3ty014Z?b006u_24m0v53xl4o1U00mP%#",
        "width": 1152,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-03T10:24:02.898Z",
        "postId": 8696455,
        "stats": {
            "cryCount": 90,
            "laughCount": 113,
            "likeCount": 850,
            "dislikeCount": 0,
            "heartCount": 274,
            "commentCount": 0
        },
        "meta": null,
        "username": "L_A_X",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 29719228,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/65b5977a-175e-4e4e-b670-5468a53c6967/width=832/65b5977a-175e-4e4e-b670-5468a53c6967.jpeg",
        "hash": "UTBVlVR%iat8JzjFNEofEbayN?j[^BWUWVoe",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-16T13:49:48.517Z",
        "postId": 6649841,
        "stats": {
            "cryCount": 38,
            "laughCount": 80,
            "likeCount": 924,
            "dislikeCount": 0,
            "heartCount": 285,
            "commentCount": 3
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3306483466,
            "steps": 40,
            "prompt": "ancientstyle, A surreal, abstract digital landscape stretches before us, where a glitched market looms under a vast, purple and black sky. The medieval merchant lady stands at the market's edge, her teal and blue scales shimmering in the eerie glow. The market, fragmented and distorted, pulses with intricate dot and line patterns, casting hypnotic wavy shapes across the scene. Above, the void stretches endlessly, swirling with vivid, otherworldly hues that blend fluidly with the dark sky.\nThe patterns and colors twist unnaturally, with vibrant psychedelic tones stark against the high-contrast, minimalistic background. Amidst this chaotic yet captivating scenery, the merchant lady gazes into the void, her figure framed by the surreal, flowing motion of the glitching world around her. The strange mix of the distorted market, the alien sky, and the tranquil yet eerie scene creates a visual both majestic and unsettling, where the familiar warps into the unknown in a mesmerizing display. (fluid motion: 2.5) (high contrast: 2.3)",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-16T1345:37.1153502Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 799872,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "idkidkidk_",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 25645523,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c1edee45-848c-4651-a7b8-8df001bc577d/width=832/c1edee45-848c-4651-a7b8-8df001bc577d.jpeg",
        "hash": "UXKBULMx~qxuRPt7xuRjM{Rjt7ofM{WBt7xu",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-24T00:07:00.000Z",
        "postId": 5733386,
        "stats": {
            "cryCount": 40,
            "laughCount": 85,
            "likeCount": 956,
            "dislikeCount": 0,
            "heartCount": 246,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2978907826,
            "steps": 35,
            "prompt": "score_9, score_8_up, score_7_up, photorealistic, rating_safe,\nlower body, green ankle booties, black thighhighs, green dress, perfect legs, simple background, fashion",
            "sampler": "Euler a",
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-08-22T2021:34.3590617Z",
            "negativePrompt": "3d, score_6, score_5, score_4,muscular,watermark, ugly, mutation, lowres, low quality, extra limbs, bad anatomy, poorly drawn, malformed, deformed, blurry, out of focus, noise, dust,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 534642,
                    "modelVersionName": "v2.1 Main + VAE"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 562470,
                    "modelVersionName": "Elegant Booties"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "mattheath869",
        "baseModel": "Pony"
    },
    {
        "id": 39975857,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a393f96e-baf9-432e-864a-74626a1bd3dc/width=832/a393f96e-baf9-432e-864a-74626a1bd3dc.jpeg",
        "hash": "UNIgliIBiw~U^*%14pNH?uIVMyWX.7t5M{%1",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-13T23:34:13.819Z",
        "postId": 9113509,
        "stats": {
            "cryCount": 44,
            "laughCount": 118,
            "likeCount": 935,
            "dislikeCount": 0,
            "heartCount": 231,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 214531940,
            "steps": 25,
            "prompt": "A majestic cat sits proudly on a marble pedestal in an ancient Roman courtyard, bathed in golden sunlight. It wears a centurion helmet with a crimson plume, exuding a commanding presence. Its emerald-green eyes gleam with fierce intelligence, and its helmet is intricately decorated with Roman insignia. Mist rises from the ground, casting an ethereal glow, while red and gold banners wave softly in the background. Tiny helmeted mice gather around in reverence, honoring their legendary feline leader, capturing the grandeur and mystery of ancient Rome",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-13T2330:28.2837714Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                }
            ]
        },
        "username": "Vaevictis",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 26128402,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8e14bcba-dca5-494e-bcb1-b0a6ae22daa3/width=832/8e14bcba-dca5-494e-bcb1-b0a6ae22daa3.jpeg",
        "hash": "UQGSJx9FR+t7_3%M4nV@~qofIURk_3t7Rjt7",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-25T20:41:46.448Z",
        "postId": 5840680,
        "stats": {
            "cryCount": 32,
            "laughCount": 87,
            "likeCount": 917,
            "dislikeCount": 0,
            "heartCount": 290,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3838421157,
            "steps": 40,
            "prompt": "(1girl:1.2),wings,(solo:1.2),color patches,left and right different colors,contrast,with a futuristic wing, mechanical wings,wings, science fiction, eyeshadow, single mechanical arm, gloves, mecha musume, cowboy shot, left black right white, black,gold, silk stockings, hkstyle, style of epic cinematic, amazing quality",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-08-25T1904:39.9068568Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 753642,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "HailoKnight",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 24410234,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9a12607c-a6b6-4b23-98db-f3d857fe7d2f/width=832/9a12607c-a6b6-4b23-98db-f3d857fe7d2f.jpeg",
        "hash": "UOHcuc$#F^J9~7a|Ndj@OWW;nQw_s.f6R+bG",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-15T10:07:56.940Z",
        "postId": 5452811,
        "stats": {
            "cryCount": 32,
            "laughCount": 93,
            "likeCount": 856,
            "dislikeCount": 0,
            "heartCount": 347,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3109308453,
            "steps": 22,
            "prompt": "pumpkin character, Tara McPherson, Jessie Willcox Smith, Vytautas Kairiukstis, Amrita Sher-Gil, Ray Caesar, Havana color | Zinfandel color | Dusky Haze color | Tijolo color | Yellow Sea color",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-08-15T1001:39.0625498Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                }
            ]
        },
        "username": "Loana",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 9746098,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7dffb068-22dc-437e-9f54-b30aaa20c107/width=1664/7dffb068-22dc-437e-9f54-b30aaa20c107.jpeg",
        "hash": "UID7z9;_9^RlsFv}%1so1NEft6xY}sK15mjG",
        "width": 1664,
        "height": 2496,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-12T20:23:35.548Z",
        "postId": 2114611,
        "stats": {
            "cryCount": 36,
            "laughCount": 72,
            "likeCount": 823,
            "dislikeCount": 0,
            "heartCount": 395,
            "commentCount": 2
        },
        "meta": null,
        "username": "Snow_T",
        "baseModel": "SDXL Lightning"
    },
    {
        "id": 31702867,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6a6d7524-75d9-4cb3-9301-02519a6e9a3d/width=832/6a6d7524-75d9-4cb3-9301-02519a6e9a3d.jpeg",
        "hash": "UZI}YLrp%$W=.T-Uxuj[Xot7xajExt-:j]jY",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-28T05:22:33.584Z",
        "postId": 7161379,
        "stats": {
            "cryCount": 63,
            "laughCount": 115,
            "likeCount": 891,
            "dislikeCount": 0,
            "heartCount": 256,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1894668866,
            "extra": {
                "remixOfId": 31702175
            },
            "steps": 14,
            "prompt": "score_4,score_5,score_6,score_7_up,score_8_up,score_9 ((masterpiece,best quality,ultra detailed,highres,HD,4k:1.2)),\nAzure Striker Gunvolt(Main)\n1girl, solo, girl forcus,solo forcus\noutdoor,,\nkurodia,dia kurosawa, black hair, ((green eyes)), blunt bangs,long hair,tattoo,black head gear,black head ornaments,earrings,\nyellow cape,yellow top,white shirt,fingerless gloves,shorts,black shorts,jewelry, \nsmile,light smile,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-28T0526:12.1869024Z",
            "negativePrompt": "(Macho, muscular, old man, fat man,Nostrils,\n,text,yuri,roll one \u0019s eyes:1.5),(worst quality, low quality:1.4), (patreon username, patreon logo, signature, watermark,easynegative,negative_hand-neg, bad-hands-5,low quality,bad-hands-5,extra limbs,missing limb,extra digit,fewer digit,missing digit,missing fingers,mutated hands and fingers,fused limb,bad hands,long neck,long body,bad anatomy,disfigured,deformed,poorly drawn,mutation,extra nippless,extra breasts,disembodied penis,:1.4)",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 828380,
                    "modelVersionName": "v3"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 819843,
                    "modelVersionName": "v1.2"
                },
                {
                    "type": "lora",
                    "weight": 1.5,
                    "modelVersionId": 878321,
                    "modelVersionName": "V.Main"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "tousaku555913485",
        "baseModel": "Pony"
    },
    {
        "id": 20625052,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/15d3474e-cc07-48cd-a887-0c5eda11978d/width=1536/15d3474e-cc07-48cd-a887-0c5eda11978d.jpeg",
        "hash": "UBAJ1uxu:%D$p{xu55Q,PVT09ZIA-pkDivVs",
        "width": 1536,
        "height": 1536,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-20T10:35:19.168Z",
        "postId": 4599461,
        "stats": {
            "cryCount": 37,
            "laughCount": 52,
            "likeCount": 937,
            "dislikeCount": 0,
            "heartCount": 298,
            "commentCount": 2
        },
        "meta": {
            "Size": "512x512",
            "seed": 188386346191853,
            "Model": "Juggernaut_X_RunDiffusion_Hyper",
            "steps": 6,
            "hashes": {
                "model": "010be7341c",
                "LORA:spo_sdxl_10ep_4k-data_lora_webui": "b6c2c16f3e"
            },
            "prompt": "fantasy art of an animated heavy crimson cape worn by a slender faceless shadow with glowing eyes, in a baroque haunted mansion at night, detailed, high resolution <lora:spo_sdxl_10ep_4k-data_lora_webui:1.0>",
            "Version": "ComfyUI",
            "sampler": "Euler",
            "cfgScale": 1,
            "resources": [
                {
                    "name": "spo_sdxl_10ep_4k-data_lora_webui",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "010be7341c",
                    "name": "Juggernaut_X_RunDiffusion_Hyper",
                    "type": "model"
                }
            ],
            "Model hash": "010be7341c"
        },
        "username": "Sajrep",
        "baseModel": "SDXL Hyper"
    },
    {
        "id": 17767485,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b2992ddb-d18b-45d0-a661-125c0b04afc8/width=832/b2992ddb-d18b-45d0-a661-125c0b04afc8.jpeg",
        "hash": "U9DILF^*9ZD+_N^jEME2r;xa-Tw]58NH^M%1",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-30T00:38:17.422Z",
        "postId": 3976308,
        "stats": {
            "cryCount": 27,
            "laughCount": 118,
            "likeCount": 907,
            "dislikeCount": 0,
            "heartCount": 272,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 167401343,
            "steps": 42,
            "prompt": "*Flow in the Name of Love*\n*Channel_42* *\u4e2d* *Broadcasting* *Station_42* \n*Autumn* *Solstice* *Majesty* *Storm* *Irradiant* *Eventide* *Peak* *Starting up* *Going Live* *Online*",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4.2,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-06-29T2315:07.7972514Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 182077,
                    "modelVersionName": "v3"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "Channel_42",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 30164307,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fad51235-4c1a-4036-bdd0-7191e2c7d18b/width=1072/fad51235-4c1a-4036-bdd0-7191e2c7d18b.jpeg",
        "hash": "UoFPywI@t8o}~pI;RPbb-QRkMxWXxtofM|f,",
        "width": 1072,
        "height": 1880,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-19T01:11:18.101Z",
        "postId": 6748692,
        "stats": {
            "cryCount": 55,
            "laughCount": 139,
            "likeCount": 838,
            "dislikeCount": 0,
            "heartCount": 291,
            "commentCount": 0
        },
        "meta": {
            "seed": 1836,
            "vaes": [
                "FLUX1\\ae.sft"
            ],
            "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 40, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 1836}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 5.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 768, \"height\": 1344, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": 768, \"height\": 1344, \"model\": [\"52\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"51\": {\"inputs\": {\"lora_name\": \"flux1\\\\realism_lora_comfy flux_converted.safetensors\", \"strength_model\": 0.85, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"52\": {\"inputs\": {\"lora_name\": \"flux1\\\\XT404.BOOBS-Bastic.XXL.safetensors\", \"strength_model\": 0.5, \"strength_clip\": 1.0, \"model\": [\"51\", 0], \"clip\": [\"51\", 1]}, \"class_type\": \"LoraLoader\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.1, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"52\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"71\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.35000000000000003, \"alpha\": 0.35000000000000003, \"image\": [\"72\", 0]}, \"class_type\": \"ImageSharpen\"}, \"72\": {\"inputs\": {\"hdr_intensity\": 0.5, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"69\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"73\": {\"inputs\": {\"intensity\": 0.12, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"71\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.35000000000000003, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 25, \"denoise\": 0.2, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"A mysterious beauty is the focal point of this intricate digital artwork, her shining silver hair barely visible beneath a hooded jacket. The jacket is made of a reflective, almost metallic material that catches and refracts light in complex ways, creating a visually stunning texture. The figure\\u2019s eyes are hidden in the shadows of the hood, adding to the air of mystery and intrigue. The background features a dramatic, on a cold mountain summit, cloud-filled sky, rich with vibrant colors and swirling patterns, as if nature itself is in turmoil or transition. The lighting is intense, with beams of light cutting through the clouds, casting dynamic shadows across the figure\\u2019s face and clothing. The overall composition is highly complex, with rich, saturated colors and extreme detail, making every element\\u2014from the texture of the jacket to the vibrant sky\\u2014stand out with striking clarity and depth.\\n\\nSitting on the ground with knees drawn up and hands resting on them.\", \"clip\": [\"52\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"109\": {\"inputs\": {\"tile_size\": 512}, \"class_type\": \"VAEEncodeTiled\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"141\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"144\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"147\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"149\": {\"inputs\": {\"scale_method\": \"lanczos\", \"scale_factor\": 1.5, \"use_tiled_vae\": false}, \"class_type\": \"LatentPixelScale\"}}, \"workflow\": {\"last_node_id\": 149, \"last_link_id\": 314, \"nodes\": [{\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1300, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 293, \"1\": -192}, \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 153}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 126, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 768, 1344]}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1801, \"1\": 21}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 159}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 355, \"1\": 764}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 112, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [768, 1344, 1]}, {\"id\": 109, \"type\": \"VAEEncodeTiled\", \"pos\": {\"0\": -510, \"1\": 806}, \"size\": {\"0\": 248.89723205566406, \"1\": 78}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncodeTiled\"}, \"widgets_values\": [512]}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1813, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [260, 299], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 117, \"type\": \"SaveImagePlus\", \"pos\": {\"0\": 4366, \"1\": 456}, \"size\": {\"0\": 832.2413940429688, \"1\": 1183.025634765625}, \"flags\": {}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 282}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImagePlus\"}, \"widgets_values\": [\"ComfyUI\", \"JPEG\", true]}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": 2156, \"1\": 435}, \"size\": {\"0\": 504.7402648925781, \"1\": 472.86358642578125}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 5, \"1\": 172}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [304], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [294, 305], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [295, 306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [296, 307], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186, 297, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3079, \"1\": -575}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 311}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 148, \"type\": \"SaveImage\", \"pos\": {\"0\": 3061, \"1\": -483}, \"size\": {\"0\": 281.4468078613281, \"1\": 480.5931091308594}, \"flags\": {}, \"order\": 64, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 313}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 146, \"type\": \"DZ_Face_Detailer\", \"pos\": {\"0\": 2658, \"1\": -843}, \"size\": {\"0\": 309.8262939453125, \"1\": 842.9425659179688}, \"flags\": {}, \"order\": 59, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 305}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 306}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 307}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DZ_Face_Detailer\"}, \"widgets_values\": [1, \"fixed\", 20, 4, \"euler\", \"sgm_uniform\", 0.5, 32, \"face\", \"dilate\", 3, 3]}, {\"id\": 142, \"type\": \"SaveImage\", \"pos\": {\"0\": 3204, \"1\": 556}, \"size\": {\"0\": 813.5270385742188, \"1\": 1236.560546875}, \"flags\": {}, \"order\": 66, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 300}], \"outputs\": [], \"title\": \"FinalPass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": 8, \"1\": 851}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": 19, \"1\": 1194}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 140, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2769, \"1\": 86}, \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 63, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 294}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 295}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 296}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 297}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 298}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.5, 1, \"fixed\", 25, 3, \"euler\", \"sgm_uniform\", 0.1, \"Linear\", 1344, 768, 24, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 700, \"1\": 54}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 133, \"1\": 321}, \"size\": [214.54766211692385, 58], \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 900, \"1\": 94}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 892, \"1\": 570}, \"size\": [210, 106], \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 149, \"type\": \"LatentPixelScale\", \"pos\": {\"0\": 465, \"1\": 1483}, \"size\": [243.60000610351562, 146], \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model_opt\", \"type\": \"UPSCALE_MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentPixelScale\"}, \"widgets_values\": [\"lanczos\", 1.5, false]}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1512, \"1\": -35}, \"size\": [140, 46], \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 879, \"1\": 949}, \"size\": [210, 130], \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.1, 10, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 820, \"1\": 1282}, \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1473, \"1\": 40}, \"size\": {\"0\": 284.1048889160156, \"1\": 619.9912719726562}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 287, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [159, 308], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 507, \"1\": 1336}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 314}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1192, \"1\": 46}, \"size\": [243.68327178665822, 82], \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1291, \"1\": 1330}, \"size\": {\"0\": 848.655029296875, \"1\": 899.4495849609375}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 2206, \"1\": 1366}, \"size\": {\"0\": 848.405029296875, \"1\": 898.4495849609375}, \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 474, \"1\": 893}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 879, \"1\": 1133}, \"size\": [210, 82], \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 486, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 40, 1]}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 893, \"1\": 720}, \"size\": [210, 178], \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 314], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 141, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2036, \"1\": 41}, \"size\": {\"0\": 428.9556884765625, \"1\": 78}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": 34, \"1\": 42}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [252], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1804, \"1\": 560}, \"size\": [235.18065691847278, 106], \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 25, 0.2], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 403, \"1\": 39}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [5], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [1836, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1812, \"1\": 375}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168, 282], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.12, 10, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 51, \"type\": \"LoraLoader\", \"pos\": {\"0\": -119, \"1\": 616}, \"size\": {\"0\": 462.208251953125, \"1\": 134.61793518066406}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 252}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 304}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [125], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [301], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\realism_lora_comfy flux_converted.safetensors\", 0.85, 1]}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1212, \"1\": 178}, \"size\": [210, 58], \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [287], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 617, \"1\": 645}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1344, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 374, \"1\": 646}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [112, 115], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [768, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 52, \"type\": \"LoraLoader\", \"pos\": {\"0\": -116, \"1\": 432}, \"size\": {\"0\": 455.3192138671875, \"1\": 131.6434326171875}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 125}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 301}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [126], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [153], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\XT404.BOOBS-Bastic.XXL.safetensors\", 0.5, 1]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 948, \"1\": 38}, \"size\": [247.96474163161452, 470.6349560288795], \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 2058, \"1\": 261}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 260}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.35000000000000003, 0.35000000000000003], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 382, \"1\": 140}, \"size\": {\"0\": 488.2522277832031, \"1\": 387.7407531738281}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"A mysterious beauty is the focal point of this intricate digital artwork, her shining silver hair barely visible beneath a hooded jacket. The jacket is made of a reflective, almost metallic material that catches and refracts light in complex ways, creating a visually stunning texture. The figure\\u2019s eyes are hidden in the shadows of the hood, adding to the air of mystery and intrigue. The background features a dramatic, on a cold mountain summit, cloud-filled sky, rich with vibrant colors and swirling patterns, as if nature itself is in turmoil or transition. The lighting is intense, with beams of light cutting through the clouds, casting dynamic shadows across the figure\\u2019s face and clothing. The overall composition is highly complex, with rich, saturated colors and extreme detail, making every element\\u2014from the texture of the jacket to the vibrant sky\\u2014stand out with striking clarity and depth.\\n\\nSitting on the ground with knees drawn up and hands resting on them.\"]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [112, 34, 0, 27, 0, \"INT\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [125, 51, 0, 52, 0, \"MODEL\"], [126, 52, 0, 30, 0, \"MODEL\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [153, 52, 1, 49, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [159, 42, 0, 69, 0, \"LATENT\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [252, 12, 0, 51, 0, \"MODEL\"], [260, 72, 0, 71, 0, \"IMAGE\"], [282, 73, 0, 117, 0, \"IMAGE\"], [285, 75, 0, 59, 0, \"IMAGE\"], [287, 134, 0, 42, 2, \"SAMPLER\"], [288, 62, 0, 41, 0, \"IMAGE\"], [294, 96, 0, 140, 1, \"MODEL\"], [295, 64, 0, 140, 2, \"CONDITIONING\"], [296, 65, 0, 140, 3, \"CONDITIONING\"], [297, 70, 0, 140, 4, \"VAE\"], [298, 141, 0, 140, 5, \"UPSCALE_MODEL\"], [299, 72, 0, 140, 0, \"IMAGE\"], [300, 140, 0, 142, 0, \"IMAGE\"], [301, 51, 1, 52, 1, \"CLIP\"], [304, 11, 0, 51, 1, \"CLIP\"], [305, 96, 0, 146, 0, \"MODEL\"], [306, 64, 0, 146, 1, \"CONDITIONING\"], [307, 65, 0, 146, 2, \"CONDITIONING\"], [308, 42, 0, 146, 3, \"LATENT\"], [310, 70, 0, 146, 4, \"VAE\"], [311, 146, 0, 147, 0, \"LATENT\"], [312, 81, 0, 147, 1, \"VAE\"], [313, 147, 0, 148, 0, \"IMAGE\"], [314, 61, 0, 77, 1, \"IMAGE\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.7715610000000022, \"offset\": [-730.2569948097515, -85.8761465135012]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}, \"140\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"146\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"140\": 1, \"146\": 0}}}",
            "steps": 40,
            "models": [],
            "prompt": "A mysterious beauty is the focal point of this intricate digital artwork, her shining silver hair barely visible beneath a hooded jacket. The jacket is made of a reflective, almost metallic material that catches and refracts light in complex ways, creating a visually stunning texture. The figure\u2019s eyes are hidden in the shadows of the hood, adding to the air of mystery and intrigue. The background features a dramatic, on a cold mountain summit, cloud-filled sky, rich with vibrant colors and swirling patterns, as if nature itself is in turmoil or transition. The lighting is intense, with beams of light cutting through the clouds, casting dynamic shadows across the figure\u2019s face and clothing. The overall composition is highly complex, with rich, saturated colors and extreme detail, making every element\u2014from the texture of the jacket to the vibrant sky\u2014stand out with striking clarity and depth.\n\nSitting on the ground with knees drawn up and hands resting on them.",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 5,
            "modelIds": [],
            "scheduler": "sgm_uniform",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "flux1\\realism_lora_comfy flux_converted.safetensors",
                    "type": "lora",
                    "strength": 0.85,
                    "strengthClip": 1
                },
                {
                    "name": "flux1\\XT404.BOOBS-Bastic.XXL.safetensors",
                    "type": "lora",
                    "strength": 0.5,
                    "strengthClip": 1
                }
            ]
        },
        "username": "salammy",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 21083083,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3b573797-5b5d-471d-b0b4-6da003e44fc4/width=832/3b573797-5b5d-471d-b0b4-6da003e44fc4.jpeg",
        "hash": "UaKdb@Rk?^xa-ps:OEbHVtayIoW=-pjFaxof",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-23T21:52:00.564Z",
        "postId": 4701910,
        "stats": {
            "cryCount": 22,
            "laughCount": 50,
            "likeCount": 987,
            "dislikeCount": 0,
            "heartCount": 264,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1597658035,
            "steps": 42,
            "prompt": "photorealistic, cells, amazing quality, masterpiece, best quality, hyper detailed, ultra detailed, UHD, perfect anatomy, portrait, dof, hyper-realism, majestic, awesome, inspiring, Create a close-up image of a cyberpunk assassin with translucent red and yellow-puple burning-head, wearing a white linen hanfu with a high collar. wielding a giant translucent amber sword, His long, disheveled long translucent ethereal hair blows in the wind. The face grins directly at the camera with a menacingly evil expression., with a white background, cinematic composition, soft shadows, very detailed, hd, RAW photograph, masterpiece, top quality, best quality, official art,highest detailed, atmospheric lighting, cinematic composition, complex multiple subjects, 4k HDR, vibrant, highly detailed, Leica Q2 with Summilux 35mm f/1.2 ASPH, Ultra High Resolution, wallpaper, 8K, Rich texture details, hyper detailed, simple background, epic composition, high quality , (8k, RAW photo, highest quality), hyperrealistic,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 3,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-07-22T1005:23.9244299Z",
            "negativePrompt": "NSFW,low quality,lowres,worst quality,bad anatomy,bad hands,bad feet,logo,text,extra arms,extra ears,extra eyes,extra mouth,multiple wings,extra face,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 128078,
                    "modelVersionName": "v1.0 VAE fix"
                },
                {
                    "type": "lora",
                    "weight": 0.95,
                    "modelVersionId": 663567,
                    "modelVersionName": "V01"
                },
                {
                    "type": "lora",
                    "weight": 0.85,
                    "modelVersionId": 413566,
                    "modelVersionName": "v0.1"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 238330,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 129692,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 240274,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "Ajuro",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 14400645,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e7453a85-930c-47d8-9983-f77d0b43432e/width=832/e7453a85-930c-47d8-9983-f77d0b43432e.jpeg",
        "hash": "U37nXN-C-#4s.lN2%E9H72EO%LbYwHxBi%My",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-02T22:21:25.073Z",
        "postId": 3197503,
        "stats": {
            "cryCount": 55,
            "laughCount": 96,
            "likeCount": 868,
            "dislikeCount": 0,
            "heartCount": 304,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 582623998,
            "steps": 45,
            "prompt": "Create an intricate diorama featuring a photorealistic depiction of a single songbird perched on a mossy branch. The bird, with its rich brown feathers, should gaze directly into the camera, creating an endearing expression.\nThe surrounding foliage adds depth to the scene, with vibrant neon hues and cinematic lighting enhancing the intricate details. Render the image in a holographic digital style, capturing the bioluminescent glow that illuminates the bird and its surroundings.\nEnsure the setting includes circular windows with warm light filtering through, giving the impression of a bioluminescent creature. The overall composition should be a true masterpiece, with UHD resolution and studio-quality detail. Pay painstaking attention to every element, making it a standout piece with high detail and incredibly detailed textures.\nThis stunning, lifelike scene should evoke a sense of wonder and awe, blending the natural beauty of the songbird with the fantastical elements of its bioluminescent environment.",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-06-02T2106:51.5606097Z",
            "negativePrompt": "(face asymmetry, eyes asymmetry, deformed eyes, open mouth)",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 490254,
                    "modelVersionName": "v7.0"
                },
                {
                    "type": "vae",
                    "weight": 1,
                    "modelVersionId": 333245,
                    "modelVersionName": "SDXL-VAE"
                }
            ]
        },
        "username": "ArtttuS",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 14080415,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/11bfc7b0-fdef-45fa-b2a5-4496e69d842a/width=1664/11bfc7b0-fdef-45fa-b2a5-4496e69d842a.jpeg",
        "hash": "UHFM*A}[1wJ9;3wJX8s.iwI:J,xGKPX8niR*",
        "width": 1664,
        "height": 2432,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-30T23:40:20.144Z",
        "postId": 3123261,
        "stats": {
            "cryCount": 58,
            "laughCount": 74,
            "likeCount": 883,
            "dislikeCount": 0,
            "heartCount": 308,
            "commentCount": 1
        },
        "meta": null,
        "username": "_degenerativeai_",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 23044603,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8078e993-081d-45fb-9283-ff9222413c2f/width=832/8078e993-081d-45fb-9283-ff9222413c2f.jpeg",
        "hash": "U8AmxP%$00My~ps84oIq?a$#D*NL^*tQIUR*",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-06T15:19:49.216Z",
        "postId": 5132240,
        "stats": {
            "cryCount": 61,
            "laughCount": 191,
            "likeCount": 821,
            "dislikeCount": 0,
            "heartCount": 249,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1786737330,
            "steps": 25,
            "prompt": "photorealistic picture of a sad cat, crying, poverty, beggar cat, delapidated city alleyway, A sign that says \"will meow for buzz\" next to cat,",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-08-06T1519:03.5257167Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "FLUX.1 [Dev]"
                }
            ]
        },
        "username": "Snapdragon",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 40600497,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1516c890-1bad-4c3b-bce2-d72e1d8e2ff7/width=832/1516c890-1bad-4c3b-bce2-d72e1d8e2ff7.jpeg",
        "hash": "UADaAF}q}Ew{^M=wNuJ8}XkBAEWX^4$PAENv",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-17T11:37:20.613Z",
        "postId": 9250434,
        "stats": {
            "cryCount": 55,
            "laughCount": 95,
            "likeCount": 909,
            "dislikeCount": 0,
            "heartCount": 262,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 279557235,
            "extra": {
                "remixOfId": 40448320
            },
            "steps": 30,
            "prompt": "A close-up, highly detailed digital painting of a small black kitten amids tulips. its head is slightly tilted to the left, gazing directly at the viewer with large, expressive teal eyes. it wears a tiny black tophat on its head.A single pink butterfly is on its nose, The butterflies surrounding her are monarch butterflies with pink bodies featuring intricate red and yellow patterns on their wings. They appear to be interacting gently with the cat, some suspended in flight around her. The background features a warm, golden-red gradient, softly lit to create a dreamy, ethereal atmosphere. The lighting is soft and diffused, casting the cats shadow,creating gentle shadows that add depth and dimension to the portrait. The overall composition is balanced and centered, focusing on the intimate interaction between the cat and the butterflies. The serene expression and the whimsical presence of the butterflies contribute to a magical and tranquil mood.",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-17T1135:18.6799897Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.2,
                    "modelVersionId": 737325,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.35,
                    "modelVersionId": 757030,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 791149,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 863655,
                    "modelVersionName": "Balance_v2.0"
                },
                {
                    "type": "lora",
                    "weight": 0.55,
                    "modelVersionId": 951509,
                    "modelVersionName": "Variant 2"
                }
            ]
        },
        "username": "Meower2024",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 38918807,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cd7b65bb-b961-466e-98bc-e59da43096fc/width=832/cd7b65bb-b961-466e-98bc-e59da43096fc.jpeg",
        "hash": "U5BVhI4W4;~n}?=0E3Nu03^$$*9bIWoJ%1t6",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-08T00:01:21.824Z",
        "postId": 8882209,
        "stats": {
            "cryCount": 44,
            "laughCount": 87,
            "likeCount": 891,
            "dislikeCount": 0,
            "heartCount": 299,
            "commentCount": 1
        },
        "meta": null,
        "username": "Rhailo",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 29817639,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8c1b1bc5-5b99-4acf-8570-12546105423c/width=832/8c1b1bc5-5b99-4acf-8570-12546105423c.jpeg",
        "hash": "UDHd,Mak4T,V-@-B^jag4TxG7#tl8{%gK4NH",
        "width": 832,
        "height": 1248,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-17T03:08:59.750Z",
        "postId": 6671697,
        "stats": {
            "cryCount": 25,
            "laughCount": 76,
            "likeCount": 874,
            "dislikeCount": 0,
            "heartCount": 346,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1248",
            "seed": 192779,
            "steps": 30,
            "hashes": {
                "model": "67ab2fd8ec",
                "embed:zPDXL": "31a5da9018",
                "LORA:SDXLFaeTastic2400": "1cf798aca8",
                "LORA:Expressive_H-000001": "7b53da0391",
                "LORA:PinkBuildingsPDXL_v2": "773024571b"
            },
            "prompt": "score_9, score_8_up, score_8,   pnkBldng, sky, day, cloud, tree, blue sky, no humans, stairs, mountain, fence, path,  BREAK,  blooming stars, luminescent petals, otherworldly fragrance blurry background, (glowwave:1.1), BREAK,  embedding:zPDXL, Expressiveh,   <lora:PinkBuildingsPDXL_v2:0.6>,  <lora:SDXLFaeTastic2400:0.5>,  <lora:Expressive_H-000001:0.4>,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 5,
            "resources": [
                {
                    "name": "PinkBuildingsPDXL_v2",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "name": "SDXLFaeTastic2400",
                    "type": "lora",
                    "weight": 0.5
                },
                {
                    "name": "Expressive_H-000001",
                    "type": "lora",
                    "weight": 0.4
                }
            ],
            "Model hash": "67ab2fd8ec",
            "negativePrompt": "text, bad hands, missing fingers, long torso, (signature:1), score_6, score_5, score_4, busty, ugly face, mutated hands, low res, blurry face, black and white,",
            "ponyDiffusionV6XL Version": "ComfyUI"
        },
        "username": "CitronLegacy",
        "baseModel": "Pony"
    },
    {
        "id": 25937901,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d6606ddf-de5a-463c-9aef-139fe29fe551/width=768/d6606ddf-de5a-463c-9aef-139fe29fe551.jpeg",
        "hash": "UGCP;19bEKxZ~nIWIUt6xpR*RRt6acf*oNWB",
        "width": 768,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-24T17:14:13.569Z",
        "postId": 5799088,
        "stats": {
            "cryCount": 45,
            "laughCount": 260,
            "likeCount": 728,
            "dislikeCount": 0,
            "heartCount": 288,
            "commentCount": 9
        },
        "meta": {
            "seed": 1574388083,
            "vaes": [],
            "comfy": "{\"prompt\": {\"10001\": {\"class_type\": \"ECHOCheckpointLoaderSimple\", \"inputs\": {\"ckpt_name\": \"EMS-446170-EMS.safetensors\"}, \"_properties\": null}, \"10004\": {\"class_type\": \"LoraTagLoader\", \"inputs\": {\"clip\": [\"10001\", 1], \"model\": [\"10001\", 0], \"text\": \"ECHO_EMPTY\"}, \"_properties\": null}, \"10007\": {\"class_type\": \"EmptySD3LatentImage\", \"inputs\": {\"batch_size\": 2, \"height\": 1152, \"width\": 768}, \"_properties\": null}, \"10019\": {\"class_type\": \"CLIPTextEncode\", \"inputs\": {\"clip\": [\"10004\", 1], \"text\": \"Hybrid between a house sparrow and a cow, the small, agile body of a house sparrow with the head of a cow, perched on a tree branch, hyper-realistic, action scene, cinematic, perfect textures, tilt-shift effect.\", \"token_normalization\": \"none\", \"weight_interpretation\": \"comfy\"}, \"_properties\": null}, \"10020\": {\"class_type\": \"CLIPTextEncode\", \"inputs\": {\"clip\": [\"10004\", 1], \"text\": \"boring,,dull\", \"token_normalization\": \"none\", \"weight_interpretation\": \"comfy\"}, \"_properties\": null}, \"10030\": {\"class_type\": \"FluxGuidance\", \"inputs\": {\"conditioning\": [\"10019\", 0], \"guidance\": 3.5}, \"_properties\": null}, \"11001\": {\"class_type\": \"KSampler\", \"inputs\": {\"cfg\": 1.0, \"denoise\": 1.0, \"ensd\": 31337, \"latent_image\": [\"10007\", 0], \"model\": [\"10004\", 0], \"negative\": [\"10020\", 0], \"positive\": [\"10030\", 0], \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"seed\": 1574388083, \"seed_mode\": \"A1111\", \"steps\": 25}, \"_properties\": null}, \"11016\": {\"class_type\": \"VAEDecode\", \"inputs\": {\"samples\": [\"11001\", 0], \"vae\": [\"10001\", 2]}, \"_properties\": null}, \"12004\": {\"class_type\": \"SaveImage\", \"inputs\": {\"filename_prefix\": \"765562458768161197\", \"images\": [\"11016\", 0]}, \"_properties\": null}}, \"workflow\": undefined}",
            "steps": 25,
            "width": 768,
            "height": 1152,
            "models": [],
            "prompt": "Hybrid between a house sparrow and a cow, the small, agile body of a house sparrow with the head of a cow, perched on a tree branch, hyper-realistic, action scene, cinematic, perfect textures, tilt-shift effect.",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 1,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "negativePrompt": "boring,,dull",
            "additionalResources": []
        },
        "username": "L10n_H34r7",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 13166403,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3ffcc25f-1d84-40e5-a350-17fc6eab41c7/width=896/3ffcc25f-1d84-40e5-a350-17fc6eab41c7.jpeg",
        "hash": "UGBNJ?t6D%xu_LxtM{V[-:oeIURj-:ofM{t7",
        "width": 896,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-21T17:11:28.241Z",
        "postId": 2911354,
        "stats": {
            "cryCount": 65,
            "laughCount": 124,
            "likeCount": 839,
            "dislikeCount": 0,
            "heartCount": 293,
            "commentCount": 3
        },
        "meta": null,
        "username": "alerus1995",
        "baseModel": ""
    },
    {
        "id": 8984542,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b5fce373-a558-4356-ad9d-0f82f599b0c0/width=832/b5fce373-a558-4356-ad9d-0f82f599b0c0.jpeg",
        "hash": "UECZRs~q?uk=_4.R%4o~x]%Mxu%MoyWEX7t6",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-02T00:04:43.411Z",
        "postId": 1940717,
        "stats": {
            "cryCount": 58,
            "laughCount": 138,
            "likeCount": 792,
            "dislikeCount": 0,
            "heartCount": 333,
            "commentCount": 1
        },
        "meta": {
            "VAE": "sdxlVAE_sdxlVAE.safetensors",
            "Size": "832x1216",
            "seed": 4174001926,
            "Model": "proteus_v04beta",
            "steps": 50,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "f5a35025a2"
            },
            "prompt": "masterpiece, best quality, 8k, professional , by famous artist , trending on artstation, intricated details, detailed,   realsitic, boekh , photorealistic,  dark shadows, natural light, dramatic,  source_realistic, zPDXL, Gazlowe - The Goblin Tinker, a clever and inventive goblin engineer, wearing goggles and a toolbelt.",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 6.5,
            "clipSkip": 2,
            "TI hashes": {
                "zPDXL": "c1fcf5eef414",
                "zPDXL-neg": "31a5da9018b9"
            },
            "resources": [
                {
                    "hash": "f5a35025a2",
                    "name": "proteus_v04beta",
                    "type": "model"
                }
            ],
            "Model hash": "f5a35025a2",
            "negativePrompt": "poor quality, ugly, poor drawed hands, blury, wanished zPDXL-neg"
        },
        "username": "Atryda",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 1990446,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fd2a6c34-5489-4c1d-8a9d-5e56acb46760/width=1208/fd2a6c34-5489-4c1d-8a9d-5e56acb46760.jpeg",
        "hash": "U4E.IbL}7#0L00-p?E$+O@00xa~BYQ4T^j9a",
        "width": 1208,
        "height": 888,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-13T23:54:56.469Z",
        "postId": 489741,
        "stats": {
            "cryCount": 52,
            "laughCount": 632,
            "likeCount": 470,
            "dislikeCount": 0,
            "heartCount": 167,
            "commentCount": 23
        },
        "meta": {
            "Size": "1208x888",
            "seed": 2453653541,
            "Model": "dreamshaper",
            "steps": 40,
            "hashes": {
                "model": "0f1b80cfe8"
            },
            "prompt": "barry allen the flash on wheelchair moving at supersonic speed creating flame trails, speed trails, motion blur, electricity speed outdoor, realistic highly detailed cinematic cinematography, movie shots footage,",
            "Version": "1.5.1",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "0f1b80cfe8",
                    "name": "dreamshaper",
                    "type": "model"
                }
            ],
            "Model hash": "0f1b80cfe8",
            "negativePrompt": "ugly, bad, sketch"
        },
        "username": "noa",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 25983099,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/90ac9626-f9a6-4269-b46b-7f951dec0b56/width=1664/90ac9626-f9a6-4269-b46b-7f951dec0b56.jpeg",
        "hash": "UPG9XR?JG^%hGIJ7xwRh9Gxv_4wbt:r=ahng",
        "width": 1664,
        "height": 2496,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-24T23:51:44.154Z",
        "postId": 5808532,
        "stats": {
            "cryCount": 26,
            "laughCount": 83,
            "likeCount": 909,
            "dislikeCount": 0,
            "heartCount": 302,
            "commentCount": 0
        },
        "meta": {
            "RNG": "CPU",
            "VAE": "sdxl_vae.safetensors",
            "Size": "832x1248",
            "seed": 572776453,
            "Model": "honeyMixXLHighContrast_v1",
            "steps": 28,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "d39f81730a",
                "lora:akenohimejima-pdxl-nvwls-v1-000005": "52bc80544a88"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime, 1girl, solo, <lora:akenohimejima-pdxl-nvwls-v1-000005:1> dxdAH, black hair, ponytail, very long hair, purple eyes, hair ribbon, white kimono, red hakama, hakama skirt, detached sleeves, large breasts, lake, mountain, blue sky, landscape, upper body, from side, looking at you, smile",
            "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
            "sampler": "Euler a",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "52bc80544a88",
                    "name": "akenohimejima-pdxl-nvwls-v1-000005",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "d39f81730a",
                    "name": "honeyMixXLHighContrast_v1",
                    "type": "model"
                }
            ],
            "Model hash": "d39f81730a",
            "Hires steps": "10",
            "Hires upscale": "2",
            "Schedule type": "Automatic",
            "Hires upscaler": "4x-AnimeSharp",
            "negativePrompt": "monochrome, greyscale",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.4.2",
            "Denoising strength": "0.5",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "novowels",
        "baseModel": "Pony"
    },
    {
        "id": 23782032,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cf3590ee-a385-4d3d-b4f3-ace1bcead2a0/width=832/cf3590ee-a385-4d3d-b4f3-ace1bcead2a0.jpeg",
        "hash": "UJCi?]Mx9Dx[*HIUIA%MyCaiMxoc?0R%WAs:",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-11T11:55:24.404Z",
        "postId": 5304341,
        "stats": {
            "cryCount": 34,
            "laughCount": 68,
            "likeCount": 949,
            "dislikeCount": 0,
            "heartCount": 268,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 205897244,
            "steps": 30,
            "prompt": "a centered below shot high detailed digital art illustration of a jedi knight in a walking pose holding with 2 purple light-sabers, wearing grey ripped dirty jedi tunic dripping with no sleeves and bare-arms,  looking at viewer with angry face, bald young girl, black gloves. volumetric light from above, rim lighting,\nthe background is a foreign planet with giant rocks,\nhigh grass in the wind, rain, storm, rainy day with dark clouds",
            "sampler": "Undefined",
            "cfgScale": 4,
            "clipSkip": 1,
            "resources": [],
            "Created Date": "2024-08-11T1112:03.8523650Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                }
            ]
        },
        "username": "cobrecht",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 28269256,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ba9ccdbc-85fa-4ab5-a5d5-e75bc6d07ff7/width=1800/ba9ccdbc-85fa-4ab5-a5d5-e75bc6d07ff7.jpeg",
        "hash": "UYHnB5kC-VsB}sWXr=ni+|ayIVWCrFn$JBfk",
        "width": 6656,
        "height": 9728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-07T22:07:06.599Z",
        "postId": 6324399,
        "stats": {
            "cryCount": 41,
            "laughCount": 100,
            "likeCount": 895,
            "dislikeCount": 0,
            "heartCount": 282,
            "commentCount": 3
        },
        "meta": {
            "Size": "832x1216",
            "seed": 887516745,
            "Model": "obsidianpdxl_V1",
            "steps": 30,
            "hashes": {
                "model": "91b62eab7b",
                "lora:f3nn3rXLP": "31729bd2b7d6",
                "lora:ral-dissolve": "f2854b318c81",
                "lora:add-detail-xl": "9c783c8ce46c"
            },
            "prompt": "zPDXL3, score_9, score_8_up, score_7_up, score_6_up, source_anime,1girl, wide hips, glowing eyes, freckles, smile, looking at viewer,, standing,BREAK  <lora:add-detail-xl:0.8> <lora:f3nn3rXLP:0.6> f3nn3r, colourful, pink, blue, black, red, trippy, abstract, abstract background, particles, colorful, bright colors, <lora:ral-dissolve:0.8> ral-dissolve , black armor,glitter cape,xl large gauntlets",
            "Version": "v1.10.1",
            "sampler": "Euler a",
            "Template": {
                "f3nn3rXLP": "0.6> f3nn3r",
                "ral-dissolve": "0.8> ral-dissolve"
            },
            "cfgScale": 5.5,
            "clipSkip": 2,
            "TI hashes": {
                "zPDXL3": "1727c6cddf61"
            },
            "resources": [
                {
                    "hash": "9c783c8ce46c",
                    "name": "add-detail-xl",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "31729bd2b7d6",
                    "name": "f3nn3rXLP",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "hash": "f2854b318c81",
                    "name": "ral-dissolve",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "91b62eab7b",
                    "name": "obsidianpdxl_V1",
                    "type": "model"
                }
            ],
            "Model hash": "91b62eab7b",
            "Hires steps": "20",
            "Hires upscale": "2",
            "Schedule type": "Automatic",
            "Hires upscaler": "R-ESRGAN 4x+ Anime6B",
            "negativePrompt": "score_6, score_5, score_4, source_pony, (worst quality:1.2), (low quality:1.2), (normal quality:1.2), lowres, bad anatomy, bad hands, signature, watermarks, ugly, imperfect eyes, skewed eyes, unnatural face, unnatural body, error, extra limb, missing limbs, painting by bad-artist, 3d art, nipple ring, extra hands, extra fingers, tan lines, sitting on other people, blushing, colored eyeglasses lens, looking at the viewer, bra,",
            "Negative Template": {
                "(low quality": "1.2)",
                "(worst quality": "1.2)",
                "(normal quality": "1.2)"
            },
            "Denoising strength": "0.3"
        },
        "username": null,
        "baseModel": "Pony"
    },
    {
        "id": 25668114,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f8b36e59-edac-4133-ac68-5d37a94b1445/width=896/f8b36e59-edac-4133-ac68-5d37a94b1445.jpeg",
        "hash": "UF98G4.SRiRP?^x]IARPxtV@MxWBx]kCRPax",
        "width": 896,
        "height": 1088,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-23T00:49:48.995Z",
        "postId": 5738346,
        "stats": {
            "cryCount": 29,
            "laughCount": 88,
            "likeCount": 897,
            "dislikeCount": 0,
            "heartCount": 304,
            "commentCount": 2
        },
        "meta": {
            "prompt": "8k wallpaper of a female drow ranger, with dark ashy skin and long white hair wearing intricate elven chainmail, with a bow and quiver on her back, in a dark forest with spiderwebs hanging in the trees, 8k photo, cinematic, dark fantasy, highly detailed"
        },
        "username": "leinad882",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 21350654,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/00beb5a8-c812-4635-8558-5da4aaed3619/width=832/00beb5a8-c812-4635-8558-5da4aaed3619.jpeg",
        "hash": "UDGIZiNG4o%M.TM{00xat,s:RPkWwHs;$jWB",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-25T20:17:49.476Z",
        "postId": 4760515,
        "stats": {
            "cryCount": 52,
            "laughCount": 69,
            "likeCount": 895,
            "dislikeCount": 0,
            "heartCount": 302,
            "commentCount": 0
        },
        "meta": {
            "seed": 229,
            "vaes": [],
            "Model": "ponyDiffusionV6XL_v6StartWithThisOne",
            "comfy": "{\"prompt\": {\"33\": {\"inputs\": {\"ckpt_name\": \"ponyDiffusionV6XL_v6StartWithThisOne.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"35\": {\"inputs\": {\"text\": \"score_5, score_4, score_3, ugly, muscular\", \"clip\": [\"95\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"36\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"41\": {\"inputs\": {\"text\": \"score_9, score_8_up, score_7_up, score_6_up, HRMN, 1girl, solo, breasts, short hair, dress, bare shoulders, medium breasts, closed mouth, upper body, white hair, hairband, sleeveless, mole, blurry, black dress, lips, wet, depth of field, blurry background, turtleneck, phone, cellphone, black hairband, wet clothes, mole under mouth, facing viewer, smartphone, rain, water drop, blindfold, wet hair, covered eyes, black blindfold, yorha no. 2 type b\", \"clip\": [\"95\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"92\": {\"inputs\": {\"lora_name\": \"HRMN\\\\HRMN-000002.safetensors\", \"strength_model\": 1.0, \"model\": [\"350\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"95\": {\"inputs\": {\"stop_at_clip_layer\": -2, \"clip\": [\"33\", 1]}, \"class_type\": \"CLIPSetLastLayer\"}, \"290\": {\"inputs\": {\"category\": \"#PLACEHOLDER\", \"preset\": \"#PRESET\", \"text\": \"4K, Anatomically Correct, Accurate, Best Quality, Highres, Masterpiece, Retina, Super Detail, Textured Skin, Studio Portrait, Soft Pastel Glow Lighting, Glowing Light, Photorealism Style, Depth Of Field\"}, \"class_type\": \"PromptBuilder //Inspire\"}, \"309\": {\"inputs\": {\"filename_prefix\": \"xXx\", \"images\": [\"311\", 0]}, \"class_type\": \"SaveImage\"}, \"310\": {\"inputs\": {\"seed\": 229, \"steps\": 25, \"cfg\": 6.0, \"sampler_name\": \"euler_ancestral\", \"scheduler\": \"karras\", \"denoise\": 1.0, \"model\": [\"92\", 0], \"positive\": [\"41\", 0], \"negative\": [\"35\", 0], \"latent_image\": [\"36\", 0]}, \"class_type\": \"KSampler\"}, \"311\": {\"inputs\": {\"samples\": [\"310\", 0], \"vae\": [\"33\", 2]}, \"class_type\": \"VAEDecode\"}, \"312\": {\"inputs\": {\"filename_prefix\": \"xXx\", \"images\": [\"314\", 0]}, \"class_type\": \"SaveImage\"}, \"313\": {\"inputs\": {\"seed\": 229, \"steps\": 25, \"cfg\": 6.0, \"sampler_name\": \"euler_ancestral\", \"scheduler\": \"karras\", \"denoise\": 1.0, \"model\": [\"315\", 0], \"positive\": [\"41\", 0], \"negative\": [\"35\", 0], \"latent_image\": [\"36\", 0]}, \"class_type\": \"KSampler\"}, \"314\": {\"inputs\": {\"samples\": [\"313\", 0], \"vae\": [\"33\", 2]}, \"class_type\": \"VAEDecode\"}, \"315\": {\"inputs\": {\"lora_name\": \"HRMN\\\\HRMN-000001.safetensors\", \"strength_model\": 1.0, \"model\": [\"350\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"336\": {\"inputs\": {\"samples\": [\"36\", 0], \"vae\": [\"33\", 2]}, \"class_type\": \"VAEDecode\"}, \"350\": {\"inputs\": {\"lora_name\": \"Expressive_H-000001.safetensors\", \"strength_model\": 0.5, \"model\": [\"33\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}}, \"workflow\": {\"last_node_id\": 352, \"last_link_id\": 550, \"nodes\": [{\"id\": 128, \"type\": \"LoraLoaderModelOnly\", \"pos\": [1410, -300], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 21, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 235}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [237], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"1dkXLP.safetensors\", 0.3], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 181, \"type\": \"Reroute\", \"pos\": [-10, -380], \"size\": [75, 26], \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 306, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 176, \"type\": \"Reroute\", \"pos\": [470, -460], \"size\": [75, 26], \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 305, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 182, \"type\": \"Reroute\", \"pos\": [380, -470], \"size\": [75, 26], \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 308, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [309], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 120, \"type\": \"Reroute\", \"pos\": [-49, -433], \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 309, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [494], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 183, \"type\": \"Reroute\", \"pos\": [790, 1030], \"size\": [75, 26], \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 311}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 186, \"type\": \"Reroute\", \"pos\": [1693, -449], \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 319, \"slot_index\": 0}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [323], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 187, \"type\": \"Reroute\", \"pos\": [1710, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 323, \"slot_index\": 0, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [472], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 190, \"type\": \"Reroute\", \"pos\": [1270, -50], \"size\": [75, 26], \"flags\": {}, \"order\": 70, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 328}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [329], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 110, \"type\": \"Reroute\", \"pos\": [30, 1030], \"size\": [75, 26], \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 206}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [284, 311], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 174, \"type\": \"Reroute\", \"pos\": [40, 1090], \"size\": [75, 26], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 284}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [313], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 193, \"type\": \"Reroute\", \"pos\": [130, 990], \"size\": [75, 26], \"flags\": {}, \"order\": 96, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 332}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [333], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 192, \"type\": \"Reroute\", \"pos\": [810, 980], \"size\": [75, 26], \"flags\": {}, \"order\": 99, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 333}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [334], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 196, \"type\": \"Reroute\", \"pos\": [671, -719], \"size\": [75, 26], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 338}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [339], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 197, \"type\": \"Reroute\", \"pos\": [-60, -721], \"size\": [75, 26], \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 339}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [340], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 198, \"type\": \"Reroute\", \"pos\": [-25, -662], \"size\": [75, 26], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 340, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [341], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 200, \"type\": \"Reroute\", \"pos\": [210, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 342}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [343, 344], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 119, \"type\": \"Reroute\", \"pos\": [-40, 1140], \"size\": [75, 26], \"flags\": {}, \"order\": 69, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 346}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [213], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 201, \"type\": \"Reroute\", \"pos\": [-100, 1070], \"size\": [75, 26], \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 345, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [346], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 121, \"type\": \"Reroute\", \"pos\": [-101, 203], \"size\": [75, 26], \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 347, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [345], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 199, \"type\": \"Reroute\", \"pos\": [-10, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 341, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [342, 347], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 191, \"type\": \"Reroute\", \"pos\": [50, 970], \"size\": [75, 26], \"flags\": {}, \"order\": 93, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 330, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [332], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 180, \"type\": \"Reroute\", \"pos\": [660, -480], \"size\": [75, 26], \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 302, \"slot_index\": 0}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [319], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 109, \"type\": \"Reroute\", \"pos\": [220, 240], \"size\": [75, 26], \"flags\": {}, \"order\": 90, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [216], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 118, \"type\": \"Reroute\", \"pos\": [470, 220], \"size\": [75, 26], \"flags\": {}, \"order\": 81, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 351}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 203, \"type\": \"Reroute\", \"pos\": [660, 220], \"size\": [75, 26], \"flags\": {}, \"order\": 71, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 350}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [351], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 122, \"type\": \"Reroute\", \"pos\": [770, 220], \"size\": [140.8, 26], \"flags\": {}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 229, \"pos\": [70.4, 0]}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [350, 352], \"slot_index\": 0}], \"properties\": {\"showOutputText\": true, \"horizontal\": true}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 202, \"type\": \"Reroute\", \"pos\": [120, 210], \"size\": [75, 26], \"flags\": {}, \"order\": 63, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 348}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [349, 357], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 209, \"type\": \"Reroute\", \"pos\": [1140, 200], \"size\": [75, 26], \"flags\": {}, \"order\": 92, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 360}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [361], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 133, \"type\": \"SaveImage\", \"pos\": [1210, 320], \"size\": {\"0\": 580, \"1\": 630}, \"flags\": {\"pinned\": true}, \"order\": 105, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 248}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"RealVisFace\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 211, \"type\": \"Reroute\", \"pos\": [1760, 180], \"size\": [75, 26], \"flags\": {}, \"order\": 98, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 362, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [363], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 206, \"type\": \"Reroute\", \"pos\": [1780, 250], \"size\": [75, 26], \"flags\": {}, \"order\": 91, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 354, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [356], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 195, \"type\": \"Reroute\", \"pos\": [1750, 120], \"size\": [75, 26], \"flags\": {}, \"order\": 104, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 337, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [336], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 155, \"type\": \"KSampler\", \"pos\": [1839, 82], \"size\": {\"0\": 320, \"1\": 470}, \"flags\": {}, \"order\": 114, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 336, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 268, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 269, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 279, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [303], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [836831938411124, \"randomize\", 8, 2.5, \"dpmpp_2m_alt\", \"karras\", 1]}, {\"id\": 172, \"type\": \"VAEDecode\", \"pos\": [1918, -22], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 115, \"mode\": 2, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 303, \"slot_index\": 0}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 318, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [281], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 132, \"type\": \"PreviewBridge\", \"pos\": [940, 360], \"size\": {\"0\": 320, \"1\": 290}, \"flags\": {\"collapsed\": true}, \"order\": 101, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 241}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [242], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"PreviewBridge\"}, \"widgets_values\": [\"$132-0\"]}, {\"id\": 150, \"type\": \"MeshGraphormer-DepthMapPreprocessor\", \"pos\": [1838, 691], \"size\": {\"0\": 320, \"1\": 220}, \"flags\": {}, \"order\": 106, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 262}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [267], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"INPAINTING_MASK\", \"type\": \"MASK\", \"links\": [278], \"shape\": 3, \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"MeshGraphormer-DepthMapPreprocessor\"}, \"widgets_values\": [15, 256, \"based_on_depth\", 5, 88, 0.6, 0.6]}, {\"id\": 153, \"type\": \"ControlNetApplyAdvanced\", \"pos\": [1926, 594], \"size\": {\"0\": 320, \"1\": 170}, \"flags\": {\"collapsed\": true}, \"order\": 110, \"mode\": 2, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 363}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 356}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 264, \"slot_index\": 2}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 267}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [268], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": [269], \"shape\": 3, \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"ControlNetApplyAdvanced\"}, \"widgets_values\": [0.6, 0, 1]}, {\"id\": 154, \"type\": \"ControlNetLoader\", \"pos\": [1825, 647], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": true}, \"order\": 0, \"mode\": 2, \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [264], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ControlNetLoader\"}, \"widgets_values\": [\"control_v11f1p_sd15_depth_fp16.safetensors\"]}, {\"id\": 205, \"type\": \"Reroute\", \"pos\": [1650, 220], \"size\": [75, 26], \"flags\": {}, \"order\": 82, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 353}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [354], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 156, \"type\": \"SetLatentNoiseMask\", \"pos\": [2216, 957], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 113, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 274, \"slot_index\": 0}, {\"name\": \"mask\", \"type\": \"MASK\", \"link\": 278, \"slot_index\": 1}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [279], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SetLatentNoiseMask\"}}, {\"id\": 185, \"type\": \"Reroute\", \"pos\": [1708, 1021], \"size\": [75, 26], \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 316}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [317, 318], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 173, \"type\": \"SaveImage\", \"pos\": [2190, -322], \"size\": {\"0\": 930, \"1\": 1230}, \"flags\": {}, \"order\": 116, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 281}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"RealVisFaceHands\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 194, \"type\": \"Reroute\", \"pos\": [1660, 990], \"size\": [75, 26], \"flags\": {}, \"order\": 102, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 334}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [337], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 170, \"type\": \"VAEEncode\", \"pos\": [1876, 964], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": false}, \"order\": 111, \"mode\": 4, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 276}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 317}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [274], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}}, {\"id\": 136, \"type\": \"SAMLoader\", \"pos\": [940, 440], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 1, \"mode\": 2, \"outputs\": [{\"name\": \"SAM_MODEL\", \"type\": \"SAM_MODEL\", \"links\": [253], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SAMLoader\"}, \"widgets_values\": [\"sam_vit_b_01ec64.pth\", \"AUTO\"]}, {\"id\": 167, \"type\": \"Reroute\", \"pos\": [1260, 970], \"size\": [75, 26], \"flags\": {}, \"order\": 107, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 275}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [276], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 111, \"type\": \"Reroute\", \"pos\": [780, 1130], \"size\": [75, 26], \"flags\": {}, \"order\": 79, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 213}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [246], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 210, \"type\": \"Reroute\", \"pos\": [1650, 180], \"size\": [75, 26], \"flags\": {}, \"order\": 95, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 361}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [362, 457], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 184, \"type\": \"Reroute\", \"pos\": [790, 1080], \"size\": [75, 26], \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 313}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [316, 458], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 281, \"type\": \"UpscaleModelLoader\", \"pos\": [691, 1301], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 2, \"mode\": 2, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [452], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 134, \"type\": \"UltralyticsDetectorProvider\", \"pos\": [940, 390], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 3, \"mode\": 2, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": [251], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [], \"shape\": 3, \"slot_index\": 1}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"bbox/face_yolov8m.pt\"]}, {\"id\": 137, \"type\": \"UltralyticsDetectorProvider\", \"pos\": [940, 480], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {\"collapsed\": true}, \"order\": 4, \"mode\": 2, \"outputs\": [{\"name\": \"BBOX_DETECTOR\", \"type\": \"BBOX_DETECTOR\", \"links\": null, \"shape\": 3}, {\"name\": \"SEGM_DETECTOR\", \"type\": \"SEGM_DETECTOR\", \"links\": [254], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltralyticsDetectorProvider\"}, \"widgets_values\": [\"segm/face_yolov8n-seg2_60.pt\"]}, {\"id\": 290, \"type\": \"PromptBuilder //Inspire\", \"pos\": [142, 1223], \"size\": {\"0\": 310, \"1\": 220}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"PromptBuilder //Inspire\"}, \"widgets_values\": [\"Picture Effect\", \"#PRESET\", \"4K, Anatomically Correct, Accurate, Best Quality, Highres, Masterpiece, Retina, Super Detail, Textured Skin, Studio Portrait, Soft Pastel Glow Lighting, Glowing Light, Photorealism Style, Depth Of Field\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 280, \"type\": \"SaveImage\", \"pos\": [1048, 1281], \"size\": {\"0\": 280, \"1\": 300}, \"flags\": {}, \"order\": 112, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 453}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 279, \"type\": \"UltimateSDUpscale\", \"pos\": [688, 1404], \"size\": {\"0\": 320, \"1\": 830}, \"flags\": {\"collapsed\": false}, \"order\": 108, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 460}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 455, \"slot_index\": 1}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 457, \"slot_index\": 2}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 456, \"slot_index\": 3}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 458, \"slot_index\": 4}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 452}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [453], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.5, 1088360099087303, \"randomize\", 8, 4, \"dpmpp_2m_alt\", \"karras\", 0.2, \"Linear\", 768, 1024, 8, 32, \"None\", 1, 64, 8, 16, true, false], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 126, \"type\": \"LoraLoaderModelOnly\", \"pos\": [1070, -300], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 14, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 231}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [235], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"1dkXLP.safetensors\", -2], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 207, \"type\": \"Reroute\", \"pos\": [400, 210], \"size\": [75, 26], \"flags\": {}, \"order\": 73, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 357}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [358], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 220, \"type\": \"Switch any [Crystools]\", \"pos\": [1290, 90], \"size\": {\"0\": 310, \"1\": 80}, \"flags\": {}, \"order\": 56, \"mode\": 2, \"inputs\": [{\"name\": \"on_true\", \"type\": \"*\", \"link\": 372}, {\"name\": \"on_false\", \"type\": \"*\", \"link\": 464}], \"outputs\": [{\"name\": \"*\", \"type\": \"*\", \"links\": [438, 455], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"Switch any [Crystools]\"}, \"widgets_values\": [false]}, {\"id\": 298, \"type\": \"IPAdapterInsightFaceLoader\", \"pos\": [860, -650], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 6, \"mode\": 2, \"outputs\": [{\"name\": \"INSIGHTFACE\", \"type\": \"INSIGHTFACE\", \"links\": [467], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"IPAdapterInsightFaceLoader\"}, \"widgets_values\": [\"CPU\"]}, {\"id\": 296, \"type\": \"CLIPVisionLoader\", \"pos\": [860, -540], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 7, \"mode\": 2, \"outputs\": [{\"name\": \"CLIP_VISION\", \"type\": \"CLIP_VISION\", \"links\": [466], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPVisionLoader\"}, \"widgets_values\": [\"IPAdapter_image_encoder_sd15.safetensors\"]}, {\"id\": 295, \"type\": \"IPAdapterModelLoader\", \"pos\": [860, -770], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 8, \"mode\": 2, \"outputs\": [{\"name\": \"IPADAPTER\", \"type\": \"IPADAPTER\", \"links\": [465], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"IPAdapterModelLoader\"}, \"widgets_values\": [\"ip-adapter-faceid-plusv2_sd15.bin\"]}, {\"id\": 292, \"type\": \"IPAdapterFaceID\", \"pos\": [1270, -740], \"size\": {\"0\": 320, \"1\": 320}, \"flags\": {}, \"order\": 51, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 463}, {\"name\": \"ipadapter\", \"type\": \"IPADAPTER\", \"link\": 465}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 473}, {\"name\": \"image_negative\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"attn_mask\", \"type\": \"MASK\", \"link\": null}, {\"name\": \"clip_vision\", \"type\": \"CLIP_VISION\", \"link\": 466}, {\"name\": \"insightface\", \"type\": \"INSIGHTFACE\", \"link\": 467}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [464], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"face_image\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"IPAdapterFaceID\"}, \"widgets_values\": [1, 1, \"linear\", \"concat\", 0, 1, \"V only\"]}, {\"id\": 138, \"type\": \"LoraLoaderModelOnly\", \"pos\": [930, 80], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 43, \"mode\": 2, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 325, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [463], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"1dkXLP.safetensors\", -2], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 189, \"type\": \"Reroute\", \"pos\": [1620, -40], \"size\": [75, 26], \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 471, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [328], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 306, \"type\": \"LoraLoaderModelOnly\", \"pos\": [1430, -150], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 55, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 470}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [471], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"1dkXLP.safetensors\", 0.7000000000000001], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 188, \"type\": \"Reroute\", \"pos\": [840, 140], \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 472, \"slot_index\": 0, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [325], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}, \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 147, \"type\": \"PreviewImage\", \"pos\": [950, 600], \"size\": {\"0\": 250, \"1\": 340}, \"flags\": {}, \"order\": 109, \"mode\": 2, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 260}], \"properties\": {\"Node name for S&R\": \"PreviewImage\"}}, {\"id\": 113, \"type\": \"Reroute\", \"pos\": [60, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 80, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 329}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [197], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 305, \"type\": \"LoadImage\", \"pos\": [1220, -1110], \"size\": {\"0\": 320, \"1\": 310}, \"flags\": {}, \"order\": 9, \"mode\": 2, \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"7d6f57171d6a0cff937326c2e493f63a.png\", \"image\"]}, {\"id\": 308, \"type\": \"LoadImage\", \"pos\": [1540, -1110], \"size\": {\"0\": 320, \"1\": 310}, \"flags\": {}, \"order\": 10, \"mode\": 2, \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [473], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"pasted/image (42).png\", \"image\"]}, {\"id\": 204, \"type\": \"Reroute\", \"pos\": [920, 240], \"size\": [75, 26], \"flags\": {}, \"order\": 72, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 352}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [353, 439, 456], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 94, \"type\": \"LoraLoaderModelOnly\", \"pos\": [1080, -160], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 50, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 240}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [372, 470], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"1dkXLP.safetensors\", 0], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 131, \"type\": \"FaceDetailer\", \"pos\": [950, 530], \"size\": {\"0\": 430, \"1\": 1100}, \"flags\": {\"collapsed\": true}, \"order\": 103, \"mode\": 2, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 242}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 438}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 246}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 440}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 439}, {\"name\": \"bbox_detector\", \"type\": \"BBOX_DETECTOR\", \"link\": 251, \"slot_index\": 6}, {\"name\": \"sam_model_opt\", \"type\": \"SAM_MODEL\", \"link\": 253}, {\"name\": \"segm_detector_opt\", \"type\": \"SEGM_DETECTOR\", \"link\": 254, \"slot_index\": 8}, {\"name\": \"detailer_hook\", \"type\": \"DETAILER_HOOK\", \"link\": null}, {\"name\": \"scheduler_func_opt\", \"type\": \"SCHEDULER_FUNC\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [248, 262, 275, 460], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"cropped_refined\", \"type\": \"IMAGE\", \"links\": [], \"shape\": 6, \"slot_index\": 1}, {\"name\": \"cropped_enhanced_alpha\", \"type\": \"IMAGE\", \"links\": [260], \"shape\": 6, \"slot_index\": 2}, {\"name\": \"mask\", \"type\": \"MASK\", \"links\": [], \"shape\": 3, \"slot_index\": 3}, {\"name\": \"detailer_pipe\", \"type\": \"DETAILER_PIPE\", \"links\": null, \"shape\": 3, \"slot_index\": 4}, {\"name\": \"cnet_images\", \"type\": \"IMAGE\", \"links\": [], \"shape\": 6, \"slot_index\": 5}], \"properties\": {\"Node name for S&R\": \"FaceDetailer\"}, \"widgets_values\": [256, true, 768, 65596133660583, \"randomize\", 20, 4, \"dpmpp_2m_alt\", \"karras\", 0.5, 5, true, true, 0.5, 10, 3, \"center-1\", 0, 0.93, 0, 0.7, \"False\", 10, \"\", 1, false, 20]}, {\"id\": 208, \"type\": \"Reroute\", \"pos\": [850, -30], \"size\": [75, 26], \"flags\": {}, \"order\": 83, \"mode\": 2, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 358}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [360, 440], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 130, \"type\": \"LoraLoaderModelOnly\", \"pos\": [740, -170], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 42, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 239}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [240], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"1dkXLP.safetensors\", 0.6], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 95, \"type\": \"CLIPSetLastLayer\", \"pos\": [420, -590], \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"collapsed\": true}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 157, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [338], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPSetLastLayer\"}, \"widgets_values\": [-2]}, {\"id\": 129, \"type\": \"LoraLoaderModelOnly\", \"pos\": [70, -160], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 28, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 237}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [238], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"Kenva.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 108, \"type\": \"Reroute\", \"pos\": [-110, -290], \"size\": [75, 26], \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 474, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"LATENT\", \"links\": [215], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 101, \"type\": \"Reroute\", \"pos\": [-110, -627], \"size\": [75, 26], \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 171, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"LATENT\", \"links\": [474], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 127, \"type\": \"LoraLoaderModelOnly\", \"pos\": [410, -170], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 36, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 238}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [239], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"incase_style_v3-1_ponyxl_ilff.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 93, \"type\": \"LoraLoaderModelOnly\", \"pos\": [740, -300], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 11, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [231], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"Concept Art Twilight Style SDXL_LoRA_Pony Diffusion V6 XL.safetensors\", 0.4], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 336, \"type\": \"VAEDecode\", \"pos\": [-980, 1090], \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 76, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 505}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 507, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [506], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 340, \"type\": \"VAEDecode\", \"pos\": [-1330, 1090], \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 77, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 512}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 517, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [511], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 42, \"type\": \"VAEDecode\", \"pos\": [-1680, 1090], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 97, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 51}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [53, 241], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 117, \"type\": \"Reroute\", \"pos\": [-50, 700], \"size\": [75, 26], \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 494, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [206, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 40, \"type\": \"KSampler\", \"pos\": [-1680, 590], \"size\": {\"0\": 210, \"1\": 470}, \"flags\": {\"pinned\": false}, \"order\": 94, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 475, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 349, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 216, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 215, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [51], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1233, \"increment\", 25, 6, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 345, \"type\": \"KSampler\", \"pos\": [-2030, 590], \"size\": {\"0\": 210, \"1\": 470}, \"flags\": {\"pinned\": false}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 521, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 526, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 527, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 525, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [523], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1233, \"increment\", 25, 6, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 346, \"type\": \"VAEDecode\", \"pos\": [-2030, 1080], \"size\": {\"0\": 210, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 78, \"mode\": 4, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 523}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 524, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [522], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 344, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-2030, -110], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 31, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 531, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [521], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"BKSTL\\\\BKSTL-6e.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 343, \"type\": \"SaveImage\", \"pos\": [-2030, 0], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 88, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 522}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 91, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-1680, -110], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 30, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 498, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [475], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"BKSTL\\\\BKSTL-6e.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 352, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-1070, -330], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 33, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 546, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [545], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"Photo 2 Style SDXL_LoRA_Pony Diffusion V6 XL.safetensors\", 0.6], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 337, \"type\": \"KSampler\", \"pos\": [-1330, 600], \"size\": {\"0\": 210, \"1\": 470}, \"flags\": {\"pinned\": false}, \"order\": 67, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 510, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 514, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 515, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 516, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [512], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1194, \"increment\", 25, 6, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 349, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-730, -430], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 32, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 533, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [550], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"NEOST\\\\NEOST-4.safetensors\", 0.6], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 338, \"type\": \"SaveImage\", \"pos\": [-1330, 0], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 87, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 511}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 43, \"type\": \"SaveImage\", \"pos\": [-1820, -10], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 100, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 53}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 320, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-1310, -540], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 24, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 539, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [498, 531, 533, 546], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"add-detail-xl.safetensors\", 0.4], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 311, \"type\": \"VAEDecode\", \"pos\": [-630, 1110], \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 74, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 478}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 479, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [480], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 314, \"type\": \"VAEDecode\", \"pos\": [-280, 1110], \"size\": {\"0\": 140, \"1\": 50}, \"flags\": {\"collapsed\": true, \"pinned\": false}, \"order\": 75, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 484}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 486, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [485], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 112, \"type\": \"Reroute\", \"pos\": [90, 340], \"size\": [75, 26], \"flags\": {}, \"order\": 89, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 197, \"pos\": [37.5, 0]}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [330], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": true}}, {\"id\": 334, \"type\": \"SaveImage\", \"pos\": [-980, 0], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 86, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 506}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 309, \"type\": \"SaveImage\", \"pos\": [-630, 0], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 84, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 480}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 312, \"type\": \"SaveImage\", \"pos\": [-280, 0], \"size\": {\"0\": 350, \"1\": 560}, \"flags\": {\"pinned\": false}, \"order\": 85, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 485}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"xXx\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 339, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-1340, -110], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 38, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 550, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [510], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"GLSHS\\\\GLSHS-3e.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 335, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-980, -110], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 46, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 549, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [502], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"GLSHS\\\\GLSHS-3e.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 350, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-640, -660], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 538, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [539], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"Expressive_H-000001.safetensors\", 0.5], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 33, \"type\": \"CheckpointLoaderSimple\", \"pos\": [80, -550], \"size\": {\"0\": 320, \"1\": 100}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [302, 305, 538], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [157], \"shape\": 3, \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [308, 479, 486, 507, 517, 524], \"shape\": 3, \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"ponyDiffusionV6XL_v6StartWithThisOne.safetensors\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 333, \"type\": \"KSampler\", \"pos\": [-980, 600], \"size\": {\"0\": 210, \"1\": 470}, \"flags\": {\"pinned\": false}, \"order\": 66, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 502, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 508, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 509, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 504, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [505], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [240, \"increment\", 25, 6, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 36, \"type\": \"EmptyLatentImage\", \"pos\": [80, -670], \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {\"collapsed\": false}, \"order\": 13, \"mode\": 0, \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [171, 491, 504, 516, 525, 532], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 351, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-700, -270], \"size\": {\"0\": 320, \"1\": 80}, \"flags\": {}, \"order\": 39, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 545, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [544, 548, 549], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"PRSNL\\\\PRSNL-V2-5.safetensors\", 0.8], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 313, \"type\": \"KSampler\", \"pos\": [-280, 600], \"size\": [210, 470], \"flags\": {\"pinned\": false}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 518, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 489, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 490, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 491, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [484], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [229, \"increment\", 25, 6, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 35, \"type\": \"CLIPTextEncode\", \"pos\": [500, 60], \"size\": {\"0\": 270, \"1\": 150}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 343}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [229, 482, 490, 509, 515, 527], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_5, score_4, score_3, ugly, muscular\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 310, \"type\": \"KSampler\", \"pos\": [-630, 600], \"size\": [210, 470], \"flags\": {\"pinned\": false}, \"order\": 64, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 547, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 481, \"slot_index\": 1}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 482, \"slot_index\": 2}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 532, \"slot_index\": 3}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [478], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [229, \"increment\", 25, 6, \"euler_ancestral\", \"karras\", 1]}, {\"id\": 92, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-630, -110], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 544}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [547], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"HRMN\\\\HRMN-000002.safetensors\", 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 315, \"type\": \"LoraLoaderModelOnly\", \"pos\": [-280, -110], \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 548, \"slot_index\": 0}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [518], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"HRMN\\\\HRMN-000001.safetensors\", 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 41, \"type\": \"CLIPTextEncode\", \"pos\": [90, 50], \"size\": {\"0\": 320, \"1\": 230}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 344}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [348, 481, 489, 508, 514, 526], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"score_9, score_8_up, score_7_up, score_6_up, HRMN, 1girl, solo, breasts, short hair, dress, bare shoulders, medium breasts, closed mouth, upper body, white hair, hairband, sleeveless, mole, blurry, black dress, lips, wet, depth of field, blurry background, turtleneck, phone, cellphone, black hairband, wet clothes, mole under mouth, facing viewer, smartphone, rain, water drop, blindfold, wet hair, covered eyes, black blindfold, yorha no. 2 type b\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}], \"links\": [[51, 40, 0, 42, 0, \"LATENT\"], [53, 42, 0, 43, 0, \"IMAGE\"], [157, 33, 1, 95, 0, \"CLIP\"], [171, 36, 0, 101, 0, \"*\"], [197, 113, 0, 112, 0, \"*\"], [206, 117, 0, 110, 0, \"*\"], [209, 118, 0, 109, 0, \"*\"], [213, 119, 0, 111, 0, \"*\"], [215, 108, 0, 40, 3, \"LATENT\"], [216, 109, 0, 40, 2, \"CONDITIONING\"], [229, 35, 0, 122, 0, \"*\"], [231, 93, 0, 126, 0, \"MODEL\"], [235, 126, 0, 128, 0, \"MODEL\"], [237, 128, 0, 129, 0, \"MODEL\"], [238, 129, 0, 127, 0, \"MODEL\"], [239, 127, 0, 130, 0, \"MODEL\"], [240, 130, 0, 94, 0, \"MODEL\"], [241, 42, 0, 132, 0, \"IMAGE\"], [242, 132, 0, 131, 0, \"IMAGE\"], [246, 111, 0, 131, 2, \"CLIP\"], [248, 131, 0, 133, 0, \"IMAGE\"], [251, 134, 0, 131, 6, \"BBOX_DETECTOR\"], [253, 136, 0, 131, 7, \"SAM_MODEL\"], [254, 137, 1, 131, 8, \"SEGM_DETECTOR\"], [260, 131, 2, 147, 0, \"IMAGE\"], [262, 131, 0, 150, 0, \"IMAGE\"], [264, 154, 0, 153, 2, \"CONTROL_NET\"], [267, 150, 0, 153, 3, \"IMAGE\"], [268, 153, 0, 155, 1, \"CONDITIONING\"], [269, 153, 1, 155, 2, \"CONDITIONING\"], [274, 170, 0, 156, 0, \"LATENT\"], [275, 131, 0, 167, 0, \"*\"], [276, 167, 0, 170, 0, \"IMAGE\"], [278, 150, 1, 156, 1, \"MASK\"], [279, 156, 0, 155, 3, \"LATENT\"], [281, 172, 0, 173, 0, \"IMAGE\"], [284, 110, 0, 174, 0, \"*\"], [302, 33, 0, 180, 0, \"*\"], [303, 155, 0, 172, 0, \"LATENT\"], [305, 33, 0, 176, 0, \"*\"], [306, 176, 0, 181, 0, \"*\"], [308, 33, 2, 182, 0, \"*\"], [309, 182, 0, 120, 0, \"*\"], [310, 117, 0, 42, 1, \"VAE\"], [311, 110, 0, 183, 0, \"*\"], [312, 183, 0, 131, 3, \"VAE\"], [313, 174, 0, 184, 0, \"*\"], [316, 184, 0, 185, 0, \"*\"], [317, 185, 0, 170, 1, \"VAE\"], [318, 185, 0, 172, 1, \"VAE\"], [319, 180, 0, 186, 0, \"*\"], [323, 186, 0, 187, 0, \"*\"], [325, 188, 0, 138, 0, \"MODEL\"], [328, 189, 0, 190, 0, \"*\"], [329, 190, 0, 113, 0, \"*\"], [330, 112, 0, 191, 0, \"*\"], [332, 191, 0, 193, 0, \"*\"], [333, 193, 0, 192, 0, \"*\"], [334, 192, 0, 194, 0, \"*\"], [336, 195, 0, 155, 0, \"MODEL\"], [337, 194, 0, 195, 0, \"*\"], [338, 95, 0, 196, 0, \"*\"], [339, 196, 0, 197, 0, \"*\"], [340, 197, 0, 198, 0, \"*\"], [341, 198, 0, 199, 0, \"*\"], [342, 199, 0, 200, 0, \"*\"], [343, 200, 0, 35, 0, \"CLIP\"], [344, 200, 0, 41, 0, \"CLIP\"], [345, 121, 0, 201, 0, \"*\"], [346, 201, 0, 119, 0, \"*\"], [347, 199, 0, 121, 0, \"*\"], [348, 41, 0, 202, 0, \"*\"], [349, 202, 0, 40, 1, \"CONDITIONING\"], [350, 122, 0, 203, 0, \"*\"], [351, 203, 0, 118, 0, \"*\"], [352, 122, 0, 204, 0, \"*\"], [353, 204, 0, 205, 0, \"*\"], [354, 205, 0, 206, 0, \"*\"], [356, 206, 0, 153, 1, \"CONDITIONING\"], [357, 202, 0, 207, 0, \"*\"], [358, 207, 0, 208, 0, \"*\"], [360, 208, 0, 209, 0, \"*\"], [361, 209, 0, 210, 0, \"*\"], [362, 210, 0, 211, 0, \"*\"], [363, 211, 0, 153, 0, \"CONDITIONING\"], [372, 94, 0, 220, 0, \"*\"], [438, 220, 0, 131, 1, \"MODEL\"], [439, 204, 0, 131, 5, \"CONDITIONING\"], [440, 208, 0, 131, 4, \"CONDITIONING\"], [452, 281, 0, 279, 5, \"UPSCALE_MODEL\"], [453, 279, 0, 280, 0, \"IMAGE\"], [455, 220, 0, 279, 1, \"MODEL\"], [456, 204, 0, 279, 3, \"CONDITIONING\"], [457, 210, 0, 279, 2, \"CONDITIONING\"], [458, 184, 0, 279, 4, \"VAE\"], [460, 131, 0, 279, 0, \"IMAGE\"], [463, 138, 0, 292, 0, \"MODEL\"], [464, 292, 0, 220, 1, \"*\"], [465, 295, 0, 292, 1, \"IPADAPTER\"], [466, 296, 0, 292, 5, \"CLIP_VISION\"], [467, 298, 0, 292, 6, \"INSIGHTFACE\"], [470, 94, 0, 306, 0, \"MODEL\"], [471, 306, 0, 189, 0, \"*\"], [472, 187, 0, 188, 0, \"*\"], [473, 308, 0, 292, 2, \"IMAGE\"], [474, 101, 0, 108, 0, \"*\"], [475, 91, 0, 40, 0, \"MODEL\"], [478, 310, 0, 311, 0, \"LATENT\"], [479, 33, 2, 311, 1, \"VAE\"], [480, 311, 0, 309, 0, \"IMAGE\"], [481, 41, 0, 310, 1, \"CONDITIONING\"], [482, 35, 0, 310, 2, \"CONDITIONING\"], [484, 313, 0, 314, 0, \"LATENT\"], [485, 314, 0, 312, 0, \"IMAGE\"], [486, 33, 2, 314, 1, \"VAE\"], [489, 41, 0, 313, 1, \"CONDITIONING\"], [490, 35, 0, 313, 2, \"CONDITIONING\"], [491, 36, 0, 313, 3, \"LATENT\"], [494, 120, 0, 117, 0, \"*\"], [498, 320, 0, 91, 0, \"MODEL\"], [502, 335, 0, 333, 0, \"MODEL\"], [504, 36, 0, 333, 3, \"LATENT\"], [505, 333, 0, 336, 0, \"LATENT\"], [506, 336, 0, 334, 0, \"IMAGE\"], [507, 33, 2, 336, 1, \"VAE\"], [508, 41, 0, 333, 1, \"CONDITIONING\"], [509, 35, 0, 333, 2, \"CONDITIONING\"], [510, 339, 0, 337, 0, \"MODEL\"], [511, 340, 0, 338, 0, \"IMAGE\"], [512, 337, 0, 340, 0, \"LATENT\"], [514, 41, 0, 337, 1, \"CONDITIONING\"], [515, 35, 0, 337, 2, \"CONDITIONING\"], [516, 36, 0, 337, 3, \"LATENT\"], [517, 33, 2, 340, 1, \"VAE\"], [518, 315, 0, 313, 0, \"MODEL\"], [521, 344, 0, 345, 0, \"MODEL\"], [522, 346, 0, 343, 0, \"IMAGE\"], [523, 345, 0, 346, 0, \"LATENT\"], [524, 33, 2, 346, 1, \"VAE\"], [525, 36, 0, 345, 3, \"LATENT\"], [526, 41, 0, 345, 1, \"CONDITIONING\"], [527, 35, 0, 345, 2, \"CONDITIONING\"], [531, 320, 0, 344, 0, \"MODEL\"], [532, 36, 0, 310, 3, \"LATENT\"], [533, 320, 0, 349, 0, \"MODEL\"], [538, 33, 0, 350, 0, \"MODEL\"], [539, 350, 0, 320, 0, \"MODEL\"], [544, 351, 0, 92, 0, \"MODEL\"], [545, 352, 0, 351, 0, \"MODEL\"], [546, 320, 0, 352, 0, \"MODEL\"], [547, 92, 0, 310, 0, \"MODEL\"], [548, 351, 0, 315, 0, \"MODEL\"], [549, 351, 0, 335, 0, \"MODEL\"], [550, 349, 0, 339, 0, \"MODEL\"]], \"groups\": [{\"title\": \"Start\", \"bounding\": [60, -680, 715, 254], \"color\": \"#88A\", \"font_size\": 24, \"locked\": false}, {\"title\": \"Loras\", \"bounding\": [50, -390, 1714, 348], \"color\": \"#a1309b\", \"font_size\": 24, \"locked\": false}, {\"title\": \"StartImage\", \"bounding\": [80, -10, 835, 977], \"color\": \"#8A8\", \"font_size\": 24, \"locked\": true}, {\"title\": \"LorasFace\", \"bounding\": [920, 0, 872, 233], \"color\": \"#a1309b\", \"font_size\": 24, \"locked\": false}, {\"title\": \"FaceFix\", \"bounding\": [930, 280, 874, 687], \"color\": \"#8A8\", \"font_size\": 24, \"locked\": false}, {\"title\": \"HandsFaceResult\", \"bounding\": [1809, -420, 1367, 1399], \"color\": \"#b58b2a\", \"font_size\": 24, \"locked\": false}, {\"title\": \"Upscale\", \"bounding\": [670, 1210, 684, 404], \"color\": \"#3f789e\", \"font_size\": 24, \"locked\": false}, {\"title\": \"face\", \"bounding\": [830, -1100, 840, 690], \"color\": \"#3f789e\", \"font_size\": 24, \"locked\": false}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.6350799082658187, \"offset\": [657.052508338193, -13.921299867549468]}}, \"version\": 0.4, \"widget_idx_map\": {\"40\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"131\": {\"seed\": 3, \"sampler_name\": 7, \"scheduler\": 8}, \"155\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"279\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"310\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"313\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"333\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"337\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}, \"345\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"40\": 0, \"131\": 3, \"155\": 0, \"279\": 1, \"310\": 0, \"313\": 0, \"333\": 0, \"337\": 0, \"345\": 0}}}",
            "steps": 25,
            "width": 832,
            "height": 1216,
            "models": [
                "ponyDiffusionV6XL_v6StartWithThisOne.safetensors"
            ],
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, HRMN, 1girl, solo, breasts, short hair, dress, bare shoulders, medium breasts, closed mouth, upper body, white hair, hairband, sleeveless, mole, blurry, black dress, lips, wet, depth of field, blurry background, turtleneck, phone, cellphone, black hairband, wet clothes, mole under mouth, facing viewer, smartphone, rain, water drop, blindfold, wet hair, covered eyes, black blindfold, yorha no. 2 type b",
            "denoise": 1,
            "sampler": "Euler a",
            "cfgScale": 6,
            "modelIds": [],
            "scheduler": "karras",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "negativePrompt": "score_5, score_4, score_3, ugly, muscular",
            "additionalResources": []
        },
        "username": "blacksnowskill",
        "baseModel": null
    },
    {
        "id": 11830895,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/da2416e3-4f7c-46f0-a198-7076aff3b6f0/width=640/da2416e3-4f7c-46f0-a198-7076aff3b6f0.jpeg",
        "hash": "U9EeSt0g0#~AF{=vJBIo0MWB-oIVJ-rrxDf+",
        "width": 640,
        "height": 944,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-07T23:58:59.065Z",
        "postId": 2607450,
        "stats": {
            "cryCount": 50,
            "laughCount": 94,
            "likeCount": 793,
            "dislikeCount": 0,
            "heartCount": 381,
            "commentCount": 2
        },
        "meta": null,
        "username": "NaomiVK",
        "baseModel": null
    },
    {
        "id": 34739979,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e6d5ad06-35c0-45f8-97a3-46e41cf64855/width=832/e6d5ad06-35c0-45f8-97a3-46e41cf64855.jpeg",
        "hash": "UHE30HEN4oxF~p%L9aWV^%RjM|tR~BRPNGx[",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-15T13:56:43.001Z",
        "postId": 7938544,
        "stats": {
            "cryCount": 50,
            "laughCount": 106,
            "likeCount": 933,
            "dislikeCount": 0,
            "heartCount": 227,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 540054746,
            "extra": {
                "remixOfId": 33298700
            },
            "steps": 19,
            "prompt": "surreal fantasy theme, beautiful warrior women, in bronze armor, armed with swords and spears, in battle stance, fearsome dragon attacking, on a mountaintop overlooking a deep gorge, viewed from behind, dark fantasy, dreamlike, max details, dynamic, great lighting, perfect shading, atmospheric, best quality, sharp focus, high contrast, stylized, clear, surreal, ultra quality, 8k, best quality, masterpiece, midjourneyv6.1",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 8.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-11T1047:03.8990330Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 641087,
                    "modelVersionName": "v9.0"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 137124,
                    "modelVersionName": "v1.0 SDXL"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 627153,
                    "modelVersionName": "SDXL"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 723149,
                    "modelVersionName": "SDXL"
                }
            ]
        },
        "username": "martinffm_pg",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 22285802,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/803cab15-9fa0-4f75-8763-eb22162443f7/width=832/803cab15-9fa0-4f75-8763-eb22162443f7.jpeg",
        "hash": "UJD0irysGwX9-?TLK7ogE2w]%1OYFfaK-Uo}",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-01T12:02:49.796Z",
        "postId": 4966527,
        "stats": {
            "cryCount": 43,
            "laughCount": 92,
            "likeCount": 856,
            "dislikeCount": 0,
            "heartCount": 325,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 4110565118,
            "steps": 50,
            "prompt": "1girl, illustration, looking at viewer, highly detailed, source_comic_illustrationskinny, looking at viewer, 1girl, masterpiece, best quality, ((((back view)))), source_photo, source_real, 1girl, solo, long hair, breasts, looking at viewer, witch skirt, witch hat, red hair, thighhighs, jewelry, purple eyes,  belt, necklace, mole, lips,  wavy hair, side slit, long skirt, realistic, long legs, curvy hips\nBREAK\nslight smile, looking at viewer, ((a staff with a luminous top:1.3))\nlong hair, red hair, hair over one eye, big hair, BREAK\nbest quality, depth of field, bokeh, (((full clothed)))\nBREAK \n((night, outdoors, sky, full moon background)) score_9, score_8_up, score_7_up, score_6_up, source_cartoon, rating_explicit, Expressiveh, ((((upper body))))), dynamic pose, dynamic pose",
            "sampler": "Euler a",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-07-31T1745:46.2832518Z",
            "negativePrompt": "score_6, score_5, score_4, censored, skin blemish, child, kid, 3D, bad anatomy, dismembered, disembodied, elderly, wrinkles, cross-eyed, deformed,  deformed fingers, short legs, body diproportion. dark scene, , disfigured, kitsch, ugly, grain, low-res, poorly drawn face, mutation, mutated, extra limb, poorly drawn hands, missing limb, blurry, floating limbs, disconnected limbs, malformed hands, blur, out of focus, long neck, long body, disgusting, poorly drawn, childish, mutilated, mangled, old, surreal, double body, double face, incorrect posture, close up, two heads, two faces, plastic, Deformed, blurry, bad anatomy, bad eyes, crossed eyes, disfigured, poorly drawn face, mutation, mutated, blender, doll, cropped, low-res, close-up, poorly-drawn face, out of frame double, two heads, blurred, ugly, disfigured, too many fingers, deformed, repetitive, text, watermark, nude, vagina, topless, furry,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 290640,
                    "modelVersionName": "V6 (start with this one)"
                },
                {
                    "type": "lora",
                    "weight": 0.15,
                    "modelVersionId": 342682,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 378830,
                    "modelVersionName": "Pony V2.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 382152,
                    "modelVersionName": "ExpressiveH"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 399443,
                    "modelVersionName": "detailed painting v1.0"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250708,
                    "modelVersionName": "safe_pos"
                },
                {
                    "type": "embed",
                    "modelVersionId": 250712,
                    "modelVersionName": "safe_neg"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "LLIATATEJlb",
        "baseModel": "Pony"
    },
    {
        "id": 33112596,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/01f05a34-6180-4fcd-a56e-5664feeefd6b/width=832/01f05a34-6180-4fcd-a56e-5664feeefd6b.jpeg",
        "hash": "U9C6+4?wE09Z0L%Mf,xu%LR*Wsa$kVxuxajY",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-06T10:44:17.006Z",
        "postId": 7576688,
        "stats": {
            "cryCount": 43,
            "laughCount": 60,
            "likeCount": 932,
            "dislikeCount": 0,
            "heartCount": 279,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3145896574,
            "steps": 8,
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up,\n1girl, cyborg,\nmechanical arms, mechanical legs, mechanical pelvis,\nplate armor,\n((solo)), \nstanding in garden,\nExpressiveh",
            "sampler": "Euler",
            "cfgScale": 1,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-12T1357:14.3668993Z",
            "negativePrompt": "score_6, score_5, score_4, easynegative, pubic hair,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 706363,
                    "modelVersionName": "v5.2"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 9208,
                    "modelVersionName": "EasyNegative"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 436121,
                    "modelVersionName": "add_detail XL v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.2,
                    "modelVersionId": 438481,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 382152,
                    "modelVersionName": "ExpressiveH"
                },
                {
                    "type": "lora",
                    "weight": 1.2,
                    "modelVersionId": 520909,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "modelVersionId": 391999,
                    "modelVersionName": "8 Steps"
                }
            ]
        },
        "username": "Starkad666",
        "baseModel": "Pony"
    },
    {
        "id": 24876586,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0d5b4f1e-f9ea-4c82-88de-0ea925571f25/width=1728/0d5b4f1e-f9ea-4c82-88de-0ea925571f25.jpeg",
        "hash": "U45hY_ayD%ofj?ayxuay~qayD%j[M{fQxuay",
        "width": 1728,
        "height": 2240,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-18T05:55:59.486Z",
        "postId": 5558393,
        "stats": {
            "cryCount": 47,
            "laughCount": 91,
            "likeCount": 847,
            "dislikeCount": 0,
            "heartCount": 329,
            "commentCount": 12
        },
        "meta": null,
        "username": "517262521lx812",
        "baseModel": ""
    },
    {
        "id": 14079162,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1364f62e-5edf-42d6-b8d5-8db9263d5b31/width=1344/1364f62e-5edf-42d6-b8d5-8db9263d5b31.jpeg",
        "hash": "U9BM.6Rk00$+?1jEE0bvU^xCTetSIlnO%hkC",
        "width": 1344,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-30T23:14:12.514Z",
        "postId": 3122963,
        "stats": {
            "cryCount": 31,
            "laughCount": 68,
            "likeCount": 899,
            "dislikeCount": 0,
            "heartCount": 316,
            "commentCount": 2
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "896x1152",
            "seed": 1370758182,
            "Model": "creapromptLightning_v13",
            "steps": 6,
            "hashes": {
                "vae": "735e4c3a44",
                "model": "00d8bce8ab"
            },
            "prompt": "In the enigmatic embrace of the Garden-Sprinkler Nebula, where cosmic winds whisper secrets, alien flora unfurl their otherworldly petals. Let us wander through this celestial garden, where nebulae bloom like stardust-kissed blossoms",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ SDE Karras",
            "cfgScale": 1.5,
            "resources": [
                {
                    "hash": "00d8bce8ab",
                    "name": "creapromptLightning_v13",
                    "type": "model"
                }
            ],
            "Model hash": "00d8bce8ab",
            "Hires steps": "5",
            "Hires upscale": "1.5",
            "Hires upscaler": "4x_NMKD-Siax_200k",
            "Denoising strength": "0.35"
        },
        "username": "Sateluco",
        "baseModel": "SDXL Lightning"
    },
    {
        "id": 11688449,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/df6934e8-73be-4939-baa5-088ac696fe0c/width=1536/df6934e8-73be-4939-baa5-088ac696fe0c.jpeg",
        "hash": "URKJxb?Y9dM}~S?ER.ay*J-T-9j?58RP-5tQ",
        "width": 1536,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-12T21:55:02.990Z",
        "postId": 2573899,
        "stats": {
            "cryCount": 28,
            "laughCount": 72,
            "likeCount": 860,
            "dislikeCount": 0,
            "heartCount": 354,
            "commentCount": 1
        },
        "meta": {
            "Size": "768x512",
            "seed": 4009679762,
            "steps": 35,
            "prompt": "ethereal fantasy concept art of  vintage postcard, magical colorful landscape made of glass, natural lighting, rich, intricate details, moody, golden hour light, professional, highly detailed, masterpiece, atmospheric, Bleak, post-apocalyptic, somber, dramatic, highly detailed . magnificent, celestial, ethereal, painterly, epic, majestic, magical, fantasy art, cover art, dreamy",
            "Version": "v1.8.0",
            "sampler": "DPM++ 3M SDE Exponential",
            "cfgScale": 7,
            "resources": [],
            "Hires prompt": {},
            "Hires upscale": "2",
            "Hires upscaler": "4x_NMKD-Superscale-SP_178000_G",
            "negativePrompt": "photographic, realistic, realism, 35mm film, dslr, cropped, frame, text, deformed, glitch, noise, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, sloppy, duplicate, mutated, black and white, ugly, deformed, noisy, blurry, low contrast, multiple lighting",
            "Face restoration": "CodeFormer",
            "Denoising strength": "0.7",
            "Style Selector Style": "Fantasy Art",
            "Style Selector Enabled": "True",
            "Style Selector Randomize": "False"
        },
        "username": "YogurtBunny556",
        "baseModel": ""
    },
    {
        "id": 40333355,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d079e99e-787b-4e21-a7fd-2be4968d0571/width=832/d079e99e-787b-4e21-a7fd-2be4968d0571.jpeg",
        "hash": "UBCFn+0L9Z~B1*-nMcXA?]MyQ-S~XnxZIUw^",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-16T00:11:00.000Z",
        "postId": 9192322,
        "stats": {
            "cryCount": 33,
            "laughCount": 60,
            "likeCount": 962,
            "dislikeCount": 0,
            "heartCount": 258,
            "commentCount": 5
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1668320162,
            "Model": "flux_dev",
            "steps": 57,
            "hashes": {
                "model": "06f96f89f6",
                "lora:anime_martzv2": "A8995C0EC2CB",
                "lora:FLUX-daubrez-DB4RZ-v2": "9A6DFC274BBD",
                "lora:FluxMythP0rtr4itStyle": "8ea428b224a8"
            },
            "prompt": "Photorealistic portrait of a stylish young woman wearing a futuristic golden sequined bodysuit that catches the light, creating a metallic, mirror-like effect. She has long, straight blonde hair with bangs framing her face, and is wearing large, reflective blue-tinted aviator sunglasses. Over her head, she wears oversized, high-tech headphones with metallic accents, giving a modern, cyber aesthetic. The background is a solid dark color, enhancing the glow and reflective quality of her outfit. Her expression is calm and confident, radiating a cool, futuristic vibe\n<lora:FluxMythP0rtr4itStyle:0.6> mythp0rt <lora:FLUX-daubrez-DB4RZ-v2:0.3> DB4RZ, glow effects, godrays, Hand drawn, render, 8k, octane render, cinema 4d, blender, dark, atmospheric 4k ultra detailed, cinematic, Sharp focus, big depth of field, Masterpiece, colors, 3d octane render, 4k, concept art, trending on artstation, hyperrealistic, Vivid colors, extremely detailed CG unity 8k wallpaper, trending on CGSociety, Intricate, High Detail, dramatic <lora:anime_martzv2:1> ., intricate, detailed . magnificent, celestial, ethereal, painterly, epic, majestic, magical, fantasy art, cover art, dreamy . shallow depth of field, vignette, highly detailed, high budget, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy . award-winning, professional, highly detailed . faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage",
            "Version": "f2.0.1v1.10.1-previous-616-g98e0adcc",
            "sampler": "[Forge] Flux Realistic",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "8ea428b224a8",
                    "name": "FluxMythP0rtr4itStyle",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "hash": "9A6DFC274BBD",
                    "name": "FLUX-daubrez-DB4RZ-v2",
                    "type": "lora",
                    "weight": 0.3
                },
                {
                    "hash": "A8995C0EC2CB",
                    "name": "anime_martzv2",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "06f96f89f6",
                    "name": "flux_dev",
                    "type": "model"
                }
            ],
            "Model hash": "06f96f89f6",
            "Schedule type": "Beta",
            "Beta schedule beta": "0.6",
            "Beta schedule alpha": "0.6",
            "Distilled CFG Scale": "2.1"
        },
        "username": "boonnyb689",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 36648864,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d8987a16-27a0-43b4-be1c-4f892ce063ca/width=1536/d8987a16-27a0-43b4-be1c-4f892ce063ca.jpeg",
        "hash": "UNAUT?.8DiMx?]t7IARktRaeMdRjMxf+ofWB",
        "width": 1536,
        "height": 2312,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-26T10:33:48.882Z",
        "postId": 8371141,
        "stats": {
            "cryCount": 56,
            "laughCount": 107,
            "likeCount": 873,
            "dislikeCount": 0,
            "heartCount": 277,
            "commentCount": 1
        },
        "meta": {
            "Size": "1030x1545",
            "seed": 2430901378,
            "Model": "midnight_v50",
            "steps": 25,
            "hashes": {
                "model": "e51e6876bb"
            },
            "Version": "v1.10.1",
            "sampler": "DPM++ 2M",
            "cfgScale": 6,
            "Mask blur": "4",
            "resources": [
                {
                    "hash": "e51e6876bb",
                    "name": "midnight_v50",
                    "type": "model"
                }
            ],
            "Model hash": "e51e6876bb",
            "Schedule type": "Karras",
            "Denoising strength": "0"
        },
        "username": "Castr0",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 17533424,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/51dbbfc9-7665-4d40-82fb-ac8486f66b01/width=1200/51dbbfc9-7665-4d40-82fb-ac8486f66b01.jpeg",
        "hash": "UPEML6X8IWM{_Nt6xtRj.8t7n$o#ozW=oftR",
        "width": 1200,
        "height": 1800,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-28T07:18:47.566Z",
        "postId": 3926016,
        "stats": {
            "cryCount": 33,
            "laughCount": 88,
            "likeCount": 843,
            "dislikeCount": 0,
            "heartCount": 348,
            "commentCount": 1
        },
        "meta": {
            "Size": "768x1152",
            "seed": 4033398959,
            "Model": "TamarinXL_v10",
            "steps": 20,
            "hashes": {
                "model": "2d1805f294"
            },
            "prompt": "A beautiful rendition of a small medieval hamlet in the mountains near a waterfall, (cumulus clouds:1.4), dramatic composition, cinematic, concept art, golden ratio, matte painting, Marc Simonetti, Sergey Vasnev, Anato Finnstark, artstation, 8k, high resolution, (masterpiece:1.2), best quality",
            "Version": "v1.9.4",
            "sampler": "DPM++ 2M SDE",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "2d1805f294",
                    "name": "TamarinXL_v10",
                    "type": "model"
                }
            ],
            "Model hash": "2d1805f294",
            "Hires steps": "10",
            "Hires resize": "1200x0",
            "Schedule type": "Karras",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "(low quality, bad quality, worst quality:1.2)",
            "Denoising strength": "0.5",
            "Hires schedule type": "Karras"
        },
        "username": "maDcaDDie",
        "baseModel": "SDXL 1.0"
    }
]