[
    {
        "id": 36631546,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7087d03e-850a-419c-b9a3-75520c579c8b/width=864/7087d03e-850a-419c-b9a3-75520c579c8b.jpeg",
        "hash": "U49G:mxZ00n.*6WE%6jX0JNG-:R%T3niD~WF",
        "width": 864,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-26T07:45:20.460Z",
        "postId": 8366958,
        "stats": {
            "cryCount": 9,
            "laughCount": 24,
            "likeCount": 100,
            "dislikeCount": 0,
            "heartCount": 42,
            "commentCount": 0
        },
        "meta": null,
        "username": "WutherWav",
        "baseModel": ""
    },
    {
        "id": 36381632,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0d52d652-b7d6-4c03-a8cc-535b286a21de/width=1248/0d52d652-b7d6-4c03-a8cc-535b286a21de.jpeg",
        "hash": "UAG8o}rV00%M%wo~yXtQ00xc~pEfUH0LD$-p",
        "width": 1248,
        "height": 1872,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-24T23:16:52.023Z",
        "postId": 8311125,
        "stats": {
            "cryCount": 13,
            "laughCount": 11,
            "likeCount": 109,
            "dislikeCount": 0,
            "heartCount": 42,
            "commentCount": 0
        },
        "meta": {
            "RNG": "CPU",
            "VAE": "sdxl_vae.safetensors",
            "Size": "832x1248",
            "seed": 408828339,
            "Model": "honeyMixXLHighContrast_v1",
            "steps": 29,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "d39f81730a",
                "lora:taimaninlina-pdxl-nvwls-v1-000005": "01f34b901903"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime, 1girl, solo, <lora:taimaninlina-pdxl-nvwls-v1-000005:1> trpglna, brown hair, ahoge, long hair, red eyes, horns, pointy ears, black jacket, fur trim, white shirt, collared shirt, red bowtie, cleavage, frills, red skirt, plaid skirt, belt, thigh strap, single thighhigh, large breasts, hand on own chest, blush, chestnut mouth, sitting, thighs, park bench, park, looking at you",
            "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
            "sampler": "Euler a",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "01f34b901903",
                    "name": "taimaninlina-pdxl-nvwls-v1-000005",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "d39f81730a",
                    "name": "honeyMixXLHighContrast_v1",
                    "type": "model"
                }
            ],
            "Model hash": "d39f81730a",
            "Hires steps": "10",
            "Hires upscale": "1.5",
            "Schedule type": "Automatic",
            "Hires upscaler": "4x-AnimeSharp",
            "negativePrompt": "monochrome, greyscale, nipples",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.4.2",
            "Denoising strength": "0.5",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True",
            "ADetailer mask only top k largest": "1"
        },
        "username": "novowels",
        "baseModel": "Pony"
    },
    {
        "id": 36216412,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f0aeaee8-dffa-4907-b765-c201028a25d1/width=1024/f0aeaee8-dffa-4907-b765-c201028a25d1.jpeg",
        "hash": "UaQb%itR*0tR-:aKR-kCtmnis,jZo}kWn3kC",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-24T01:05:59.020Z",
        "postId": 8274108,
        "stats": {
            "cryCount": 7,
            "laughCount": 19,
            "likeCount": 109,
            "dislikeCount": 0,
            "heartCount": 40,
            "commentCount": 0
        },
        "meta": {
            "Size": "1024x1024",
            "seed": 1622710507,
            "extra": {
                "remixOfId": 35596602
            },
            "steps": 30,
            "prompt": "Cat, Cute Cat, Holding a sign that says 'buzz pwease! I'm very poor.' on the front, extremely cute fluffy orange cat with blue eyes, in anime art style, kawaii, detailed, looking at viewer",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-24T0104:51.2369207Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                }
            ]
        },
        "username": "Zyrnox",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 36145292,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fc13d732-f375-4e82-abf8-9250dceb064e/width=832/fc13d732-f375-4e82-abf8-9250dceb064e.jpeg",
        "hash": "UWKI^is:Egt7}?juf8j?5TayRjV[Wajskpjb",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-23T15:27:14.576Z",
        "postId": 8258056,
        "stats": {
            "cryCount": 9,
            "laughCount": 55,
            "likeCount": 73,
            "dislikeCount": 0,
            "heartCount": 38,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 4232344214,
            "steps": 4,
            "prompt": "McDonald's advert poster. Donald Trump stands behind the counter of McDonald's, looking confused in an oversized uniform, and tiny hands, while surrounded by a chaotic mix of clowns, mascots. The slogan on top reads: 'Make America Buzz Again!' with ketchup stains splattered across the slogan. The color scheme is exaggerated, with over-the-top patriotic red, white, and mustard-yellow.",
            "sampler": "Undefined",
            "cfgScale": 1,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-23T1525:58.4790883Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 699279,
                    "modelVersionName": "Schnell"
                }
            ]
        },
        "username": "Cruise0880",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 36086554,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cf2c699f-a4d8-4a15-8cd3-9528c26d5203/width=1024/cf2c699f-a4d8-4a15-8cd3-9528c26d5203.jpeg",
        "hash": "U8DJ9jSi%%=|MwM|xXxW0dWWR4M{%goe%NWF",
        "width": 1024,
        "height": 1536,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-23T06:12:52.764Z",
        "postId": 8244303,
        "stats": {
            "cryCount": 0,
            "laughCount": 25,
            "likeCount": 112,
            "dislikeCount": 0,
            "heartCount": 38,
            "commentCount": 0
        },
        "meta": {
            "Size": "1024x1536",
            "seed": 3129370191,
            "Model": "flux1-dev-fp8",
            "steps": 10,
            "hashes": {
                "model": "1BE961341B",
                "schnell_v1.0": "C41F8106C9",
                "Movie_Posters": "350CF54A13"
            },
            "prompt": "Vintage Movie poster for \"Money for Nothing and Buzz for Free\" featuring the band Dire Straits. The band members are shown in a retro 80s style, standing in a playful pose with guitars and synthesizers, surrounded by neon lights and dollar bills floating around. Frontman Mark Knopfler is holding a guitar made of cash, while another band member strums on a guitar that doubles as a rocket ship. In the background, a stylized space scene shows planets and stars, with a rocket labeled \"Buzz\" soaring across the sky. The tagline reads: \"Why pay when you can get buzz for free?\" The poster uses vibrant colors, a neon glow, and a fun, energetic tone. <lora:Movie_Posters:0.8> <lora:schnell_v1.0:1.0><lora:787620917024084093:0>",
            "sampler": "Euler a",
            "cfgScale": 3.5,
            "resources": [
                {
                    "name": "Movie_Posters",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "name": "schnell_v1.0",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "name": "787620917024084093",
                    "type": "lora",
                    "weight": 0
                },
                {
                    "hash": "1BE961341B",
                    "name": "flux1-dev-fp8",
                    "type": "model"
                }
            ],
            "Model hash": "1BE961341B"
        },
        "username": "NowhereManGoes",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 35817899,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8e51d93c-d689-4a83-8aa6-3b24ffb208f5/width=832/8e51d93c-d689-4a83-8aa6-3b24ffb208f5.jpeg",
        "hash": "U47BWZ4T0z~W]xJQ4T_NJE-W-;9Z00-o^+00",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-21T18:55:18.183Z",
        "postId": 8185027,
        "stats": {
            "cryCount": 2,
            "laughCount": 7,
            "likeCount": 131,
            "dislikeCount": 0,
            "heartCount": 35,
            "commentCount": 0
        },
        "meta": null,
        "username": "DoreenAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 35696137,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/70d470e6-87e1-40b6-982f-961181090a19/width=832/70d470e6-87e1-40b6-982f-961181090a19.jpeg",
        "hash": "UJF4_.}@WV%0?b?F-pX9x]oKxD%1%1R+R+fk",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-21T01:41:51.924Z",
        "postId": 8157043,
        "stats": {
            "cryCount": 0,
            "laughCount": 1,
            "likeCount": 148,
            "dislikeCount": 0,
            "heartCount": 26,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2086548910,
            "steps": 32,
            "prompt": "Breathtaking views, nostalgia, detailed landscape, captivating, a harmony of nostalgia and innovation, great lighting, Nature, autumn leaves, fall, forests, rural townscapes, gassho-style houses, Scenery that blends Meiji and modern times, sun, sunlight, beautiful rivers, double exposure, beautiful view, mysterious glow, beautiful clouds, depth of field, masterpiece, best quality, 8k, ultra-detailed, very aesthetic, illustration, superb composition, finest details, , intricate details, absurdres, high contrast, RAW, concept art,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-21T0126:36.1958098Z",
            "negativePrompt": "extra digit, fewer digits, cropped, worst quality, low quality, normal quality, very displeasing, blurry, artist name, human",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 403131,
                    "modelVersionName": "v3.1"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 135867,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "yuyusikiAI",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 35631681,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/292b03f5-600f-40cf-afa4-1738ef6455cf/width=1560/292b03f5-600f-40cf-afa4-1738ef6455cf.jpeg",
        "hash": "UNEolM~Wxt-oxU%Lxuof0LIURPE3xsWCM{E1",
        "width": 1560,
        "height": 2280,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-20T16:55:52.528Z",
        "postId": 8141342,
        "stats": {
            "cryCount": 8,
            "laughCount": 11,
            "likeCount": 113,
            "dislikeCount": 0,
            "heartCount": 43,
            "commentCount": 1
        },
        "meta": null,
        "username": "fussypixel",
        "baseModel": ""
    },
    {
        "id": 35273110,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9e8b5297-764b-4e5d-a002-45398fa962a5/width=1536/9e8b5297-764b-4e5d-a002-45398fa962a5.jpeg",
        "hash": "URD,1M_3IUR*~q%MM{ax_3%LIUayxuayWBt7",
        "width": 1536,
        "height": 2304,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-18T16:11:45.897Z",
        "postId": 8061144,
        "stats": {
            "cryCount": 2,
            "laughCount": 8,
            "likeCount": 133,
            "dislikeCount": 0,
            "heartCount": 34,
            "commentCount": 4
        },
        "meta": {
            "Size": "1024x1536",
            "seed": 3289270812,
            "Model": "wildcardxXLFusion_fusionOG",
            "steps": 20,
            "hashes": {
                "model": "22ebc61141"
            },
            "Version": "v1.10.1",
            "sampler": "DPM++ 2M",
            "cfgScale": 5,
            "Mask blur": "4",
            "resources": [
                {
                    "hash": "22ebc61141",
                    "name": "wildcardxXLFusion_fusionOG",
                    "type": "model"
                }
            ],
            "Model hash": "22ebc61141",
            "Schedule type": "Karras",
            "Denoising strength": "0"
        },
        "username": "Castr0",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 35271051,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a970f74e-5daf-4bc3-bb78-573b4065ebdf/width=1072/a970f74e-5daf-4bc3-bb78-573b4065ebdf.jpeg",
        "hash": "UGD]@$D%E1_2b_i^DiT0.8E1DiV[~qxuIUxu",
        "width": 1072,
        "height": 1376,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-18T15:54:24.673Z",
        "postId": 8060689,
        "stats": {
            "cryCount": 0,
            "laughCount": 4,
            "likeCount": 121,
            "dislikeCount": 0,
            "heartCount": 51,
            "commentCount": 3
        },
        "meta": {
            "seed": 905553738525482,
            "vaes": [
                "FLUX1\\ae.sft"
            ],
            "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\clip_l.safetensors\", \"clip_name2\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux_dev.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 80, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 905553738525482}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 5.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 896, \"height\": 1152, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": 896, \"height\": 1152, \"model\": [\"154\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.4, \"alpha\": 0.4, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.5, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.05, \"scale\": 100.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"154\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 1], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"71\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"69\", 0]}, \"class_type\": \"ImageSharpen\"}, \"73\": {\"inputs\": {\"intensity\": 0.1, \"scale\": 100.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"181\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.3, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"184\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 40, \"denoise\": 0.15, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"a photorealistic depiction of a cybernetic oracle, a fusion of advanced artificial intelligence and mystical, spiritual elements. The character should have a humanoid appearance but with distinct features that highlight their artificial nature. Their skin is smooth and dark, resembling a matte metallic surface, but it should feel almost organic, as if the line between machine and flesh has been blurred. The skin should be adorned with intricate, glowing circuitry that follows the natural contours of the face and body, emitting a warm golden light. These lines should not only function as part of their mechanical systems but also resemble ancient, arcane symbols, giving the impression that this being possesses knowledge that transcends time and space.\\n\\nThe oracle's eyes are golden, suggesting a state of deep meditation or connection with a higher level of consciousness. Their facial features are soft and serene, with a peaceful expression that radiates wisdom and calm. The nose, lips, and cheeks should have the same metallic sheen as the rest of the body, but the lips should be slightly more defined, perhaps with a hint of human warmth, as if they could speak in both mechanical and organic languages.\\n\\nAdorning the oracle\\u2019s head is a hooded white cloak that gives them a regal, priestess-like appearance. The cloak should be made of a futuristic, silky material that flows like liquid metal, catching the light in ways that enhance the figure's divine appearance. The cloak should feature complex golden patterns, similar to celestial maps or ancient star charts, giving the sense that this being is connected to the cosmos in a profound way. The patterns should glow faintly, pulsing with energy, as if the oracle is drawing power from the universe itself.\\n\\nIn the background, create an ethereal, abstract environment that hints at both technological and mystical realms. Perhaps the oracle is seated in a vast chamber filled with floating holographic symbols, ancient runes, and digital streams of data. The lighting should be soft, with beams of light filtering through the atmosphere, casting gentle shadows across the oracle's face and cloak, further emphasizing their divine presence.\\n\\nThe overall mood of the image should evoke a sense of awe and wonder, as if this being holds the secrets to both the future of technology and the ancient mysteries of the universe. Every detail, from the glowing circuitry to the flowing cloak, should enhance the oracle\\u2019s role as a bridge between the physical and the metaphysical, the mechanical and the spiritual.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", \"clip\": [\"154\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"154\": {\"inputs\": {\"lora_name\": \"flux1\\\\detailed_skin_portraits-000005.safetensors\", \"strength_model\": 0.2, \"strength_clip\": 1.0, \"model\": [\"155\", 0], \"clip\": [\"155\", 1]}, \"class_type\": \"LoraLoader\"}, \"155\": {\"inputs\": {\"lora_name\": \"flux1\\\\realism_lora_comfy flux_converted.safetensors\", \"strength_model\": 0.7000000000000001, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"181\": {\"inputs\": {\"hdr_intensity\": 0.5, \"shadow_intensity\": 1.0, \"highlight_intensity\": 0.0, \"gamma_intensity\": 0.0, \"contrast\": 0.0, \"enhance_color\": 0.0, \"image\": [\"71\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"184\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"UpscaleModelLoader\"}}, \"workflow\": {\"last_node_id\": 184, \"last_link_id\": 401, \"nodes\": [{\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1465, \"1\": 40}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -124}, \"size\": [75, 26], \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 283, \"1\": -178}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 356}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -5, \"1\": 183}, \"size\": {\"0\": 302.84521484375, \"1\": 109.7906265258789}, \"flags\": {\"collapsed\": true}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [333], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\clip_l.safetensors\", \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"flux\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1457, \"1\": 152}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 350}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [390], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 1780, \"1\": 855}, \"size\": {\"0\": 510.7679443359375, \"1\": 941.9960327148438}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1228, \"1\": 152}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [393], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -50}, \"size\": [75, 26], \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1199, \"1\": 23}, \"size\": {\"0\": 245.11636352539062, \"1\": 82}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 67, \"1\": 805}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {\"collapsed\": true}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 342, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [896, 1152, 1]}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 320.2164611816406, \"1\": 122}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 324, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 398], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 896, 1152]}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 854, \"1\": 612}, \"size\": {\"0\": 272.3565368652344, \"1\": 106}, \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.4, 0.4], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1613, \"1\": 255}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 58, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 391}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [399], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.08, 0.98, 1, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": -54, \"1\": 51}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux_dev.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 1, \"1\": 239}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {\"collapsed\": true}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 521, \"1\": -98}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 871, \"1\": 762}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [289, 397], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 594, \"1\": 766}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [905553738525482, \"randomize\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 883, \"1\": 1143}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.3], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 450, \"1\": 1353}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 401}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 289}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 923, \"1\": 66}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": [], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 184, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 874, \"1\": 1291}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [401], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"]}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1621, \"1\": 694}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 398, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [394], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 40, 0.15], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 881, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 397}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 100, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 153, \"type\": \"LoraLoader\", \"pos\": {\"0\": -4, \"1\": 383}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 26, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 326}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 327}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [324], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [356], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\XT404.BOOBS-Bastic.XXL.safetensors\", 0.35000000000000003, 1]}, {\"id\": 181, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1838, \"1\": 255}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 399}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [400], \"slot_index\": 0, \"shape\": 3}], \"title\": \"HDR Effects darker\", \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 1, 0, 0, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 154, \"type\": \"LoraLoader\", \"pos\": {\"0\": -759, \"1\": 591}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 347}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 348}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [326], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [327], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\detailed_skin_portraits-000005.safetensors\", 0.2, 1]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 364, \"1\": 782}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 483, \"1\": 998}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 80, 1]}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1620, \"1\": 495}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 400}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.1, 100, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 625, \"1\": 643}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1152, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 391, \"1\": 654}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 342], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [896, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 1822, \"1\": 90}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 390}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [391], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 161, \"type\": \"LoraLoader\", \"pos\": {\"0\": -755, \"1\": 406}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 23, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 343}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 344}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [347], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [348], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\FluxF4ngs.safetensors\", 0.5, 1]}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1212, \"1\": 272}, \"size\": {\"0\": 300.22662353515625, \"1\": 545.8931884765625}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 393, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 394, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [350], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": [], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 916, \"1\": 50}, \"size\": {\"0\": 236.8000030517578, \"1\": 514.9979248046875}, \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": [], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 160, \"type\": \"LoraLoader\", \"pos\": {\"0\": -384, \"1\": 411}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 20, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 346}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 345}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [343], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [344], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Bimbos_and_models-000005.safetensors\", 1, 1]}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1217, \"1\": 871}, \"size\": {\"0\": 513.1029052734375, \"1\": 947.150634765625}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 156, \"type\": \"LoraLoader\", \"pos\": {\"0\": -407, \"1\": 605}, \"size\": {\"0\": 350.4808654785156, \"1\": 126}, \"flags\": {}, \"order\": 17, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 396}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 331}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [346], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [345], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\starcraftqob.safetensors\", 0.5, 1]}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 238, \"1\": -91}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [5], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 369, \"1\": 133}, \"size\": {\"0\": 458.922607421875, \"1\": 422.7685852050781}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"a photorealistic depiction of a cybernetic oracle, a fusion of advanced artificial intelligence and mystical, spiritual elements. The character should have a humanoid appearance but with distinct features that highlight their artificial nature. Their skin is smooth and dark, resembling a matte metallic surface, but it should feel almost organic, as if the line between machine and flesh has been blurred. The skin should be adorned with intricate, glowing circuitry that follows the natural contours of the face and body, emitting a warm golden light. These lines should not only function as part of their mechanical systems but also resemble ancient, arcane symbols, giving the impression that this being possesses knowledge that transcends time and space.\\n\\nThe oracle's eyes are golden, suggesting a state of deep meditation or connection with a higher level of consciousness. Their facial features are soft and serene, with a peaceful expression that radiates wisdom and calm. The nose, lips, and cheeks should have the same metallic sheen as the rest of the body, but the lips should be slightly more defined, perhaps with a hint of human warmth, as if they could speak in both mechanical and organic languages.\\n\\nAdorning the oracle\\u2019s head is a hooded white cloak that gives them a regal, priestess-like appearance. The cloak should be made of a futuristic, silky material that flows like liquid metal, catching the light in ways that enhance the figure's divine appearance. The cloak should feature complex golden patterns, similar to celestial maps or ancient star charts, giving the sense that this being is connected to the cosmos in a profound way. The patterns should glow faintly, pulsing with energy, as if the oracle is drawing power from the universe itself.\\n\\nIn the background, create an ethereal, abstract environment that hints at both technological and mystical realms. Perhaps the oracle is seated in a vast chamber filled with floating holographic symbols, ancient runes, and digital streams of data. The lighting should be soft, with beams of light filtering through the atmosphere, casting gentle shadows across the oracle's face and cloak, further emphasizing their divine presence.\\n\\nThe overall mood of the image should evoke a sense of awe and wonder, as if this being holds the secrets to both the future of technology and the ancient mysteries of the universe. Every detail, from the glowing circuitry to the flowing cloak, should enhance the oracle\\u2019s role as a bridge between the physical and the metaphysical, the mechanical and the spiritual.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"]}, {\"id\": 155, \"type\": \"LoraLoader\", \"pos\": {\"0\": -10, \"1\": 605}, \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 332}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 333}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [396], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [331], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\realism_lora_comfy flux_converted.safetensors\", 0.7000000000000001, 1]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [285, 75, 0, 59, 0, \"IMAGE\"], [288, 62, 0, 41, 0, \"IMAGE\"], [289, 61, 0, 77, 1, \"IMAGE\"], [324, 153, 0, 30, 0, \"MODEL\"], [326, 154, 0, 153, 0, \"MODEL\"], [327, 154, 1, 153, 1, \"CLIP\"], [331, 155, 1, 156, 1, \"CLIP\"], [332, 12, 0, 155, 0, \"MODEL\"], [333, 11, 0, 155, 1, \"CLIP\"], [342, 34, 0, 27, 0, \"INT\"], [343, 160, 0, 161, 0, \"MODEL\"], [344, 160, 1, 161, 1, \"CLIP\"], [345, 156, 1, 160, 1, \"CLIP\"], [346, 156, 0, 160, 0, \"MODEL\"], [347, 161, 0, 154, 0, \"MODEL\"], [348, 161, 1, 154, 1, \"CLIP\"], [350, 42, 1, 69, 0, \"LATENT\"], [356, 153, 1, 49, 0, \"*\"], [390, 69, 0, 71, 0, \"IMAGE\"], [391, 71, 0, 72, 0, \"IMAGE\"], [393, 134, 0, 42, 2, \"SAMPLER\"], [394, 79, 0, 42, 3, \"SIGMAS\"], [396, 155, 0, 156, 0, \"MODEL\"], [397, 61, 0, 62, 0, \"IMAGE\"], [398, 30, 0, 79, 0, \"MODEL\"], [399, 72, 0, 181, 0, \"IMAGE\"], [400, 181, 0, 73, 0, \"IMAGE\"], [401, 184, 0, 77, 0, \"UPSCALE_MODEL\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.9487171000000025, \"offset\": [-238.9718354652477, -150.4022051791077]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}}}}",
            "steps": 80,
            "models": [],
            "prompt": "a photorealistic depiction of a cybernetic oracle, a fusion of advanced artificial intelligence and mystical, spiritual elements. The character should have a humanoid appearance but with distinct features that highlight their artificial nature. Their skin is smooth and dark, resembling a matte metallic surface, but it should feel almost organic, as if the line between machine and flesh has been blurred. The skin should be adorned with intricate, glowing circuitry that follows the natural contours of the face and body, emitting a warm golden light. These lines should not only function as part of their mechanical systems but also resemble ancient, arcane symbols, giving the impression that this being possesses knowledge that transcends time and space.\n\nThe oracle's eyes are golden, suggesting a state of deep meditation or connection with a higher level of consciousness. Their facial features are soft and serene, with a peaceful expression that radiates wisdom and calm. The nose, lips, and cheeks should have the same metallic sheen as the rest of the body, but the lips should be slightly more defined, perhaps with a hint of human warmth, as if they could speak in both mechanical and organic languages.\n\nAdorning the oracle\u2019s head is a hooded white cloak that gives them a regal, priestess-like appearance. The cloak should be made of a futuristic, silky material that flows like liquid metal, catching the light in ways that enhance the figure's divine appearance. The cloak should feature complex golden patterns, similar to celestial maps or ancient star charts, giving the sense that this being is connected to the cosmos in a profound way. The patterns should glow faintly, pulsing with energy, as if the oracle is drawing power from the universe itself.\n\nIn the background, create an ethereal, abstract environment that hints at both technological and mystical realms. Perhaps the oracle is seated in a vast chamber filled with floating holographic symbols, ancient runes, and digital streams of data. The lighting should be soft, with beams of light filtering through the atmosphere, casting gentle shadows across the oracle's face and cloak, further emphasizing their divine presence.\n\nThe overall mood of the image should evoke a sense of awe and wonder, as if this being holds the secrets to both the future of technology and the ancient mysteries of the universe. Every detail, from the glowing circuitry to the flowing cloak, should enhance the oracle\u2019s role as a bridge between the physical and the metaphysical, the mechanical and the spiritual.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 5,
            "modelIds": [],
            "scheduler": "sgm_uniform",
            "upscalers": [
                "4x_UniversalUpscalerV2-Sharper_103000_G.pth"
            ],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "flux1\\detailed_skin_portraits-000005.safetensors",
                    "type": "lora",
                    "strength": 0.2,
                    "strengthClip": 1
                },
                {
                    "name": "flux1\\realism_lora_comfy flux_converted.safetensors",
                    "type": "lora",
                    "strength": 0.7000000000000001,
                    "strengthClip": 1
                }
            ]
        },
        "username": "1stgenerationpme",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 34783284,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/58df6b14-2e1a-4100-a3b9-7e7123fa808b/width=832/58df6b14-2e1a-4100-a3b9-7e7123fa808b.jpeg",
        "hash": "U86uIcMKN[yC~BR5NHoz-UoeTJRPxsofTJVs",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-15T20:01:49.575Z",
        "postId": 7948511,
        "stats": {
            "cryCount": 0,
            "laughCount": 3,
            "likeCount": 130,
            "dislikeCount": 0,
            "heartCount": 42,
            "commentCount": 0
        },
        "meta": null,
        "username": "DoreenAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 34724120,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/024e5de6-2529-4ad9-853f-244674b8361d/width=832/024e5de6-2529-4ad9-853f-244674b8361d.jpeg",
        "hash": "UPC?Q6s:Iobb~WWBD%of-;WVIUt7xufQMyoL",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-16T12:41:00.000Z",
        "postId": 7934478,
        "stats": {
            "cryCount": 6,
            "laughCount": 14,
            "likeCount": 102,
            "dislikeCount": 0,
            "heartCount": 53,
            "commentCount": 4
        },
        "meta": null,
        "username": "RandomDiffusion",
        "baseModel": "Pony"
    },
    {
        "id": 34511473,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/86e3220d-6c6b-4c92-8098-47bb965478f5/width=864/86e3220d-6c6b-4c92-8098-47bb965478f5.jpeg",
        "hash": "UAN0#Zt8^+~pGGR*H@RkrXkC58RP9aR*-n%0",
        "width": 864,
        "height": 1152,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-14T06:21:04.098Z",
        "postId": 7884610,
        "stats": {
            "cryCount": 4,
            "laughCount": 3,
            "likeCount": 99,
            "dislikeCount": 0,
            "heartCount": 69,
            "commentCount": 0
        },
        "meta": {
            "RNG": "NV",
            "VAE": "sdxl_vae.safetensors",
            "Size": "864x1152",
            "seed": 2332632779,
            "Model": "autismmixSDXL_autismmixPony",
            "steps": 30,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "821aa5537f",
                "lora:RabbitonesieXLP": "c599fcea1eb3"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up,  <lora:RabbitonesieXLP:1> rabbit onesie, rabbit costume, rabbit ears, hood, barefoot, rabbit tail, solo, 1girl, curvy, long hair, black hair, pajamas,",
            "Version": "v1.10.1",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "c599fcea1eb3",
                    "name": "RabbitonesieXLP",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "821aa5537f",
                    "name": "autismmixSDXL_autismmixPony",
                    "type": "model"
                }
            ],
            "Model hash": "821aa5537f",
            "Schedule type": "Automatic",
            "negativePrompt": "watermark, signature, artist name, twitter username, censored, realistic, 3d, child, kid, loli",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.9.0",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.25",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "freckledvixon",
        "baseModel": "Pony"
    },
    {
        "id": 34331197,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ea4a810f-91fe-4f15-8a2d-7ba3e5af3f85/width=832/ea4a810f-91fe-4f15-8a2d-7ba3e5af3f85.jpeg",
        "hash": "U59sr1E200jZ$iRkJ7xa02%1?GkC~VR,D*M|",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-13T06:38:08.348Z",
        "postId": 7844762,
        "stats": {
            "cryCount": 0,
            "laughCount": 4,
            "likeCount": 128,
            "dislikeCount": 0,
            "heartCount": 43,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 210825985,
            "steps": 40,
            "prompt": "19-year-old woman with a side buzz cut  looking up and to the side, 35mm, F/2.8, bare breasts,  armour,  black simple draped cloth, character, hypermaximalist, elegant,  beautiful, exotic, revealing, appealing, attractive, amative, hyper-realistic, dune the film, popular on Flickr",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-12T1944:32.8709213Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 840288,
                    "modelVersionName": "artisketchyfs"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 732922,
                    "modelVersionName": "Skin Details V1"
                }
            ]
        },
        "username": "Memetic",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 34285105,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cb895917-2e22-4629-a573-559b77fbe729/width=832/cb895917-2e22-4629-a573-559b77fbe729.jpeg",
        "hash": "UBHLh$004=x%9W0NOb.8H@0%=_}syZ$0sPS5",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-13T01:05:19.783Z",
        "postId": 7834942,
        "stats": {
            "cryCount": 4,
            "laughCount": 8,
            "likeCount": 130,
            "dislikeCount": 0,
            "heartCount": 33,
            "commentCount": 0
        },
        "meta": {
            "seed": 133760494,
            "Model": "flux1-schnell-Q8_0.gguf",
            "steps": 5,
            "width": 832,
            "height": 1216,
            "prompt": "woman, outdoor portrait, Watercolor painting, transparent and delicate layers, luminous and ethereal effects, spontaneous and fluid compositions, subtle gradients and blending, captures light and atmosphere, creates soft and dreamy scenes,mirror maze, distorted reflections, flickering lights, eerie silence, confusing paths, unsettling tension, strange echoes, haunting reflections, spooky and surreal,hidden waterfall, gentle cascading water, surrounded by lush greenery, soft mist, peaceful and serene, intimate escape, glowing reflection, tranquil beauty,wildflower meadow, colorful blooms, bright sunlight, soft breeze, peaceful and joyful ambiance, vibrant nature, lively and serene atmosphere, tranquil beauty, ",
            "sampler": "Euler",
            "cfgScale": 1,
            "scheduler": "beta",
            "originalSampler": "euler"
        },
        "username": "nisse91",
        "baseModel": "Flux.1 S"
    },
    {
        "id": 1072657,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3979e187-2604-4bd5-abcf-c791d9e8712c/width=960/3979e187-2604-4bd5-abcf-c791d9e8712c.jpeg",
        "hash": "UTL47{IpJQx]_Nt6%goyELX9%MV@-Uj[RQkC",
        "width": 960,
        "height": 1440,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-10T03:14:56.423Z",
        "postId": 283176,
        "stats": {
            "cryCount": 0,
            "laughCount": 2,
            "likeCount": 80,
            "dislikeCount": 0,
            "heartCount": 93,
            "commentCount": 3
        },
        "meta": {
            "Size": "640x960",
            "seed": 2107694712,
            "steps": 20,
            "prompt": "masterpiece,best quality,1girl,smile, pop, fancy,city,road,stylish pose,jump,dynamic",
            "Version": "v1.3.2",
            "sampler": "DPM++ 2M",
            "cfgScale": 11,
            "Clip skip": "2",
            "resources": [],
            "Model hash": "fbd0ba3424",
            "Hires upscale": "1.5",
            "Hires upscaler": "Latent",
            "negativePrompt": "lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry,nsfw, (,bad hands,bad fingers,negative_hand-neg:1.5)",
            "Denoising strength": "0.55"
        },
        "username": "pawapawa",
        "baseModel": "SD 1.5"
    },
    {
        "id": 1247109,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b9f932c9-0deb-47ec-9fe1-4025c2af7e09/width=1800/b9f932c9-0deb-47ec-9fe1-4025c2af7e09.jpeg",
        "hash": "UQG+mw~p%gx[.9%2WEofD~oInNslD*NIw]aK",
        "width": 2048,
        "height": 3072,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-06-22T20:43:31.970Z",
        "postId": 322739,
        "stats": {
            "cryCount": 20,
            "laughCount": 124,
            "likeCount": 21,
            "dislikeCount": 0,
            "heartCount": 10,
            "commentCount": 0
        },
        "meta": {
            "Size": "512x768",
            "seed": 2004466197,
            "Model": "anyloraCheckpoint_bakedvaeFtmseFp16NOT",
            "steps": 25,
            "hashes": {
                "vae": "c6a580b13a",
                "model": "8a952cafe9",
                "lora:FlashgitzV5": "6f5b091ddc",
                "lora:hatsunemiku1-000006": "966b9b5d04"
            },
            "prompt": "flashgitz, vocaloid3, fat <lora:FlashgitzV1:1.2> <lora:hatsunemiku1-000006:0.8>",
            "{\"vae\"": "\"c6a580b13a\"",
            "\"model\"": "\"8a952cafe9\"}",
            "sampler": "Euler a",
            "cfgScale": 10,
            "Clip skip": "2",
            "resources": [
                {
                    "name": "FlashgitzV5",
                    "type": "lora",
                    "weight": 1.2
                },
                {
                    "hash": "8a952cafe9",
                    "name": "anyloraCheckpoint_bakedvaeFtmseFp16NOT",
                    "type": "model"
                }
            ],
            "Model hash": "8a952cafe9",
            "FlashgitzV5\"": "\"6f5b091ddc\"",
            "Hires upscale": "2",
            "Hires upscaler": "R-ESRGAN 4x+ Anime6B",
            "negativePrompt": "(low quality, worst quality:1.4), text, watermark, cropped, blurry",
            "Denoising strength": "0.4",
            "hatsunemiku1-000006\"": "\"966b9b5d04\""
        },
        "username": "Xypher",
        "baseModel": "SD 1.5"
    },
    {
        "id": 3364702,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/fe91e76e-0821-4552-9e79-a1350659f707/width=1536/fe91e76e-0821-4552-9e79-a1350659f707.jpeg",
        "hash": "U8MP?s00YN_1]_}?Kk9a00=^rs4o7gr=#mtl",
        "width": 1536,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-11-03T20:04:48.521Z",
        "postId": 770224,
        "stats": {
            "cryCount": 0,
            "laughCount": 22,
            "likeCount": 81,
            "dislikeCount": 0,
            "heartCount": 72,
            "commentCount": 2
        },
        "meta": {
            "vaes": [],
            "Model": "sd_xl_refiner_1.0",
            "comfy": "{\"prompt\":{\"4\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"5\":{\"inputs\":{\"width\":1536,\"height\":1024,\"batch_size\":1},\"class_type\":\"EmptyLatentImage\"},\"8\":{\"inputs\":{\"samples\":{\"inputs\":{\"add_noise\":\"disable\",\"noise_seed\":380364824789770,\"steps\":50,\"cfg\":3,\"sampler_name\":\"dpmpp_sde\",\"scheduler\":\"karras\",\"start_at_step\":40,\"end_at_step\":50,\"return_with_leftover_noise\":\"disable\",\"model\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"positive\":{\"inputs\":{\"ascore\":6,\"width\":4096,\"height\":4096,\"text\":\"A photo of a cat made out of sushi roll\",\"clip\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"CLIPTextEncodeSDXLRefiner\"},\"negative\":{\"inputs\":{\"ascore\":1,\"width\":4096,\"height\":4096,\"text\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"CLIPTextEncodeSDXLRefiner\"},\"latent_image\":{\"inputs\":{\"add_noise\":\"enable\",\"noise_seed\":380364824789770,\"steps\":50,\"cfg\":3,\"sampler_name\":\"dpmpp_sde\",\"scheduler\":\"karras\",\"start_at_step\":0,\"end_at_step\":40,\"return_with_leftover_noise\":\"enable\",\"model\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"},\"positive\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"A photo of a cat made out of sushi roll\",\"text_l\":\"cinematic, fujifilm, RTX, bokeh\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"negative\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"text_l\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"latent_image\":{\"inputs\":{\"width\":1536,\"height\":1024,\"batch_size\":1},\"class_type\":\"EmptyLatentImage\"}},\"class_type\":\"KSamplerAdvanced\"}},\"class_type\":\"KSamplerAdvanced\"},\"vae\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"VAEDecode\"},\"10\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"22\":{\"inputs\":{\"add_noise\":\"enable\",\"noise_seed\":380364824789770,\"steps\":50,\"cfg\":3,\"sampler_name\":\"dpmpp_sde\",\"scheduler\":\"karras\",\"start_at_step\":0,\"end_at_step\":40,\"return_with_leftover_noise\":\"enable\",\"model\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"},\"positive\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"A photo of a cat made out of sushi roll\",\"text_l\":\"cinematic, fujifilm, RTX, bokeh\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"negative\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"text_l\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"latent_image\":{\"inputs\":{\"width\":1536,\"height\":1024,\"batch_size\":1},\"class_type\":\"EmptyLatentImage\"}},\"class_type\":\"KSamplerAdvanced\"},\"23\":{\"inputs\":{\"add_noise\":\"disable\",\"noise_seed\":380364824789770,\"steps\":50,\"cfg\":3,\"sampler_name\":\"dpmpp_sde\",\"scheduler\":\"karras\",\"start_at_step\":40,\"end_at_step\":50,\"return_with_leftover_noise\":\"disable\",\"model\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"positive\":{\"inputs\":{\"ascore\":6,\"width\":4096,\"height\":4096,\"text\":\"A photo of a cat made out of sushi roll\",\"clip\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"CLIPTextEncodeSDXLRefiner\"},\"negative\":{\"inputs\":{\"ascore\":1,\"width\":4096,\"height\":4096,\"text\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"CLIPTextEncodeSDXLRefiner\"},\"latent_image\":{\"inputs\":{\"add_noise\":\"enable\",\"noise_seed\":380364824789770,\"steps\":50,\"cfg\":3,\"sampler_name\":\"dpmpp_sde\",\"scheduler\":\"karras\",\"start_at_step\":0,\"end_at_step\":40,\"return_with_leftover_noise\":\"enable\",\"model\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"},\"positive\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"A photo of a cat made out of sushi roll\",\"text_l\":\"cinematic, fujifilm, RTX, bokeh\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"negative\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"text_l\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"latent_image\":{\"inputs\":{\"width\":1536,\"height\":1024,\"batch_size\":1},\"class_type\":\"EmptyLatentImage\"}},\"class_type\":\"KSamplerAdvanced\"}},\"class_type\":\"KSamplerAdvanced\"},\"75\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"A photo of a cat made out of sushi roll\",\"text_l\":\"cinematic, fujifilm, RTX, bokeh\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"81\":{\"inputs\":{\"ascore\":1,\"width\":4096,\"height\":4096,\"text\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"CLIPTextEncodeSDXLRefiner\"},\"82\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"text_l\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"120\":{\"inputs\":{\"ascore\":6,\"width\":4096,\"height\":4096,\"text\":\"A photo of a cat made out of sushi roll\",\"clip\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"CLIPTextEncodeSDXLRefiner\"},\"122\":{\"inputs\":{\"filename_prefix\":\"ComfyUI\",\"images\":{\"inputs\":{\"samples\":{\"inputs\":{\"add_noise\":\"disable\",\"noise_seed\":380364824789770,\"steps\":50,\"cfg\":3,\"sampler_name\":\"dpmpp_sde\",\"scheduler\":\"karras\",\"start_at_step\":40,\"end_at_step\":50,\"return_with_leftover_noise\":\"disable\",\"model\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"positive\":{\"inputs\":{\"ascore\":6,\"width\":4096,\"height\":4096,\"text\":\"A photo of a cat made out of sushi roll\",\"clip\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"CLIPTextEncodeSDXLRefiner\"},\"negative\":{\"inputs\":{\"ascore\":1,\"width\":4096,\"height\":4096,\"text\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"CLIPTextEncodeSDXLRefiner\"},\"latent_image\":{\"inputs\":{\"add_noise\":\"enable\",\"noise_seed\":380364824789770,\"steps\":50,\"cfg\":3,\"sampler_name\":\"dpmpp_sde\",\"scheduler\":\"karras\",\"start_at_step\":0,\"end_at_step\":40,\"return_with_leftover_noise\":\"enable\",\"model\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"},\"positive\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"A photo of a cat made out of sushi roll\",\"text_l\":\"cinematic, fujifilm, RTX, bokeh\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"negative\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"text_l\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"latent_image\":{\"inputs\":{\"width\":1536,\"height\":1024,\"batch_size\":1},\"class_type\":\"EmptyLatentImage\"}},\"class_type\":\"KSamplerAdvanced\"}},\"class_type\":\"KSamplerAdvanced\"},\"vae\":{\"inputs\":{\"ckpt_name\":\"sd_xl_refiner_1.0.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"VAEDecode\"}},\"class_type\":\"SaveImage\"},\"146\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"},\"147\":{\"inputs\":{\"samples\":{\"inputs\":{\"add_noise\":\"enable\",\"noise_seed\":380364824789770,\"steps\":50,\"cfg\":3,\"sampler_name\":\"dpmpp_sde\",\"scheduler\":\"karras\",\"start_at_step\":0,\"end_at_step\":40,\"return_with_leftover_noise\":\"enable\",\"model\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"},\"positive\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"A photo of a cat made out of sushi roll\",\"text_l\":\"cinematic, fujifilm, RTX, bokeh\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"negative\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"text_l\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"latent_image\":{\"inputs\":{\"width\":1536,\"height\":1024,\"batch_size\":1},\"class_type\":\"EmptyLatentImage\"}},\"class_type\":\"KSamplerAdvanced\"},\"vae\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"VAEDecode\"},\"148\":{\"inputs\":{\"images\":{\"inputs\":{\"samples\":{\"inputs\":{\"add_noise\":\"enable\",\"noise_seed\":380364824789770,\"steps\":50,\"cfg\":3,\"sampler_name\":\"dpmpp_sde\",\"scheduler\":\"karras\",\"start_at_step\":0,\"end_at_step\":40,\"return_with_leftover_noise\":\"enable\",\"model\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"},\"positive\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"A photo of a cat made out of sushi roll\",\"text_l\":\"cinematic, fujifilm, RTX, bokeh\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"negative\":{\"inputs\":{\"width\":4096,\"height\":4096,\"crop_w\":0,\"crop_h\":0,\"target_width\":4096,\"target_height\":4096,\"text_g\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"text_l\":\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"clip\":{\"inputs\":{\"lora_name\":\"PerfectEyesXL.safetensors\",\"strength_model\":0.65,\"strength_clip\":0.65,\"model\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"},\"clip\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"LoraLoader\"}},\"class_type\":\"CLIPTextEncodeSDXL\"},\"latent_image\":{\"inputs\":{\"width\":1536,\"height\":1024,\"batch_size\":1},\"class_type\":\"EmptyLatentImage\"}},\"class_type\":\"KSamplerAdvanced\"},\"vae\":{\"inputs\":{\"ckpt_name\":\"D4ll34_001CKPT.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\"}},\"class_type\":\"VAEDecode\"}},\"class_type\":\"PreviewImage\"}},\"workflow\":{\"last_node_id\":150,\"last_link_id\":554,\"nodes\":[{\"id\":134,\"type\":\"Reroute\",\"pos\":[805.2004028320308,-1248.6007812500018],\"size\":[75,26],\"flags\":{},\"order\":21,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":514,\"slot_index\":0}],\"outputs\":[{\"name\":\"\",\"type\":\"VAE\",\"links\":[515],\"slot_index\":0}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":8,\"type\":\"VAEDecode\",\"pos\":[920.2004028320308,-1218.6007812500018],\"size\":{\"0\":140,\"1\":46},\"flags\":{\"collapsed\":true},\"order\":28,\"mode\":0,\"inputs\":[{\"name\":\"samples\",\"type\":\"LATENT\",\"link\":56},{\"name\":\"vae\",\"type\":\"VAE\",\"link\":515}],\"outputs\":[{\"name\":\"IMAGE\",\"type\":\"IMAGE\",\"links\":[491],\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"VAEDecode\"},\"color\":\"#222\",\"bgcolor\":\"#000\"},{\"id\":141,\"type\":\"Reroute\",\"pos\":[454.93465574072343,-601.4836639351809],\"size\":[75,26],\"flags\":{},\"order\":14,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":554}],\"outputs\":[{\"name\":\"\",\"type\":\"CLIP\",\"links\":[531,533],\"slot_index\":0}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":142,\"type\":\"Reroute\",\"pos\":[454.93465574072343,-621.4836639351809],\"size\":[75,26],\"flags\":{},\"order\":13,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":553}],\"outputs\":[{\"name\":\"\",\"type\":\"MODEL\",\"links\":[529],\"slot_index\":0}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":120,\"type\":\"CLIPTextEncodeSDXLRefiner\",\"pos\":[559.3724688311294,-604.8169886593452],\"size\":{\"0\":400,\"1\":200},\"flags\":{\"collapsed\":true},\"order\":20,\"mode\":0,\"inputs\":[{\"name\":\"clip\",\"type\":\"CLIP\",\"link\":533,\"slot_index\":0},{\"name\":\"text\",\"type\":\"STRING\",\"link\":478,\"widget\":{\"name\":\"text\",\"config\":[\"STRING\",{\"multiline\":true}]},\"slot_index\":1},{\"name\":\"ascore\",\"type\":\"FLOAT\",\"link\":518,\"widget\":{\"name\":\"ascore\",\"config\":[\"FLOAT\",{\"default\":6,\"min\":0,\"max\":1000,\"step\":0.01}]},\"slot_index\":2}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[480],\"shape\":3,\"slot_index\":0}],\"title\":\"Positive Refiner\",\"properties\":{\"Node name for S&R\":\"CLIPTextEncodeSDXLRefiner\"},\"widgets_values\":[6,4096,4096,\"A photo of a cat made out of sushi\"],\"color\":\"#232\",\"bgcolor\":\"#353\"},{\"id\":81,\"type\":\"CLIPTextEncodeSDXLRefiner\",\"pos\":[559.3724688311294,-574.8169886593452],\"size\":{\"0\":400,\"1\":200},\"flags\":{\"collapsed\":true},\"order\":19,\"mode\":0,\"inputs\":[{\"name\":\"clip\",\"type\":\"CLIP\",\"link\":531},{\"name\":\"text\",\"type\":\"STRING\",\"link\":494,\"widget\":{\"name\":\"text\",\"config\":[\"STRING\",{\"multiline\":true}]}},{\"name\":\"ascore\",\"type\":\"FLOAT\",\"link\":534,\"widget\":{\"name\":\"ascore\",\"config\":[\"FLOAT\",{\"default\":6,\"min\":0,\"max\":1000,\"step\":0.01}]}}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[299],\"shape\":3,\"slot_index\":0}],\"title\":\"Negative Refiner\",\"properties\":{\"Node name for S&R\":\"CLIPTextEncodeSDXLRefiner\"},\"widgets_values\":[1,4096,4096,\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\"],\"color\":\"#322\",\"bgcolor\":\"#533\"},{\"id\":126,\"type\":\"Reroute\",\"pos\":[770.2418319675904,-622.9673278703617],\"size\":[75,26],\"flags\":{},\"order\":18,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":529}],\"outputs\":[{\"name\":\"\",\"type\":\"MODEL\",\"links\":[506],\"slot_index\":0}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":133,\"type\":\"Reroute\",\"pos\":[770.2418319675904,-582.9673278703617],\"size\":[75,26],\"flags\":{},\"order\":15,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":513}],\"outputs\":[{\"name\":\"\",\"type\":\"VAE\",\"links\":[514]}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":139,\"type\":\"Reroute\",\"pos\":[434.93465574072343,-31.483663935180807],\"size\":[75,26],\"flags\":{},\"order\":17,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":538}],\"outputs\":[{\"name\":\"\",\"type\":\"CLIP\",\"links\":[522,523],\"slot_index\":0}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":140,\"type\":\"Reroute\",\"pos\":[434.93465574072343,-51.483663935180815],\"size\":[75,26],\"flags\":{},\"order\":16,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":539}],\"outputs\":[{\"name\":\"\",\"type\":\"MODEL\",\"links\":[535],\"slot_index\":0}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":43,\"type\":\"PrimitiveNode\",\"pos\":[-310,-890],\"size\":{\"0\":609.0048828125,\"1\":172.01026916503906},\"flags\":{},\"order\":0,\"mode\":0,\"outputs\":[{\"name\":\"STRING\",\"type\":\"STRING\",\"links\":[302,476,494],\"slot_index\":0,\"widget\":{\"name\":\"text_g\",\"config\":[\"STRING\",{\"multiline\":true,\"default\":\"CLIP_G\"}]}}],\"title\":\"Fundamental Negative\",\"properties\":{},\"widgets_values\":[\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\"],\"color\":\"#322\",\"bgcolor\":\"#533\"},{\"id\":78,\"type\":\"PrimitiveNode\",\"pos\":[-310,-1230],\"size\":{\"0\":302.9015197753906,\"1\":300.84906005859375},\"flags\":{\"collapsed\":false},\"order\":1,\"mode\":0,\"outputs\":[{\"name\":\"STRING\",\"type\":\"STRING\",\"links\":[434,478],\"slot_index\":0,\"widget\":{\"name\":\"text_g\",\"config\":[\"STRING\",{\"multiline\":true,\"default\":\"CLIP_G\"}]}}],\"title\":\"Linguistic Positive\",\"properties\":{},\"widgets_values\":[\"A photo of a cat made out of sushi roll\"],\"color\":\"#232\",\"bgcolor\":\"#353\"},{\"id\":77,\"type\":\"PrimitiveNode\",\"pos\":[6,-1231],\"size\":{\"0\":291.2458190917969,\"1\":302.58148193359375},\"flags\":{},\"order\":2,\"mode\":0,\"outputs\":[{\"name\":\"STRING\",\"type\":\"STRING\",\"links\":[470],\"slot_index\":0,\"widget\":{\"name\":\"text_l\",\"config\":[\"STRING\",{\"multiline\":true,\"default\":\"CLIP_L\"}]}}],\"title\":\"Supporting Terms\",\"properties\":{},\"widgets_values\":[\"cinematic, fujifilm, RTX, bokeh\"],\"color\":\"#232\",\"bgcolor\":\"#353\"},{\"id\":145,\"type\":\"Reroute\",\"pos\":[767,-51],\"size\":[75,26],\"flags\":{},\"order\":22,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":535}],\"outputs\":[{\"name\":\"\",\"type\":\"MODEL\",\"links\":[536],\"slot_index\":0}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":137,\"type\":\"PrimitiveNode\",\"pos\":[328,-804],\"size\":{\"0\":210,\"1\":82},\"flags\":{},\"order\":3,\"mode\":0,\"outputs\":[{\"name\":\"FLOAT\",\"type\":\"FLOAT\",\"links\":[518],\"slot_index\":0,\"widget\":{\"name\":\"ascore\",\"config\":[\"FLOAT\",{\"default\":6,\"min\":0,\"max\":1000,\"step\":0.01}]}}],\"title\":\"Positive A Score\",\"properties\":{},\"widgets_values\":[6,\"fixed\"],\"color\":\"#233\",\"bgcolor\":\"#355\"},{\"id\":138,\"type\":\"PrimitiveNode\",\"pos\":[554,-802],\"size\":{\"0\":210,\"1\":82},\"flags\":{\"collapsed\":false},\"order\":4,\"mode\":0,\"outputs\":[{\"name\":\"FLOAT\",\"type\":\"FLOAT\",\"links\":[534],\"slot_index\":0,\"widget\":{\"name\":\"ascore\",\"config\":[\"FLOAT\",{\"default\":6,\"min\":0,\"max\":1000,\"step\":0.01}]}}],\"title\":\"Negative A Score\",\"properties\":{},\"widgets_values\":[1,\"fixed\"],\"color\":\"#233\",\"bgcolor\":\"#355\"},{\"id\":66,\"type\":\"PrimitiveNode\",\"pos\":[330,-940],\"size\":{\"0\":210,\"1\":82},\"flags\":{},\"order\":5,\"mode\":0,\"outputs\":[{\"name\":\"INT\",\"type\":\"INT\",\"links\":[214,482],\"widget\":{\"name\":\"noise_seed\",\"config\":[\"INT\",{\"default\":0,\"min\":0,\"max\":18446744073709552000}]},\"slot_index\":0}],\"title\":\"Seed\",\"properties\":{},\"widgets_values\":[380364824789770,\"randomize\"],\"color\":\"#233\",\"bgcolor\":\"#355\"},{\"id\":146,\"type\":\"LoraLoader\",\"pos\":[66,-51],\"size\":{\"0\":315,\"1\":126},\"flags\":{},\"order\":12,\"mode\":0,\"inputs\":[{\"name\":\"model\",\"type\":\"MODEL\",\"link\":540},{\"name\":\"clip\",\"type\":\"CLIP\",\"link\":537}],\"outputs\":[{\"name\":\"MODEL\",\"type\":\"MODEL\",\"links\":[539],\"shape\":3,\"slot_index\":0},{\"name\":\"CLIP\",\"type\":\"CLIP\",\"links\":[538],\"shape\":3,\"slot_index\":1}],\"properties\":{\"Node name for S&R\":\"LoraLoader\"},\"widgets_values\":[\"PerfectEyesXL.safetensors\",0.65,0.65]},{\"id\":115,\"type\":\"PrimitiveNode\",\"pos\":[330,-1080],\"size\":{\"0\":210,\"1\":82},\"flags\":{\"collapsed\":false},\"order\":6,\"mode\":0,\"outputs\":[{\"name\":\"INT\",\"type\":\"INT\",\"links\":[474,475],\"slot_index\":0,\"widget\":{\"name\":\"steps\",\"config\":[\"INT\",{\"default\":20,\"min\":1,\"max\":10000}]}}],\"title\":\"Steps\",\"properties\":{},\"widgets_values\":[50,\"fixed\"],\"color\":\"#233\",\"bgcolor\":\"#355\"},{\"id\":5,\"type\":\"EmptyLatentImage\",\"pos\":[330,-1230],\"size\":{\"0\":423.9580383300781,\"1\":106},\"flags\":{\"collapsed\":false},\"order\":7,\"mode\":0,\"inputs\":[],\"outputs\":[{\"name\":\"LATENT\",\"type\":\"LATENT\",\"links\":[49],\"slot_index\":0}],\"title\":\"Image Resolution\",\"properties\":{\"Node name for S&R\":\"EmptyLatentImage\"},\"widgets_values\":[1536,1024,1],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":10,\"type\":\"CheckpointLoaderSimple\",\"pos\":[-305.06534425927657,-51.483663935180815],\"size\":{\"0\":315,\"1\":98},\"flags\":{},\"order\":8,\"mode\":0,\"outputs\":[{\"name\":\"MODEL\",\"type\":\"MODEL\",\"links\":[540],\"slot_index\":0},{\"name\":\"CLIP\",\"type\":\"CLIP\",\"links\":[537],\"slot_index\":1},{\"name\":\"VAE\",\"type\":\"VAE\",\"links\":[542],\"slot_index\":2}],\"title\":\"Base Model\",\"properties\":{\"Node name for S&R\":\"CheckpointLoaderSimple\"},\"widgets_values\":[\"D4ll34_001CKPT.safetensors\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":22,\"type\":\"KSamplerAdvanced\",\"pos\":[880.2418319675904,-272.9673278703617],\"size\":{\"0\":269.9818420410156,\"1\":298},\"flags\":{\"collapsed\":false},\"order\":25,\"mode\":0,\"inputs\":[{\"name\":\"model\",\"type\":\"MODEL\",\"link\":536},{\"name\":\"positive\",\"type\":\"CONDITIONING\",\"link\":282},{\"name\":\"negative\",\"type\":\"CONDITIONING\",\"link\":304},{\"name\":\"latent_image\",\"type\":\"LATENT\",\"link\":49},{\"name\":\"noise_seed\",\"type\":\"INT\",\"link\":214,\"widget\":{\"name\":\"noise_seed\",\"config\":[\"INT\",{\"default\":0,\"min\":0,\"max\":18446744073709552000}]}},{\"name\":\"cfg\",\"type\":\"FLOAT\",\"link\":380,\"widget\":{\"name\":\"cfg\",\"config\":[\"FLOAT\",{\"default\":8,\"min\":0,\"max\":100}]}},{\"name\":\"steps\",\"type\":\"INT\",\"link\":474,\"widget\":{\"name\":\"steps\",\"config\":[\"INT\",{\"default\":20,\"min\":1,\"max\":10000}]},\"slot_index\":7}],\"outputs\":[{\"name\":\"LATENT\",\"type\":\"LATENT\",\"links\":[55,541],\"slot_index\":0}],\"title\":\"First Pass Latent\",\"properties\":{\"Node name for S&R\":\"KSamplerAdvanced\"},\"widgets_values\":[\"enable\",464011599411789,\"fixed\",50,3,\"dpmpp_sde\",\"karras\",0,40,\"enable\"],\"color\":\"#323\",\"bgcolor\":\"#535\"},{\"id\":23,\"type\":\"KSamplerAdvanced\",\"pos\":[880,-623],\"size\":{\"0\":268.3213195800781,\"1\":298},\"flags\":{\"collapsed\":false},\"order\":26,\"mode\":0,\"inputs\":[{\"name\":\"model\",\"type\":\"MODEL\",\"link\":506},{\"name\":\"positive\",\"type\":\"CONDITIONING\",\"link\":480},{\"name\":\"negative\",\"type\":\"CONDITIONING\",\"link\":299},{\"name\":\"latent_image\",\"type\":\"LATENT\",\"link\":55},{\"name\":\"cfg\",\"type\":\"FLOAT\",\"link\":384,\"widget\":{\"name\":\"cfg\",\"config\":[\"FLOAT\",{\"default\":8,\"min\":0,\"max\":100}]}},{\"name\":\"steps\",\"type\":\"INT\",\"link\":475,\"widget\":{\"name\":\"steps\",\"config\":[\"INT\",{\"default\":20,\"min\":1,\"max\":10000}]}},{\"name\":\"noise_seed\",\"type\":\"INT\",\"link\":482,\"widget\":{\"name\":\"noise_seed\",\"config\":[\"INT\",{\"default\":0,\"min\":0,\"max\":18446744073709552000}]},\"slot_index\":6}],\"outputs\":[{\"name\":\"LATENT\",\"type\":\"LATENT\",\"links\":[56],\"slot_index\":0}],\"title\":\"Second Pass Latent\",\"properties\":{\"Node name for S&R\":\"KSamplerAdvanced\"},\"widgets_values\":[\"disable\",464011599411789,\"fixed\",50,3,\"dpmpp_sde\",\"karras\",40,50,\"disable\"],\"color\":\"#323\",\"bgcolor\":\"#535\"},{\"id\":122,\"type\":\"SaveImage\",\"pos\":[806,-1166],\"size\":{\"0\":404.3124694824219,\"1\":454.1047668457031},\"flags\":{},\"order\":30,\"mode\":0,\"inputs\":[{\"name\":\"images\",\"type\":\"IMAGE\",\"link\":491}],\"title\":\"Refiner Output\",\"properties\":{},\"widgets_values\":[\"ComfyUI\"],\"color\":\"#223\",\"bgcolor\":\"#335\"},{\"id\":147,\"type\":\"VAEDecode\",\"pos\":[1273,-494],\"size\":{\"0\":210,\"1\":46},\"flags\":{},\"order\":27,\"mode\":0,\"inputs\":[{\"name\":\"samples\",\"type\":\"LATENT\",\"link\":541},{\"name\":\"vae\",\"type\":\"VAE\",\"link\":542}],\"outputs\":[{\"name\":\"IMAGE\",\"type\":\"IMAGE\",\"links\":[543],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"VAEDecode\"}},{\"id\":75,\"type\":\"CLIPTextEncodeSDXL\",\"pos\":[448,-162],\"size\":{\"0\":400,\"1\":289.9999694824219},\"flags\":{\"collapsed\":true},\"order\":24,\"mode\":0,\"inputs\":[{\"name\":\"clip\",\"type\":\"CLIP\",\"link\":523,\"slot_index\":0},{\"name\":\"text_g\",\"type\":\"STRING\",\"link\":434,\"widget\":{\"name\":\"text_g\",\"config\":[\"STRING\",{\"multiline\":true,\"default\":\"CLIP_G\"}]}},{\"name\":\"text_l\",\"type\":\"STRING\",\"link\":470,\"widget\":{\"name\":\"text_l\",\"config\":[\"STRING\",{\"multiline\":true,\"default\":\"CLIP_L\"}]},\"slot_index\":2}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[282],\"shape\":3,\"slot_index\":0}],\"title\":\"Positive Base\",\"properties\":{\"Node name for S&R\":\"CLIPTextEncodeSDXL\"},\"widgets_values\":[4096,4096,0,0,4096,4096,\"A photo of a cat made out of sushi\",\"cinematic, fujifilm, RTX, bokeh\"],\"color\":\"#232\",\"bgcolor\":\"#353\"},{\"id\":82,\"type\":\"CLIPTextEncodeSDXL\",\"pos\":[620,91],\"size\":{\"0\":400,\"1\":289.9999694824219},\"flags\":{\"collapsed\":true},\"order\":23,\"mode\":0,\"inputs\":[{\"name\":\"clip\",\"type\":\"CLIP\",\"link\":522,\"slot_index\":0},{\"name\":\"text_g\",\"type\":\"STRING\",\"link\":302,\"widget\":{\"name\":\"text_g\",\"config\":[\"STRING\",{\"multiline\":true,\"default\":\"CLIP_G\"}]}},{\"name\":\"text_l\",\"type\":\"STRING\",\"link\":476,\"widget\":{\"name\":\"text_l\",\"config\":[\"STRING\",{\"multiline\":true,\"default\":\"CLIP_L\"}]}}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[304],\"shape\":3,\"slot_index\":0}],\"title\":\"Negative Base\",\"properties\":{\"Node name for S&R\":\"CLIPTextEncodeSDXL\"},\"widgets_values\":[4096,4096,0,0,4096,4096,\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\",\"multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast\"],\"color\":\"#322\",\"bgcolor\":\"#533\"},{\"id\":4,\"type\":\"CheckpointLoaderSimple\",\"pos\":[-305.06534425927657,-621.4836639351809],\"size\":{\"0\":315,\"1\":98},\"flags\":{},\"order\":9,\"mode\":0,\"outputs\":[{\"name\":\"MODEL\",\"type\":\"MODEL\",\"links\":[553],\"slot_index\":0},{\"name\":\"CLIP\",\"type\":\"CLIP\",\"links\":[554],\"slot_index\":1},{\"name\":\"VAE\",\"type\":\"VAE\",\"links\":[513],\"slot_index\":2}],\"title\":\"Refiner Model\",\"properties\":{\"Node name for S&R\":\"CheckpointLoaderSimple\"},\"widgets_values\":[\"sd_xl_refiner_1.0.safetensors\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":101,\"type\":\"PrimitiveNode\",\"pos\":[550,-1080],\"size\":{\"0\":210,\"1\":82},\"flags\":{},\"order\":10,\"mode\":0,\"outputs\":[{\"name\":\"FLOAT\",\"type\":\"FLOAT\",\"links\":[380],\"slot_index\":0,\"widget\":{\"name\":\"cfg\",\"config\":[\"FLOAT\",{\"default\":8,\"min\":0,\"max\":100}]}}],\"title\":\"Base CFG\",\"properties\":{},\"widgets_values\":[3,\"fixed\"],\"color\":\"#233\",\"bgcolor\":\"#355\"},{\"id\":102,\"type\":\"PrimitiveNode\",\"pos\":[550,-940],\"size\":{\"0\":210,\"1\":82},\"flags\":{},\"order\":11,\"mode\":0,\"outputs\":[{\"name\":\"FLOAT\",\"type\":\"FLOAT\",\"links\":[384],\"slot_index\":0,\"widget\":{\"name\":\"cfg\",\"config\":[\"FLOAT\",{\"default\":8,\"min\":0,\"max\":100}]}}],\"title\":\"Refiner CFG\",\"properties\":{},\"widgets_values\":[3,\"fixed\"],\"color\":\"#233\",\"bgcolor\":\"#355\"},{\"id\":148,\"type\":\"PreviewImage\",\"pos\":[1274,-1307],\"size\":{\"0\":416.63958740234375,\"1\":498.5003662109375},\"flags\":{},\"order\":29,\"mode\":0,\"inputs\":[{\"name\":\"images\",\"type\":\"IMAGE\",\"link\":543}],\"properties\":{\"Node name for S&R\":\"PreviewImage\"}}],\"links\":[[49,5,0,22,3,\"LATENT\"],[55,22,0,23,3,\"LATENT\"],[56,23,0,8,0,\"LATENT\"],[214,66,0,22,4,\"INT\"],[282,75,0,22,1,\"CONDITIONING\"],[299,81,0,23,2,\"CONDITIONING\"],[302,43,0,82,1,\"STRING\"],[304,82,0,22,2,\"CONDITIONING\"],[380,101,0,22,5,\"FLOAT\"],[384,102,0,23,4,\"FLOAT\"],[434,78,0,75,1,\"STRING\"],[470,77,0,75,2,\"STRING\"],[474,115,0,22,6,\"INT\"],[475,115,0,23,5,\"INT\"],[476,43,0,82,2,\"STRING\"],[478,78,0,120,1,\"STRING\"],[480,120,0,23,1,\"CONDITIONING\"],[482,66,0,23,6,\"INT\"],[491,8,0,122,0,\"IMAGE\"],[494,43,0,81,1,\"STRING\"],[506,126,0,23,0,\"MODEL\"],[513,4,2,133,0,\"*\"],[514,133,0,134,0,\"*\"],[515,134,0,8,1,\"VAE\"],[518,137,0,120,2,\"FLOAT\"],[522,139,0,82,0,\"CLIP\"],[523,139,0,75,0,\"CLIP\"],[529,142,0,126,0,\"*\"],[531,141,0,81,0,\"CLIP\"],[533,141,0,120,0,\"CLIP\"],[534,138,0,81,2,\"FLOAT\"],[535,140,0,145,0,\"*\"],[536,145,0,22,0,\"MODEL\"],[537,10,1,146,1,\"CLIP\"],[538,146,1,139,0,\"*\"],[539,146,0,140,0,\"*\"],[540,10,0,146,0,\"MODEL\"],[541,22,0,147,0,\"LATENT\"],[542,10,2,147,1,\"VAE\"],[543,147,0,148,0,\"IMAGE\"],[553,4,0,142,0,\"*\"],[554,4,1,141,0,\"*\"]],\"groups\":[{\"title\":\"Final Image\",\"bounding\":[779,-1302,427,593],\"color\":\"#444\"},{\"title\":\"Samplers\",\"bounding\":[760,-700,451,758],\"color\":\"#444\"},{\"title\":\"Models, Encoders, and LoRAs\",\"bounding\":[-318,-699,1067,759],\"color\":\"#444\"},{\"title\":\"Prompting\",\"bounding\":[-318,-1300,626,590],\"color\":\"#444\"},{\"title\":\"Gen Settings\",\"bounding\":[318,-1301,451,592],\"color\":\"#444\"}],\"config\":{},\"extra\":{},\"version\":0.4}}",
            "steps": 50,
            "width": 1536,
            "height": 1024,
            "models": [
                "sd_xl_refiner_1.0.safetensors",
                "D4ll34_001CKPT.safetensors"
            ],
            "prompt": "A photo of a cat made out of sushi roll, cinematic, fujifilm, RTX, bokeh",
            "sampler": "DPM++ SDE Karras",
            "cfgScale": 3,
            "modelIds": [],
            "scheduler": "karras",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "negativePrompt": "multiple people, deformed, people in backdround, hands, unrealistic, bad quality, grainy, noisy, plastic, hazy, low contrast",
            "additionalResources": [
                {
                    "name": "PerfectEyesXL.safetensors",
                    "type": "lora",
                    "strength": 0.65,
                    "strengthClip": 0.65
                }
            ]
        },
        "username": "Thaevilone",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 4025311,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9fc69d31-fa46-4ed0-ad0a-56f901d11e48/width=768/9fc69d31-fa46-4ed0-ad0a-56f901d11e48.jpeg",
        "hash": "UJFGXvOF9]-o0zNGrCjY{{H@-Vx[J7Iq7MxZ",
        "width": 768,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-11-29T14:57:07.888Z",
        "postId": 903491,
        "stats": {
            "cryCount": 0,
            "laughCount": 13,
            "likeCount": 104,
            "dislikeCount": 0,
            "heartCount": 58,
            "commentCount": 6
        },
        "meta": null,
        "username": "Titto13",
        "baseModel": "SD 1.5"
    },
    {
        "id": 4097895,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c72ecdb4-6b14-4354-91f4-3218c19a8da1/width=1440/c72ecdb4-6b14-4354-91f4-3218c19a8da1.jpeg",
        "hash": "U6AT}*MdvMyC?]RjMy-5^%t60ikDUbKQIU$e",
        "width": 1440,
        "height": 2560,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-26T13:57:49.681Z",
        "postId": 917889,
        "stats": {
            "cryCount": 15,
            "laughCount": 15,
            "likeCount": 86,
            "dislikeCount": 0,
            "heartCount": 59,
            "commentCount": 0
        },
        "meta": {
            "Size": "576x1024",
            "seed": 3339461945,
            "Model": "SDXL TURBO PLUS",
            "steps": 50,
            "hashes": {
                "model": "f45814a546"
            },
            "prompt": "oniric portrait of a tall cloaked figure with a white mask, Azem the Traveler, yearning to explore the ends of the world to discover its wonders and help its denizens, by Andy Kehoe, a gradient masterpiece, blue cyan yellow, Rococopunk, luminism, seamless, China ink, Ink Bubbles, Gold leaf lines, alcohol ink elements, curved lines, cinematic, realism, chiaroscuro, Shadow play, Gold leaf small lines, bright splashes of alcohol ink puddles, volumetric light, auras, rays of sunlight, bright colors reflect, isometric, digital art, smog, pollution, toxic waste, chimneys and railroads, 3d render, octane render, volumetrics, by greg rutkowski",
            "Version": "1.5.1",
            "sampler": "Euler a",
            "cfgScale": 15,
            "resources": [
                {
                    "hash": "f45814a546",
                    "name": "SDXL TURBO PLUS",
                    "type": "model"
                }
            ],
            "Model hash": "f45814a546",
            "Hires steps": "25",
            "Hires upscale": "2.5",
            "Hires upscaler": "4x_foolhardy_Remacri",
            "negativePrompt": "bad quality, bad anatomy, worst quality, low quality, low resolution, extra fingers, blur, blurry, ugly, wrong proportions, watermark, image artifacts, lowres, ugly, jpeg artifacts, deformed, noisy image",
            "Denoising strength": "0.25"
        },
        "username": "Yamer",
        "baseModel": "SDXL Turbo"
    },
    {
        "id": 4357073,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2a05a4e9-5f43-48c0-b169-70e7853c8669/width=1600/2a05a4e9-5f43-48c0-b169-70e7853c8669.jpeg",
        "hash": "U9CFeS~A0#O?H@-U5R029u9a-T^j9_%L~A-o",
        "width": 1600,
        "height": 2400,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-12-10T13:05:28.826Z",
        "postId": 971653,
        "stats": {
            "cryCount": 2,
            "laughCount": 1,
            "likeCount": 95,
            "dislikeCount": 0,
            "heartCount": 77,
            "commentCount": 0
        },
        "meta": {
            "VAE": "vae-ft-mse-840000-ema-pruned.ckpt",
            "Size": "512x768",
            "seed": 1557383379,
            "Model": "CyberRealistic_Basic_V1.0_FP32",
            "steps": 28,
            "hashes": {
                "model": "925bd947d7"
            },
            "prompt": "photograph of a woman, (troubled facial expression), textured skin, goosebumps, blonde afro hair, plaid flannel shirt with distressed boyfriend jeans, cowboy shot, dark and mysterious cave with unique rock formations and hidden wonders, perfect eyes, (candlelight,chiaroscuro), Porta 160 color, shot on ARRI ALEXA 65, bokeh, sharp focus on subject, shot by Don McCullin",
            "Version": "v1.7.0-RC-5-gf92d6149",
            "sampler": "DPM++ 2M Karras",
            "VAE hash": "df3c506e51",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "925bd947d7",
                    "name": "CyberRealistic_Basic_V1.0_FP32",
                    "type": "model"
                }
            ],
            "Model hash": "925bd947d7",
            "Hires steps": "10",
            "Hires upscale": "2",
            "Hires upscaler": "4x_NickelbackFS_72000_G",
            "negativePrompt": "(CyberRealistic_Negative:0.8), (deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, amputation",
            "Denoising strength": "0.35"
        },
        "username": "Cyberdelia",
        "baseModel": "SD 1.5"
    },
    {
        "id": 5222053,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/24c97fc4-1e55-4a1b-b3c7-218a9930afd7/width=832/24c97fc4-1e55-4a1b-b3c7-218a9930afd7.jpeg",
        "hash": "UOH-}9yC02OY};E359%2rXRkM|RkVFr;%1kW",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-01-06T14:39:23.743Z",
        "postId": 1141216,
        "stats": {
            "cryCount": 4,
            "laughCount": 15,
            "likeCount": 78,
            "dislikeCount": 0,
            "heartCount": 78,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1530763022,
            "steps": 30,
            "prompt": "A captivating poster showcasing Anne Bachelier's artistic flair: A strikingly attractive young woman gazes intently as she traverses along a tenuous line to a mesmerizing dreamscape filled with radiant colors and otherworldly beauty, embodying the surrealistic allure of her distinctive style.",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "EasyNegative,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 277071
                }
            ]
        },
        "username": "muf00d",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 5420878,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0c791e4b-3a46-4cfd-965a-2c261cfd634c/width=920/0c791e4b-3a46-4cfd-965a-2c261cfd634c.jpeg",
        "hash": "U7BWPtzs?9:8xetT^mRQVLb^t8RN~E%Kvev}",
        "width": 920,
        "height": 1120,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-01-12T18:00:36.094Z",
        "postId": 1182148,
        "stats": {
            "cryCount": 0,
            "laughCount": 8,
            "likeCount": 112,
            "dislikeCount": 0,
            "heartCount": 55,
            "commentCount": 0
        },
        "meta": {
            "Size": "924x1124",
            "seed": 1047362277235374,
            "Model": "SDXLFaetastic_v24",
            "steps": 40,
            "hashes": {
                "model": "07b985d12f"
            },
            "prompt": "photo of a beautiful transparent glass crystal that glows within, glowing lights, made out of multicolored translucent  delicate glass, magical sparkles,vibrant whimsical colors,masterpice, detailed, galaxy,<lora:SDXLFaeTastic2400:0.8>",
            "Version": "ComfyUI",
            "sampler": "dpmpp_3m_sde_gpu_karras",
            "CFG Scale": "5.0",
            "resources": [
                {
                    "name": "SDXLFaeTastic2400",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "07b985d12f",
                    "name": "SDXLFaetastic_v24",
                    "type": "model"
                }
            ],
            "Model hash": "07b985d12f",
            "negativePrompt": "skin,unaestheticXL_hk1,negativeXL_D,3d,(asymmetry, worst quality, low quality, illustration, 3d, 2d, painting, cartoons, sketch),open mouth"
        },
        "username": "Pampelmusi",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 5880619,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b1b024bc-37ba-4043-b809-aeb806e22d1c/width=1024/b1b024bc-37ba-4043-b809-aeb806e22d1c.jpeg",
        "hash": "UZDKDDVtMxx]_Ns:M_oz-otRRPWAtQxuWBRP",
        "width": 1024,
        "height": 1536,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-01-25T20:39:40.388Z",
        "postId": 1276382,
        "stats": {
            "cryCount": 2,
            "laughCount": 12,
            "likeCount": 98,
            "dislikeCount": 0,
            "heartCount": 63,
            "commentCount": 2
        },
        "meta": {
            "Size": "512x768",
            "grsw": "0.5>\"",
            "seed": 3103106036,
            "Model": "xenodiffusion_v10",
            "steps": 24,
            "hashes": {
                "lora:grsw": "d7fdcba379",
                "lora:Fractal_Vines": "bf516ee186",
                "lora:GigerRainbowXL": "7d2390434e"
            },
            "prompt": "illustrious, Darling, kraken hatchling, dancing on leaves and flower petals made of g1h3r, grsw and covered in fractal vines, intricate details, colorful, magical, realism, hyperrealistic, <lora:Fractal_Vines:0.6> fractalvines, <lora:GigerRainbowXL:0.5> <lora:grsw:0.5>",
            "sampler": "DPM++ SDE Karras",
            "Template": "\"illustrious, Darling, kraken hatchling, dancing on leaves and flower petals made of g1h3r, grsw and covered in fractal vines, intricate details, colorful, magical, realism, hyperrealistic",
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [
                {
                    "name": "Fractal_Vines",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "name": "GigerRainbowXL",
                    "type": "lora",
                    "weight": 0.5
                },
                {
                    "name": "grsw",
                    "type": "lora",
                    "weight": 0.5
                }
            ],
            "disfigured": "1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs",
            "Hires steps": "8",
            "Fractal_Vines": "0.6> fractalvines",
            "Hires upscale": "2",
            "\"Fractal_Vines": "4d8a4690489e",
            "GigerRainbowXL": "458cb12c04b2",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "(deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, (mutated hands and fingers:1.4), disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation, comic, drawing, painting, anime, cartoon, paint,",
            "ADetailer model": "face_yolov8n.pt",
            "Hypertile U-Net": "True",
            "Face restoration": "CodeFormer",
            "ADetailer version": "24.1.2",
            "Negative Template": "\"(deformed, distorted",
            "Denoising strength": "0.7",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "(mutated hands and fingers": "1.4), disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation, comic, drawing, painting, anime, cartoon, paint,\"",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "Manuka",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 5982040,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/134bbc4e-94ed-46e3-8070-6214d16793dd/width=1024/134bbc4e-94ed-46e3-8070-6214d16793dd.jpeg",
        "hash": "UME2|Y?b.T%N%3azI:WBj[RjS2oLITxuV?bH",
        "width": 1024,
        "height": 1536,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-01-28T17:00:00.000Z",
        "postId": 1296904,
        "stats": {
            "cryCount": 0,
            "laughCount": 47,
            "likeCount": 78,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 0
        },
        "meta": {
            "RNG": "NV",
            "VAE": "vae-ft-mse-840000-ema-pruned.safetensors",
            "Size": "1024x1536",
            "seed": 54760436,
            "Model": "mfcgPseudoMix_v10",
            "steps": 30,
            "hashes": {
                "vae": "735e4c3a44",
                "model": "7d9e33a8bc",
                "lora:Char_Meme_Wendy": "3b1d8c4b90"
            },
            "prompt": "IncrsNeverGonnaGiveUUp, smile, looking at viewer, microphone stand, upper body, black jacket, striped shirt, open mouth, <lora:NeverGonnaGiveUUp:1>, ffwendys, twin braids, hair bow, <lora:Char_Meme_Wendy:1>",
            "Contour": "False",
            "Version": "v1.7.0",
            "sampler": "Restart",
            "Add Blur": "None",
            "Contrast": "1",
            "VAE hash": "fc04b52838",
            "cfgScale": 9,
            "clipSkip": 2,
            "Sharpness": "0.92",
            "Smoothing": "None",
            "resources": [
                {
                    "name": "NeverGonnaGiveUUp",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "name": "Char_Meme_Wendy",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "7d9e33a8bc",
                    "name": "mfcgPseudoMix_v10",
                    "type": "model"
                }
            ],
            "Add Detail": "None",
            "Brightness": "1",
            "Model hash": "7d9e33a8bc",
            "Color Strength": "1",
            "negativePrompt": "(worst quality, low quality:1.4), (interlocked fingers, badly drawn hands and fingers, anatomically incorrect hands), blurry, blurry background, bokeh, text, signature, speech bubble",
            "Char_Meme_Wendy": "9c9f5b81155b\"",
            "\"NeverGonnaGiveUUp": "24d853a8a15e",
            "Denoising strength": "0.35",
            "Dimension increment factor": "Linear",
            "Denoising strength change factor": "1"
        },
        "username": "FallenIncursio",
        "baseModel": "SD 1.5"
    },
    {
        "id": 5632028,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/58571553-ad5a-4a91-9e97-598ec50ab9ab/width=960/58571553-ad5a-4a91-9e97-598ec50ab9ab.jpeg",
        "hash": "UNDvD,oNT1bc1kbHr=kBn4j@H?js}mjbm,af",
        "width": 960,
        "height": 1280,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-01-18T17:56:37.802Z",
        "postId": 1226474,
        "stats": {
            "cryCount": 7,
            "laughCount": 10,
            "likeCount": 108,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 1
        },
        "meta": {
            "RNG": "CPU",
            "MJ52": "000c96b6bd08\"",
            "Size": "960x1280",
            "seed": 2099741980,
            "Model": "zavychromaxl_v31",
            "steps": 40,
            "hashes": {
                "model": "c41f93afea",
                "lora:MJ52": "e526855052",
                "lora:SDXLFaeTastic2400": "1cf798aca8",
                "lora:xl_more_art-full_v1": "15e31fe2b6"
            },
            "Version": "v1.7.0",
            "sampler": "DPM++ 3M SDE Exponential",
            "cfgScale": 5.5,
            "resources": [
                {
                    "name": "SDXLFaeTastic2400",
                    "type": "lora",
                    "weight": 0.25
                },
                {
                    "name": "MJ52",
                    "type": "lora",
                    "weight": 0.35
                },
                {
                    "hash": "c41f93afea",
                    "name": "zavychromaxl_v31",
                    "type": "model"
                }
            ],
            "Model hash": "c41f93afea",
            "SDXLFaeTastic2400": "e7da1e0c0933",
            "\"xl_more_art-full_v1": "fe3b4816be83"
        },
        "username": "sunnytiersen",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 6167733,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3040e63e-433c-4e65-b837-778c2901f38a/width=832/3040e63e-433c-4e65-b837-778c2901f38a.jpeg",
        "hash": "ULIO2u~A4;58-:xY%Lxt0%NIxDwc58IpaejZ",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-02T06:21:17.108Z",
        "postId": 1334435,
        "stats": {
            "cryCount": 3,
            "laughCount": 12,
            "likeCount": 111,
            "dislikeCount": 0,
            "heartCount": 49,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 564916818,
            "steps": 34,
            "prompt": "old book style ink illustration, on parchment, ink splashes, ink stains, ink smears, faded ink,  (female enforcer:1.2), (futuristic:1.5) city of steel, glass, fog, sun, in the clouds, skyscrapers, futuristic transit, fractals, sunrise, moody tones, mentixis, linquivera",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "text, watermark, low quality, medium quality, blurry, censored, wrinkles, deformed, mutated text, watermark, low quality, medium quality, blurry, censored, wrinkles, deformed, mutated, embedding:easynegative",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 288982
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 281935
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 318677
                }
            ]
        },
        "username": "Brainslaughter",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 6781353,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/88a93e3b-8119-42ee-ac29-aff05685f77d/width=1248/88a93e3b-8119-42ee-ac29-aff05685f77d.jpeg",
        "hash": "UKCG}iM_IV$%yZRixCNf$%x]IT$|NLxuWARP",
        "width": 1248,
        "height": 1824,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-18T08:17:50.424Z",
        "postId": 1463625,
        "stats": {
            "cryCount": 0,
            "laughCount": 4,
            "likeCount": 104,
            "dislikeCount": 0,
            "heartCount": 67,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1119715178,
            "Model": "JuggernautXL_RunDiffusionPhoto2_V9_Final",
            "steps": 35,
            "hashes": {
                "model": "c9e3e68f89"
            },
            "prompt": "A beautiful portrait photograph of a dragon with diamond and gemstone scales, opal eyes, cinematic, gem, diamond, crystal, fantasy art, hyperdetailed photograph, shiny scales, 8k resolution,",
            "Version": "v1.7.0",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "c9e3e68f89",
                    "name": "JuggernautXL_RunDiffusionPhoto2_V9_Final",
                    "type": "model"
                }
            ],
            "Model hash": "c9e3e68f89",
            "Hires steps": "15",
            "Hires upscale": "1.5",
            "Hires upscaler": "4x_NMKD-Siax_200k",
            "negativePrompt": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)",
            "Denoising strength": "0.3"
        },
        "username": "KandooAI",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 6550792,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/dd2e82ce-d43f-4b5f-84bb-591f11848b15/width=768/dd2e82ce-d43f-4b5f-84bb-591f11848b15.jpeg",
        "hash": "UDBNi;tRMJRj?wxaRjRjD*WCS#V@OFbIRPay",
        "width": 768,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-12T11:43:35.065Z",
        "postId": 1413830,
        "stats": {
            "cryCount": 8,
            "laughCount": 13,
            "likeCount": 99,
            "dislikeCount": 0,
            "heartCount": 55,
            "commentCount": 1
        },
        "meta": {
            "Size": "768x1024",
            "seed": 1070243261,
            "Model": "RealitiesEdgeXLSDXL_TURBOXLV2",
            "steps": 7,
            "hashes": {
                "model": "c66605317b"
            },
            "prompt": "landscape of a (transparent nightwear dresses:1.3) from inside of a Lake Tahoe, Dense and Floating, mountains, Stormy weather, detailed, masterpiece, Light and Bright, Impressionism, Indirect light, telephoto lens, Iridescent hue, Swirling Gore-Tex, Unsplash, Flickr, stylized by Lisa Keene, Vincent van Gogh and Raymond Swanland, <lora:xl_more_art-full_v1:1>, <lora:add-detail-xl:1>",
            "Version": "v1.7.0",
            "sampler": "DPM++ SDE Karras",
            "cfgScale": 2.5,
            "resources": [
                {
                    "hash": "c66605317b",
                    "name": "RealitiesEdgeXLSDXL_TURBOXLV2",
                    "type": "model"
                }
            ],
            "Model hash": "c66605317b",
            "Mimic scale": "10",
            "add-detail-xl": "9c783c8ce46c\"",
            "negativePrompt": "(photograph:1.3), (photorealism:1.3), anime, low contrast, modernist, minimalist, simplistic, minimalism, plain, simple, sunny, vibrant, colorful, cropped, worst quality, low quality, poorly drawn, low resolution, realism, modern, ordinary, mundane,",
            "Interpolate Phi": "1",
            "Scaling Startpoint": "MEAN",
            "Variability Measure": "AD",
            "\"xl_more_art-full_v1": "fe3b4816be83",
            "Style Selector Style": "base",
            "Threshold percentile": "100",
            "Style Selector Enabled": "True",
            "Style Selector Randomize": "False",
            "Separate Feature Channels": "True",
            "Dynamic thresholding enabled": "True"
        },
        "username": "Igor_39ru",
        "baseModel": "SDXL Turbo"
    },
    {
        "id": 7461123,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a029836a-2109-4d46-bf3f-54993a792fb5/width=896/a029836a-2109-4d46-bf3f-54993a792fb5.jpeg",
        "hash": "ULHBe-Xn01V?F}%1IUNb59Ips*%L5sN{~9ad",
        "width": 896,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-03-05T01:48:03.285Z",
        "postId": 1615146,
        "stats": {
            "cryCount": 1,
            "laughCount": 9,
            "likeCount": 109,
            "dislikeCount": 0,
            "heartCount": 56,
            "commentCount": 0
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "896x1152",
            "seed": 1346890445,
            "Model": "atomixXL_v20LightningDPMSDE",
            "steps": 4,
            "hashes": {
                "model": "cd6beca4e6"
            },
            "prompt": "(anime style:1.1), boat full of fruits, anchored on a sandy beach, palm trees, blue water, setting sun., (highres, highly detailed:1.2), cinematic lighting, vibrant colors",
            "Version": "v1.8.0",
            "sampler": "DPM++ SDE Karras",
            "VAE hash": "235745af8d",
            "cfgScale": 1,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "cd6beca4e6",
                    "name": "atomixXL_v20LightningDPMSDE",
                    "type": "model"
                }
            ],
            "Model hash": "cd6beca4e6",
            "negativePrompt": "(low quality, worst quality:1.2), (low saturation, grainy, border), (watermark, signature, text:1.1)",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.3.0",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.6",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.3",
            "ADetailer inpaint only masked": "True"
        },
        "username": null,
        "baseModel": "SDXL Lightning"
    },
    {
        "id": 7472963,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6cde492d-5bbe-469f-b722-9e64a2920ee2/width=832/6cde492d-5bbe-469f-b722-9e64a2920ee2.jpeg",
        "hash": "U9FhCJ5A03E347^1qwv$5Y${WB$yMzt5~9NK",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-03-05T08:13:55.644Z",
        "postId": 1617872,
        "stats": {
            "cryCount": 0,
            "laughCount": 5,
            "likeCount": 111,
            "dislikeCount": 0,
            "heartCount": 59,
            "commentCount": 0
        },
        "meta": null,
        "username": "wolfvantrack",
        "baseModel": ""
    },
    {
        "id": 9284338,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e9485917-4d50-4844-80cb-3fc808aa6c81/width=1408/e9485917-4d50-4844-80cb-3fc808aa6c81.jpeg",
        "hash": "U7CFky+[5QXnTeI:IVoL02Nbv~wv}@r?ozf*",
        "width": 1408,
        "height": 2064,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-04-06T12:29:34.615Z",
        "postId": 2007246,
        "stats": {
            "cryCount": 9,
            "laughCount": 13,
            "likeCount": 88,
            "dislikeCount": 0,
            "heartCount": 65,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3464844566,
            "steps": 25,
            "hashes": {
                "model": "67ab2fd8ec",
                "LORA:sinfully_stylish_SDXL": "033c44dfb8",
                "LORA:Concept Art Ultimatum Style LoRA_Pony XL v6": "af6820bbf7"
            },
            "prompt": "score_9, score_8_up, score_7_up,  score_9, score_8_up, score_7_up,   kitsune girl, floral kimono, exposed shoulders, beautiful face, thick eyelashes, glowing white eyes, fox ears, long flowy silver hair, cute smile, dark eyeshadow, glowing shoulders tattoos, glowing back tattoos, floral decoration in hair, night time, shinning moon, lit by moonlight, ambient lighting, fangs, long fluffy tail  <lora:Concept Art Ultimatum Style LoRA_Pony XL v6> <lora:sinfully_stylish_SDXL>",
            "sampler": "Euler a Karras",
            "cfgScale": 7,
            "resources": [],
            "Model hash": "67ab2fd8ec",
            "negativePrompt": "score_6, score_5, score_4, pubic hair, pony, gaping, muscular, makeup, censored, furry, child, kid, chibi, teen,",
            "ponyDiffusionV6XL_v6StartWithThisOne Version": "ComfyUI"
        },
        "username": "popyay",
        "baseModel": "Pony"
    },
    {
        "id": 9522326,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/13962e7c-02b8-4302-852a-fa1b5447ee7c/width=832/13962e7c-02b8-4302-852a-fa1b5447ee7c.jpeg",
        "hash": "UVEp1ioz9ZkCbbj[n%ayoJj[Rjay~qofIokC",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-09T19:07:21.145Z",
        "postId": 2062401,
        "stats": {
            "cryCount": 11,
            "laughCount": 7,
            "likeCount": 53,
            "dislikeCount": 0,
            "heartCount": 104,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1620854661,
            "steps": 45,
            "prompt": "ink illustration, gloomy scene of Little Red Riding Hood walking through the dark woods alone, the woman's red cape and hood are the only splashes of color, ink splashes, rough ink sketch, from the fog, Wolf's head watching her, wolf head positioned top center, looking straight at the red hood, faded into background, shiny wolf eyes",
            "sampler": "Euler a",
            "cfgScale": 2.5,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "photo, 3D, render, cartoon, manga, child, childlike, text, signature",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 338512
                }
            ]
        },
        "username": "dianos577",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 9690609,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/de08e230-1fcc-4aa2-ad44-f6c9497b74ee/width=1024/de08e230-1fcc-4aa2-ad44-f6c9497b74ee.jpeg",
        "hash": "U8D9q_4:R:IU0N~V00jE5ASPs+9G$$M{~pj?",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-12T01:24:17.086Z",
        "postId": 2100881,
        "stats": {
            "cryCount": 5,
            "laughCount": 10,
            "likeCount": 117,
            "dislikeCount": 0,
            "heartCount": 43,
            "commentCount": 0
        },
        "meta": {
            "Size": "1024x1024",
            "seed": 124646111,
            "steps": 29,
            "prompt": "mechanical snail, steel, shiny and gold, tracked, roboticizer, ribbed shell, armed, gears, sci-fi",
            "sampler": "Euler",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "worst quality, low quality, broken, extra horns, blurry, legs, bad anatomy",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 369130
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 302107
                }
            ]
        },
        "username": "PrincessArt",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 10667315,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4d835515-bfa2-4c35-ab5f-b6d07b4b9517/width=1408/4d835515-bfa2-4c35-ab5f-b6d07b4b9517.jpeg",
        "hash": "UAAJ=+~V009a?bocITt7aeoet7V@s+?H?bD%",
        "width": 1408,
        "height": 2064,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-24T22:07:09.585Z",
        "postId": 2339477,
        "stats": {
            "cryCount": 1,
            "laughCount": 6,
            "likeCount": 111,
            "dislikeCount": 0,
            "heartCount": 57,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3874973652,
            "steps": 35,
            "hashes": {
                "model": "9a4a1f5868",
                "LORA:add-detail-xl": "0d9bd1b873",
                "LORA:xl_more_art-full_v1": "15e31fe2b6",
                "LORA:sdxl/nicola_samori_dark_art_style": "fb1212a747"
            },
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "resources": [
                {
                    "name": "add-detail-xl",
                    "type": "lora",
                    "weight": 0.7
                },
                {
                    "name": "xl_more_art-full_v1",
                    "type": "lora",
                    "weight": 0.7
                }
            ],
            "Model hash": "9a4a1f5868",
            "negativePrompt": "(worst quality, jpeg artifacts:1.2)",
            "imaginarium_v10 Version": "ComfyUI"
        },
        "username": "Stellaaa",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 10527873,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3060d96a-b15d-4081-a2ee-19cfda175350/width=832/3060d96a-b15d-4081-a2ee-19cfda175350.jpeg",
        "hash": "UKNAL{~W~W_2~pkBkCxu?HoeIURk%Mj[ayj[",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-23T04:59:18.283Z",
        "postId": 2306472,
        "stats": {
            "cryCount": 7,
            "laughCount": 17,
            "likeCount": 95,
            "dislikeCount": 0,
            "heartCount": 56,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 792872751,
            "steps": 40,
            "prompt": "Hand drawn, dark, gritty, realistic sketch, Rough sketch, mix of bold dark lines and loose lines, bold lines, on paper, turnaround character sheet, a female cyber demon in dark fantasy sf world, Full body, arcane symbols, runes, dark theme, Perfect composition golden ratio, masterpiece, best quality, monochromatic, sharp focus. Better hand, perfect anatomy",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "mutated nose, mutated ear, mutated fingers, mutated hands, mutated legs, mutated feet, mutated mouth, mutated teeth, mutated eye, helmet",
            "civitaiResources": [
                {
                    "type": "model",
                    "modelVersionId": 299716
                },
                {
                    "type": "embedding",
                    "weight": 1,
                    "modelVersionId": 77169
                },
                {
                    "type": "vae",
                    "weight": 1,
                    "modelVersionId": 333245
                }
            ]
        },
        "username": "CP2077",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 10562047,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b23614d3-d513-4fd8-87fb-cf66f204dc78/width=1800/b23614d3-d513-4fd8-87fb-cf66f204dc78.jpeg",
        "hash": "UiHxQxxb-=WB~CRjM_ay%2RjRiofxuWCofof",
        "width": 2496,
        "height": 3648,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-23T16:12:48.621Z",
        "postId": 2314378,
        "stats": {
            "cryCount": 0,
            "laughCount": 4,
            "likeCount": 122,
            "dislikeCount": 0,
            "heartCount": 49,
            "commentCount": 0
        },
        "meta": {
            "RNG": "CPU",
            "VAE": "sdxl_vae.safetensors",
            "Size": "832x1216",
            "seed": 1146667963,
            "Model": "epicrealismXL_v6Miracle",
            "steps": 35,
            "hashes": {
                "vae": "235745af8d",
                "model": "81877f3be6"
            },
            "prompt": "woman posing, 20yo, winter, outdoors,  suggestive smile, dark long hair, pale skin, sunset, snow, snowing",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ 2M SDE Karras",
            "cfgScale": 5,
            "clipSkip": 2,
            "Mask blur": "4",
            "resources": [
                {
                    "hash": "81877f3be6",
                    "name": "epicrealismXL_v6Miracle",
                    "type": "model"
                }
            ],
            "Model hash": "81877f3be6",
            "Hires steps": "15",
            "Inpaint area": "Only masked",
            "Hires upscale": "2",
            "Hires upscaler": "4x_NMKD-Superscale-SP_178000_G",
            "ADetailer model": "face_yolov8n_v2.pt",
            "ADetailer version": "24.3.5",
            "Denoising strength": "0.4",
            "ADetailer mask blur": "4",
            "ADetailer model 2nd": "hand_yolov8n.pt",
            "ADetailer model 3rd": "breasts_seg.pt",
            "Masked area padding": "32",
            "ADetailer confidence": "0.3",
            "ADetailer prompt 2nd": "hand",
            "ADetailer prompt 3rd": "breasts",
            "ADetailer dilate erode": "4",
            "ADetailer mask blur 2nd": "4",
            "ADetailer mask blur 3rd": "4",
            "ADetailer confidence 2nd": "0.3",
            "ADetailer confidence 3rd": "0.3",
            "ADetailer inpaint padding": "32",
            "ADetailer dilate erode 2nd": "4",
            "ADetailer dilate erode 3rd": "4",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True",
            "ADetailer inpaint padding 2nd": "32",
            "ADetailer inpaint padding 3rd": "32",
            "ADetailer denoising strength 2nd": "0.4",
            "ADetailer denoising strength 3rd": "0.4",
            "ADetailer inpaint only masked 2nd": "True",
            "ADetailer inpaint only masked 3rd": "True"
        },
        "username": "delrisu",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 11739758,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d47843db-3ac1-4b89-819c-3e619d7b1981/width=1080/d47843db-3ac1-4b89-819c-3e619d7b1981.jpeg",
        "hash": "U9F4[f^*1Ow]Ck%L-ni{20oe%1V@~V-oxaIp",
        "width": 1080,
        "height": 1920,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-06T23:51:36.831Z",
        "postId": 2585793,
        "stats": {
            "cryCount": 3,
            "laughCount": 28,
            "likeCount": 93,
            "dislikeCount": 0,
            "heartCount": 51,
            "commentCount": 0
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "540x960",
            "seed": 1999236619,
            "Model": "ForRealXL",
            "steps": 10,
            "hashes": {
                "vae": "235745af8d",
                "model": "91ce21e3fd",
                "lora:MJ52": "000c96b6bd08",
                "lora:ral-cltc": "6230fd608352",
                "lora:add-detail-xl": "9c783c8ce46c",
                "lora:SDXLFaeTastic2400": "e7da1e0c0933",
                "lora:ral-mtclniscp-sdxl": "1ffaa94b5c99",
                "lora:xl_more_art-full_v1": "fe3b4816be83"
            },
            "prompt": "View from the fisheye lens: You're tiptoeing along the edge of a giant pizza slice, with gooey cheese and toppings spread out beneath you like a surreal Italian countryside. extreme fish eye view, \nabsurdres, ultra realistic, professional lightning\nmany details, extreme detailed, full of details,\nWide range of colors., Dramatic,Dynamic,Cinematic,Sharp details\nInsane quality. Insane resolution. Insane details. Masterpiece. 32k resolution.\n <lora:MJ52:0.2>\n <lora:add-detail-xl:0.8> <lora:xl_more_art-full_v1:0.7>\n <lora:ral-cltc:0.2> ral-cltc <lora:ral-mtclniscp-sdxl:0.2> ral-mtclniscp <lora:SDXLFaeTastic2400:0.3>",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DDPM",
            "cfgScale": 1.5,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "000c96b6bd08",
                    "name": "MJ52",
                    "type": "lora",
                    "weight": 0.2
                },
                {
                    "hash": "9c783c8ce46c",
                    "name": "add-detail-xl",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "hash": "fe3b4816be83",
                    "name": "xl_more_art-full_v1",
                    "type": "lora",
                    "weight": 0.7
                },
                {
                    "hash": "6230fd608352",
                    "name": "ral-cltc",
                    "type": "lora",
                    "weight": 0.2
                },
                {
                    "hash": "1ffaa94b5c99",
                    "name": "ral-mtclniscp-sdxl",
                    "type": "lora",
                    "weight": 0.2
                },
                {
                    "hash": "e7da1e0c0933",
                    "name": "SDXLFaeTastic2400",
                    "type": "lora",
                    "weight": 0.3
                },
                {
                    "hash": "91ce21e3fd",
                    "name": "ForRealXL",
                    "type": "model"
                }
            ],
            "Model hash": "91ce21e3fd",
            "Hires steps": "9",
            "Hires upscale": "2",
            "Hires upscaler": "SwinIR_4x",
            "Variation seed": "4013996341",
            "negativePrompt": "camera, lens, fish eye lens,",
            "Denoising strength": "0.27",
            "Variation seed strength": "0.41"
        },
        "username": "AIDigitalMediaAgency",
        "baseModel": "SDXL Lightning"
    },
    {
        "id": 11998308,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f16a7ad2-24c4-4421-9d3c-6f9a94fab286/width=832/f16a7ad2-24c4-4421-9d3c-6f9a94fab286.jpeg",
        "hash": "U88zS;9a56~C^PI:E2=|Ipoej[ay9uxZ-VE2",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-09T20:09:22.927Z",
        "postId": 2647218,
        "stats": {
            "cryCount": 10,
            "laughCount": 15,
            "likeCount": 85,
            "dislikeCount": 0,
            "heartCount": 65,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1294706696,
            "steps": 40,
            "prompt": "A Closeup Portrait of a Girl in Argyle printed camo-black bodysuit, a scene with dark natural and black tones details, very detailed, big breasts, atmospheric haze, Film grain, cinematic film still, shallow depth of field, highly detailed, high budget, cinemascope, moody, epic, OverallDetail, 2000s vintage RAW photo, photorealistic, candid camera, color graded cinematic, eye catchlights, atmospheric lighting, imperfections, natural, shallow dof",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 3,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "NEG-fixl-2, easynegative, bad proportions, low resolution, bad, ugly, terrible, painting, 3d, render, comic, anime, manga, unrealistic, flat, watermark, signature, worst quality, low quality, normal quality, lowres, simple background, inaccurate limb, extra fingers, fewer fingers, missing fingers, extra arms, (extra legs:1.3), inaccurate eyes, bad composition, bad anatomy, error, extra digit, fewer digits, cropped, low res, worst quality, low quality, normal quality, jpeg artifacts, extra digit, fewer digits, trademark, watermark, artist's name, username, signature, text, words, human,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 345685
                },
                {
                    "type": "ImageJobNetworkParams { Strength = 0.4, TriggerWord = , Type = lora }",
                    "weight": 0.4,
                    "modelVersionId": 258687
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 429806
                },
                {
                    "type": "ImageJobNetworkParams { Strength = 1, TriggerWord = , Type = lora }",
                    "weight": 1,
                    "modelVersionId": 488308
                },
                {
                    "type": "ImageJobNetworkParams { Strength = 1, TriggerWord = , Type = vae }",
                    "weight": 1,
                    "modelVersionId": 333245
                },
                {
                    "type": "embed",
                    "modelVersionId": 250708
                },
                {
                    "type": "embed",
                    "modelVersionId": 250712
                }
            ]
        },
        "username": "c33Gre",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 12927334,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e6fbe8a5-2060-498e-b8e8-8615c9cd7d8e/width=512/e6fbe8a5-2060-498e-b8e8-8615c9cd7d8e.jpeg",
        "hash": "USC?_+%gD$a{_Nx]M_ay?vx[n,bHtQt7jcWV",
        "width": 512,
        "height": 768,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-19T06:55:34.669Z",
        "postId": 2857372,
        "stats": {
            "cryCount": 7,
            "laughCount": 16,
            "likeCount": 110,
            "dislikeCount": 0,
            "heartCount": 42,
            "commentCount": 2
        },
        "meta": {
            "Size": "512x768",
            "seed": 683626741,
            "steps": 12,
            "prompt": "((((art representation of a harmonious nature elements, light, ice, stone, fire, crystal flowers, water, wind,  amorph glass, dynamic angle, ))))\nBackground: a space with clean lines and neutral colors to contrast with the explosion of vibrant colors,\nColor: Monochrome at the beginning with a gradual transition to vibrant, colorful tones,\nLighting: Soft, ambient lighting to enhance the serene atmosphere and highlight the colors, \n(((Stunning Quality, Masterpiece, Best Quality, Hyper Detail, Ultra Detail, Hyper Realism Majestic, Intimidating, Inspiring. cinematic composition, soft shadows, )))\n((Stunning Quality, Masterpiece, Best Quality, Hyper Detail, Ultra Detail, Hyper Realism Majestic, Intimidating, Inspiring. cinematic composition, soft lights))",
            "sampler": "Euler a",
            "cfgScale": 8.5,
            "clipSkip": 1,
            "resources": [],
            "Created Date": "2024-05-19T0653:47.9576442Z",
            "negativePrompt": "(((((girl, woman, human body, face,))))) easynegative, low resolution, bad, terrible, painting, 3d, render, comic, anime, manga, unrealistic, flat, watermark, signature, worst quality, low quality, normal quality, lowres, simple background, bad composition, error, extra digit, fewer digits, cropped, low res, worst quality, low quality, normal quality, jpeg artifacts, extra digit, fewer digits, trademark, watermark, artist's name, username, signature, text, words,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 132760,
                    "modelVersionName": "v1.8.1"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 87153,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1.25,
                    "modelVersionId": 123732,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "vae",
                    "modelVersionId": 94036,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "MetroCat",
        "baseModel": "SD 1.5"
    },
    {
        "id": 14121140,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/10d6f055-b5a3-46ae-bb27-c28181608945/width=1664/10d6f055-b5a3-46ae-bb27-c28181608945.jpeg",
        "hash": "U49adA#R0hPW.n%14:Ns00rWx[RiY*S$$wQ;",
        "width": 1664,
        "height": 2304,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-31T08:45:18.369Z",
        "postId": 3132706,
        "stats": {
            "cryCount": 0,
            "laughCount": 0,
            "likeCount": 133,
            "dislikeCount": 0,
            "heartCount": 42,
            "commentCount": 6
        },
        "meta": {
            "seed": 1066384153952274,
            "steps": 4,
            "prompt": " colorful translucent elemental horse made of water,made of fire,made of earth,made of air, glowing,Fantasy concept art style, digital painting, imaginative, dynamic composition, professional-grade execution, creates immersive world and landscape, brush strokes, epic, magical",
            "sampler": "DPM++ SDE",
            "cfgScale": 1
        },
        "username": "green21st",
        "baseModel": ""
    },
    {
        "id": 15603332,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c36558d7-2d68-4e13-911c-f3c5a9350013/width=1800/c36558d7-2d68-4e13-911c-f3c5a9350013.jpeg",
        "hash": "U#M[Wco|I-jX-@WD%LkCOuaxrxkDbdbaV@V@",
        "width": 2048,
        "height": 2048,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-13T04:13:56.060Z",
        "postId": 3476705,
        "stats": {
            "cryCount": 18,
            "laughCount": 80,
            "likeCount": 61,
            "dislikeCount": 0,
            "heartCount": 16,
            "commentCount": 1
        },
        "meta": null,
        "username": "tubbymeatball",
        "baseModel": "SD 3"
    },
    {
        "id": 16160023,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/694d20ee-c946-4ad5-be1d-bdadc2594d45/width=832/694d20ee-c946-4ad5-be1d-bdadc2594d45.jpeg",
        "hash": "U68gmU-;00RjK7OY%L%L4oxt~pkq$|t7I[Rj",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-17T19:59:18.106Z",
        "postId": 3613456,
        "stats": {
            "cryCount": 7,
            "laughCount": 18,
            "likeCount": 109,
            "dislikeCount": 0,
            "heartCount": 41,
            "commentCount": 0
        },
        "meta": null,
        "username": "eduardo_saffe",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 16667417,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/282db83a-3528-4286-8877-dca0dd9d3b82/width=832/282db83a-3528-4286-8877-dca0dd9d3b82.jpeg",
        "hash": "UKIDp*~B5RIUI?NGM|R+ELo0sot7RjNGR+of",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-22T00:02:27.167Z",
        "postId": 3739202,
        "stats": {
            "cryCount": 3,
            "laughCount": 8,
            "likeCount": 119,
            "dislikeCount": 0,
            "heartCount": 45,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3654273434,
            "steps": 30,
            "prompt": "An award winning photo , a cute little baby cat,sitting around in a Peach costume, (fruit) , (((cuteness overload))) <lora:add-detail-xl:1>,  <lora:WowifierXL-V2:1>, zhibi",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [
                {
                    "name": "add-detail-xl",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "name": "WowifierXL-V2",
                    "type": "lora",
                    "weight": 1
                }
            ],
            "Created Date": "2024-06-21T2354:47.0386371Z",
            "negativePrompt": "low quality, worst quality, unsharp, low details , ImgFixerPre0.3, ng_deepnegative_v1_75t , negativeXL_D",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 291443,
                    "modelVersionName": "v24"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 135867,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 209649,
                    "modelVersionName": "SDXL"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 217866,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "vae",
                    "weight": 1,
                    "modelVersionId": 333245,
                    "modelVersionName": "SDXL-VAE"
                }
            ]
        },
        "username": "Jedas",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 16667541,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/46238554-3489-422e-86d1-c90da86f1c6b/width=1800/46238554-3489-422e-86d1-c90da86f1c6b.jpeg",
        "hash": "U9Ad_Z--8w0:okuhf}Z2KhyqxtQ8ufobv}t7",
        "width": 2048,
        "height": 2048,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-22T00:04:12.162Z",
        "postId": 3739233,
        "stats": {
            "cryCount": 0,
            "laughCount": 19,
            "likeCount": 123,
            "dislikeCount": 0,
            "heartCount": 33,
            "commentCount": 1
        },
        "meta": {
            "": {
                "\\skip_factor\\": "0.4}]",
                "{\\backbone_factor\\": "1.2",
                "[{\\backbone_factor\\": "1.1"
            },
            "Eta": "0.5",
            "RNG": "CPU",
            "VAE": "sdxl_vae.safetensors",
            "Size": "1024x1024",
            "seed": 88888888,
            "Model": "paradox_3-xl",
            "steps": 120,
            "hashes": {
                "vae": "42a404c885",
                "model": "a32d1921a6",
                "lora:more_artful-xl": "15e31fe2b6",
                "embed:ng-beyond_sdxl-v3": "7a11b7b2ad",
                "lora:envybetterhiresfixxl01-xl": "930e286cfd",
                "lora:midjourney_mimic-xl-by_andrexsel": "e526855052",
                "lora:extremely_detailed-detail_slider-v2-xl-by_ntc": "a6443748eb",
                "lora:lyco-style-envydramaticlightingxl01_digital_art-xl": "ecbbe6e3d9"
            },
            "prompt": "old masters painting style, intricate details, famous artwork inspired by (james cameron's avatar:1.1) and (hyper light drifter:1.1) and (tyler jacobson:1.4) and (stephan martiniere:1.1) and (genevieve valentine:1.3) and (larry elmore:1.2), detailed expressive eyes, fantasy style, the \"brave slimebonk\", a (mysterious:1.1) and (whimsical:1.2) life form with psychic powers emenating from its flumbering ufti, it likes to lay in ambush within the tranquil ponds of the lush coundrilsized oases that dot the colorful lampremblative deserts of the accursed (paradisical:1.1) planet \"tryonicon v\", stay away vogons, this planet is just horribly nice, <lora:lyco-style-envydramaticlightingxl01_digital_art-xl:0.8> <lora:midjourney_mimic-xl-by_andrexsel:0.4> <lora:more_artful-xl:0.4> <lora:extremely_detailed-detail_slider-v2-xl-by_ntc:1.0> <lora:envybetterhiresfixxl01-xl:0.0:hr=1.0>",
            "Version": "v1.9.4",
            "sampler": "DPM++ 2M SDE",
            "cfgScale": 8,
            "resources": [
                {
                    "name": "lyco-style-envydramaticlightingxl01_digital_art-xl",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "name": "midjourney_mimic-xl-by_andrexsel",
                    "type": "lora",
                    "weight": 0.4
                },
                {
                    "name": "more_artful-xl",
                    "type": "lora",
                    "weight": 0.4
                },
                {
                    "name": "extremely_detailed-detail_slider-v2-xl-by_ntc",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "a32d1921a6",
                    "name": "paradox_3-xl",
                    "type": "model"
                }
            ],
            "Model hash": "a32d1921a6",
            "Hires steps": "36",
            "FreeU Stages": {},
            "FreeU Version": "2",
            "Hires upscale": "2",
            "Schedule type": "Exponential",
            "FreeU Schedule": {},
            "Hires upscaler": "4x_foolhardy_remacri",
            "negativePrompt": "ng-beyond_sdxl-v3, boring, frame, sloppy, sketch, flat, 2d, anime, oversaturated, comic, cropped, duplicate, low quality, margins, photorealistic, simple, text",
            "Denoising strength": "0.36"
        },
        "username": "OneViolentGentleman",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 16797415,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2897cb20-bef8-42a4-9920-1fd603b29ff1/width=832/2897cb20-bef8-42a4-9920-1fd603b29ff1.jpeg",
        "hash": "UdEo_R%M-;oz?wtRW=bbbdxaRislRkkDf5a#",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-23T00:02:35.447Z",
        "postId": 3768332,
        "stats": {
            "cryCount": 1,
            "laughCount": 2,
            "likeCount": 150,
            "dislikeCount": 0,
            "heartCount": 22,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 740682872,
            "steps": 30,
            "prompt": "castle on a (rock spire), mountain in background, best quality, masterpiece, illustration, realistic, photo-realistic, amazing, finely detail, incredibly absurdres, huge filesize, ultra-detailed, highres, extremely detailed CG unity 8k wallpaper",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-06-22T2220:23.2396471Z",
            "negativePrompt": "worst quality, low quality, text, censored, deformed, bad hand, blurry, (watermark), incorrect anatomy, malformed, multiple limbs, bad legs, bad feet, bad arms, anime, animation, drawed, women, girl,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 159123,
                    "modelVersionName": "v3.31_BF16_Experimental"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 454594,
                    "modelVersionName": "Gar_Fantasy castle"
                }
            ]
        },
        "username": "the_dyslexic_one582",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 17017744,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7c8ffd02-27ac-41cc-9e94-c7750cf63001/width=832/7c8ffd02-27ac-41cc-9e94-c7750cf63001.jpeg",
        "hash": "U6A]~X0K~qM|?vIV?an$00~V0LR+01xu4oxu",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-24T14:54:06.482Z",
        "postId": 3816255,
        "stats": {
            "cryCount": 0,
            "laughCount": 2,
            "likeCount": 149,
            "dislikeCount": 0,
            "heartCount": 24,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 830783542,
            "steps": 32,
            "prompt": "A high-resolution, dramatic photograph of a lone tree standing in the middle of a golden field of tall, swaying grass. Above, dark, stormy clouds dominate the sky, with a break in the clouds allowing a glimpse of light to shine through, creating a striking contrast between the dark sky and the illuminated landscape. The scene is moody and atmospheric, evoking a sense of impending storm and the beauty of nature's raw power. The tree, with its gnarled branches and dark leaves, stands as a focal point against the vast, turbulent sky.",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-06-24T1452:36.1607098Z",
            "negativePrompt": "extra digit, fewer digits, cropped, worst quality, low quality, normal quality, very displeasing,  blurry, artist name,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 403131,
                    "modelVersionName": "v3.1"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 135867,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "ARTAIM",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 17548684,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/36086c17-83c2-4c40-8f0f-b71d6cd6a230/width=832/36086c17-83c2-4c40-8f0f-b71d6cd6a230.jpeg",
        "hash": "U7BfnZE20L-:3EfP,Bt7_3%19aj?_NRks8S5",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-28T10:22:25.409Z",
        "postId": 3929348,
        "stats": {
            "cryCount": 5,
            "laughCount": 10,
            "likeCount": 109,
            "dislikeCount": 0,
            "heartCount": 51,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2843440363,
            "steps": 8,
            "prompt": "cinematic  by (((Hugh Ferriss) and wlop) and Brian Mashburn) and Tom Whalen,   action shot, fighting, fantasy, gigantic pet dragon, bosstyle <lora:boss_battles:0.55>  , shallow depth of field",
            "sampler": "Euler",
            "cfgScale": 1,
            "clipSkip": 2,
            "resources": [
                {
                    "name": "boss_battles",
                    "type": "lora",
                    "weight": 0.55
                }
            ],
            "Created Date": "2024-06-28T1005:46.1156593Z",
            "negativePrompt": "Unspeakable-Horrors-Composition-SDXL, SDXL_TI_my_eyes_are_bleeding, unaestheticXL_Alb2, poorly drawn, gloomy, messy, low quality, blurry, doll, deviant, animal ears, topless, breasts, nipples, strange clothing",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 128078,
                    "modelVersionName": "v1.0 VAE fix"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 363593,
                    "modelVersionName": "_Alb2"
                },
                {
                    "type": "lora",
                    "weight": 0.55,
                    "modelVersionId": 369959,
                    "modelVersionName": "Sword"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 340980,
                    "modelVersionName": "v2.0 - Negative Embedding"
                },
                {
                    "type": "vae",
                    "weight": 1,
                    "modelVersionId": 333245,
                    "modelVersionName": "SDXL-VAE"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 391999,
                    "modelVersionName": "8 Steps"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "rbcom",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 18744632,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c0021f38-4f8b-4d11-9568-ed220cb8d363/width=1216/c0021f38-4f8b-4d11-9568-ed220cb8d363.jpeg",
        "hash": "UGD];wtm0KMypyOZt*ae0R$i.6o{MJ$6kDJ$",
        "width": 1216,
        "height": 832,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-06T23:18:09.549Z",
        "postId": 4185927,
        "stats": {
            "cryCount": 2,
            "laughCount": 4,
            "likeCount": 139,
            "dislikeCount": 0,
            "heartCount": 30,
            "commentCount": 0
        },
        "meta": {
            "Size": "1216x832",
            "seed": 1101899894,
            "steps": 19,
            "prompt": "cinematic, (masterpiece), (best quality), (ultra-detailed), very aesthetic, illustration, perfect composition, intricate details, absurdres, (anime, masterpiece, intricate:1.3), (best quality, hires textures, high detail:1.2), (4k),(incredibly detailed:1.4)\nhouses near hot spring, mist, rocks, Peony, glittery mist, moonlight, sky, lots of stars in the sky, water reflections of the night sky, (bamboo), aurora, lotus floating on water with candle, flower petals in the water, moon in the sky, Anime art style, <lora:more_details:0.5>",
            "sampler": "Euler a",
            "cfgScale": 8,
            "clipSkip": 2,
            "resources": [
                {
                    "name": "more_details",
                    "type": "lora",
                    "weight": 0.5
                }
            ],
            "Created Date": "2024-07-06T1501:53.5972991Z",
            "negativePrompt": "loli, child, longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, worst quality, low quality, normal quality, watermark, artist name, signature",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 403131,
                    "modelVersionName": "v3.1"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 129711,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 135867,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 152309,
                    "modelVersionName": "xl_more_art-full-v1"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 469308,
                    "modelVersionName": "Detailed v1.0"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 77169,
                    "modelVersionName": "BadDream v1.0"
                }
            ]
        },
        "username": "Ghost6n",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 18950242,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7593a968-bf25-4d2a-a105-096cdeb11feb/width=1152/7593a968-bf25-4d2a-a105-096cdeb11feb.jpeg",
        "hash": "UJBET|o#IVxZN+k8s~RR%$V[MLWBt$RQr;WB",
        "width": 1152,
        "height": 2016,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-07-08T11:20:19.465Z",
        "postId": 4231641,
        "stats": {
            "cryCount": 0,
            "laughCount": 4,
            "likeCount": 135,
            "dislikeCount": 0,
            "heartCount": 36,
            "commentCount": 0
        },
        "meta": {
            "RNG": "NV",
            "Size": "768x1344",
            "seed": 156269351,
            "Model": "realcartoonXL_v6",
            "steps": 35,
            "hashes": {
                "model": "d370e2fbaa"
            },
            "prompt": "digital art of gradient-colored see-through slime creature , the slime has big anime like eyes without mouth, isekai world, depth of field, nature, sparkling eyes, sparkling aura,   vibrant colors blending seamlessly, high-definition textures, intricate details, perfect lighting, 8k resolution, sliding , glossy surface, highly detailed, vivid reflections, dynamic composition",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "Euler",
            "cfgScale": 5,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "d370e2fbaa",
                    "name": "realcartoonXL_v6",
                    "type": "model"
                }
            ],
            "Model hash": "d370e2fbaa",
            "Extra noise": "0.01",
            "Hires upscale": "1.5",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "low resolution, blurry, unrealistic, flat colors, poorly lit, grainy, dull, pixelated, distorted",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.5.1",
            "Denoising strength": "0.4",
            "ADetailer mask blur": "32",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer ControlNet model": "thibaud_xl_openpose [c7b9cadd]",
            "ADetailer ControlNet module": "dw_openpose_full",
            "ADetailer denoising strength": "0.6",
            "ADetailer inpaint only masked": "True"
        },
        "username": "salammy",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 17261558,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/02ee0462-38ce-4a7e-8915-7dbc837db9ec/width=1024/02ee0462-38ce-4a7e-8915-7dbc837db9ec.jpeg",
        "hash": "UCHx4x00029a-N~V00x]I9IoXUM{IAIo%gn+",
        "width": 1024,
        "height": 1536,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-06-26T07:55:07.391Z",
        "postId": 3867773,
        "stats": {
            "cryCount": 8,
            "laughCount": 77,
            "likeCount": 131,
            "dislikeCount": 0,
            "heartCount": 69,
            "commentCount": 0
        },
        "meta": {
            "Size": "512x768",
            "seed": 3884536579,
            "Model": "autismmixSDXL_autismmixPony",
            "steps": 20,
            "hashes": {
                "model": "821aa5537f",
                "lora:Concept_Go_do_a_crime_meme": "2ac0bf1ec8d2"
            },
            "prompt": "zPDXL,   <lora:Concept_Go_do_a_crime_meme:1>, 1girl, GODOACRIME, go do a crime (meme), english text, gun, zelda breath of the wild, chibi",
            "Version": "v1.9.4",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "2ac0bf1ec8d2",
                    "name": "Concept_Go_do_a_crime_meme",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "821aa5537f",
                    "name": "autismmixSDXL_autismmixPony",
                    "type": "model"
                }
            ],
            "Model hash": "821aa5537f",
            "Hires steps": "10",
            "Hires upscale": "2",
            "Schedule type": "Automatic",
            "Hires upscaler": "R-ESRGAN 4x+ Anime6B",
            "negativePrompt": "zPDXL-neg, watermark, text, logo, bad hands, bad anatomy, extra fingers, extra arms, extra legs, 3d",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.6.0",
            "Denoising strength": "0.45",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "Oktaze",
        "baseModel": "Pony"
    },
    {
        "id": 13605344,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0c9fea1a-cdb1-4687-9732-ac6933f5d0b1/width=1248/0c9fea1a-cdb1-4687-9732-ac6933f5d0b1.jpeg",
        "hash": "UDGuBw%Mxu?G~WRPocE2?u9G9at7l9x[Rkxa",
        "width": 1248,
        "height": 1824,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-26T05:36:52.718Z",
        "postId": 3013114,
        "stats": {
            "cryCount": 10,
            "laughCount": 82,
            "likeCount": 143,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 1
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "832x1216",
            "seed": 84773495,
            "Model": "zavychromaxl_v70",
            "steps": 30,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "3e0a3274d0"
            },
            "prompt": "a crab holding a gun, pov, from above, attacking viewer, pointing gun at viewer,",
            "Version": "f0.0.17v1.8.0rc-latest-276-g29be1da7",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "3e0a3274d0",
                    "name": "zavychromaxl_v70",
                    "type": "model"
                }
            ],
            "Model hash": "3e0a3274d0",
            "Hires steps": "12",
            "Hires upscale": "1.5",
            "Hires upscaler": "4x-UltraSharp",
            "Denoising strength": "0.5"
        },
        "username": "Rythievakem",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 12528820,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/23992335-04b8-4b23-bec2-20bc37fc4279/width=832/23992335-04b8-4b23-bec2-20bc37fc4279.jpeg",
        "hash": "UXIC+#E25m={~BRPn*$*K6wIxZa~t8rrS#S4",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-15T08:52:50.823Z",
        "postId": 2768603,
        "stats": {
            "cryCount": 5,
            "laughCount": 15,
            "likeCount": 192,
            "dislikeCount": 0,
            "heartCount": 73,
            "commentCount": 0
        },
        "meta": null,
        "username": "Regiiina",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 12483178,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/34350a64-486f-468a-8751-70040e095da5/width=832/34350a64-486f-468a-8751-70040e095da5.jpeg",
        "hash": "UNHU%,?G~B-o?vxt9aj[%#M|-pofX-RjxYxZ",
        "width": 832,
        "height": 1248,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-14T22:24:55.449Z",
        "postId": 2758549,
        "stats": {
            "cryCount": 65,
            "laughCount": 18,
            "likeCount": 118,
            "dislikeCount": 0,
            "heartCount": 84,
            "commentCount": 0
        },
        "meta": {
            "RNG": "CPU",
            "VAE": "sdxl_vae.safetensors",
            "Size": "832x1248",
            "seed": 2656192446,
            "Model": "incursiosMemeDiffusion_v16PDXL",
            "steps": 28,
            "hashes": {
                "vae": "235745af8d",
                "model": "c8c641fa3a",
                "lora:yoshidasaki-pdxl-nvwls-v1-000006": "e7ffe672f160"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime BREAK 1girl,  <lora:yoshidasaki-pdxl-nvwls-v1-000006:1> defSaki, blue eyes, twin braids, hair over shoulders, glasses, navy blue shirt, serafuku, white neckkerchief, long sleeves, pleated skirt, stare, looking at you, city, arms at sides, blue sky",
            "Version": "v1.9.3",
            "sampler": "Euler a",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "e7ffe672f160",
                    "name": "yoshidasaki-pdxl-nvwls-v1-000006",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "c8c641fa3a",
                    "name": "incursiosMemeDiffusion_v16PDXL",
                    "type": "model"
                }
            ],
            "Model hash": "c8c641fa3a",
            "Schedule type": "Automatic",
            "negativePrompt": "3d, photorealistic, monochrome",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.4.2",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "32",
            "Downcast alphas_cumprod": "True",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "novowels",
        "baseModel": "Pony"
    },
    {
        "id": 12146028,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d6218b88-1841-4bb7-8c42-5bd3f5c17a99/width=832/d6218b88-1841-4bb7-8c42-5bd3f5c17a99.jpeg",
        "hash": "U6BDf[4;0KNHCTxZRPoL00$%%M?a4nXm?a9Z",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-11T10:48:25.438Z",
        "postId": 2681484,
        "stats": {
            "cryCount": 3,
            "laughCount": 25,
            "likeCount": 190,
            "dislikeCount": 0,
            "heartCount": 67,
            "commentCount": 0
        },
        "meta": null,
        "username": null,
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 11430045,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/655a1499-b331-4207-8f8e-cddeb35c13e4/width=1152/655a1499-b331-4207-8f8e-cddeb35c13e4.jpeg",
        "hash": "UDAw6j={D*EM^n$#NaI@,-VrXUkXt1ROW?t7",
        "width": 1152,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-05-03T14:01:19.007Z",
        "postId": 2512894,
        "stats": {
            "cryCount": 0,
            "laughCount": 10,
            "likeCount": 202,
            "dislikeCount": 0,
            "heartCount": 73,
            "commentCount": 0
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "Size": "768x1152",
            "seed": 2025473007,
            "Model": "dreamshaperXL_v21TurboDPMSDE",
            "steps": 8,
            "hashes": {
                "vae": "235745af8d",
                "model": "4496b36d48",
                "lora:linquivera": "b276d415375b",
                "embed:unaestheticXL_Alb2": "6c1c4cfa35",
                "lora:juggernaut_cinematic": "91f68961ddc0",
                "embed:SDXL_TI_my_eyes_are_bleeding": "dd3cbf652a",
                "embed:Unspeakable-Horrors-Composition-SDXL": "0cc1e424ab"
            },
            "prompt": "by Scott Naismith and Aaron Jasinski and Jeff Easley in the style of Bess Hamiti and Emilia Wilk,  movie still <lora:juggernaut_cinematic:1.00> ,   linquivera <lora:linquivera:1.00>",
            "Version": "v1.8.0",
            "sampler": "DPM++ SDE Karras",
            "cfgScale": 2.5,
            "Pad conds": "True",
            "TI hashes": {
                "unaestheticXL_Alb2": "6c1c4cfa35e9",
                "SDXL_TI_my_eyes_are_bleeding": "dd3cbf652a1d",
                "Unspeakable-Horrors-Composition-SDXL": "0cc1e424ab42"
            },
            "resources": [
                {
                    "hash": "91f68961ddc0",
                    "name": "juggernaut_cinematic",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "b276d415375b",
                    "name": "linquivera",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "4496b36d48",
                    "name": "dreamshaperXL_v21TurboDPMSDE",
                    "type": "model"
                }
            ],
            "Model hash": "4496b36d48",
            "Hires steps": "5",
            "Hires upscale": "1.5",
            "Hires upscaler": "4x-UltraSharp",
            "negativePrompt": "Unspeakable-Horrors-Composition-SDXL, SDXL_TI_my_eyes_are_bleeding, unaestheticXL_Alb2, poorly drawn, gloomy, messy, low quality, blurry, doll, deviant, animal ears, topless, breasts, nipples, strange clothing",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer prompt": {},
            "ADetailer VAE 3rd": "vae-ft-mse-840000-ema-pruned.ckpt",
            "ADetailer version": "24.3.0",
            "Denoising strength": "0.45",
            "ADetailer mask blur": "12",
            "ADetailer model 2nd": "hand_yolov8n.pt",
            "ADetailer model 3rd": "female-breast-v4.0-fantasy.pt",
            "ADetailer steps 3rd": "20",
            "ADetailer confidence": "0.5",
            "ADetailer prompt 2nd": {},
            "ADetailer prompt 3rd": {},
            "ADetailer sampler 3rd": "DPM++ 2M Karras",
            "ADetailer dilate erode": "12",
            "ADetailer CFG scale 3rd": "7.0",
            "ADetailer inpaint width": "1152",
            "ADetailer mask blur 2nd": "12",
            "ADetailer mask blur 3rd": "12",
            "ADetailer checkpoint 3rd": "SD1.5\\wafflemix7.safetensors [4844f773bb]",
            "ADetailer confidence 2nd": "0.5",
            "ADetailer confidence 3rd": "0.4",
            "ADetailer inpaint height": "1152",
            "ADetailer mask min ratio": "0.001",
            "ADetailer inpaint padding": "128",
            "ADetailer dilate erode 2nd": "12",
            "ADetailer dilate erode 3rd": "12",
            "ADetailer inpaint width 2nd": "896",
            "ADetailer inpaint width 3rd": "1024",
            "ADetailer denoising strength": "0.45",
            "ADetailer inpaint height 2nd": "896",
            "ADetailer inpaint height 3rd": "1024",
            "ADetailer mask min ratio 2nd": "0.001",
            "ADetailer mask min ratio 3rd": "0.001",
            "ADetailer inpaint only masked": "True",
            "ADetailer inpaint padding 2nd": "128",
            "ADetailer inpaint padding 3rd": "128",
            "ADetailer negative prompt 3rd": {
                "(tan lines": "1.4)",
                "normal quality": "2.0)"
            },
            "ADetailer use separate VAE 3rd": "True",
            "ADetailer denoising strength 2nd": "0.45",
            "ADetailer denoising strength 3rd": "0.45",
            "ADetailer use separate steps 3rd": "True",
            "ADetailer inpaint only masked 2nd": "True",
            "ADetailer inpaint only masked 3rd": "True",
            "ADetailer mask only top k largest": "5",
            "ADetailer use inpaint width height": "True",
            "ADetailer use separate sampler 3rd": "True",
            "ADetailer use separate CFG scale 3rd": "True",
            "ADetailer mask only top k largest 2nd": "6",
            "ADetailer mask only top k largest 3rd": "4",
            "ADetailer use separate checkpoint 3rd": "True",
            "ADetailer use inpaint width height 2nd": "True",
            "ADetailer use inpaint width height 3rd": "True"
        },
        "username": "LordTerror",
        "baseModel": "SDXL Turbo"
    },
    {
        "id": 10901022,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a65d78ac-000c-4cfb-9828-6641efda9e1f/width=832/a65d78ac-000c-4cfb-9828-6641efda9e1f.jpeg",
        "hash": "UFD9bWa101X9_LR*RlaK_1R*IpR+~oWW9aWB",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-04-27T14:52:46.121Z",
        "postId": 2390513,
        "stats": {
            "cryCount": 7,
            "laughCount": 17,
            "likeCount": 190,
            "dislikeCount": 0,
            "heartCount": 71,
            "commentCount": 1
        },
        "meta": null,
        "username": "3mcg33",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 8060320,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/33dcc961-f2ed-40a5-8b5d-e6f8c3ac7b59/width=1432/33dcc961-f2ed-40a5-8b5d-e6f8c3ac7b59.jpeg",
        "hash": "U87-TetRD%M{~q%LIUM{IpxtozRj9Fad%Nog",
        "width": 1432,
        "height": 2144,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-03-16T19:18:15.774Z",
        "postId": 1745403,
        "stats": {
            "cryCount": 7,
            "laughCount": 13,
            "likeCount": 188,
            "dislikeCount": 0,
            "heartCount": 77,
            "commentCount": 1
        },
        "meta": {
            "seed": 295199585472974,
            "vaes": [],
            "Model": "stable_cascade_stage_c",
            "comfy": "{\"prompt\":{\"34\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}},\"41\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"125\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"126\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"127\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"129\":{\"inputs\":{\"filename_prefix\":\"cascade-txt2img/cascade\",\"images\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"SaveImage\",\"_meta\":{\"title\":\"Save Image\"}},\"133\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"134\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"136\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"149\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"159\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"276\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"277\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt) +\"}},\"278\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt) -\"}},\"288\":{\"inputs\":{\"filename_prefix\":\"cascade-txt2img-rmsdxl/cascade-rmsdxl\",\"images\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":14,\"cfg\":2,\"sampler_name\":\"dpmpp_2m\",\"scheduler\":\"sgm_uniform\",\"denoise\":0.35000000000000003,\"model\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt) +\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt) -\"}},\"latent_image\":{\"inputs\":{\"pixels\":{\"inputs\":{\"upscale_method\":\"bilinear\",\"scale_by\":0.35000000000000003,\"image\":{\"inputs\":{\"upscale_model\":{\"inputs\":{\"model_name\":\"4x_NMKD-Siax_200k.pth\"},\"class_type\":\"UpscaleModelLoader\",\"_meta\":{\"title\":\"Load Upscale Model\"}},\"image\":{\"inputs\":{\"sharpen_radius\":1,\"sigma\":0.4,\"alpha\":0.30000000000000004,\"image\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"ImageSharpen\",\"_meta\":{\"title\":\"ImageSharpen\"}}},\"class_type\":\"ImageUpscaleWithModel\",\"_meta\":{\"title\":\"Upscale Image (using Model)\"}}},\"class_type\":\"ImageScaleBy\",\"_meta\":{\"title\":\"Upscale Image By\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEEncode\",\"_meta\":{\"title\":\"VAE Encode\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"SaveImage\",\"_meta\":{\"title\":\"Save Image\"}},\"294\":{\"inputs\":{\"sharpen_radius\":1,\"sigma\":0.4,\"alpha\":0.30000000000000004,\"image\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"ImageSharpen\",\"_meta\":{\"title\":\"ImageSharpen\"}},\"299\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}},\"305\":{\"inputs\":{\"upscale_model\":{\"inputs\":{\"model_name\":\"4x_NMKD-Siax_200k.pth\"},\"class_type\":\"UpscaleModelLoader\",\"_meta\":{\"title\":\"Load Upscale Model\"}},\"image\":{\"inputs\":{\"sharpen_radius\":1,\"sigma\":0.4,\"alpha\":0.30000000000000004,\"image\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"ImageSharpen\",\"_meta\":{\"title\":\"ImageSharpen\"}}},\"class_type\":\"ImageUpscaleWithModel\",\"_meta\":{\"title\":\"Upscale Image (using Model)\"}},\"306\":{\"inputs\":{\"model_name\":\"4x_NMKD-Siax_200k.pth\"},\"class_type\":\"UpscaleModelLoader\",\"_meta\":{\"title\":\"Load Upscale Model\"}},\"309\":{\"inputs\":{\"seed\":295199585472974,\"steps\":14,\"cfg\":2,\"sampler_name\":\"dpmpp_2m\",\"scheduler\":\"sgm_uniform\",\"denoise\":0.35000000000000003,\"model\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt) +\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt) -\"}},\"latent_image\":{\"inputs\":{\"pixels\":{\"inputs\":{\"upscale_method\":\"bilinear\",\"scale_by\":0.35000000000000003,\"image\":{\"inputs\":{\"upscale_model\":{\"inputs\":{\"model_name\":\"4x_NMKD-Siax_200k.pth\"},\"class_type\":\"UpscaleModelLoader\",\"_meta\":{\"title\":\"Load Upscale Model\"}},\"image\":{\"inputs\":{\"sharpen_radius\":1,\"sigma\":0.4,\"alpha\":0.30000000000000004,\"image\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"ImageSharpen\",\"_meta\":{\"title\":\"ImageSharpen\"}}},\"class_type\":\"ImageUpscaleWithModel\",\"_meta\":{\"title\":\"Upscale Image (using Model)\"}}},\"class_type\":\"ImageScaleBy\",\"_meta\":{\"title\":\"Upscale Image By\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEEncode\",\"_meta\":{\"title\":\"VAE Encode\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"312\":{\"inputs\":{\"pixels\":{\"inputs\":{\"upscale_method\":\"bilinear\",\"scale_by\":0.35000000000000003,\"image\":{\"inputs\":{\"upscale_model\":{\"inputs\":{\"model_name\":\"4x_NMKD-Siax_200k.pth\"},\"class_type\":\"UpscaleModelLoader\",\"_meta\":{\"title\":\"Load Upscale Model\"}},\"image\":{\"inputs\":{\"sharpen_radius\":1,\"sigma\":0.4,\"alpha\":0.30000000000000004,\"image\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"ImageSharpen\",\"_meta\":{\"title\":\"ImageSharpen\"}}},\"class_type\":\"ImageUpscaleWithModel\",\"_meta\":{\"title\":\"Upscale Image (using Model)\"}}},\"class_type\":\"ImageScaleBy\",\"_meta\":{\"title\":\"Upscale Image By\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEEncode\",\"_meta\":{\"title\":\"VAE Encode\"}},\"313\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":14,\"cfg\":2,\"sampler_name\":\"dpmpp_2m\",\"scheduler\":\"sgm_uniform\",\"denoise\":0.35000000000000003,\"model\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt) +\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt) -\"}},\"latent_image\":{\"inputs\":{\"pixels\":{\"inputs\":{\"upscale_method\":\"bilinear\",\"scale_by\":0.35000000000000003,\"image\":{\"inputs\":{\"upscale_model\":{\"inputs\":{\"model_name\":\"4x_NMKD-Siax_200k.pth\"},\"class_type\":\"UpscaleModelLoader\",\"_meta\":{\"title\":\"Load Upscale Model\"}},\"image\":{\"inputs\":{\"sharpen_radius\":1,\"sigma\":0.4,\"alpha\":0.30000000000000004,\"image\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"ImageSharpen\",\"_meta\":{\"title\":\"ImageSharpen\"}}},\"class_type\":\"ImageUpscaleWithModel\",\"_meta\":{\"title\":\"Upscale Image (using Model)\"}}},\"class_type\":\"ImageScaleBy\",\"_meta\":{\"title\":\"Upscale Image By\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEEncode\",\"_meta\":{\"title\":\"VAE Encode\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"RMSDXLLightning.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}},\"315\":{\"inputs\":{\"upscale_method\":\"bilinear\",\"scale_by\":0.35000000000000003,\"image\":{\"inputs\":{\"upscale_model\":{\"inputs\":{\"model_name\":\"4x_NMKD-Siax_200k.pth\"},\"class_type\":\"UpscaleModelLoader\",\"_meta\":{\"title\":\"Load Upscale Model\"}},\"image\":{\"inputs\":{\"sharpen_radius\":1,\"sigma\":0.4,\"alpha\":0.30000000000000004,\"image\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"ImageSharpen\",\"_meta\":{\"title\":\"ImageSharpen\"}}},\"class_type\":\"ImageUpscaleWithModel\",\"_meta\":{\"title\":\"Upscale Image (using Model)\"}}},\"class_type\":\"ImageScaleBy\",\"_meta\":{\"title\":\"Upscale Image By\"}},\"321\":{\"inputs\":{\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecode\",\"_meta\":{\"title\":\"VAE Decode\"}},\"322\":{\"inputs\":{\"images\":{\"inputs\":{\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecode\",\"_meta\":{\"title\":\"VAE Decode\"}}},\"class_type\":\"PreviewImage\",\"_meta\":{\"title\":\"Preview Image\"}},\"324\":{\"inputs\":{\"images\":{\"inputs\":{\"upscale_method\":\"bilinear\",\"scale_by\":0.35000000000000003,\"image\":{\"inputs\":{\"upscale_model\":{\"inputs\":{\"model_name\":\"4x_NMKD-Siax_200k.pth\"},\"class_type\":\"UpscaleModelLoader\",\"_meta\":{\"title\":\"Load Upscale Model\"}},\"image\":{\"inputs\":{\"sharpen_radius\":1,\"sigma\":0.4,\"alpha\":0.30000000000000004,\"image\":{\"inputs\":{\"tile_size\":512,\"samples\":{\"inputs\":{\"seed\":295199585472974,\"steps\":15,\"cfg\":1.1,\"sampler_name\":\"ddpm\",\"scheduler\":\"karras\",\"denoise\":1,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}},\"positive\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"stage_c\":{\"inputs\":{\"seed\":295199585472974,\"steps\":20,\"cfg\":4,\"sampler_name\":\"euler_ancestral\",\"scheduler\":\"simple\",\"denoise\":1,\"model\":{\"inputs\":{\"shift\":2,\"model\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"ModelSamplingStableCascade\",\"_meta\":{\"title\":\"ModelSamplingStableCascade\"}},\"positive\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"negative\":{\"inputs\":{\"text\":\"cartoon, fake, sketch\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}}},\"class_type\":\"StableCascade_StageB_Conditioning\",\"_meta\":{\"title\":\"StableCascade_StageB_Conditioning\"}},\"negative\":{\"inputs\":{\"conditioning\":{\"inputs\":{\"text\":\"hollow that looks like a creature sleeping\",\"clip\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_c.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"CLIPTextEncode\",\"_meta\":{\"title\":\"CLIP Text Encode (Prompt)\"}}},\"class_type\":\"ConditioningZeroOut\",\"_meta\":{\"title\":\"ConditioningZeroOut\"}},\"latent_image\":{\"inputs\":{\"width\":1024,\"height\":1536,\"compression\":48,\"batch_size\":1},\"class_type\":\"StableCascade_EmptyLatentImage\",\"_meta\":{\"title\":\"StableCascade_EmptyLatentImage\"}}},\"class_type\":\"KSampler\",\"_meta\":{\"title\":\"KSampler\"}},\"vae\":{\"inputs\":{\"ckpt_name\":\"stable_cascade_stage_b.safetensors\"},\"class_type\":\"CheckpointLoaderSimple\",\"_meta\":{\"title\":\"Load Checkpoint\"}}},\"class_type\":\"VAEDecodeTiled\",\"_meta\":{\"title\":\"VAE Decode (Tiled)\"}}},\"class_type\":\"ImageSharpen\",\"_meta\":{\"title\":\"ImageSharpen\"}}},\"class_type\":\"ImageUpscaleWithModel\",\"_meta\":{\"title\":\"Upscale Image (using Model)\"}}},\"class_type\":\"ImageScaleBy\",\"_meta\":{\"title\":\"Upscale Image By\"}}},\"class_type\":\"PreviewImage\",\"_meta\":{\"title\":\"Preview Image\"}}},\"workflow\":{\"last_node_id\":325,\"last_link_id\":422,\"nodes\":[{\"id\":43,\"type\":\"Note\",\"pos\":[871.7588550488282,128.10510126953125],\"size\":{\"0\":287.48663330078125,\"1\":173.3572998046875},\"flags\":{},\"order\":0,\"mode\":0,\"properties\":{\"text\":\"\"},\"widgets_values\":[\"This is stage c, the model generates a low resolution latent, the default compression of 42 means that the width and height of the stage c latent are 1024 divided by 42.\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":134,\"type\":\"StableCascade_StageB_Conditioning\",\"pos\":[1431.7588550488288,-201.89489873046875],\"size\":{\"0\":277.20001220703125,\"1\":46},\"flags\":{},\"order\":31,\"mode\":0,\"inputs\":[{\"name\":\"conditioning\",\"type\":\"CONDITIONING\",\"link\":213},{\"name\":\"stage_c\",\"type\":\"LATENT\",\"link\":214}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[210],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"StableCascade_StageB_Conditioning\"}},{\"id\":144,\"type\":\"Note\",\"pos\":[-305.8751459511719,24.091196269531284],\"size\":{\"0\":210,\"1\":58},\"flags\":{},\"order\":1,\"mode\":2,\"properties\":{\"text\":\"\"},\"widgets_values\":[\"default: \\n1840x3072\"],\"color\":\"#222\",\"bgcolor\":\"#000\"},{\"id\":145,\"type\":\"Note\",\"pos\":[-416.8751459511719,128.09119626953122],\"size\":{\"0\":321.3078918457031,\"1\":260.244873046875},\"flags\":{},\"order\":2,\"mode\":2,\"properties\":{\"text\":\"\"},\"widgets_values\":[\"1:2 Aspect Ratio (and its inverse 2:1)\\n1:2: 1024x512 (close to the center point, portrait)\\n2:1: 2048x1024 (maximized width, landscape)\\n\\n\\n2:3 Aspect Ratio (and its inverse 3:2)\\n2:3: 1360x2048 (maximized height, portrait)\\n3:2: 2048x1360 (maximized width, landscape)\\n\\n\\n3:4 Aspect Ratio (and its inverse 4:3)\\n3:4: 1536x2048 (maximized height, portrait)\\n4:3: 2048x1536 (maximized width, landscape)\\n\\n\\n16:9 Aspect Ratio\\n16:9: 2048x1152 (maximized width, landscape)\\n9:16: 1152x2048 (maximized height, portrait)\"],\"color\":\"#222\",\"bgcolor\":\"#000\"},{\"id\":146,\"type\":\"Note\",\"pos\":[-60.875145951172,124.09119626953121],\"size\":{\"0\":296.00335693359375,\"1\":256.8496398925781},\"flags\":{},\"order\":3,\"mode\":2,\"properties\":{\"text\":\"\"},\"widgets_values\":[\"1:2 Aspect Ratio (and its inverse 2:1)\\n1:2: 3072x1536 (landscape)\\n2:1: 1536x3072 (portrait)\\n\\n\\n2:3 Aspect Ratio (and its inverse 3:2)\\n2:3: 2048x3072 (portrait)\\n3:2: 3072x2048 (landscape)\\n\\n\\n3:4 Aspect Ratio (and its inverse 4:3)\\n3:4: 2304x3072 (portrait)\\n4:3: 3072x2304 (landscape)\\n\\n\\n16:9 Aspect Ratio (and its inverse 9:16)\\n16:9: 3072x1728 (landscape)\\n9:16: 1728x3072 (portrait)\"],\"color\":\"#222\",\"bgcolor\":\"#000\"},{\"id\":158,\"type\":\"Note\",\"pos\":[-62.875145951171994,-464.90880373046895],\"size\":{\"0\":306.5346984863281,\"1\":135.54510498046875},\"flags\":{},\"order\":4,\"mode\":0,\"title\":\"Project Name\",\"properties\":{\"text\":\"\"},\"widgets_values\":[\"Argus-v30-txt2img (Checkpoint Version)\\n- Stable Cascade\\n- hires fix\\n\\n\\narticle: https://civitai.com/articles/4109/\\nwww.fivebelowfive.uk\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":142,\"type\":\"Note\",\"pos\":[1361.7588550488288,-451.89489873046875],\"size\":{\"0\":306.5346984863281,\"1\":135.54510498046875},\"flags\":{},\"order\":5,\"mode\":0,\"title\":\"Project Name\",\"properties\":{\"text\":\"\"},\"widgets_values\":[\"Argus-v30-img2img (Checkpoint Version)\\n- img2img mode (B & C)\\n- Stable Cascade\\n- models guide\\n- hires fix\\n- shift support\\n\\narticle: https://civitai.com/articles/4109/\\nwww.fivebelowfive.uk\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":291,\"type\":\"PrimitiveNode\",\"pos\":[2161,-383],\"size\":{\"0\":563.6315307617188,\"1\":148.01963806152344},\"flags\":{},\"order\":6,\"mode\":0,\"outputs\":[{\"name\":\"STRING\",\"type\":\"STRING\",\"links\":[359,362],\"slot_index\":0,\"widget\":{\"name\":\"text\"}}],\"properties\":{\"Run widget replace on values\":false},\"widgets_values\":[\"cartoon, fake, sketch\"],\"color\":\"#322\",\"bgcolor\":\"#533\"},{\"id\":312,\"type\":\"VAEEncode\",\"pos\":[905.6432168261715,645.5578496289063],\"size\":{\"0\":210,\"1\":46},\"flags\":{},\"order\":40,\"mode\":0,\"inputs\":[{\"name\":\"pixels\",\"type\":\"IMAGE\",\"link\":397},{\"name\":\"vae\",\"type\":\"VAE\",\"link\":386}],\"outputs\":[{\"name\":\"LATENT\",\"type\":\"LATENT\",\"links\":[387],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"VAEEncode\"}},{\"id\":278,\"type\":\"CLIPTextEncode\",\"pos\":[-86.35678317382823,784.5578496289063],\"size\":{\"0\":566.0027465820312,\"1\":106.8553237915039},\"flags\":{\"collapsed\":true},\"order\":24,\"mode\":0,\"inputs\":[{\"name\":\"clip\",\"type\":\"CLIP\",\"link\":401,\"slot_index\":0},{\"name\":\"text\",\"type\":\"STRING\",\"link\":362,\"widget\":{\"name\":\"text\"}}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[390],\"shape\":3,\"slot_index\":0}],\"title\":\"CLIP Text Encode (Prompt) -\",\"properties\":{\"Node name for S&R\":\"CLIPTextEncode\"},\"widgets_values\":[\"cartoon, fake, sketch\"],\"color\":\"#332922\",\"bgcolor\":\"#593930\"},{\"id\":277,\"type\":\"CLIPTextEncode\",\"pos\":[-329.35678317382843,785.5578496289063],\"size\":{\"0\":571.0027465820312,\"1\":101.12482452392578},\"flags\":{\"collapsed\":true},\"order\":26,\"mode\":0,\"inputs\":[{\"name\":\"clip\",\"type\":\"CLIP\",\"link\":404,\"slot_index\":0},{\"name\":\"text\",\"type\":\"STRING\",\"link\":358,\"widget\":{\"name\":\"text\"}}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[389],\"shape\":3,\"slot_index\":0}],\"title\":\"CLIP Text Encode (Prompt) +\",\"properties\":{\"Node name for S&R\":\"CLIPTextEncode\"},\"widgets_values\":[\"hollow that looks like a creature sleeping\"],\"color\":\"#332922\",\"bgcolor\":\"#593930\"},{\"id\":319,\"type\":\"Reroute\",\"pos\":[274.75885504882837,-379.89489873046875],\"size\":[75,26],\"flags\":{},\"order\":22,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":407}],\"outputs\":[{\"name\":\"\",\"type\":\"MODEL\",\"links\":[406],\"slot_index\":0}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":149,\"type\":\"ModelSamplingStableCascade\",\"pos\":[371.75885504882837,-380.89489873046875],\"size\":{\"0\":315,\"1\":58},\"flags\":{},\"order\":27,\"mode\":0,\"inputs\":[{\"name\":\"model\",\"type\":\"MODEL\",\"link\":406}],\"outputs\":[{\"name\":\"MODEL\",\"type\":\"MODEL\",\"links\":[409],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"ModelSamplingStableCascade\"},\"widgets_values\":[2]},{\"id\":320,\"type\":\"Reroute\",\"pos\":[719.7588550488282,-306.89489873046875],\"size\":[75,26],\"flags\":{},\"order\":29,\"mode\":0,\"inputs\":[{\"name\":\"\",\"type\":\"*\",\"link\":409}],\"outputs\":[{\"name\":\"\",\"type\":\"MODEL\",\"links\":[408],\"slot_index\":0}],\"properties\":{\"showOutputText\":false,\"horizontal\":false}},{\"id\":143,\"type\":\"Note\",\"pos\":[463.75885504882837,-428.89489873046875],\"size\":[235.1999969482422,58],\"flags\":{\"collapsed\":true},\"order\":7,\"mode\":2,\"title\":\"Combo Calculator (estimated)\",\"properties\":{\"text\":\"\"},\"widgets_values\":[\"shift:\\ndefault 2.00\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":126,\"type\":\"CLIPTextEncode\",\"pos\":[326.75885504882837,-236.89489873046875],\"size\":[249.79629638671884,54],\"flags\":{\"collapsed\":false},\"order\":25,\"mode\":0,\"inputs\":[{\"name\":\"clip\",\"type\":\"CLIP\",\"link\":355},{\"name\":\"text\",\"type\":\"STRING\",\"link\":357,\"widget\":{\"name\":\"text\"}}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[201,215],\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"CLIPTextEncode\"},\"widgets_values\":[\"hollow that looks like a creature sleeping\"],\"color\":\"#232\",\"bgcolor\":\"#353\"},{\"id\":127,\"type\":\"CLIPTextEncode\",\"pos\":[328.75885504882837,-125.89489873046875],\"size\":[250.2162963867188,54],\"flags\":{\"collapsed\":false},\"order\":23,\"mode\":0,\"inputs\":[{\"name\":\"clip\",\"type\":\"CLIP\",\"link\":227},{\"name\":\"text\",\"type\":\"STRING\",\"link\":359,\"widget\":{\"name\":\"text\"}}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[202],\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"CLIPTextEncode\"},\"widgets_values\":[\"cartoon, fake, sketch\"],\"color\":\"#322\",\"bgcolor\":\"#533\"},{\"id\":313,\"type\":\"VAEDecodeTiled\",\"pos\":[2906,-161],\"size\":[736.0195302734378,78],\"flags\":{\"collapsed\":false},\"order\":43,\"mode\":0,\"inputs\":[{\"name\":\"samples\",\"type\":\"LATENT\",\"link\":391},{\"name\":\"vae\",\"type\":\"VAE\",\"link\":392}],\"outputs\":[{\"name\":\"IMAGE\",\"type\":\"IMAGE\",\"links\":[399],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"VAEDecodeTiled\"},\"widgets_values\":[512]},{\"id\":293,\"type\":\"PrimitiveNode\",\"pos\":[2397,-507],\"size\":{\"0\":210,\"1\":82},\"flags\":{},\"order\":8,\"mode\":0,\"outputs\":[{\"name\":\"INT\",\"type\":\"INT\",\"links\":[361],\"slot_index\":0,\"widget\":{\"name\":\"width\"}}],\"properties\":{\"Run widget replace on values\":false},\"widgets_values\":[1024,\"fixed\"],\"color\":\"#223\",\"bgcolor\":\"#335\"},{\"id\":292,\"type\":\"PrimitiveNode\",\"pos\":[2636,-504],\"size\":{\"0\":210,\"1\":82},\"flags\":{},\"order\":9,\"mode\":0,\"outputs\":[{\"name\":\"INT\",\"type\":\"INT\",\"links\":[360],\"slot_index\":0,\"widget\":{\"name\":\"height\"}}],\"properties\":{\"Run widget replace on values\":false},\"widgets_values\":[1536,\"fixed\"],\"color\":\"#223\",\"bgcolor\":\"#335\"},{\"id\":137,\"type\":\"Note\",\"pos\":[-386.8751459511719,-87.90880373046876],\"size\":{\"0\":295.33441162109375,\"1\":70.86398315429688},\"flags\":{},\"order\":10,\"mode\":2,\"properties\":{\"text\":\"\"},\"widgets_values\":[\"48 - Increasing the compression to 64 allows for higher resolution.\\nthanks to https://openart.ai/workflows/@data_lt\"],\"color\":\"#222\",\"bgcolor\":\"#000\"},{\"id\":300,\"type\":\"PrimitiveNode\",\"pos\":[2161,-507],\"size\":{\"0\":210,\"1\":82},\"flags\":{},\"order\":11,\"mode\":0,\"outputs\":[{\"name\":\"INT\",\"type\":\"INT\",\"links\":[375,376,410],\"slot_index\":0,\"widget\":{\"name\":\"seed\"}}],\"properties\":{\"Run widget replace on values\":false},\"widgets_values\":[295199585472974,\"randomize\"]},{\"id\":288,\"type\":\"SaveImage\",\"pos\":[2901,-124],\"size\":{\"0\":752.398193359375,\"1\":1102.1134033203125},\"flags\":{},\"order\":44,\"mode\":0,\"inputs\":[{\"name\":\"images\",\"type\":\"IMAGE\",\"link\":399}],\"properties\":{},\"widgets_values\":[\"cascade-txt2img-rmsdxl/cascade-rmsdxl\"]},{\"id\":41,\"type\":\"CheckpointLoaderSimple\",\"pos\":[-76.8751459511721,-248.90880373046878],\"size\":{\"0\":336,\"1\":98},\"flags\":{},\"order\":12,\"mode\":0,\"outputs\":[{\"name\":\"MODEL\",\"type\":\"MODEL\",\"links\":[407],\"shape\":3,\"slot_index\":0},{\"name\":\"CLIP\",\"type\":\"CLIP\",\"links\":[227,355],\"shape\":3,\"slot_index\":1},{\"name\":\"VAE\",\"type\":\"VAE\",\"links\":[413],\"shape\":3,\"slot_index\":2}],\"properties\":{\"Node name for S&R\":\"CheckpointLoaderSimple\"},\"widgets_values\":[\"stable_cascade_stage_c.safetensors\"]},{\"id\":152,\"type\":\"Note\",\"pos\":[311,-1],\"size\":{\"0\":450.99127197265625,\"1\":86.7520523071289},\"flags\":{},\"order\":13,\"mode\":2,\"title\":\"Simple Prompt\",\"properties\":{\"text\":\"\"},\"widgets_values\":[\"Raw photo of police car, surrounded by junk and sewage, rain falling down on the dystopian cyberpunk residents, the motel that fills the negative space between reality and nightclubs, bright lights, bokeh, laser holograms, sunrise lighting\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":151,\"type\":\"Note\",\"pos\":[309,128],\"size\":{\"0\":454.47772216796875,\"1\":134.13369750976562},\"flags\":{},\"order\":14,\"mode\":2,\"title\":\"Prompt Randomiser\",\"properties\":{\"text\":\"\"},\"widgets_values\":[\"Raw photo of a man, futuristic post dystopian technocratic sprawl, a {highway|street|traintrack|runway|police car}, surrounded by junk and sewage, {rain|snow|sludge|soot|acid} falling down on the dystopian cyberpunk {woman|man|person|robot|residents}, the {house|slum|ghetto|apartments|motel} that {expands|fills|explodes|enriched} the negative space between {reality|skyscrapers|security|fast food|temples|server cave} and {shanty towns|casinos|nightclubs|bars}, bright lights, bokeh, laser holograms, {night time|mid day|sunrise|sunset} lighting\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":321,\"type\":\"VAEDecode\",\"pos\":[307,307],\"size\":{\"0\":210,\"1\":46},\"flags\":{},\"order\":32,\"mode\":0,\"inputs\":[{\"name\":\"samples\",\"type\":\"LATENT\",\"link\":412},{\"name\":\"vae\",\"type\":\"VAE\",\"link\":413}],\"outputs\":[{\"name\":\"IMAGE\",\"type\":\"IMAGE\",\"links\":[411],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"VAEDecode\"}},{\"id\":136,\"type\":\"ConditioningZeroOut\",\"pos\":[1205,-112],\"size\":{\"0\":211.60000610351562,\"1\":26},\"flags\":{},\"order\":28,\"mode\":0,\"inputs\":[{\"name\":\"conditioning\",\"type\":\"CONDITIONING\",\"link\":215}],\"outputs\":[{\"name\":\"CONDITIONING\",\"type\":\"CONDITIONING\",\"links\":[211,213],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"ConditioningZeroOut\"}},{\"id\":159,\"type\":\"CheckpointLoaderSimple\",\"pos\":[1351.7588550488288,-41.894898730468746],\"size\":{\"0\":349.90911865234375,\"1\":98},\"flags\":{},\"order\":15,\"mode\":0,\"outputs\":[{\"name\":\"MODEL\",\"type\":\"MODEL\",\"links\":[415],\"shape\":3,\"slot_index\":0},{\"name\":\"CLIP\",\"type\":\"CLIP\",\"links\":null,\"shape\":3},{\"name\":\"VAE\",\"type\":\"VAE\",\"links\":[373],\"shape\":3,\"slot_index\":2}],\"properties\":{\"Node name for S&R\":\"CheckpointLoaderSimple\"},\"widgets_values\":[\"stable_cascade_stage_b.safetensors\"]},{\"id\":125,\"type\":\"KSampler\",\"pos\":[851.7588550488282,-181.89489873046875],\"size\":{\"0\":315,\"1\":262},\"flags\":{},\"order\":30,\"mode\":0,\"inputs\":[{\"name\":\"model\",\"type\":\"MODEL\",\"link\":408,\"slot_index\":0},{\"name\":\"positive\",\"type\":\"CONDITIONING\",\"link\":201},{\"name\":\"negative\",\"type\":\"CONDITIONING\",\"link\":202},{\"name\":\"latent_image\",\"type\":\"LATENT\",\"link\":231},{\"name\":\"seed\",\"type\":\"INT\",\"link\":376,\"widget\":{\"name\":\"seed\"}}],\"outputs\":[{\"name\":\"LATENT\",\"type\":\"LATENT\",\"links\":[214,412],\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"KSampler\"},\"widgets_values\":[295199585472974,\"randomize\",20,4,\"euler_ancestral\",\"simple\",1]},{\"id\":44,\"type\":\"Note\",\"pos\":[1202,114],\"size\":{\"0\":272.0986633300781,\"1\":138.81549072265625},\"flags\":{},\"order\":16,\"mode\":0,\"properties\":{\"text\":\"\"},\"widgets_values\":[\"This is stage b where the low resolution stage c latent is passed to the stage b model as conditioning. Stage b takes the low resolution latent and upscales it to a higher resolution one. \\n\\n\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":46,\"type\":\"Note\",\"pos\":[1497,126],\"size\":{\"0\":210,\"1\":73.69999694824219},\"flags\":{},\"order\":17,\"mode\":0,\"properties\":{\"text\":\"\"},\"widgets_values\":[\"Stage a is what the VAE is called. It decodes the stage b latent into pixel space.\"],\"color\":\"#432\",\"bgcolor\":\"#653\"},{\"id\":34,\"type\":\"StableCascade_EmptyLatentImage\",\"pos\":[-60.875145951172,-81.90880373046876],\"size\":{\"0\":315,\"1\":150},\"flags\":{},\"order\":21,\"mode\":0,\"inputs\":[{\"name\":\"height\",\"type\":\"INT\",\"link\":360,\"widget\":{\"name\":\"height\"}},{\"name\":\"width\",\"type\":\"INT\",\"link\":361,\"widget\":{\"name\":\"width\"}}],\"outputs\":[{\"name\":\"stage_c\",\"type\":\"LATENT\",\"links\":[231],\"shape\":3,\"slot_index\":0},{\"name\":\"stage_b\",\"type\":\"LATENT\",\"links\":[232],\"shape\":3,\"slot_index\":1}],\"properties\":{\"Node name for S&R\":\"StableCascade_EmptyLatentImage\"},\"widgets_values\":[1024,1536,48,1]},{\"id\":306,\"type\":\"UpscaleModelLoader\",\"pos\":[144,787],\"size\":{\"0\":315,\"1\":58},\"flags\":{},\"order\":18,\"mode\":0,\"outputs\":[{\"name\":\"UPSCALE_MODEL\",\"type\":\"UPSCALE_MODEL\",\"links\":[383],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"UpscaleModelLoader\"},\"widgets_values\":[\"4x_NMKD-Siax_200k.pth\"]},{\"id\":315,\"type\":\"ImageScaleBy\",\"pos\":[595,757],\"size\":{\"0\":315,\"1\":82},\"flags\":{},\"order\":39,\"mode\":0,\"inputs\":[{\"name\":\"image\",\"type\":\"IMAGE\",\"link\":421}],\"outputs\":[{\"name\":\"IMAGE\",\"type\":\"IMAGE\",\"links\":[397,417],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"ImageScaleBy\"},\"widgets_values\":[\"bilinear\",0.35000000000000003]},{\"id\":276,\"type\":\"CheckpointLoaderSimple\",\"pos\":[-354.35678317382843,634.5578496289063],\"size\":{\"0\":415.959228515625,\"1\":98},\"flags\":{},\"order\":19,\"mode\":0,\"outputs\":[{\"name\":\"MODEL\",\"type\":\"MODEL\",\"links\":[388],\"shape\":3,\"slot_index\":0},{\"name\":\"CLIP\",\"type\":\"CLIP\",\"links\":[401,404],\"shape\":3,\"slot_index\":1},{\"name\":\"VAE\",\"type\":\"VAE\",\"links\":[386,392],\"shape\":3,\"slot_index\":2}],\"properties\":{\"Node name for S&R\":\"CheckpointLoaderSimple\"},\"widgets_values\":[\"RMSDXLLightning.safetensors\"],\"color\":\"#322\",\"bgcolor\":\"#533\"},{\"id\":324,\"type\":\"PreviewImage\",\"pos\":[1192,606],\"size\":[513.7220059570316,354.15267233886743],\"flags\":{},\"order\":41,\"mode\":0,\"inputs\":[{\"name\":\"images\",\"type\":\"IMAGE\",\"link\":417}],\"properties\":{\"Node name for S&R\":\"PreviewImage\"}},{\"id\":294,\"type\":\"ImageSharpen\",\"pos\":[142,618],\"size\":{\"0\":315,\"1\":106},\"flags\":{},\"order\":37,\"mode\":0,\"inputs\":[{\"name\":\"image\",\"type\":\"IMAGE\",\"link\":422}],\"outputs\":[{\"name\":\"IMAGE\",\"type\":\"IMAGE\",\"links\":[416],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"ImageSharpen\"},\"widgets_values\":[1,0.4,0.30000000000000004]},{\"id\":305,\"type\":\"ImageUpscaleWithModel\",\"pos\":[536,613],\"size\":{\"0\":241.79998779296875,\"1\":46},\"flags\":{},\"order\":38,\"mode\":0,\"inputs\":[{\"name\":\"upscale_model\",\"type\":\"UPSCALE_MODEL\",\"link\":383},{\"name\":\"image\",\"type\":\"IMAGE\",\"link\":416}],\"outputs\":[{\"name\":\"IMAGE\",\"type\":\"IMAGE\",\"links\":[421],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"ImageUpscaleWithModel\"}},{\"id\":299,\"type\":\"VAEDecodeTiled\",\"pos\":[2127,-159],\"size\":[755.0465302734374,78],\"flags\":{\"collapsed\":false},\"order\":35,\"mode\":0,\"inputs\":[{\"name\":\"samples\",\"type\":\"LATENT\",\"link\":374},{\"name\":\"vae\",\"type\":\"VAE\",\"link\":373}],\"outputs\":[{\"name\":\"IMAGE\",\"type\":\"IMAGE\",\"links\":[371,422],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"VAEDecodeTiled\"},\"widgets_values\":[512]},{\"id\":129,\"type\":\"SaveImage\",\"pos\":[2121,-121],\"size\":{\"0\":767.7642211914062,\"1\":1103.2705078125},\"flags\":{},\"order\":36,\"mode\":0,\"inputs\":[{\"name\":\"images\",\"type\":\"IMAGE\",\"link\":371}],\"properties\":{},\"widgets_values\":[\"cascade-txt2img/cascade\"]},{\"id\":133,\"type\":\"KSampler\",\"pos\":[1756,-211],\"size\":{\"0\":315,\"1\":262},\"flags\":{},\"order\":33,\"mode\":0,\"inputs\":[{\"name\":\"model\",\"type\":\"MODEL\",\"link\":415,\"slot_index\":0},{\"name\":\"positive\",\"type\":\"CONDITIONING\",\"link\":210},{\"name\":\"negative\",\"type\":\"CONDITIONING\",\"link\":211},{\"name\":\"latent_image\",\"type\":\"LATENT\",\"link\":232},{\"name\":\"seed\",\"type\":\"INT\",\"link\":375,\"widget\":{\"name\":\"seed\"}}],\"outputs\":[{\"name\":\"LATENT\",\"type\":\"LATENT\",\"links\":[374],\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"KSampler\"},\"widgets_values\":[295199585472974,\"randomize\",15,1.1,\"ddpm\",\"karras\",1]},{\"id\":322,\"type\":\"PreviewImage\",\"pos\":[1753,101],\"size\":[319.38410742187534,352.3939155273439],\"flags\":{\"collapsed\":false},\"order\":34,\"mode\":0,\"inputs\":[{\"name\":\"images\",\"type\":\"IMAGE\",\"link\":411}],\"properties\":{\"Node name for S&R\":\"PreviewImage\"}},{\"id\":309,\"type\":\"KSampler\",\"pos\":[1760,612],\"size\":[315,262],\"flags\":{},\"order\":42,\"mode\":0,\"inputs\":[{\"name\":\"model\",\"type\":\"MODEL\",\"link\":388,\"slot_index\":0},{\"name\":\"positive\",\"type\":\"CONDITIONING\",\"link\":389,\"slot_index\":1},{\"name\":\"negative\",\"type\":\"CONDITIONING\",\"link\":390,\"slot_index\":2},{\"name\":\"latent_image\",\"type\":\"LATENT\",\"link\":387},{\"name\":\"seed\",\"type\":\"INT\",\"link\":410,\"widget\":{\"name\":\"seed\"}}],\"outputs\":[{\"name\":\"LATENT\",\"type\":\"LATENT\",\"links\":[391],\"shape\":3,\"slot_index\":0}],\"properties\":{\"Node name for S&R\":\"KSampler\"},\"widgets_values\":[295199585472974,\"randomize\",14,2,\"dpmpp_2m\",\"sgm_uniform\",0.35000000000000003],\"color\":\"#223\",\"bgcolor\":\"#335\"},{\"id\":289,\"type\":\"PrimitiveNode\",\"pos\":[2890,-376],\"size\":{\"0\":778.2001953125,\"1\":130.65216064453125},\"flags\":{\"collapsed\":false},\"order\":20,\"mode\":0,\"outputs\":[{\"name\":\"STRING\",\"type\":\"STRING\",\"links\":[357,358],\"slot_index\":0,\"widget\":{\"name\":\"text\"}}],\"properties\":{\"Run widget replace on values\":\"on\"},\"widgets_values\":[\"hollow that looks like a creature sleeping\"],\"color\":\"#232\",\"bgcolor\":\"#353\"}],\"links\":[[201,126,0,125,1,\"CONDITIONING\"],[202,127,0,125,2,\"CONDITIONING\"],[210,134,0,133,1,\"CONDITIONING\"],[211,136,0,133,2,\"CONDITIONING\"],[213,136,0,134,0,\"CONDITIONING\"],[214,125,0,134,1,\"LATENT\"],[215,126,0,136,0,\"CONDITIONING\"],[227,41,1,127,0,\"CLIP\"],[231,34,0,125,3,\"LATENT\"],[232,34,1,133,3,\"LATENT\"],[355,41,1,126,0,\"CLIP\"],[357,289,0,126,1,\"STRING\"],[358,289,0,277,1,\"STRING\"],[359,291,0,127,1,\"STRING\"],[360,292,0,34,0,\"INT\"],[361,293,0,34,1,\"INT\"],[362,291,0,278,1,\"STRING\"],[371,299,0,129,0,\"IMAGE\"],[373,159,2,299,1,\"VAE\"],[374,133,0,299,0,\"LATENT\"],[375,300,0,133,4,\"INT\"],[376,300,0,125,4,\"INT\"],[383,306,0,305,0,\"UPSCALE_MODEL\"],[386,276,2,312,1,\"VAE\"],[387,312,0,309,3,\"LATENT\"],[388,276,0,309,0,\"MODEL\"],[389,277,0,309,1,\"CONDITIONING\"],[390,278,0,309,2,\"CONDITIONING\"],[391,309,0,313,0,\"LATENT\"],[392,276,2,313,1,\"VAE\"],[397,315,0,312,0,\"IMAGE\"],[399,313,0,288,0,\"IMAGE\"],[401,276,1,278,0,\"CLIP\"],[404,276,1,277,0,\"CLIP\"],[406,319,0,149,0,\"MODEL\"],[407,41,0,319,0,\"*\"],[408,320,0,125,0,\"MODEL\"],[409,149,0,320,0,\"*\"],[410,300,0,309,4,\"INT\"],[411,321,0,322,0,\"IMAGE\"],[412,125,0,321,0,\"LATENT\"],[413,41,2,321,1,\"VAE\"],[415,159,0,133,0,\"MODEL\"],[416,294,0,305,1,\"IMAGE\"],[417,315,0,324,0,\"IMAGE\"],[421,305,0,315,0,\"IMAGE\"],[422,299,0,294,0,\"IMAGE\"]],\"groups\":[{\"title\":\"Group\",\"bounding\":[-440,-579,2530,1051],\"color\":\"#3f789e\",\"font_size\":24},{\"title\":\"Group\",\"bounding\":[-420,531,2512,448],\"color\":\"#3f789e\",\"font_size\":24},{\"title\":\"Group\",\"bounding\":[2114,-581,1569,355],\"color\":\"#3f789e\",\"font_size\":24}],\"config\":{},\"extra\":{},\"version\":0.4}}",
            "steps": 20,
            "width": 1024,
            "height": 1536,
            "models": [
                "stable_cascade_stage_c.safetensors",
                "stable_cascade_stage_b.safetensors",
                "RMSDXLLightning.safetensors"
            ],
            "prompt": "hollow that looks like a creature sleeping",
            "denoise": 1,
            "sampler": "Euler a",
            "cfgScale": 4,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [
                "4x_NMKD-Siax_200k.pth"
            ],
            "versionIds": [],
            "controlNets": [],
            "negativePrompt": "cartoon, fake, sketch",
            "additionalResources": []
        },
        "username": "rMada",
        "baseModel": ""
    },
    {
        "id": 7753175,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a3fb1159-acb2-415c-a6b0-3e4f6b2a2b38/width=1712/a3fb1159-acb2-415c-a6b0-3e4f6b2a2b38.jpeg",
        "hash": "U9AdGoE30f~U?aMxIV-:M_a0jFTJJ8sp$jNb",
        "width": 1712,
        "height": 2384,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-03-10T22:12:52.699Z",
        "postId": 1679922,
        "stats": {
            "cryCount": 1,
            "laughCount": 19,
            "likeCount": 172,
            "dislikeCount": 0,
            "heartCount": 93,
            "commentCount": 0
        },
        "meta": {
            "Size": "856x1192",
            "seed": 370840736,
            "Model": "turboDiffusionXLv1.32",
            "steps": 7,
            "hashes": {
                "model": "45ed730beb",
                "lora:SDXLFaeTastic2400": "1cf798aca8",
                "lora:- SDXL - shrubbery_n_green-stuff_V1.0": "d6e5f0b1c3"
            },
            "prompt": "kawaii style monster hunter mizutsune, in a jungle at night, fog, cloudy sky, detailed eyes,  <lora:SDXLFaeTastic2400:0.5> ,   <lora:- SDXL - shrubbery_n_green-stuff_V1.0:0.8>, shrubbery, . cute, adorable, brightly colored, cheerful, anime influence, highly detailed",
            "\"model\"": "\"45ed730beb\"}",
            "Version": "v1.8.0",
            "sampler": "DPM++ SDE Karras",
            "cfgScale": 1,
            "clipSkip": 2,
            "resources": [
                {
                    "name": "SDXLFaeTastic2400",
                    "type": "lora",
                    "weight": 0.5
                },
                {
                    "hash": "45ed730beb",
                    "name": "turboDiffusionXLv1.32",
                    "type": "model"
                }
            ],
            "Model hash": "45ed730beb",
            "negativePrompt": "dark, scary, realistic, monochrome, abstract, wings open,, long neck, asymmetrical eyes, signature, watermark, jpeg artifacts, ,",
            "\"SDXLFaeTastic2400": "e7da1e0c0933",
            "SDXLFaeTastic2400\"": "\"1cf798aca8\"",
            "- SDXL - shrubbery_n_green-stuff_V1.0": "2d6797c84d65\"",
            "- SDXL - shrubbery_n_green-stuff_V1.0\"": "\"d6e5f0b1c3\""
        },
        "username": "moxie1776",
        "baseModel": "SDXL Lightning"
    },
    {
        "id": 7112951,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/90acf480-188a-4429-9886-88b8a14a4114/width=512/90acf480-188a-4429-9886-88b8a14a4114.jpeg",
        "hash": "UEFhI,~B9v^PI]9^Eg9]00IAi_Io0#-U=vbc",
        "width": 512,
        "height": 768,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-25T20:53:04.815Z",
        "postId": 1535122,
        "stats": {
            "cryCount": 0,
            "laughCount": 48,
            "likeCount": 124,
            "dislikeCount": 0,
            "heartCount": 113,
            "commentCount": 0
        },
        "meta": {
            "Size": "512x768",
            "seed": 2610762283,
            "\"lisa": "24ce20ec979d\"",
            "Model": "furryVixens_v20",
            "steps": 25,
            "hashes": {
                "model": "fec0e39345"
            },
            "prompt": "(solo female) furry vixen, chibi, female focus (<lora:lisa:0.6>), Pappy, (long eyelashes:1.1), eyes makeup, piercing, realism, (black collar), (white t-shirt, (print \"fox\":1.2)) holding guitar, (night, stars), detailed background",
            "Version": "1.6.1",
            "sampler": "Euler a",
            "cfgScale": 9,
            "resources": [
                {
                    "name": "lisa",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "hash": "fec0e39345",
                    "name": "furryVixens_v20",
                    "type": "model"
                }
            ],
            "Model hash": "fec0e39345",
            "negativePrompt": "(low quality:1.4), (easynegative:0.8), bang, leans on the wall, three_ears, white background, (white frame:1.2), watermark, (long hair), simple background, fat, long neck, fat face, artifacts, (outline:1.3), amputated, wrong_proportions, black gloves,"
        },
        "username": "RioDeja",
        "baseModel": "Other"
    },
    {
        "id": 6981808,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a2f57676-8515-44a6-a339-ede2c6b4915e/width=1536/a2f57676-8515-44a6-a339-ede2c6b4915e.jpeg",
        "hash": "U8E1]X1a01=d_2Fy9a;zwZ~BXmR69]$l-:RP",
        "width": 1536,
        "height": 2048,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-22T21:32:56.531Z",
        "postId": 1506846,
        "stats": {
            "cryCount": 0,
            "laughCount": 9,
            "likeCount": 176,
            "dislikeCount": 0,
            "heartCount": 100,
            "commentCount": 8
        },
        "meta": {
            "seed": 1017805938064176,
            "steps": 30,
            "prompt": "masterpiece, intricate detail, 8K, HDR, \n\nThe beautiful and ornate hand. Five fingers.\n\n<lora:Perfect Hands v2:1.2>",
            "sampler": "DPM++ 3M SDE Exponential",
            "cfgScale": 6,
            "negativePrompt": "(worst quality, low resolution, bad hands), distorted, twisted, watermark, six fingers, disfigured, bad anatomy"
        },
        "username": null,
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 5608795,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ea842196-fdc6-4f77-a2a2-3c1af3f46161/width=832/ea842196-fdc6-4f77-a2a2-3c1af3f46161.jpeg",
        "hash": "UHGS4G00tlMb00~W9FtR9FRjD%?b%1Iqnhae",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-01-18T00:35:23.949Z",
        "postId": 1221445,
        "stats": {
            "cryCount": 5,
            "laughCount": 18,
            "likeCount": 174,
            "dislikeCount": 0,
            "heartCount": 88,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 104572453,
            "steps": 50,
            "prompt": "(silhouette:2), highly detailed linework reminiscent of Carne Griffiths, imbued with Wadim Kashim's bold texture, light and airy as Carl Larsson's compositions, gandalf the grey, motion, featuring Pascal Blanche-style hyper-realistic characters, pastel, elegance, dramatic lighting, expressive camera angle, matte, concept art, linquivera",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 6.5,
            "clipSkip": 2,
            "resources": [],
            "negativePrompt": "3d rendering, 3d animation, cgi illustration, oversaturated, old, ugly, unrealistic",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 238308
                },
                {
                    "type": "lora",
                    "weight": 2,
                    "modelVersionId": 135867
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 281935
                }
            ]
        },
        "username": "gaindalf8693",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 4692956,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/70320940-8ab6-4791-b7b5-f10234e6d522/width=920/70320940-8ab6-4791-b7b5-f10234e6d522.jpeg",
        "hash": "UHF5y{Q,M|D%.9D%t6ay~WMxn$xtJCoIxZoI",
        "width": 920,
        "height": 1224,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2023-12-18T19:44:27.681Z",
        "postId": 1022512,
        "stats": {
            "cryCount": 5,
            "laughCount": 44,
            "likeCount": 152,
            "dislikeCount": 0,
            "heartCount": 84,
            "commentCount": 0
        },
        "meta": {
            "VAE": "sdxl_vae.safetensors",
            "ENSD": "31337",
            "Size": "768x1024",
            "seed": 3607541875,
            "Model": "SDXL SleipnirT_v125BF16",
            "steps": 46,
            "hashes": {
                "model": "c005f06a68"
            },
            "prompt": "picture of cat with monocle and beard gloves hat reading newspaper title \"VILLAIN NEWS\" in open cafe cup of milk on table\n<lora:SDXL DET more_art-full_v1:0.3>, masterpiece, best quality, high quality, highres, ultra-detailed",
            "Version": "v1.6.0-2-g4afaaf8a",
            "sampler": "Euler a",
            "VAE hash": "235745af8d",
            "cfgScale": 3,
            "resources": [
                {
                    "hash": "c005f06a68",
                    "name": "SDXL SleipnirT_v125BF16",
                    "type": "model"
                }
            ],
            "Model hash": "c005f06a68",
            "Hires steps": "26",
            "Hires upscale": "1.2",
            "Hires upscaler": "4xUltrasharp_4xUltrasharpV10",
            "negativePrompt": "close-up, worst quality,low quality,normal quality,watermark, flat color, covering crotch, pubic hair, tattoo, merged objects",
            "Denoising strength": "0.26",
            "\"SDXL DET more_art-full_v1": "fe3b4816be83\""
        },
        "username": "kus",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 595761,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2c9600c3-8a46-4a37-cf29-9dcd08a76700/width=832/2c9600c3-8a46-4a37-cf29-9dcd08a76700.jpeg",
        "hash": "UKG9sc[-K*GG?]kW9uRjtTAb9u=ZEhRj$2xZ",
        "width": 832,
        "height": 1280,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-02-03T09:23:17.242Z",
        "postId": 168016,
        "stats": {
            "cryCount": 1,
            "laughCount": 11,
            "likeCount": 138,
            "dislikeCount": 0,
            "heartCount": 135,
            "commentCount": 3
        },
        "meta": {
            "Size": "512x768",
            "seed": 2738140648,
            "Model": "lyriel_v13",
            "steps": 35,
            "hashes": {
                "model": "1c0ed90d69"
            },
            "prompt": "abstract 1998 european blond hiphop girl by sachin teng x supreme, attractive, stylish, designer, green, asymmetrical, geometric shapes, graffiti, street art",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "1c0ed90d69",
                    "name": "lyriel_v13",
                    "type": "model"
                }
            ],
            "Model hash": "1c0ed90d69",
            "Hires steps": "40",
            "Hires resize": "832x1280",
            "Hires upscaler": "Latent",
            "negativePrompt": "3d, cartoon, anime, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, bad anatomy, girl, loli, young, large breasts, red eyes, muscular, over saturated, over saturated, over saturated",
            "Denoising strength": "0.52"
        },
        "username": "gbaeukfexboxo",
        "baseModel": "SD 1.5SD 1.5"
    },
    {
        "id": 41911817,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8713efbf-29be-43f0-9d98-64c0f76bdc23/width=832/8713efbf-29be-43f0-9d98-64c0f76bdc23.jpeg",
        "hash": "U69s@nNI0M%K00xZ^*WB~At69aNHW?R*?F%0",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-24T23:54:26.936Z",
        "postId": 9540559,
        "stats": {
            "cryCount": 4,
            "laughCount": 4,
            "likeCount": 240,
            "dislikeCount": 0,
            "heartCount": 41,
            "commentCount": 2
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1396413991,
            "steps": 26,
            "prompt": "A luminous row of massive trees clipped into globular shapes, the species now extinct. ",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-24T1033:40.6306255Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 753053,
                    "modelVersionName": "Flux Original"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 863655,
                    "modelVersionName": "Balance_v2.0"
                },
                {
                    "type": "lora",
                    "weight": 0.15,
                    "modelVersionId": 857586,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 959406,
                    "modelVersionName": "FLUX V2"
                },
                {
                    "type": "lora",
                    "weight": 0.85,
                    "modelVersionId": 841415,
                    "modelVersionName": "v01"
                }
            ]
        },
        "username": "dougs0011",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 41571151,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/648ecd8b-d91f-4be9-b647-62dcdcb1b45a/width=832/648ecd8b-d91f-4be9-b647-62dcdcb1b45a.jpeg",
        "hash": "UkJ+cOt6KkkX*0xFyDo#RNV@s:ofxts:aJoe",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-23T01:22:35.304Z",
        "postId": 9465785,
        "stats": {
            "cryCount": 4,
            "laughCount": 21,
            "likeCount": 202,
            "dislikeCount": 0,
            "heartCount": 57,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "nsfw": true,
            "seed": 240974772,
            "draft": false,
            "steps": 24,
            "width": 832,
            "height": 1216,
            "prompt": "score_9, score_8_up, score_7_up, source_anime, 145, perfect face, (illustration), intricately detailed illustration, Exquisite color design, (best quality, ultra detailed), smooth skin, high details, (1girls), beauty, kijin_seija, short hair, multicolored hair, (black hair), streaked hair, red hair, white hair, hair flaps, hair between eyes, red eyes, horns, small horns, grey horns, cone horns, white horns, white collared shirt, white buttons, sailor collar, bracelet, purple bowtie, bowtie upside-down, puffy short sleeves, white dress, white skirt, layered skirt, underskirt, purple belt, purple bow, bow upside-down, arrow print, arrow \\(symbol\\), facing viewer, narrowed eyes, looking at viewer, grin, sharp teeth, front view, low angle, day, hands on hips,",
            "sampler": "Euler",
            "cfgScale": 6,
            "clipSkip": 2,
            "quantity": 2,
            "workflow": "txt2img",
            "baseModel": "Pony",
            "resources": [],
            "Created Date": "2024-11-23T0055:42.0929597Z",
            "fluxUltraRaw": false,
            "negativePrompt": "N0R3AL_PDXL, deep_negative_pony, NEGATIVE_HANDS, negative_hand, score_6, score_5, score_4, source_pony, worst quality, low quality, text, censored, deformed, bad hand, blurry, (watermark), multiple phones, weights, extra hands, dark-skinned male, detached penis, disembodied penis, bad anatomy, bad proportions, extra legs, messy color, deformed fingers, source_furry, knotted penis, dark skinned male, multiple hands, missing fingers, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, extra digit, fewer digits, cropped, jpeg artifacts, distorted, disfigured, poorly drawn, bad iris,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 575495,
                    "modelVersionName": "v1.3(better eyes version)"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 651075,
                    "modelVersionName": "v0.1-Pony"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 564545,
                    "modelVersionName": "N0R3AL_PDXL"
                },
                {
                    "type": "lora",
                    "weight": 0.5,
                    "modelVersionId": 945805,
                    "modelVersionName": "v1.0"
                },
                {
                    "type": "embed",
                    "weight": 1,
                    "modelVersionId": 930629,
                    "modelVersionName": "B5"
                },
                {
                    "type": "lora",
                    "weight": 0.6,
                    "modelVersionId": 1036443,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 666102,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.9,
                    "modelVersionId": 790726,
                    "modelVersionName": "v2.0"
                }
            ]
        },
        "username": "GrAdm",
        "baseModel": "Pony"
    },
    {
        "id": 41182142,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8b6198e5-0c1d-493c-9539-f400de86ef2b/width=832/8b6198e5-0c1d-493c-9539-f400de86ef2b.jpeg",
        "hash": "U9K_L5?w00D%0000R5xuxr9FXBt74TNHbxxt",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-20T19:44:01.226Z",
        "postId": 9379631,
        "stats": {
            "cryCount": 15,
            "laughCount": 47,
            "likeCount": 167,
            "dislikeCount": 0,
            "heartCount": 55,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 710218144,
            "extra": {
                "remixOfId": 41009612
            },
            "steps": 20,
            "prompt": "A tube of \"Aquafresh\" tooth paste, laying horizontally on a bathroom counter. Large text underneath logo reads \"YELLOW BUZZ FLAVOR\". A small picture of a yellow lightning bolt symbol in the bottom right of the tube. Highly detailed, 4k.",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-20T1943:18.3537747Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                }
            ]
        },
        "username": "BingTester",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 40843798,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ac26c647-10bb-4041-833e-71181d5b7082/width=832/ac26c647-10bb-4041-833e-71181d5b7082.jpeg",
        "hash": "UhMDc%wd@asp}Fw{nOR*rrR*OXt7n4X8bvae",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-11-18T23:30:00.000Z",
        "postId": 9305566,
        "stats": {
            "cryCount": 14,
            "laughCount": 14,
            "likeCount": 178,
            "dislikeCount": 0,
            "heartCount": 78,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2165172488,
            "Model": "flux1-dev-bnb-nf4-v2",
            "steps": 30,
            "hashes": {
                "model": "bea01d51bd",
                "lora:Anime v1.3": "79c7519eff6f",
                "lora:VividlyReal": "86cb56b6bc17",
                "lora:FLUX-daubrez-DB4RZ-v2": "9A6DFC274BBD",
                "lora:FluxMythP0rtr4itStyle": "8ea428b224a8"
            },
            "prompt": "Highly detailed and dramatic digital artwork featuring a futuristic, cybernetic female character against a solid red background. The character has pale skin and striking blue eyes, with long, platinum blonde hair. She is wearing a white crop top that reveals her toned midriff, adorned with intricate tattoos of flowers and other designs. Her arms and legs are cybernetic, with metallic components and floral engravings, showcasing a blend of organic and mechanical elements. A katana is slung across her back, adding to her warrior-like appearance. The overall style is highly detailed and realistic, with a focus on the contrast between the character's human and robotic features. The image conveys a sense of strength and modernity, with a clean and bold aesthetic.  <lora:Anime v1.3:0.6> <lora:VividlyReal:0.6> <lora:FLUX-daubrez-DB4RZ-v2:0.4> <lora:FluxMythP0rtr4itStyle:0.6>",
            "Version": "f2.0.1v1.10.1-previous-519-g44eb4ea8",
            "sampler": "Euler",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "86cb56b6bc17",
                    "name": "VividlyReal",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "hash": "9A6DFC274BBD",
                    "name": "FLUX-daubrez-DB4RZ-v2",
                    "type": "lora",
                    "weight": 0.4
                },
                {
                    "hash": "8ea428b224a8",
                    "name": "FluxMythP0rtr4itStyle",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "hash": "79c7519eff6f",
                    "name": "Anime v1.3",
                    "type": "lora"
                },
                {
                    "hash": "bea01d51bd",
                    "name": "flux1-dev-bnb-nf4-v2",
                    "type": "model"
                }
            ],
            "Model hash": "bea01d51bd",
            "Schedule type": "Simple",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.8.0",
            "ADetailer mask blur": "4",
            "Distilled CFG Scale": "3.5",
            "ADetailer confidence": "0.3",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True",
            "ADetailer mask only top k largest": "1"
        },
        "username": "VelvetS",
        "baseModel": null
    },
    {
        "id": 40525446,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b12a6f91-e87d-4abf-9b0e-d793fc6f0fed/width=1024/b12a6f91-e87d-4abf-9b0e-d793fc6f0fed.jpeg",
        "hash": "U9DIODAB05tk8B$%M#nR0h-U^dIW}GI:R.tQ",
        "width": 1024,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-17T01:16:24.649Z",
        "postId": 9233834,
        "stats": {
            "cryCount": 26,
            "laughCount": 42,
            "likeCount": 151,
            "dislikeCount": 0,
            "heartCount": 65,
            "commentCount": 0
        },
        "meta": {
            "seed": 712425937,
            "Model": "flux_schnell",
            "steps": 4,
            "width": 1024,
            "height": 1024,
            "prompt": "anime screencap of a sad anthropomorphic cartoon bee sitting on a couch in a run-down apartment and holding a remote. The words \"No Buzz November\" are in yellow neon lights above his head. The image overall evokes a cartoonish anime style,with vivid colors and dynamic shading.",
            "cfgScale": 1,
            "negativePrompt": "nude,nsfw,child,loli,blurry,distorted,deformed"
        },
        "username": "burnera679889",
        "baseModel": ""
    },
    {
        "id": 40418781,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5fe38dab-8b87-4ef4-9ed7-890d44b7e55c/width=1664/5fe38dab-8b87-4ef4-9ed7-890d44b7e55c.jpeg",
        "hash": "UPJ%dj?F~As:?[%LxtWCrW-oEMWB57s,$$oe",
        "width": 1664,
        "height": 2432,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-16T10:45:13.508Z",
        "postId": 9210051,
        "stats": {
            "cryCount": 10,
            "laughCount": 42,
            "likeCount": 169,
            "dislikeCount": 0,
            "heartCount": 64,
            "commentCount": 0
        },
        "meta": {
            "seed": 1111652520562857,
            "vaes": [
                "ae.safetensors"
            ],
            "comfy": "{\"prompt\": {\"85\": {\"inputs\": {\"image\": \"1_221106222303_1.jpg\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"9560eb813bf4ec4b7002b0f9ea1e5ff790e11e6703cf29009e499e0ebce8c53f\"]}, \"102\": {\"inputs\": {\"delimiter\": \"\", \"clean_whitespace\": \"true\", \"text_b\": [\"112\", 0], \"text_c\": [\"103\", 0]}, \"class_type\": \"Text Concatenate\"}, \"103\": {\"inputs\": {\"prompt\": \"face to viwer,\", \"speak_and_recognation\": true}, \"class_type\": \"CR Prompt Text\"}, \"110\": {\"inputs\": {\"prompt\": \"In a post-apocalyptic desert wasteland under a blazing sun, a heavily modified off-road vehicle roars toward the camera, kicking up a massive plume of dust and sand. The car is a chaotic fusion of rusted metal, scavenged parts, and aggressive spikes jutting out from its sides. Its oversized tires crush the cracked earth beneath, and the engine snarls like a beast on the hunt. Bolted to the hood is a makeshift ram adorned with skeletal remains, adding to its menacing appearance.\\n\\nPerched atop the car is a ragged black flag flapping violently in the wind, emblazoned with the words \\u201cBUZZ ROBBER\\u201d in jagged, hand-painted letters. Two wild-eyed female marauders lean out from opposite windows, their faces smeared with dirt and war paint. One wields a battered shotgun, its muzzle gleaming in the harsh light, while the other brandishes a crude, cobbled-together rifle, laughing maniacally as they close in on their unseen prey.\\n\\nThe barren landscape stretches endlessly in the background, with jagged rock formations breaking the monotony of the desert. The sky above is a hazy, sickly yellow, filled with swirling dust that obscures the horizon. The heat distorts the air, creating a shimmering mirage effect that only amplifies the scene\\u2019s intensity.\\n\\nThe camera captures this moment head-on, with a low-angle shot emphasizing the vehicle\\u2019s monstrous size and the ferocity of its occupants. The depth of field is shallow, keeping the car and its occupants in sharp focus while the distant landscape blurs slightly, drawing all attention to the approaching chaos.\\n\\nThe color palette is dominated by scorched earth tones\\u2014rusty reds, sandy browns, and dirty metallic grays\\u2014contrasted by the dark flag and the muted yellow sky. The scene radiates raw energy and lawless aggression, perfectly embodying the brutal, high-octane world of Mad Max-style survival.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", \"main\": \"none\", \"lighting\": \"none\", \"speak_and_recognation\": true}, \"class_type\": \"easy prompt\"}, \"111\": {\"inputs\": {\"boolean\": false, \"on_true\": [\"102\", 0], \"on_false\": [\"113\", 0]}, \"class_type\": \"easy ifElse\"}, \"112\": {\"inputs\": {\"styles\": \"fooocus_styles\", \"select_styles\": \"artstyle-steampunk\"}, \"class_type\": \"easy stylesSelector\"}, \"113\": {\"inputs\": {\"delimiter\": \"\", \"clean_whitespace\": \"true\", \"text_a\": [\"110\", 0], \"text_b\": [\"112\", 0]}, \"class_type\": \"Text Concatenate\"}, \"119\": {\"inputs\": {\"facedetection\": \"retinaface_resnet50\", \"codeformer_fidelity\": 0.5, \"facerestore_model\": [\"121\", 0], \"image\": [\"120\", 0]}, \"class_type\": \"FaceRestoreCFWithModel\"}, \"120\": {\"inputs\": {\"upscale_method\": \"nearest-exact\", \"factor\": 2.0, \"upscale_model\": [\"122\", 0], \"image\": [\"181\", 0]}, \"class_type\": \"Upscale by Factor with Model (WLSH)\"}, \"121\": {\"inputs\": {\"model_name\": \"GFPGANv1.4.pth\"}, \"class_type\": \"FaceRestoreModelLoader\"}, \"122\": {\"inputs\": {\"model_name\": \"4xNomos8kSCHAT-L.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"129\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"130\": {\"inputs\": {\"text\": [\"111\", 0], \"speak_and_recognation\": true, \"clip\": [\"129\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"131\": {\"inputs\": {\"MODEL\": [\"144\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"132\": {\"inputs\": {\"CONDITIONING\": [\"130\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"135\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"136\": {\"inputs\": {\"noise_seed\": 1111652520562857}, \"class_type\": \"RandomNoise\"}, \"137\": {\"inputs\": {\"scheduler\": \"ddim_uniform\", \"steps\": 25, \"denoise\": 1.0, \"model\": [\"144\", 0]}, \"class_type\": \"BasicScheduler\"}, \"141\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\"}, \"142\": {\"inputs\": {\"VAE\": [\"141\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"144\": {\"inputs\": {\"PowerLoraLoaderHeaderWidget\": {\"type\": \"PowerLoraLoaderHeaderWidget\"}, \"lora_1\": {\"on\": true, \"lora\": \"flux\\\\flux_realism_lora.safetensors\", \"strength\": 0.4}, \"lora_2\": {\"on\": false, \"lora\": \"flux\\\\anatomy_fineart_nudity_by_caith.safetensors\", \"strength\": 0.65}, \"lora_3\": {\"on\": true, \"lora\": \"flux\\\\aidmaImageUpgrader-FLUX-V0.1.safetensors\", \"strength\": 0.45}, \"lora_4\": {\"on\": false, \"lora\": \"train\\\\cnql-v1.safetensors\", \"strength\": 0.6}, \"lora_5\": {\"on\": false, \"lora\": \"train\\\\cnxf-v1.safetensors\", \"strength\": 0.6}, \"lora_6\": {\"on\": false, \"lora\": \"train\\\\cnzz-v1.safetensors\", \"strength\": 0.85}, \"lora_7\": {\"on\": false, \"lora\": \"train\\\\huahuamao-v1.safetensors\", \"strength\": 0.75}, \"lora_8\": {\"on\": false, \"lora\": \"train\\\\cnzf-v1.safetensors\", \"strength\": 0.8}, \"lora_9\": {\"on\": false, \"lora\": \"train\\\\cnzf-v2.safetensors\", \"strength\": 0.8}, \"lora_10\": {\"on\": false, \"lora\": \"train\\\\YunaFluxV1.safetensors\", \"strength\": 0.5}, \"lora_11\": {\"on\": false, \"lora\": \"train\\\\cnhy-v1.safetensors\", \"strength\": 0.5}, \"lora_12\": {\"on\": false, \"lora\": \"train\\\\10ypy-v1.safetensors\", \"strength\": 0.6}, \"lora_13\": {\"on\": false, \"lora\": \"train\\\\cnmt-v1.safetensors\", \"strength\": 0.8}, \"lora_14\": {\"on\": false, \"lora\": \"train\\\\cnyy-v1.safetensors\", \"strength\": 0.8}, \"lora_15\": {\"on\": false, \"lora\": \"train\\\\cntt-v1.safetensors\", \"strength\": 0.85}, \"lora_16\": {\"on\": false, \"lora\": \"train\\\\cnww-v2.safetensors\", \"strength\": 0.8}, \"lora_17\": {\"on\": false, \"lora\": \"flux\\\\Flux-uncensored.safetensors\", \"strength\": 0.65}, \"lora_18\": {\"on\": false, \"lora\": \"train\\\\ghostbride-v1.safetensors\", \"strength\": 0.9}, \"lora_19\": {\"on\": false, \"lora\": \"train\\\\cnva-v1.safetensors\", \"strength\": 0.8}, \"lora_20\": {\"on\": false, \"lora\": \"train\\\\cnxy-v2.safetensors\", \"strength\": 0.4}, \"lora_21\": {\"on\": false, \"lora\": \"train\\\\cnxy-v3.safetensors\", \"strength\": 0.8}, \"lora_22\": {\"on\": false, \"lora\": \"train\\\\cnxy-v3-000012.safetensors\", \"strength\": 0.8}, \"lora_23\": {\"on\": false, \"lora\": \"train\\\\cnxy-v3-000008.safetensors\", \"strength\": 0.8}, \"lora_24\": {\"on\": false, \"lora\": \"train\\\\nsfw-v1.safetensors\", \"strength\": 0.9}, \"lora_25\": {\"on\": false, \"lora\": \"train\\\\reddit_nudes_v1.safetensors\", \"strength\": 1}, \"\\u2795 Add Lora\": \"\", \"model\": [\"171\", 0], \"clip\": [\"129\", 0]}, \"class_type\": \"Power Lora Loader (rgthree)\"}, \"145\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"aspect_ratio\": \"5:8 portrait 832x1216\", \"swap_dimensions\": \"Off\", \"upscale_factor\": 1.0, \"batch_size\": 1}, \"class_type\": \"CR SDXL Aspect Ratio\"}, \"171\": {\"inputs\": {\"unet_name\": \"flux1-dev.sft\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"175\": {\"inputs\": {\"guider\": [\"176\", 0], \"noise\": [\"136\", 0], \"sampler\": [\"135\", 0], \"sigmas\": [\"137\", 0], \"latent_image\": [\"145\", 4]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"176\": {\"inputs\": {\"conditioning\": [\"204\", 0], \"model\": [\"144\", 0]}, \"class_type\": \"BasicGuider\"}, \"181\": {\"inputs\": {\"samples\": [\"175\", 0], \"vae\": [\"141\", 0]}, \"class_type\": \"VAEDecode\"}, \"183\": {\"inputs\": {\"IMAGE\": [\"181\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"192\": {\"inputs\": {\"NOISE\": [\"136\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"193\": {\"inputs\": {\"SAMPLER\": [\"135\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"194\": {\"inputs\": {\"SIGMAS\": [\"137\", 0]}, \"class_type\": \"Anything Everywhere\"}, \"195\": {\"inputs\": {\"LATENT\": [\"145\", 4]}, \"class_type\": \"Anything Everywhere\"}, \"198\": {\"inputs\": {\"rgthree_comparer\": {\"images\": [{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_pqree_00009_.png&type=temp&subfolder=&rand=0.46127308900122244\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_pqree_00010_.png&type=temp&subfolder=&rand=0.25896346303898166\"}]}, \"image_b\": [\"119\", 0], \"image_a\": [\"181\", 0]}, \"class_type\": \"Image Comparer (rgthree)\"}, \"202\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"119\", 0]}, \"class_type\": \"SaveImage\"}, \"204\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"130\", 0]}, \"class_type\": \"FluxGuidance\"}}, \"workflow\": {\"last_node_id\": 211, \"last_link_id\": 430, \"nodes\": [{\"id\": 88, \"type\": \"LoadFlorence2Model\", \"pos\": {\"0\": -10, \"1\": -750}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {\"pinned\": true}, \"order\": 0, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"FLORENCE2\", \"type\": \"FLORENCE2\", \"links\": [404], \"shape\": 3, \"label\": \"FLORENCE2\"}], \"properties\": {\"Node name for S&R\": \"LoadFlorence2Model\"}, \"widgets_values\": [\"large-ft\"]}, {\"id\": 102, \"type\": \"Text Concatenate\", \"pos\": {\"0\": 380, \"1\": -200}, \"size\": {\"0\": 320, \"1\": 150}, \"flags\": {\"pinned\": true}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"text_a\", \"type\": \"STRING\", \"link\": 256, \"widget\": {\"name\": \"text_a\"}, \"label\": \"\\u6587\\u672c_A\"}, {\"name\": \"text_b\", \"type\": \"STRING\", \"link\": 257, \"widget\": {\"name\": \"text_b\"}, \"label\": \"\\u6587\\u672c_B\"}, {\"name\": \"text_c\", \"type\": \"STRING\", \"link\": 258, \"widget\": {\"name\": \"text_c\"}, \"label\": \"\\u6587\\u672c_C\"}, {\"name\": \"text_d\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"text_d\"}, \"label\": \"\\u6587\\u672c_d\"}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [240], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u5b57\\u7b26\\u4e32\"}], \"properties\": {\"Node name for S&R\": \"Text Concatenate\"}, \"widgets_values\": [\"\", \"true\", \"false\", \"\", \"\", \"\"], \"color\": \"#1b262b\", \"bgcolor\": \"#071217\"}, {\"id\": 113, \"type\": \"Text Concatenate\", \"pos\": {\"0\": 380, \"1\": 100}, \"size\": {\"0\": 320, \"1\": 150}, \"flags\": {\"pinned\": true}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"text_a\", \"type\": \"STRING\", \"link\": 401, \"widget\": {\"name\": \"text_a\"}, \"label\": \"\\u6587\\u672c_A\"}, {\"name\": \"text_b\", \"type\": \"STRING\", \"link\": 249, \"widget\": {\"name\": \"text_b\"}, \"label\": \"\\u6587\\u672c_B\"}, {\"name\": \"text_c\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"text_c\"}, \"label\": \"\\u6587\\u672c_C\"}, {\"name\": \"text_d\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"text_d\"}, \"label\": \"\\u6587\\u672c_d\"}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [254], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u5b57\\u7b26\\u4e32\"}], \"properties\": {\"Node name for S&R\": \"Text Concatenate\"}, \"widgets_values\": [\"\", \"true\", \"false\", \"\", \"\", \"\"], \"color\": \"#1b262b\", \"bgcolor\": \"#071217\"}, {\"id\": 116, \"type\": \"Note\", \"pos\": {\"0\": 760, \"1\": 30}, \"size\": {\"0\": 210, \"1\": 58}, \"flags\": {\"pinned\": true}, \"order\": 1, \"mode\": 4, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"ON = img2prompt\\nOFF = text2prompt\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 118, \"type\": \"Note\", \"pos\": {\"0\": 0, \"1\": -130}, \"size\": {\"0\": 310, \"1\": 60}, \"flags\": {\"pinned\": true}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"Add custom prompt\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 171, \"type\": \"UNETLoader\", \"pos\": {\"0\": 1020, \"1\": -760}, \"size\": {\"0\": 310, \"1\": 100}, \"flags\": {\"pinned\": true}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [334], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev.sft\", \"fp8_e4m3fn\"]}, {\"id\": 192, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1220, \"1\": -50}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"NOISE\", \"type\": \"*\", \"link\": 356, \"label\": \"NOISE\", \"color_on\": \"\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 136, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1020, \"1\": -170}, \"size\": {\"0\": 310, \"1\": 82}, \"flags\": {\"pinned\": true}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [356], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [1111652520562857, \"randomize\"]}, {\"id\": 142, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1220, \"1\": -210}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"VAE\", \"type\": \"*\", \"link\": 294, \"label\": \"VAE\", \"color_on\": \"#be616b\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 141, \"type\": \"VAELoader\", \"pos\": {\"0\": 1020, \"1\": -310}, \"size\": {\"0\": 310, \"1\": 60}, \"flags\": {\"pinned\": true}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [294], \"slot_index\": 0, \"shape\": 3, \"label\": \"VAE\"}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 193, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1220, \"1\": -350}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"SAMPLER\", \"type\": \"*\", \"link\": 357, \"label\": \"SAMPLER\", \"color_on\": \"\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 135, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1020, \"1\": -450}, \"size\": {\"0\": 310, \"1\": 60}, \"flags\": {\"pinned\": true}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [357], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u91c7\\u6837\\u5668\"}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 180, \"type\": \"ImageResize+\", \"pos\": {\"0\": 2200, \"1\": -770}, \"size\": {\"0\": 320, \"1\": 220}, \"flags\": {\"pinned\": true}, \"order\": 35, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 363, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [339], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"width\", \"type\": \"INT\", \"links\": [], \"slot_index\": 1, \"shape\": 3, \"label\": \"\\u5bbd\\u5ea6\"}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [], \"slot_index\": 2, \"shape\": 3, \"label\": \"\\u9ad8\\u5ea6\"}], \"properties\": {\"Node name for S&R\": \"ImageResize+\"}, \"widgets_values\": [832, 1152, \"nearest\", \"stretch\", \"always\", 0]}, {\"id\": 174, \"type\": \"ControlNetApplySD3\", \"pos\": {\"0\": 2200, \"1\": -370}, \"size\": {\"0\": 320, \"1\": 230}, \"flags\": {\"pinned\": true}, \"order\": 46, \"mode\": 4, \"inputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 360, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 361, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}, {\"name\": \"control_net\", \"type\": \"CONTROL_NET\", \"link\": 338, \"label\": \"ControlNet\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null, \"label\": \"VAE\"}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 339, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"positive\", \"type\": \"CONDITIONING\", \"links\": [402], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6b63\\u9762\\u6761\\u4ef6\"}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"links\": null, \"shape\": 3, \"label\": \"\\u8d1f\\u9762\\u6761\\u4ef6\"}], \"properties\": {\"Node name for S&R\": \"ControlNetApplySD3\"}, \"widgets_values\": [0.33, 0, 0.6]}, {\"id\": 131, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1840, \"1\": -760}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"MODEL\", \"type\": \"*\", \"link\": 285, \"label\": \"MODEL\", \"color_on\": \"#8978a7\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 132, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1970, \"1\": -760}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"CONDITIONING\", \"type\": \"*\", \"link\": 286, \"label\": \"CONDITIONING\", \"color_on\": \"#cf876f\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 194, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1970, \"1\": -430}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"SIGMAS\", \"type\": \"*\", \"link\": 358, \"label\": \"SIGMAS\", \"color_on\": \"\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 195, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 1970, \"1\": -50}, \"size\": {\"0\": 210, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"LATENT\", \"type\": \"*\", \"link\": 359, \"label\": \"LATENT\", \"color_on\": \"#b38ead\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 145, \"type\": \"CR SDXL Aspect Ratio\", \"pos\": {\"0\": 1830, \"1\": -370}, \"size\": {\"0\": 250, \"1\": 280}, \"flags\": {\"pinned\": true}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"width\", \"type\": \"INT\", \"links\": [], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u5bbd\\u5ea6\"}, {\"name\": \"height\", \"type\": \"INT\", \"links\": [], \"slot_index\": 1, \"shape\": 3, \"label\": \"\\u9ad8\\u5ea6\"}, {\"name\": \"upscale_factor\", \"type\": \"FLOAT\", \"links\": null, \"shape\": 3, \"label\": \"\\u653e\\u5927\\u7cfb\\u6570\"}, {\"name\": \"batch_size\", \"type\": \"INT\", \"links\": [], \"slot_index\": 3, \"shape\": 3, \"label\": \"\\u6279\\u6b21\\u5927\\u5c0f\"}, {\"name\": \"empty_latent\", \"type\": \"LATENT\", \"links\": [359], \"slot_index\": 4, \"shape\": 3, \"label\": \"empty_latent\"}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3, \"label\": \"show_help\"}], \"properties\": {\"Node name for S&R\": \"CR SDXL Aspect Ratio\"}, \"widgets_values\": [1024, 1024, \"5:8 portrait 832x1216\", \"Off\", 1, 1]}, {\"id\": 130, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 1830, \"1\": -720}, \"size\": {\"0\": 250, \"1\": 90}, \"flags\": {\"pinned\": true}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 367, \"label\": \"CLIP\"}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 298, \"slot_index\": 1, \"widget\": {\"name\": \"text\"}, \"label\": \"\\u6587\\u672c\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [286, 360, 361], \"slot_index\": 0, \"label\": \"\\u6761\\u4ef6\"}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"A 20-year-old Asian girl wearing a pink thin shoulder strap cheongsam. The girl has bright big eyes, wheat-colored skin, the scene is a hut full of gemstones, and her feet are vast.there are floating stars and petals on the pool, she is dancing in the front of the lens and looking at viewer, the photo full of details, bright tones, 8K\", true]}, {\"id\": 184, \"type\": \"Reroute\", \"pos\": {\"0\": 350, \"1\": -900}, \"size\": [75, 26], \"flags\": {\"pinned\": true}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 349, \"label\": \"\"}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [364], \"slot_index\": 0, \"label\": \"\"}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}, \"shape\": 2}, {\"id\": 173, \"type\": \"InstantX Flux Union ControlNet Loader\", \"pos\": {\"0\": 2200, \"1\": -500}, \"size\": {\"0\": 320, \"1\": 82}, \"flags\": {\"pinned\": true}, \"order\": 8, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"CONTROL_NET\", \"type\": \"CONTROL_NET\", \"links\": [338], \"slot_index\": 0, \"shape\": 3, \"label\": \"CONTROL_NET\"}], \"properties\": {\"Node name for S&R\": \"InstantX Flux Union ControlNet Loader\"}, \"widgets_values\": [\"FLUX.1-dev-ControlNet-Union-Pro-diffusion_pytorch_model.safetensors\", \"pose\"]}, {\"id\": 103, \"type\": \"CR Prompt Text\", \"pos\": {\"0\": 0, \"1\": -290}, \"size\": {\"0\": 310, \"1\": 110}, \"flags\": {\"pinned\": true}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [258], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u63d0\\u793a\\u8bcd\\u6587\\u672c\"}, {\"name\": \"show_help\", \"type\": \"STRING\", \"links\": null, \"shape\": 3, \"label\": \"show_help\"}], \"properties\": {\"Node name for S&R\": \"CR Prompt Text\"}, \"widgets_values\": [\"face to viwer,\", true], \"color\": \"#1b262b\", \"bgcolor\": \"#071217\"}, {\"id\": 196, \"type\": \"Reroute\", \"pos\": {\"0\": 2130, \"1\": -900}, \"size\": [75, 26], \"flags\": {\"pinned\": true}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 364, \"label\": \"\"}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [363], \"slot_index\": 0, \"label\": \"\"}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 86, \"type\": \"ShowText|pysssss\", \"pos\": {\"0\": 340, \"1\": -480}, \"size\": {\"0\": 360, \"1\": 230}, \"flags\": {\"pinned\": true}, \"order\": 33, \"mode\": 4, \"inputs\": [{\"name\": \"text\", \"type\": \"STRING\", \"link\": 406, \"widget\": {\"name\": \"text\"}, \"label\": \"\\u6587\\u672c\"}], \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [256], \"slot_index\": 0, \"shape\": 6, \"label\": \"\\u5b57\\u7b26\\u4e32\"}], \"properties\": {\"Node name for S&R\": \"ShowText|pysssss\"}, \"widgets_values\": [[\"A pencil sketch of a woman. The woman has long hair. The hair is messy. The sketch is black and white. There is a shirt on the woman. There are earrings hanging from her ear. The shirt is a denim style. The wall behind the woman is a light beige color.\"], \"A black and white line drawing of a Hello Kitty holding a teddy bear. The Hello Kitty is wearing a dress and has a large bow on her head. The bear is also wearing a coat. The background is plain white.\"]}, {\"id\": 191, \"type\": \"Fast Groups Bypasser (rgthree)\", \"pos\": {\"0\": -20, \"1\": -1120}, \"size\": {\"0\": 320, \"1\": 250}, \"flags\": {\"pinned\": true}, \"order\": 10, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"OPT_CONNECTION\", \"type\": \"*\", \"links\": null, \"label\": \"\\u53ef\\u9009\\u8fde\\u63a5\"}], \"properties\": {\"matchColors\": \"\", \"matchTitle\": \"\", \"showNav\": true, \"sort\": \"position\", \"customSortAlphabet\": \"\", \"toggleRestriction\": \"default\"}}, {\"id\": 129, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 1020, \"1\": -610}, \"size\": {\"0\": 310, \"1\": 110}, \"flags\": {\"pinned\": true}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [297, 367], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 137, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1830, \"1\": -580}, \"size\": {\"0\": 250, \"1\": 110}, \"flags\": {\"pinned\": true}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0, \"label\": \"\\u6a21\\u578b\"}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [358], \"slot_index\": 0, \"shape\": 3, \"label\": \"Sigmas\"}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"ddim_uniform\", 25, 1]}, {\"id\": 85, \"type\": \"LoadImage\", \"pos\": {\"0\": -10, \"1\": -650}, \"size\": [320, 310], \"flags\": {\"pinned\": true}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [349, 405], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3, \"label\": \"\\u906e\\u7f69\"}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"1_221106222303_1.jpg\", \"image\"]}, {\"id\": 111, \"type\": \"easy ifElse\", \"pos\": {\"0\": 760, \"1\": -110}, \"size\": {\"0\": 210, \"1\": 80}, \"flags\": {\"pinned\": true}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"on_true\", \"type\": \"*\", \"link\": 240, \"label\": \"on_true\"}, {\"name\": \"on_false\", \"type\": \"*\", \"link\": 254, \"label\": \"on_false\"}], \"outputs\": [{\"name\": \"*\", \"type\": \"*\", \"links\": [298], \"slot_index\": 0, \"shape\": 3, \"label\": \"*\"}], \"properties\": {\"Node name for S&R\": \"easy ifElse\"}, \"widgets_values\": [false]}, {\"id\": 198, \"type\": \"Image Comparer (rgthree)\", \"pos\": {\"0\": 3040, \"1\": -760}, \"size\": {\"0\": 1090, \"1\": 1470}, \"flags\": {\"pinned\": true}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"image_a\", \"type\": \"IMAGE\", \"link\": null, \"label\": \"\\u56fe\\u50cf_A\", \"dir\": 3}, {\"name\": \"image_b\", \"type\": \"IMAGE\", \"link\": 366, \"label\": \"\\u56fe\\u50cf_B\", \"dir\": 3}], \"outputs\": [], \"properties\": {\"comparer_mode\": \"Slide\"}, \"widgets_values\": [[{\"name\": \"A\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_pqree_00009_.png&type=temp&subfolder=&rand=0.46127308900122244\"}, {\"name\": \"B\", \"selected\": true, \"url\": \"/api/view?filename=rgthree.compare._temp_pqree_00010_.png&type=temp&subfolder=&rand=0.25896346303898166\"}]]}, {\"id\": 124, \"type\": \"LoadImage\", \"pos\": {\"0\": 1050, \"1\": 500}, \"size\": {\"0\": 430, \"1\": 350}, \"flags\": {\"pinned\": true}, \"order\": 14, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [271], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3, \"label\": \"\\u906e\\u7f69\"}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"Donald-J-Trump-2010.webp\", \"image\"]}, {\"id\": 125, \"type\": \"ReActorFaceSwap\", \"pos\": {\"0\": 1540, \"1\": 500}, \"size\": {\"0\": 320, \"1\": 360}, \"flags\": {\"pinned\": true}, \"order\": 34, \"mode\": 4, \"inputs\": [{\"name\": \"input_image\", \"type\": \"IMAGE\", \"link\": 409, \"label\": \"\\u76ee\\u6807\\u56fe\\u50cf\"}, {\"name\": \"source_image\", \"type\": \"IMAGE\", \"link\": 271, \"label\": \"\\u6e90\\u56fe\\u50cf\"}, {\"name\": \"face_model\", \"type\": \"FACE_MODEL\", \"link\": null, \"label\": \"\\u9762\\u90e8\\u6a21\\u578b\"}, {\"name\": \"face_boost\", \"type\": \"FACE_BOOST\", \"link\": null, \"label\": \"\\u9762\\u90e8\\u589e\\u5f3a\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [282, 411], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"FACE_MODEL\", \"type\": \"FACE_MODEL\", \"links\": [], \"slot_index\": 1, \"shape\": 3, \"label\": \"\\u9762\\u90e8\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"ReActorFaceSwap\"}, \"widgets_values\": [true, \"inswapper_128_fp16.onnx\", \"retinaface_resnet50\", \"GFPGANv1.4.pth\", 1, 1, \"no\", \"no\", \"0\", \"0\", 1]}, {\"id\": 144, \"type\": \"Power Lora Loader (rgthree)\", \"pos\": {\"0\": 1370, \"1\": -760}, \"size\": {\"0\": 410, \"1\": 720}, \"flags\": {\"pinned\": true}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 334, \"dir\": 3, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 297, \"dir\": 3, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [285], \"slot_index\": 0, \"shape\": 3, \"dir\": 4, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [], \"slot_index\": 1, \"shape\": 3, \"dir\": 4, \"label\": \"CLIP\"}], \"properties\": {\"Show Strengths\": \"Single Strength\"}, \"widgets_values\": [null, {\"type\": \"PowerLoraLoaderHeaderWidget\"}, {\"on\": true, \"lora\": \"flux\\\\flux_realism_lora.safetensors\", \"strength\": 0.4, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\anatomy_fineart_nudity_by_caith.safetensors\", \"strength\": 0.65, \"strengthTwo\": null}, {\"on\": true, \"lora\": \"flux\\\\aidmaImageUpgrader-FLUX-V0.1.safetensors\", \"strength\": 0.45, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnql-v1.safetensors\", \"strength\": 0.6, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnxf-v1.safetensors\", \"strength\": 0.6, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnzz-v1.safetensors\", \"strength\": 0.85, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\huahuamao-v1.safetensors\", \"strength\": 0.75, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnzf-v1.safetensors\", \"strength\": 0.8, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnzf-v2.safetensors\", \"strength\": 0.8, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\YunaFluxV1.safetensors\", \"strength\": 0.5, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnhy-v1.safetensors\", \"strength\": 0.5, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\10ypy-v1.safetensors\", \"strength\": 0.6, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnmt-v1.safetensors\", \"strength\": 0.8, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnyy-v1.safetensors\", \"strength\": 0.8, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cntt-v1.safetensors\", \"strength\": 0.85, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnww-v2.safetensors\", \"strength\": 0.8, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"flux\\\\Flux-uncensored.safetensors\", \"strength\": 0.65, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\ghostbride-v1.safetensors\", \"strength\": 0.9, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnva-v1.safetensors\", \"strength\": 0.8, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnxy-v2.safetensors\", \"strength\": 0.4, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnxy-v3.safetensors\", \"strength\": 0.8, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnxy-v3-000012.safetensors\", \"strength\": 0.8, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\cnxy-v3-000008.safetensors\", \"strength\": 0.8, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\nsfw-v1.safetensors\", \"strength\": 0.9, \"strengthTwo\": null}, {\"on\": false, \"lora\": \"train\\\\reddit_nudes_v1.safetensors\", \"strength\": 1, \"strengthTwo\": null}, null, \"\"]}, {\"id\": 204, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 2630, \"1\": -770}, \"size\": {\"0\": 310, \"1\": 60}, \"flags\": {\"pinned\": true}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 402, \"label\": \"\\u6761\\u4ef6\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [403], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6761\\u4ef6\"}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5]}, {\"id\": 183, \"type\": \"Anything Everywhere\", \"pos\": {\"0\": 2820, \"1\": -60}, \"size\": {\"0\": 240, \"1\": 30}, \"flags\": {\"collapsed\": true, \"pinned\": true}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"IMAGE\", \"type\": \"*\", \"link\": 348, \"label\": \"IMAGE\", \"color_on\": \"#80a1c0\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"Anything Everywhere\", \"group_restricted\": 0, \"color_restricted\": 0}, \"widgets_values\": []}, {\"id\": 181, \"type\": \"VAEDecode\", \"pos\": {\"0\": 2630, \"1\": -160}, \"size\": {\"0\": 310, \"1\": 50}, \"flags\": {\"pinned\": true}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 346, \"label\": \"Latent\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null, \"label\": \"VAE\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [348], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"widgets_values\": []}, {\"id\": 175, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 2630, \"1\": -550}, \"size\": {\"0\": 310, \"1\": 330}, \"flags\": {\"pinned\": true}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": null, \"slot_index\": 0, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 341, \"slot_index\": 1, \"label\": \"\\u5f15\\u5bfc\"}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": null, \"slot_index\": 2, \"label\": \"\\u91c7\\u6837\\u5668\"}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": null, \"slot_index\": 3, \"label\": \"Sigmas\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": null, \"slot_index\": 4, \"label\": \"Latent\"}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [346], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u8f93\\u51fa\"}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3, \"label\": \"\\u964d\\u566a\\u8f93\\u51fa\"}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"widgets_values\": []}, {\"id\": 176, \"type\": \"BasicGuider\", \"pos\": {\"0\": 2630, \"1\": -650}, \"size\": {\"0\": 310, \"1\": 50}, \"flags\": {\"pinned\": true}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 403, \"slot_index\": 1, \"label\": \"\\u6761\\u4ef6\"}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [341], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u5f15\\u5bfc\"}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}, \"widgets_values\": []}, {\"id\": 205, \"type\": \"Florence2\", \"pos\": {\"0\": 380, \"1\": -750}, \"size\": {\"0\": 320, \"1\": 220}, \"flags\": {}, \"order\": 28, \"mode\": 4, \"inputs\": [{\"name\": \"FLORENCE2\", \"type\": \"FLORENCE2\", \"link\": 404, \"label\": \"FLORENCE2\"}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 405, \"label\": \"image\"}], \"outputs\": [{\"name\": \"preview\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3, \"label\": \"preview\"}, {\"name\": \"string\", \"type\": \"STRING\", \"links\": [406], \"shape\": 3, \"label\": \"string\"}, {\"name\": \"F_BBOXES\", \"type\": \"F_BBOXES\", \"links\": null, \"shape\": 3, \"label\": \"F_BBOXES\"}], \"properties\": {\"Node name for S&R\": \"Florence2\"}, \"widgets_values\": [\"detailed caption\", \"\", 1024, 3, false, false]}, {\"id\": 207, \"type\": \"ReActorFaceSwap\", \"pos\": {\"0\": 1540, \"1\": 90}, \"size\": {\"0\": 320, \"1\": 360}, \"flags\": {}, \"order\": 29, \"mode\": 4, \"inputs\": [{\"name\": \"input_image\", \"type\": \"IMAGE\", \"link\": null, \"label\": \"\\u76ee\\u6807\\u56fe\\u50cf\"}, {\"name\": \"source_image\", \"type\": \"IMAGE\", \"link\": 408, \"label\": \"\\u6e90\\u56fe\\u50cf\"}, {\"name\": \"face_model\", \"type\": \"FACE_MODEL\", \"link\": null, \"label\": \"\\u9762\\u90e8\\u6a21\\u578b\"}, {\"name\": \"face_boost\", \"type\": \"FACE_BOOST\", \"link\": null, \"label\": \"\\u9762\\u90e8\\u589e\\u5f3a\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [409], \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"FACE_MODEL\", \"type\": \"FACE_MODEL\", \"links\": null, \"shape\": 3, \"label\": \"\\u9762\\u90e8\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"ReActorFaceSwap\"}, \"widgets_values\": [true, \"inswapper_128.onnx\", \"retinaface_resnet50\", \"GFPGANv1.4.pth\", 1, 0.3, \"no\", \"no\", \"0\", \"0\", 1]}, {\"id\": 206, \"type\": \"LoadImage\", \"pos\": {\"0\": 1050, \"1\": 90}, \"size\": {\"0\": 430, \"1\": 350}, \"flags\": {}, \"order\": 15, \"mode\": 4, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [408], \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3, \"label\": \"\\u906e\\u7f69\"}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"1280x854_669f6243c1c54.png\", \"image\"]}, {\"id\": 120, \"type\": \"Upscale by Factor with Model (WLSH)\", \"pos\": {\"0\": 1970, \"1\": 560}, \"size\": {\"0\": 320, \"1\": 102}, \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 265, \"label\": \"upscale_model\"}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 282, \"label\": \"image\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [266], \"slot_index\": 0, \"shape\": 3, \"label\": \"IMAGE\"}], \"properties\": {\"Node name for S&R\": \"Upscale by Factor with Model (WLSH)\"}, \"widgets_values\": [\"nearest-exact\", 2]}, {\"id\": 119, \"type\": \"FaceRestoreCFWithModel\", \"pos\": {\"0\": 2650, \"1\": 90}, \"size\": {\"0\": 280, \"1\": 102}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"facerestore_model\", \"type\": \"FACERESTORE_MODEL\", \"link\": 264, \"label\": \"\\u9762\\u90e8\\u4fee\\u590d\\u6a21\\u578b\"}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 266, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [366, 399], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"FaceRestoreCFWithModel\"}, \"widgets_values\": [\"retinaface_resnet50\", 0.5]}, {\"id\": 208, \"type\": \"SaveImage\", \"pos\": {\"0\": 1970, \"1\": 720}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 16, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": null, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 210, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1970, \"1\": 230}, \"size\": {\"0\": 320, \"1\": 180}, \"flags\": {}, \"order\": 41, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 410, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.5, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 209, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 1970, \"1\": 80}, \"size\": {\"0\": 320, \"1\": 110}, \"flags\": {}, \"order\": 38, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 411, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [410], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.33, 0.33], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 202, \"type\": \"SaveImage\", \"pos\": {\"0\": 2330, \"1\": 240}, \"size\": {\"0\": 610, \"1\": 610}, \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 399, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 121, \"type\": \"FaceRestoreModelLoader\", \"pos\": {\"0\": 2330, \"1\": 90}, \"size\": {\"0\": 280, \"1\": 60}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"FACERESTORE_MODEL\", \"type\": \"FACERESTORE_MODEL\", \"links\": [264], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u9762\\u90e8\\u4fee\\u590d\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"FaceRestoreModelLoader\"}, \"widgets_values\": [\"GFPGANv1.4.pth\"]}, {\"id\": 122, \"type\": \"UpscaleModelLoader\", \"pos\": {\"0\": 1970, \"1\": 450}, \"size\": {\"0\": 320, \"1\": 60}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [265], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u653e\\u5927\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4xNomos8kSCHAT-L.pth\"]}, {\"id\": 110, \"type\": \"easy prompt\", \"pos\": {\"0\": 0, \"1\": 100}, \"size\": {\"0\": 330, \"1\": 300}, \"flags\": {\"pinned\": true}, \"order\": 19, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"prompt\", \"type\": \"STRING\", \"links\": [401], \"slot_index\": 0, \"shape\": 3, \"label\": \"prompt\"}], \"properties\": {\"Node name for S&R\": \"easy prompt\"}, \"widgets_values\": [\"In a post-apocalyptic desert wasteland under a blazing sun, a heavily modified off-road vehicle roars toward the camera, kicking up a massive plume of dust and sand. The car is a chaotic fusion of rusted metal, scavenged parts, and aggressive spikes jutting out from its sides. Its oversized tires crush the cracked earth beneath, and the engine snarls like a beast on the hunt. Bolted to the hood is a makeshift ram adorned with skeletal remains, adding to its menacing appearance.\\n\\nPerched atop the car is a ragged black flag flapping violently in the wind, emblazoned with the words \\u201cBUZZ ROBBER\\u201d in jagged, hand-painted letters. Two wild-eyed female marauders lean out from opposite windows, their faces smeared with dirt and war paint. One wields a battered shotgun, its muzzle gleaming in the harsh light, while the other brandishes a crude, cobbled-together rifle, laughing maniacally as they close in on their unseen prey.\\n\\nThe barren landscape stretches endlessly in the background, with jagged rock formations breaking the monotony of the desert. The sky above is a hazy, sickly yellow, filled with swirling dust that obscures the horizon. The heat distorts the air, creating a shimmering mirage effect that only amplifies the scene\\u2019s intensity.\\n\\nThe camera captures this moment head-on, with a low-angle shot emphasizing the vehicle\\u2019s monstrous size and the ferocity of its occupants. The depth of field is shallow, keeping the car and its occupants in sharp focus while the distant landscape blurs slightly, drawing all attention to the approaching chaos.\\n\\nThe color palette is dominated by scorched earth tones\\u2014rusty reds, sandy browns, and dirty metallic grays\\u2014contrasted by the dark flag and the muted yellow sky. The scene radiates raw energy and lawless aggression, perfectly embodying the brutal, high-octane world of Mad Max-style survival.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", \"none\", \"none\", true]}, {\"id\": 112, \"type\": \"easy stylesSelector\", \"pos\": {\"0\": -30, \"1\": 480}, \"size\": {\"0\": 760, \"1\": 390}, \"flags\": {\"collapsed\": false, \"pinned\": true}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"positive\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"positive\"}, \"label\": \"\\u6b63\\u9762\\u63d0\\u793a\\u8bcd\\uff08\\u53ef\\u9009\\uff09\"}, {\"name\": \"negative\", \"type\": \"STRING\", \"link\": null, \"widget\": {\"name\": \"negative\"}, \"label\": \"\\u8d1f\\u9762\\u63d0\\u793a\\u8bcd\\uff08\\u53ef\\u9009\\uff09\"}], \"outputs\": [{\"name\": \"positive\", \"type\": \"STRING\", \"links\": [249, 257], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6b63\\u9762\\u63d0\\u793a\\u8bcd\"}, {\"name\": \"negative\", \"type\": \"STRING\", \"links\": [], \"slot_index\": 1, \"shape\": 3, \"label\": \"\\u8d1f\\u9762\\u63d0\\u793a\\u8bcd\"}], \"properties\": {\"Node name for S&R\": \"easy stylesSelector\", \"values\": [\"artstyle-steampunk\"]}, \"widgets_values\": [\"fooocus_styles\", \"\", \"\", \"artstyle-steampunk\"]}], \"links\": [[240, 102, 0, 111, 0, \"*\"], [249, 112, 0, 113, 1, \"STRING\"], [254, 113, 0, 111, 1, \"*\"], [256, 86, 0, 102, 0, \"STRING\"], [257, 112, 0, 102, 1, \"STRING\"], [258, 103, 0, 102, 2, \"STRING\"], [264, 121, 0, 119, 0, \"FACERESTORE_MODEL\"], [265, 122, 0, 120, 0, \"UPSCALE_MODEL\"], [266, 120, 0, 119, 1, \"IMAGE\"], [271, 124, 0, 125, 1, \"IMAGE\"], [282, 125, 0, 120, 1, \"IMAGE\"], [285, 144, 0, 131, 0, \"MODEL\"], [286, 130, 0, 132, 0, \"CONDITIONING\"], [294, 141, 0, 142, 0, \"VAE\"], [297, 129, 0, 144, 1, \"CLIP\"], [298, 111, 0, 130, 1, \"STRING\"], [334, 171, 0, 144, 0, \"MODEL\"], [338, 173, 0, 174, 2, \"CONTROL_NET\"], [339, 180, 0, 174, 4, \"IMAGE\"], [341, 176, 0, 175, 1, \"GUIDER\"], [346, 175, 0, 181, 0, \"LATENT\"], [348, 181, 0, 183, 0, \"IMAGE\"], [349, 85, 0, 184, 0, \"*\"], [356, 136, 0, 192, 0, \"NOISE\"], [357, 135, 0, 193, 0, \"SAMPLER\"], [358, 137, 0, 194, 0, \"SIGMAS\"], [359, 145, 4, 195, 0, \"LATENT\"], [360, 130, 0, 174, 0, \"CONDITIONING\"], [361, 130, 0, 174, 1, \"CONDITIONING\"], [363, 196, 0, 180, 0, \"IMAGE\"], [364, 184, 0, 196, 0, \"*\"], [366, 119, 0, 198, 1, \"IMAGE\"], [367, 129, 0, 130, 0, \"CLIP\"], [371, 181, 0, 120, 1, \"IMAGE\"], [372, 144, 0, 137, 0, \"MODEL\"], [373, 144, 0, 176, 0, \"MODEL\"], [374, 136, 0, 175, 0, \"NOISE\"], [375, 135, 0, 175, 2, \"SAMPLER\"], [376, 137, 0, 175, 3, \"SIGMAS\"], [377, 145, 4, 175, 4, \"LATENT\"], [378, 181, 0, 198, 0, \"IMAGE\"], [379, 141, 0, 181, 1, \"VAE\"], [380, 181, 0, 120, 1, \"IMAGE\"], [381, 144, 0, 137, 0, \"MODEL\"], [382, 144, 0, 176, 0, \"MODEL\"], [383, 136, 0, 175, 0, \"NOISE\"], [384, 135, 0, 175, 2, \"SAMPLER\"], [385, 137, 0, 175, 3, \"SIGMAS\"], [386, 145, 4, 175, 4, \"LATENT\"], [387, 181, 0, 198, 0, \"IMAGE\"], [388, 141, 0, 181, 1, \"VAE\"], [389, 181, 0, 120, 1, \"IMAGE\"], [390, 144, 0, 137, 0, \"MODEL\"], [391, 144, 0, 176, 0, \"MODEL\"], [392, 136, 0, 175, 0, \"NOISE\"], [393, 135, 0, 175, 2, \"SAMPLER\"], [394, 137, 0, 175, 3, \"SIGMAS\"], [395, 145, 4, 175, 4, \"LATENT\"], [396, 181, 0, 198, 0, \"IMAGE\"], [397, 141, 0, 181, 1, \"VAE\"], [398, 181, 0, 201, 0, \"IMAGE\"], [399, 119, 0, 202, 0, \"IMAGE\"], [401, 110, 0, 113, 0, \"STRING\"], [402, 174, 0, 204, 0, \"CONDITIONING\"], [403, 204, 0, 176, 1, \"CONDITIONING\"], [404, 88, 0, 205, 0, \"FLORENCE2\"], [405, 85, 0, 205, 1, \"IMAGE\"], [406, 205, 1, 86, 0, \"STRING\"], [408, 206, 0, 207, 1, \"IMAGE\"], [409, 207, 0, 125, 0, \"IMAGE\"], [410, 209, 0, 210, 0, \"IMAGE\"], [411, 125, 0, 209, 0, \"IMAGE\"], [412, 144, 0, 137, 0, \"MODEL\"], [413, 181, 0, 198, 0, \"IMAGE\"], [414, 141, 0, 181, 1, \"VAE\"], [415, 136, 0, 175, 0, \"NOISE\"], [416, 135, 0, 175, 2, \"SAMPLER\"], [417, 137, 0, 175, 3, \"SIGMAS\"], [418, 145, 4, 175, 4, \"LATENT\"], [419, 144, 0, 176, 0, \"MODEL\"], [420, 181, 0, 209, 0, \"IMAGE\"], [421, 181, 0, 120, 1, \"IMAGE\"], [422, 144, 0, 137, 0, \"MODEL\"], [423, 181, 0, 198, 0, \"IMAGE\"], [424, 141, 0, 181, 1, \"VAE\"], [425, 136, 0, 175, 0, \"NOISE\"], [426, 135, 0, 175, 2, \"SAMPLER\"], [427, 137, 0, 175, 3, \"SIGMAS\"], [428, 145, 4, 175, 4, \"LATENT\"], [429, 144, 0, 176, 0, \"MODEL\"], [430, 181, 0, 120, 1, \"IMAGE\"]], \"groups\": [{\"title\": \"reactor\", \"bounding\": [1020, 0, 880, 870], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"image2prompt\", \"bounding\": [-30, -840, 760, 810], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"upscale\", \"bounding\": [1940, 0, 1030, 870], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"image output\", \"bounding\": [3020, -850, 1140, 1720], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"text prompt\", \"bounding\": [-30, 0, 760, 420], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"FLUX text2image\", \"bounding\": [1000, -850, 1130, 820], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"controlnet\", \"bounding\": [2170, -850, 400, 820], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}, {\"title\": \"image generate\", \"bounding\": [2600, -850, 370, 820], \"color\": \"#3f789e\", \"font_size\": 24, \"flags\": {}}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.9090909090909091, \"offset\": [-1870.7617288436586, 722.9064918379887]}, \"groupNodes\": {}, \"0246.VERSION\": [0, 0, 4], \"workspace_info\": {\"id\": \"PUhXP5KXmQZ1xJnLdIUiE\", \"saveLock\": false, \"cloudID\": null, \"coverMediaPath\": null}}, \"version\": 0.4, \"widget_idx_map\": {\"135\": {\"sampler_name\": 0}, \"136\": {\"noise_seed\": 0}, \"137\": {\"scheduler\": 0}}, \"seed_widgets\": {\"136\": 0}}}",
            "steps": 25,
            "models": [],
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 3.5,
            "modelIds": [],
            "scheduler": "ddim_uniform",
            "upscalers": [
                "4xNomos8kSCHAT-L.pth"
            ],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": []
        },
        "username": "xu0831294",
        "baseModel": ""
    },
    {
        "id": 39265292,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c10604a7-3a25-4db7-a8c0-5ab843fbd1e9/width=1792/c10604a7-3a25-4db7-a8c0-5ab843fbd1e9.jpeg",
        "hash": "U59Q,JM{MwNc_N%2E1R%?wtRDiWFs*XT%gDi",
        "width": 1792,
        "height": 2304,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-09T23:47:12.421Z",
        "postId": 8959932,
        "stats": {
            "cryCount": 0,
            "laughCount": 8,
            "likeCount": 222,
            "dislikeCount": 0,
            "heartCount": 54,
            "commentCount": 1
        },
        "meta": {
            "Size": "512x512",
            "seed": 1047406003911984,
            "Model": "Flux_Dev_FP8",
            "steps": 44,
            "hashes": {
                "model": "",
                "LORA:models\\Flux\\aidmaMJ6.1-FLUX-v0.4": "08089fc88b",
                "LORA:models\\Flux\\The_Deep_Abyss-000021": "bbe085060d",
                "LORA:models\\Flux\\custom\\apostle-of-decay-2-000019": "77209140d6",
                "LORA:models\\Flux\\custom\\psychedelic-cyberpunk-000005": "a28b1bccff"
            },
            "prompt": "chaotic distorted image composition of a transparent cyborg buried among translucent tubing connected, abandoned organic decay  <lora:models\\Flux\\aidmaMJ6.1-FLUX-v0.4:0.3>, <lora:models\\Flux\\custom\\psychedelic-cyberpunk-000005:0.55>, <lora:models\\Flux\\custom\\apostle-of-decay-2-000019:0.5>, <lora:models\\Flux\\The_Deep_Abyss-000021:0.6> 4byss, rainbow holographic prismatic iridescent multi-colored ornate glossy material, hard plastic, black tar ooze, tubing, surreal, global illumination, volumetric lighting, atmospheric haze, dense fog, sharp focus, selective focus, soft focus, dof, depth of field, specular occlusion ambient lighting, god rays, anaglyphic distortions, rainbow light prism explosions",
            "Version": "ComfyUI",
            "sampler": "Euler",
            "cfgScale": 1,
            "resources": [],
            "Model hash": "",
            "negativePrompt": "----- NO NEGATIVE PROMPT USED -----"
        },
        "username": "psychedelic_cyberpunk",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 38983812,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/827ef1a5-27e1-466a-a154-45e3066db7e5/width=832/827ef1a5-27e1-466a-a154-45e3066db7e5.jpeg",
        "hash": "UIGI43xpIU?G~BNHD*NfS6IVRPbv_2s+jY^i",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-08T08:06:18.784Z",
        "postId": 8896343,
        "stats": {
            "cryCount": 19,
            "laughCount": 27,
            "likeCount": 179,
            "dislikeCount": 0,
            "heartCount": 59,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 540054746,
            "extra": {
                "remixOfId": 34739979
            },
            "steps": 25,
            "prompt": "surreal fantasy theme, beautiful hero women, in golden armor, armed with swords and shield, battle stance, fearsome dragon attacking with fire, on a mountaintop overlooking a deep gorge, viewed from behind, dark fantasy, dreamlike, max details, dynamic, great lighting, perfect shading, atmospheric, best quality, sharp focus, high contrast, stylized, clear, surreal, ultra quality, 8k, best quality, masterpiece, midjourneyv6.1",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 8.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-11-05T1017:44.4323109Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 641087,
                    "modelVersionName": "v9.0"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 137124,
                    "modelVersionName": "v1.0 SDXL"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 627153,
                    "modelVersionName": "SDXL"
                },
                {
                    "type": "lora",
                    "weight": 0.8,
                    "modelVersionId": 723149,
                    "modelVersionName": "SDXL"
                }
            ]
        },
        "username": "martinffm_pg",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 38890357,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f5ede8c0-ad1f-42a1-8f8a-4dc6e738d7f1/width=1248/f5ede8c0-ad1f-42a1-8f8a-4dc6e738d7f1.jpeg",
        "hash": "U7BfOh4o0#~BDOpItRrq=xNH9axtAD-UsVNc",
        "width": 1248,
        "height": 1824,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-07T20:02:55.582Z",
        "postId": 8875402,
        "stats": {
            "cryCount": 0,
            "laughCount": 2,
            "likeCount": 208,
            "dislikeCount": 0,
            "heartCount": 74,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1653948096,
            "Model": "PonyRealism_v2.2_VAE",
            "steps": 30,
            "hashes": {
                "model": "7c97ecf786",
                "lora:zy_Realism_Enhancer_v1": "610934a2f133"
            },
            "prompt": "score_9, score_8_up, score_7_up, redhead woman, library, reading, sit, cozy, highly detailed, film grain, <lora:zy_Realism_Enhancer_v1:0.75>",
            "Version": "v1.10.1",
            "sampler": "DPM++ SDE",
            "Template": {
                "zy_Realism_Enhancer_v1": "0.75>"
            },
            "cfgScale": 6,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "610934a2f133",
                    "name": "zy_Realism_Enhancer_v1",
                    "type": "lora",
                    "weight": 0.75
                },
                {
                    "hash": "7c97ecf786",
                    "name": "PonyRealism_v2.2_VAE",
                    "type": "model"
                }
            ],
            "Model hash": "7c97ecf786",
            "Schedule type": "Karras",
            "negativePrompt": "score_6, score_5, score_4, text, censored, deformed, bad hand",
            "ADetailer model": "mediapipe_face_full",
            "ADetailer version": "24.8.0",
            "Negative Template": {},
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "Downcast alphas_cumprod": "True",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "ZyloO",
        "baseModel": "Pony"
    },
    {
        "id": 38637718,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ae40f5fb-8fb9-4024-b492-5a7ff0330f4c/width=1344/ae40f5fb-8fb9-4024-b492-5a7ff0330f4c.jpeg",
        "hash": "UNAv9xxID~R%J4bEjXR%t7j[NDWA=*sqRioM",
        "width": 1344,
        "height": 1728,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-11-06T08:54:52.913Z",
        "postId": 8819106,
        "stats": {
            "cryCount": 9,
            "laughCount": 24,
            "likeCount": 190,
            "dislikeCount": 0,
            "heartCount": 61,
            "commentCount": 0
        },
        "meta": {
            "Size": "896x1152",
            "seed": 2445827458,
            "Model": "flux1-dev-bnb-nf4-v2",
            "steps": 25,
            "hashes": {
                "model": "bea01d51bd",
                "lora:ImageUpgraderV2": "e5598e0ef11d",
                "lora:flux_dev_flmft5": "1C835C0967",
                "lora:artisketchyfs-v02": "2097f7b0e740",
                "lora:dark_fantasy_flux": "6E5F580C0E",
                "lora:FredFraiStyle-FLUX-Share": "63BFAA1CF9",
                "lora:flux.1_lora_flyway_Epic-Characters_v1": "B73E077D02BF"
            },
            "Version": "f2.0.1v1.10.1-previous-450-gdb6448df",
            "sampler": "Euler",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "63BFAA1CF9",
                    "name": "FredFraiStyle-FLUX-Share",
                    "type": "lora"
                },
                {
                    "hash": "6E5F580C0E",
                    "name": "dark_fantasy_flux",
                    "type": "lora"
                },
                {
                    "hash": "e5598e0ef11d",
                    "name": "ImageUpgraderV2",
                    "type": "lora"
                },
                {
                    "hash": "2097f7b0e740",
                    "name": "artisketchyfs-v02",
                    "type": "lora"
                },
                {
                    "hash": "1C835C0967",
                    "name": "flux_dev_flmft5",
                    "type": "lora"
                },
                {
                    "hash": "B73E077D02BF",
                    "name": "flux.1_lora_flyway_Epic-Characters_v1",
                    "type": "lora"
                },
                {
                    "hash": "bea01d51bd",
                    "name": "flux1-dev-bnb-nf4-v2",
                    "type": "model"
                }
            ],
            "Model hash": "bea01d51bd",
            "Hires steps": "20",
            "Hires prompt": {
                "dark_fantasy_flux": "0.9>"
            },
            "Hires upscale": "1.5",
            "Schedule type": "Normal",
            "Hires upscaler": "4x-UltraSharp",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.8.0",
            "Denoising strength": "0.25",
            "ADetailer mask blur": "10",
            "Distilled CFG Scale": "3.1",
            "ADetailer confidence": "0.3",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint width": "768",
            "ADetailer inpaint height": "1024",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.2",
            "ADetailer inpaint only masked": "True",
            "ADetailer use inpaint width height": "True"
        },
        "username": "ArtifyAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 37423388,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3c117dd4-0904-4685-a96c-2cc8dba8f41a/width=832/3c117dd4-0904-4685-a96c-2cc8dba8f41a.jpeg",
        "hash": "UfMX.Bt2-UxZ~AoJkCs.-pWBNHsor^xGRljG",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-30T18:09:48.295Z",
        "postId": 8547200,
        "stats": {
            "cryCount": 6,
            "laughCount": 18,
            "likeCount": 200,
            "dislikeCount": 0,
            "heartCount": 60,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 768934788,
            "steps": 28,
            "prompt": "An elephant standing by a body of water in the savannah during sunset. The warm orange-pink hues of the sky are reflected in the water, creating a calm and peaceful atmosphere. The elephant stands majestically on the shore, its reflection clearly visible on the surface of the water. A lonely tree can be seen in the background",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-25T1732:13.7401624Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 0.7,
                    "modelVersionId": 857586,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 0.9,
                    "modelVersionId": 959406,
                    "modelVersionName": "FLUX V2"
                },
                {
                    "type": "lora",
                    "weight": 0.85,
                    "modelVersionId": 753053,
                    "modelVersionName": "Flux Original"
                },
                {
                    "type": "lora",
                    "weight": 0.65,
                    "modelVersionId": 806265,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "AtomGirl",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 36013804,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6b661eb4-e3f6-4714-9ebb-b785fa887fe5/width=1800/6b661eb4-e3f6-4714-9ebb-b785fa887fe5.jpeg",
        "hash": "U7EfZ@_N00I99ZxYHq9GAdoe8^-o-;?H={n}",
        "width": 3840,
        "height": 6720,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-23T08:00:00.000Z",
        "postId": 8228213,
        "stats": {
            "cryCount": 6,
            "laughCount": 14,
            "likeCount": 186,
            "dislikeCount": 0,
            "heartCount": 78,
            "commentCount": 2
        },
        "meta": null,
        "username": "MrSana",
        "baseModel": "Pony"
    },
    {
        "id": 35639242,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/576f8d78-1903-420a-bcc4-d593d4eac219/width=832/576f8d78-1903-420a-bcc4-d593d4eac219.jpeg",
        "hash": "UPMY{RIA_NxH^7-qODpHxvW;tktk?a%Ltk9Z",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-20T18:30:41.637Z",
        "postId": 8143346,
        "stats": {
            "cryCount": 7,
            "laughCount": 13,
            "likeCount": 207,
            "dislikeCount": 0,
            "heartCount": 57,
            "commentCount": 0
        },
        "meta": null,
        "username": "DoreenAI",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 35504107,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8b1fe016-fa5b-48c6-b107-26df2d52ee5e/width=1248/8b1fe016-fa5b-48c6-b107-26df2d52ee5e.jpeg",
        "hash": "UJG8+hD*AtTKyZ$%tlTKt-MyxcXA5aIU%goh",
        "width": 1248,
        "height": 1872,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-20T00:12:17.093Z",
        "postId": 8113016,
        "stats": {
            "cryCount": 7,
            "laughCount": 2,
            "likeCount": 191,
            "dislikeCount": 0,
            "heartCount": 84,
            "commentCount": 4
        },
        "meta": {
            "RNG": "CPU",
            "VAE": "sdxl_vae.safetensors",
            "Size": "832x1248",
            "seed": 2865308968,
            "Model": "incursiosMemeDiffusion_v27PDXL",
            "steps": 28,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "5e37c6849c",
                "lora:kouzukikallen-pdxl-nvwls-v1-000006": "95ea59639ecf"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, source_anime, 1girl, solo, <lora:kouzukikallen-pdxl-nvwls-v1-000006:1> kouklln, red hair, flipped hair, short hair, blue eyes, red headband, large breasts, purple kimono, wide sleeves, sash, kneeling, blue sky, field, flowers, looking at you, happy, off-shoulder kimono",
            "Version": "f0.0.20.1dev-v1.10.0RC-latest-685-gf033e578",
            "sampler": "Euler a",
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "95ea59639ecf",
                    "name": "kouzukikallen-pdxl-nvwls-v1-000006",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "5e37c6849c",
                    "name": "incursiosMemeDiffusion_v27PDXL",
                    "type": "model"
                }
            ],
            "Model hash": "5e37c6849c",
            "Hires steps": "10",
            "Hires upscale": "1.5",
            "Schedule type": "Automatic",
            "Hires upscaler": "4x-AnimeSharp",
            "negativePrompt": "monochrome, greyscale, 3d",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.4.2",
            "Denoising strength": "0.5",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "ADetailer inpaint only masked": "True"
        },
        "username": "novowels",
        "baseModel": "Pony"
    },
    {
        "id": 35132769,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7d0c73bf-4438-46af-94d2-319e178a4a2a/width=832/7d0c73bf-4438-46af-94d2-319e178a4a2a.jpeg",
        "hash": "UHHBuH00lowang%LIp%19Ft,,.Ipm+k=t6D*",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-10-18T07:00:00.000Z",
        "postId": 8029862,
        "stats": {
            "cryCount": 4,
            "laughCount": 16,
            "likeCount": 204,
            "dislikeCount": 0,
            "heartCount": 60,
            "commentCount": 6
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1215549446,
            "extra": {
                "remixOfId": 12036350
            },
            "steps": 4,
            "prompt": "a Glamorous woman,Bushy hair,Blond hair,own hands together,pristine beaches of the Seychelles are the perfect place to relax and unwind,style by Edward OkuA,High quality lots of details Magic Realism,Fuji superia 400,soft lighting",
            "sampler": "Undefined",
            "cfgScale": 1,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-17T2110:47.3918717Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 699279,
                    "modelVersionName": "Schnell"
                }
            ]
        },
        "username": null,
        "baseModel": "Flux.1 D"
    },
    {
        "id": 33910085,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9b10c194-208f-4c67-a6a5-082de1eb12ae/width=1248/9b10c194-208f-4c67-a6a5-082de1eb12ae.jpeg",
        "hash": "UpNTj{j]~qxa_3%MofM{tQIUt7ofM{RjWBxa",
        "width": 1248,
        "height": 1824,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-10T23:49:28.061Z",
        "postId": 7752212,
        "stats": {
            "cryCount": 8,
            "laughCount": 14,
            "likeCount": 179,
            "dislikeCount": 0,
            "heartCount": 83,
            "commentCount": 0
        },
        "meta": {
            "": {},
            "VAE": "sdxl_vae_fixed.safetensors",
            "Size": "1248x1824",
            "seed": 2191944694,
            "Model": "prefect_pony_xl_v3.fp16",
            "steps": 20,
            "hashes": {
                "vae": "235745af8d",
                "model": "e31a2563f0",
                "lora:jima_style_pdxl_goofy": "1d857b56d69c"
            },
            "prompt": "score_9,score_8_up,score_7_up, <lora:jima_style_pdxl_goofy:1>1girl, alternate costume, animal ears, asymmetrical bangs, black hair, black skirt, breasts, closed mouth, cowboy shot, eyebrow piercing, horse ears, horse girl, horse tail, long hair, looking at another, looking at viewer, piercing, school uniform, shirt, short sleeves, simple background, skirt, small breasts, solo, tail, tail through clothes, white background, white shirt, yellow eyes",
            "Version": "v1.10.1",
            "sampler": "DPM++ 2M",
            "{Method": {},
            "Upscaler": {},
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "1d857b56d69c",
                    "name": "jima_style_pdxl_goofy",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "e31a2563f0",
                    "name": "prefect_pony_xl_v3.fp16",
                    "type": "model"
                }
            ],
            "Model hash": "e31a2563f0",
            "Tile Overlap": "48",
            "Schedule type": "Karras",
            "Upscale factor": "1.5",
            "negativePrompt": "realistic,monochrome,greyscale, artist name, signature, watermark,",
            "ADetailer model": "face_yolov8n.pt",
            "Keep input size": "true}",
            "Tile batch size": "6",
            "Tile tile width": "160",
            "Tiled Diffusion": {},
            "Tile tile height": "160",
            "ADetailer version": "24.8.0",
            "Denoising strength": "0.3",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "Tiled Diffusion upscaler": "4x-UltraSharp",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "Tiled Diffusion scale factor": "1.5",
            "ADetailer inpaint only masked": "True"
        },
        "username": "Goofy_Ai",
        "baseModel": "Pony"
    },
    {
        "id": 33765823,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a236a923-99b2-4e2a-b11d-184ebc0c54a8/width=864/a236a923-99b2-4e2a-b11d-184ebc0c54a8.jpeg",
        "hash": "UHFOGr$%Y5tR}@niOXoz9uWWxaR+OXs:R+NG",
        "width": 864,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-10T02:41:06.459Z",
        "postId": 7720107,
        "stats": {
            "cryCount": 9,
            "laughCount": 22,
            "likeCount": 178,
            "dislikeCount": 0,
            "heartCount": 75,
            "commentCount": 0
        },
        "meta": {
            "RNG": "NV",
            "VAE": "sdxl_vae.safetensors",
            "Size": "864x1152",
            "seed": 818817364,
            "Model": "autismmixSDXL_autismmixPony",
            "steps": 30,
            "hashes": {
                "vae": "63aeecb90f",
                "model": "821aa5537f",
                "lora:MerryRemembrancerXLP": "228745bdad75"
            },
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up,  <lora:MerryRemembrancerXLP:1> merryremembrancer, 1girl, ginger hair, freckles, grey eyes,",
            "Version": "v1.10.1",
            "sampler": "Euler a",
            "cfgScale": 7,
            "clipSkip": 2,
            "resources": [
                {
                    "hash": "228745bdad75",
                    "name": "MerryRemembrancerXLP",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "821aa5537f",
                    "name": "autismmixSDXL_autismmixPony",
                    "type": "model"
                }
            ],
            "Model hash": "821aa5537f",
            "Schedule type": "Automatic",
            "negativePrompt": "watermark, signature, artist name, twitter username, censored, realistic,",
            "ADetailer model": "face_yolov8n.pt",
            "ADetailer version": "24.9.0",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.3",
            "ADetailer inpaint only masked": "True"
        },
        "username": "freckledvixon",
        "baseModel": "Pony"
    },
    {
        "id": 33729350,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f523705f-2cee-4da6-95fa-883701b8b962/width=832/f523705f-2cee-4da6-95fa-883701b8b962.jpeg",
        "hash": "UMBC}j%#9F4n~Vx]E1D%r=WBSgn+VsRjW;xZ",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-10-09T22:18:38.244Z",
        "postId": 7712666,
        "stats": {
            "cryCount": 3,
            "laughCount": 12,
            "likeCount": 204,
            "dislikeCount": 0,
            "heartCount": 65,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1189842738,
            "steps": 30,
            "prompt": "Dark gothic oil painting, vampire lord portrait: left side aristocratic pale skin, right side monstrous bat-like features. Divide is a stream of crimson blood.",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-10-09T1933:35.7509059Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 828027,
                    "modelVersionName": "v2.0"
                },
                {
                    "type": "lora",
                    "weight": 0.9,
                    "modelVersionId": 930954,
                    "modelVersionName": "V1"
                }
            ]
        },
        "username": "ledadu",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 31831951,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ca5a4ece-ddc8-40f2-acb7-81e1ac894379/width=1800/ca5a4ece-ddc8-40f2-acb7-81e1ac894379.jpeg",
        "hash": "UBAmJjm753p{UHIUrWtkBLNFrrt3=L$mNHs.",
        "width": 3072,
        "height": 1280,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-29T00:37:12.025Z",
        "postId": 7244952,
        "stats": {
            "cryCount": 0,
            "laughCount": 12,
            "likeCount": 207,
            "dislikeCount": 0,
            "heartCount": 65,
            "commentCount": 2
        },
        "meta": {
            "RNG": "CPU",
            "Size": "1920x800",
            "seed": 88888888,
            "Model": "atomix_flux-nf4",
            "steps": 48,
            "hashes": {
                "model": "dab1841294",
                "lora:image_enhancer-flux-by_dever": "471ee7052a",
                "lora:style-alena_aenami-flux-by_tangbohu": "a0437717f2",
                "lora:style-fantastic_landscapes-flux-by_artifyai": "e8572fc2c4",
                "lora:style-midjourney_whisper_chromaplex-flux-by_aihonobono2023": "ef7f80c497"
            },
            "prompt": "(dramatic scene:1.4), (fractal art:0.5), gothic fantasy style, dynamic angle, this (bioluminescent organism:1.3), the \"lively cragtribble\" with its iridescent hide hunts hazzarblinked (colorful insects:1.1) in the vibrant primeval forests on planet \"koldball iii\", its ripturbined body casting a soft, pulsing glow on the zurbled surroundings, extremely detailed and intricate background, style of alena aenami, <lora:style-alena_aenami-flux-by_tangbohu:0.6> <lora:style-midjourney_whisper_chromaplex-flux-by_aihonobono2023:0.4> <lora:style-fantastic_landscapes-flux-by_artifyai:0.44> <lora:image_enhancer-flux-by_dever:0.6>",
            "Version": "f2.0.1v1.10.1-previous-537-g95b54a27",
            "sampler": "Euler",
            "cfgScale": 1,
            "resources": [
                {
                    "name": "style-alena_aenami-flux-by_tangbohu",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "name": "style-midjourney_whisper_chromaplex-flux-by_aihonobono2023",
                    "type": "lora",
                    "weight": 0.4
                },
                {
                    "name": "style-fantastic_landscapes-flux-by_artifyai",
                    "type": "lora",
                    "weight": 0.44
                },
                {
                    "name": "image_enhancer-flux-by_dever",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "hash": "6408576a5b",
                    "name": "atomix_flux-nf4",
                    "type": "model"
                }
            ],
            "Model hash": "6408576a5b",
            "Hires steps": "36",
            "Hires upscale": "1.6",
            "Schedule type": "Simple",
            "Hires upscaler": "4x_nomos8khat-l_otf",
            "Hires CFG Scale": "1",
            "Denoising strength": "0.36",
            "Distilled CFG Scale": "4",
            "Diffusion in Low Bits": "Automatic (fp16 LoRA)",
            "Hires Distilled CFG Scale": "5"
        },
        "username": "OneViolentGentleman",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 31430776,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc0babe5-5139-482c-a1d5-5b40939b0316/width=832/bc0babe5-5139-482c-a1d5-5b40939b0316.jpeg",
        "hash": "UGM%TPtRUH%2-hoMKQbat,MxH?x]I9xu.9RQ",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-26T11:48:46.930Z",
        "postId": 7025757,
        "stats": {
            "cryCount": 7,
            "laughCount": 17,
            "likeCount": 190,
            "dislikeCount": 0,
            "heartCount": 70,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1963637639,
            "extra": {
                "remixOfId": 30588493
            },
            "steps": 14,
            "prompt": "score_4,score_5,score_6,score_7_up,score_8_up,score_9\n((masterpiece,best quality,ultra detailed,highres,HD,4k:1.2)),\n1girl, solo, girl forcus,solo forcus,\njyuukyuu, flat color, deformed, deformed characters, round face,\n((mob face,black eyes, eyes filled with black)),\npokemonirida, blonde hair,  hair between eyes, medium hair,\nbracelet, hairband, jewelry, neck ring, red headwear, red shirt, sash, shirt, shorts, strapless, strapless shirt, waist cape, white shorts,\nsmile,happy smile,Smiling with teeth showing,",
            "sampler": "DPM++ 2M Karras",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-26T1153:11.0576967Z",
            "negativePrompt": "(Macho, muscular, old man, fat man,Nostrils,\n,text,yuri,roll one \u0019s eyes:1.5),(worst quality, low quality:1.4), (patreon username, patreon logo, signature, watermark:1.0),easynegative,negative_hand-neg, bad-hands-5,low quality,bad-hands-5,extra limbs,missing limb,extra digit,fewer digit,missing digit,missing fingers,mutated hands and fingers,fused limb,bad hands,long neck,long body,bad anatomy,disfigured,deformed,poorly drawn,mutation,extra nippless,extra breasts,disembodied penis,",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 828380,
                    "modelVersionName": "v3"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 846059,
                    "modelVersionName": "V1"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 418364,
                    "modelVersionName": "booru"
                },
                {
                    "type": "embed",
                    "modelVersionId": 106916,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "mramra54620",
        "baseModel": "Pony"
    },
    {
        "id": 31275975,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/edf75ccb-cfcc-4ac1-bcd1-d6c3e9f4dadf/width=832/edf75ccb-cfcc-4ac1-bcd1-d6c3e9f4dadf.jpeg",
        "hash": "UBF;f%JA03$*57bFS0ah01ay~TR*1P$f^JX8",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-25T13:18:34.189Z",
        "postId": 6991678,
        "stats": {
            "cryCount": 1,
            "laughCount": 17,
            "likeCount": 216,
            "dislikeCount": 0,
            "heartCount": 50,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 1571339515,
            "steps": 30,
            "sampler": "Undefined",
            "cfgScale": 5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-25T1307:10.1547865Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                },
                {
                    "type": "lora",
                    "weight": 1.8,
                    "modelVersionId": 887624,
                    "modelVersionName": "Variant 2"
                },
                {
                    "type": "lora",
                    "weight": 0.4,
                    "modelVersionId": 720252,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": "Regiiina",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 31156128,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c573a94d-6d2e-4fba-9f00-ba1f34f46ed7/width=768/c573a94d-6d2e-4fba-9f00-ba1f34f46ed7.jpeg",
        "hash": "UQ6b=onhtmV?yGi^bbayi]V=ROkXi^V@V@bI",
        "width": 768,
        "height": 1344,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-24T20:03:32.821Z",
        "postId": 6964083,
        "stats": {
            "cryCount": 2,
            "laughCount": 14,
            "likeCount": 208,
            "dislikeCount": 0,
            "heartCount": 60,
            "commentCount": 1
        },
        "meta": {
            "seed": 1071132755450175,
            "vaes": [
                "FLUX-ae.safetensors"
            ],
            "comfy": "{\"prompt\": {\"6\": {\"inputs\": {\"text\": \"a powerful young female mage with long dark hair and intricate robes. She holds a glowing magical staff, set against a futuristic, neon-lit circuit board landscape. The image should feature ultra-realistic textures and ultra-high definition, with photorealistic details and natural, dynamic lighting. The mage is in a pensive pose, with a thoughtful expression and her gaze directed downward. The overall style should have a cinematic quality, with highly detailed and realistic textures and shadows, showcasing hyperrealism.\", \"speak_and_recognation\": true, \"clip\": [\"228\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"222\", 1], \"vae\": [\"229\", 0]}, \"class_type\": \"VAEDecode\"}, \"128\": {\"inputs\": {\"filename_prefix\": \"bailing9\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"222\": {\"inputs\": {\"noise\": [\"223\", 0], \"guider\": [\"224\", 0], \"sampler\": [\"226\", 0], \"sigmas\": [\"225\", 0], \"latent_image\": [\"233\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"223\": {\"inputs\": {\"noise_seed\": 1071132755450175}, \"class_type\": \"RandomNoise\"}, \"224\": {\"inputs\": {\"model\": [\"231\", 0], \"conditioning\": [\"6\", 0]}, \"class_type\": \"BasicGuider\"}, \"225\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 22, \"denoise\": 1.0, \"model\": [\"231\", 0]}, \"class_type\": \"BasicScheduler\"}, \"226\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"228\": {\"inputs\": {\"clip_name1\": \"sd3\\\\t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"sd3\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"229\": {\"inputs\": {\"vae_name\": \"FLUX-ae.safetensors\"}, \"class_type\": \"VAELoader\"}, \"231\": {\"inputs\": {\"unet_name\": \"\\u81ea\\u7ec3flux\\\\flux_bailing_0912-8_00003_.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"233\": {\"inputs\": {\"width\": 768, \"height\": 1344, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"234\": {\"inputs\": {\"lora_name\": \"FLUX\\\\FL-bailing-24-0911monochromatic8p.safetensors\", \"strength_model\": 1, \"model\": [\"231\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}}, \"workflow\": {\"last_node_id\": 235, \"last_link_id\": 31, \"nodes\": [{\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1885.199951171875, \"1\": 130}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 15, \"label\": \"Latent\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 16, \"label\": \"VAE\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [17], \"shape\": 3, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 222, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1430, \"1\": 130}, \"size\": {\"0\": 355.20001220703125, \"1\": 326}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 18, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 19, \"label\": \"\\u5f15\\u5bfc\"}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 20, \"label\": \"\\u91c7\\u6837\\u5668\"}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 21, \"label\": \"Sigmas\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 22, \"label\": \"Latent\"}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3, \"label\": \"\\u8f93\\u51fa\"}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [15], \"shape\": 3, \"label\": \"\\u964d\\u566a\\u8f93\\u51fa\"}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 223, \"type\": \"RandomNoise\", \"pos\": {\"0\": 100, \"1\": 130}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [18], \"shape\": 3, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [1071132755450175, \"randomize\"]}, {\"id\": 224, \"type\": \"BasicGuider\", \"pos\": {\"0\": 1015, \"1\": 130}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 31, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 24, \"label\": \"\\u6761\\u4ef6\"}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [19], \"shape\": 3, \"label\": \"\\u5f15\\u5bfc\"}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 225, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1015, \"1\": 306}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 30, \"label\": \"\\u6a21\\u578b\"}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [21], \"shape\": 3, \"label\": \"Sigmas\"}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 22, 1]}, {\"id\": 226, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 100, \"1\": 342}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [20], \"shape\": 3, \"label\": \"\\u91c7\\u6837\\u5668\"}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 229, \"type\": \"VAELoader\", \"pos\": {\"0\": 100, \"1\": 766}, \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [16], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX-ae.safetensors\"]}, {\"id\": 228, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": -21, \"1\": 499}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [27], \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"sd3\\\\t5xxl_fp8_e4m3fn.safetensors\", \"sd3\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 235, \"type\": \"Lora Loader Stack (rgthree)\", \"pos\": {\"0\": 346, \"1\": 462}, \"size\": {\"0\": 633.6495971679688, \"1\": 268.7115173339844}, \"flags\": {}, \"order\": 7, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 29, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 27, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [30, 31], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [28], \"slot_index\": 1, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"Lora Loader Stack (rgthree)\"}, \"widgets_values\": [\"FLUX\\\\FL-bailing-24-0823Threads of light-000010.safetensors\", 0.8, \"FLUX\\\\FL-bailing-24-00826flower10p.safetensors\", 0.3, \"None\", 0.4, \"None\", 0.4]}, {\"id\": 231, \"type\": \"UNETLoader\", \"pos\": {\"0\": 100, \"1\": 954}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [26, 29], \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"\\u81ea\\u7ec3flux\\\\flux_bailing_0912-8_00003_.safetensors\", \"fp8_e4m3fn\"]}, {\"id\": 234, \"type\": \"LoraLoaderModelOnly\", \"pos\": {\"0\": -248, \"1\": 757}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 26, \"label\": \"\\u6a21\\u578b\"}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"FLUX\\\\FL-bailing-24-0911monochromatic8p.safetensors\", 1]}, {\"id\": 128, \"type\": \"SaveImage\", \"pos\": {\"0\": 2195.199951171875, \"1\": 130}, \"size\": [483.41351923892216, 353.436045625878], \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 17, \"label\": \"\\u56fe\\u50cf\"}], \"outputs\": [], \"properties\": {}, \"widgets_values\": [\"bailing9\"]}, {\"id\": 233, \"type\": \"EmptyLatentImage\", \"pos\": {\"0\": 1008, \"1\": 466}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [22], \"shape\": 3, \"label\": \"Latent\"}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [768, 1344, 1]}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 486, \"1\": 197}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 28, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [24], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6761\\u4ef6\"}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"a powerful young female mage with long dark hair and intricate robes. She holds a glowing magical staff, set against a futuristic, neon-lit circuit board landscape. The image should feature ultra-realistic textures and ultra-high definition, with photorealistic details and natural, dynamic lighting. The mage is in a pensive pose, with a thoughtful expression and her gaze directed downward. The overall style should have a cinematic quality, with highly detailed and realistic textures and shadows, showcasing hyperrealism.\", true]}], \"links\": [[15, 222, 1, 8, 0, \"LATENT\"], [16, 229, 0, 8, 1, \"VAE\"], [17, 8, 0, 128, 0, \"IMAGE\"], [18, 223, 0, 222, 0, \"NOISE\"], [19, 224, 0, 222, 1, \"GUIDER\"], [20, 226, 0, 222, 2, \"SAMPLER\"], [21, 225, 0, 222, 3, \"SIGMAS\"], [22, 233, 0, 222, 4, \"LATENT\"], [24, 6, 0, 224, 1, \"CONDITIONING\"], [26, 231, 0, 234, 0, \"MODEL\"], [27, 228, 0, 235, 1, \"CLIP\"], [28, 235, 1, 6, 0, \"CLIP\"], [29, 231, 0, 235, 0, \"MODEL\"], [30, 235, 0, 225, 0, \"MODEL\"], [31, 235, 0, 224, 0, \"MODEL\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.1167815779424761, \"offset\": [294.5207261783059, 231.97035183748042]}}, \"version\": 0.4, \"widget_idx_map\": {\"223\": {\"noise_seed\": 0}, \"225\": {\"scheduler\": 0}, \"226\": {\"sampler_name\": 0}}}}",
            "steps": 22,
            "width": 768,
            "height": 1344,
            "models": [],
            "prompt": "a powerful young female mage with long dark hair and intricate robes. She holds a glowing magical staff, set against a futuristic, neon-lit circuit board landscape. The image should feature ultra-realistic textures and ultra-high definition, with photorealistic details and natural, dynamic lighting. The mage is in a pensive pose, with a thoughtful expression and her gaze directed downward. The overall style should have a cinematic quality, with highly detailed and realistic textures and shadows, showcasing hyperrealism.",
            "denoise": 1,
            "sampler": "Euler",
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "FLUX\\FL-bailing-24-0911monochromatic8p.safetensors",
                    "type": "lora",
                    "strength": 1
                }
            ]
        },
        "username": "bailing_SHAN",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 31110463,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/df0ca407-cfa9-4fc5-994c-26aa0acd362a/width=832/df0ca407-cfa9-4fc5-994c-26aa0acd362a.jpeg",
        "hash": "U6L3[S?u00={L}M|9knh00R5~pjI00WC~ks;",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-24T13:04:01.837Z",
        "postId": 6954429,
        "stats": {
            "cryCount": 14,
            "laughCount": 60,
            "likeCount": 151,
            "dislikeCount": 0,
            "heartCount": 59,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 3688303119,
            "Model": "flux1-dev-fp8",
            "steps": 30,
            "hashes": {
                "model": "275ef623d3",
                "lora:Yu-Gi-Oh_Flux_Cards": "08a217236b7a"
            },
            "prompt": "yugioh card \"Buzz Collector\", Effect Monster, effect-frame, 5000 ATK, 2500 DEF, Level 8, Race: Spellcaster, attribute: LIGHT, Card Text:\"When you see this card, you must give Buzz.\"., Perfect english text with detailed font, 1girl, solo, blonde hair, blue eyes, beg,cadge, close-up, begging, <lora:Yu-Gi-Oh_Flux_Cards:1>",
            "Version": "f2.0.1v1.10.1-previous-538-ga82d5d17",
            "sampler": "Euler",
            "Module 1": "ae",
            "Module 2": "clip_l",
            "Module 3": "t5xxl_fp8_e4m3fn",
            "cfgScale": 1,
            "resources": [
                {
                    "hash": "08a217236b7a",
                    "name": "Yu-Gi-Oh_Flux_Cards",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "275ef623d3",
                    "name": "flux1-dev-fp8",
                    "type": "model"
                }
            ],
            "Model hash": "275ef623d3",
            "Schedule type": "Simple",
            "Distilled CFG Scale": "3.5"
        },
        "username": "SysDeep",
        "baseModel": ""
    },
    {
        "id": 30733747,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2017b0fc-da37-40d4-97ab-c88d6ff1f756/width=832/2017b0fc-da37-40d4-97ab-c88d6ff1f756.jpeg",
        "hash": "U4566iH@00?^tRMwbcx]8wt7%gM{Di%#xuDj",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-22T10:50:57.033Z",
        "postId": 6874471,
        "stats": {
            "cryCount": 5,
            "laughCount": 7,
            "likeCount": 213,
            "dislikeCount": 0,
            "heartCount": 59,
            "commentCount": 1
        },
        "meta": {
            "seed": 637493442796758,
            "vaes": [
                "ae.safetensors"
            ],
            "comfy": "{\"prompt\": {\"5\": {\"inputs\": {\"width\": [\"76\", 0], \"height\": [\"73\", 0], \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"6\": {\"inputs\": {\"text\": [\"74\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"cui\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"10\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"5\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 20, \"denoise\": 1.0, \"model\": [\"61\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"61\", 0], \"conditioning\": [\"60\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 637493442796758}, \"class_type\": \"RandomNoise\"}, \"60\": {\"inputs\": {\"guidance\": 3.5, \"conditioning\": [\"6\", 0]}, \"class_type\": \"FluxGuidance\"}, \"61\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5, \"width\": [\"76\", 0], \"height\": [\"73\", 0], \"model\": [\"72\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"72\": {\"inputs\": {\"lora_name\": \"aidmaMJ6.1-FLUX-V0.1.safetensors\", \"strength_model\": 0.5, \"model\": [\"12\", 0]}, \"class_type\": \"LoraLoaderModelOnly\"}, \"73\": {\"inputs\": {\"int\": 1216}, \"class_type\": \"Int Literal (Image Saver)\"}, \"74\": {\"inputs\": {\"string\": \"A masterpiece of wane style created by the collaboration of H.R. Giger and Friedrich Stuhl.    In this photo, the concept of \\\"wane\\\" is depicted through a striking and ethereal scene. The foreground showcases a crescent moon that appears almost like a thin sliver in the night sky, emphasizing its waning phase. Surrounding the moon are wispy clouds that seem to emanate from it, as if the moon is exhaling a gentle, glowing mist.In the background, a vast expanse of darkened clouds rolls over a tranquil sea, with only a few stars twinkling intermittently. The water reflects the diminishing light of the waning moon, creating ripples and waves that shimmer faintly under the remaining lunar glow. A lone, ancient lighthouse stands on a rocky promontory, its beacon still flickering, casting long shadows over the tranquil waters.The overall atmosphere is one of quiet beauty and a sense of something fading away, encapsulating the essence of \\\"wane\\\" in both its literal astronomical meaning and a broader metaphorical sense.    HD32K, hyperdetailed, best quality, midjourneyv6.1.\"}, \"class_type\": \"String Literal (Image Saver)\"}, \"76\": {\"inputs\": {\"int\": 832}, \"class_type\": \"Int Literal (Image Saver)\"}}, \"workflow\": {\"last_node_id\": 76, \"last_link_id\": 115, \"nodes\": [{\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": [809, 261], \"size\": {\"0\": 268.2277526855469, \"1\": 58}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": [893.71875, 612.052001953125], \"size\": {\"0\": 196.9998779296875, \"1\": 62.66668701171875}, \"flags\": {\"collapsed\": false}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 94, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 87, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [30], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": [424.71875, 618.052001953125], \"size\": {\"0\": 210, \"1\": 54}, \"flags\": {\"collapsed\": false}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 108}, {\"name\": \"text\", \"type\": \"STRING\", \"link\": 109, \"widget\": {\"name\": \"text\"}, \"slot_index\": 1}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [86], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 61, \"type\": \"ModelSamplingFlux\", \"pos\": [774, 389], \"size\": {\"0\": 321.8402404785156, \"1\": 122}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 106}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"widget\": {\"name\": \"width\"}, \"slot_index\": 1}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 111, \"widget\": {\"name\": \"height\"}, \"slot_index\": 2}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [93, 94], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 1024, 1024]}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": [1106, -218], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [9], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": [26, 379], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": [18, 84], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [107], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"]}, {\"id\": 60, \"type\": \"FluxGuidance\", \"pos\": [659, 614], \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 86}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [87], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3.5], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 5, \"type\": \"EmptyLatentImage\", \"pos\": [422, 101], \"size\": {\"0\": 330.5548400878906, \"1\": 78}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 114, \"widget\": {\"name\": \"width\"}, \"slot_index\": 0}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 110, \"widget\": {\"name\": \"height\"}, \"slot_index\": 1}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [23], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 76, \"type\": \"Int Literal (Image Saver)\", \"pos\": [649, 796], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [114, 115], \"shape\": 3}], \"title\": \"width\\n\", \"properties\": {\"Node name for S&R\": \"Int Literal (Image Saver)\"}, \"widgets_values\": [832]}, {\"id\": 72, \"type\": \"LoraLoaderModelOnly\", \"pos\": [419, 403], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 107}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [106], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"LoraLoaderModelOnly\"}, \"widgets_values\": [\"aidmaMJ6.1-FLUX-V0.1.safetensors\", 0.5]}, {\"id\": 73, \"type\": \"Int Literal (Image Saver)\", \"pos\": [648, 902], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [110, 111], \"shape\": 3}], \"title\": \"height\\n\", \"properties\": {\"Node name for S&R\": \"Int Literal (Image Saver)\"}, \"widgets_values\": [1216]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": [22, 214], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [108], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\"]}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": [1584, 7], \"size\": {\"0\": 820.130859375, \"1\": 1215.3121337890625}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 9}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"cui\"]}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": [424, 236], \"size\": {\"0\": 327.1990661621094, \"1\": 94.58134460449219}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [637493442796758, \"randomize\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": [797, 94], \"size\": {\"0\": 281.2428283691406, \"1\": 106}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 93, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 20, 1]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": [1216, 87], \"size\": {\"0\": 352.4039611816406, \"1\": 463.3393859863281}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 30, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 23, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"shape\": 3, \"slot_index\": 0}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 74, \"type\": \"String Literal (Image Saver)\", \"pos\": [1130, 744], \"size\": {\"0\": 439.3828430175781, \"1\": 380.7576599121094}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"outputs\": [{\"name\": \"STRING\", \"type\": \"STRING\", \"links\": [109], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"String Literal (Image Saver)\"}, \"widgets_values\": [\"A masterpiece of wane style created by the collaboration of H.R. Giger and Friedrich Stuhl.    In this photo, the concept of \\\"wane\\\" is depicted through a striking and ethereal scene. The foreground showcases a crescent moon that appears almost like a thin sliver in the night sky, emphasizing its waning phase. Surrounding the moon are wispy clouds that seem to emanate from it, as if the moon is exhaling a gentle, glowing mist.In the background, a vast expanse of darkened clouds rolls over a tranquil sea, with only a few stars twinkling intermittently. The water reflects the diminishing light of the waning moon, creating ripples and waves that shimmer faintly under the remaining lunar glow. A lone, ancient lighthouse stands on a rocky promontory, its beacon still flickering, casting long shadows over the tranquil waters.The overall atmosphere is one of quiet beauty and a sense of something fading away, encapsulating the essence of \\\"wane\\\" in both its literal astronomical meaning and a broader metaphorical sense.    HD32K, hyperdetailed, best quality, midjourneyv6.1.\"]}], \"links\": [[9, 8, 0, 9, 0, \"IMAGE\"], [12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [23, 5, 0, 13, 4, \"LATENT\"], [24, 13, 0, 8, 0, \"LATENT\"], [30, 22, 0, 13, 1, \"GUIDER\"], [37, 25, 0, 13, 0, \"NOISE\"], [86, 6, 0, 60, 0, \"CONDITIONING\"], [87, 60, 0, 22, 1, \"CONDITIONING\"], [93, 61, 0, 17, 0, \"MODEL\"], [94, 61, 0, 22, 0, \"MODEL\"], [106, 72, 0, 61, 0, \"MODEL\"], [107, 12, 0, 72, 0, \"MODEL\"], [108, 11, 0, 6, 0, \"CLIP\"], [109, 74, 0, 6, 1, \"STRING\"], [110, 73, 0, 5, 1, \"INT\"], [111, 73, 0, 61, 2, \"INT\"], [114, 76, 0, 5, 0, \"INT\"], [115, 76, 0, 61, 1, \"INT\"]], \"groups\": [{\"title\": \"Load FLUX.1\", \"bounding\": [1, 2, 369, 693], \"color\": \"#3f789e\", \"font_size\": 24}, {\"title\": \"Set Parameters\", \"bounding\": [379, 0, 733, 526], \"color\": \"#3f789e\", \"font_size\": 24}, {\"title\": \"FLUX Prompt\", \"bounding\": [1130, 718, 368, 318], \"color\": \"#3f789e\", \"font_size\": 24}, {\"title\": \"Conditioning\", \"bounding\": [379, 535, 732, 159], \"color\": \"#3f789e\", \"font_size\": 24}, {\"title\": \"1st Pass\", \"bounding\": [1119, 0, 402, 693], \"color\": \"#3f789e\", \"font_size\": 24}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.895430243255241, \"offset\": [-199.9153915660461, -17.461235829689123]}}, \"version\": 0.4}}",
            "steps": 20,
            "width": 832,
            "height": 1216,
            "models": [],
            "prompt": "A masterpiece of wane style created by the collaboration of H.R. Giger and Friedrich Stuhl.    In this photo, the concept of \"wane\" is depicted through a striking and ethereal scene. The foreground showcases a crescent moon that appears almost like a thin sliver in the night sky, emphasizing its waning phase. Surrounding the moon are wispy clouds that seem to emanate from it, as if the moon is exhaling a gentle, glowing mist.In the background, a vast expanse of darkened clouds rolls over a tranquil sea, with only a few stars twinkling intermittently. The water reflects the diminishing light of the waning moon, creating ripples and waves that shimmer faintly under the remaining lunar glow. A lone, ancient lighthouse stands on a rocky promontory, its beacon still flickering, casting long shadows over the tranquil waters.The overall atmosphere is one of quiet beauty and a sense of something fading away, encapsulating the essence of \"wane\" in both its literal astronomical meaning and a broader metaphorical sense.    HD32K, hyperdetailed, best quality, midjourneyv6.1.",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 3.5,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "aidmaMJ6.1-FLUX-V0.1.safetensors",
                    "type": "lora",
                    "strength": 0.5
                }
            ]
        },
        "username": "lin041012908",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 29998480,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1aea8d9c-5ece-4e54-b91f-5d7071adb947/width=896/1aea8d9c-5ece-4e54-b91f-5d7071adb947.jpeg",
        "hash": "UHDJbV00?vbu~WM|r;tRoMVs-VZ$x]r?son$",
        "width": 896,
        "height": 1152,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-18T03:18:05.978Z",
        "postId": 6712556,
        "stats": {
            "cryCount": 6,
            "laughCount": 15,
            "likeCount": 182,
            "dislikeCount": 0,
            "heartCount": 81,
            "commentCount": 0
        },
        "meta": {
            "seed": 1222,
            "vaes": [
                "FLUX1\\ae.sft"
            ],
            "comfy": "{\"prompt\": {\"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"27\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 50, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 1222}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 3.0, \"conditioning\": [\"98\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 896, \"height\": 1152, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.1500000000000001, \"base_shift\": 0.5, \"width\": 896, \"height\": 1152, \"model\": [\"51\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"41\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"62\", 0]}, \"class_type\": \"SaveImage\"}, \"42\": {\"inputs\": {\"noise\": [\"43\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"134\", 0], \"sigmas\": [\"79\", 0], \"latent_image\": [\"59\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"43\": {\"inputs\": {\"noise_seed\": 4367}, \"class_type\": \"RandomNoise\"}, \"51\": {\"inputs\": {\"lora_name\": \"flux1\\\\3D_render_flux.safetensors\", \"strength_model\": 0.5, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"59\": {\"inputs\": {\"pixels\": [\"75\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEEncode\"}, \"60\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.45, \"alpha\": 0.45, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"61\": {\"inputs\": {\"hdr_intensity\": 1.0, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"60\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"62\": {\"inputs\": {\"intensity\": 0.05, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"61\", 0]}, \"class_type\": \"FilmGrain\"}, \"68\": {\"inputs\": {\"text\": \"\", \"clip\": [\"51\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"69\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"71\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.4, \"alpha\": 0.4, \"image\": [\"72\", 0]}, \"class_type\": \"ImageSharpen\"}, \"72\": {\"inputs\": {\"hdr_intensity\": 0.5, \"shadow_intensity\": 0.25, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.25, \"image\": [\"69\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"73\": {\"inputs\": {\"intensity\": 0.02, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"71\", 0]}, \"class_type\": \"FilmGrain\"}, \"74\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"73\", 0]}, \"class_type\": \"SaveImage\"}, \"75\": {\"inputs\": {\"upscale_method\": \"lanczos\", \"scale_by\": 0.4, \"image\": [\"77\", 0]}, \"class_type\": \"ImageScaleBy\"}, \"76\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"77\": {\"inputs\": {\"upscale_model\": [\"76\", 0], \"image\": [\"61\", 0]}, \"class_type\": \"ImageUpscaleWithModel\"}, \"79\": {\"inputs\": {\"scheduler\": \"sgm_uniform\", \"steps\": 25, \"denoise\": 0.15, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"98\": {\"inputs\": {\"text\": \"A 3D render using Unreal Engine of a young woman with short blue hair, wearing a knit beanie and a black leather jacket, detailed with skull earrings, chokers, and skull-themed necklaces. The background is A large mural painted on the side of a building, showcasing vibrant street art and urban culture. focusing on cinematic photorealism.\\n\\nmicrodetail maps for extremely fine texture details, especially on the skin and clothing.Add roughness variation across materials to enhance realism, especially on skin and fabric. real-time tessellation for dynamic surface detail, such as on the fabric of the beanie.Add subtle wear and tear to materials like the leather jacket, giving it a more lived-in look.Introduce slight imperfections like freckles, pores, and subtle blemishes to enhance skin realism.4k resolution textures for detailed surfaces, especially for the skin, leather jacket, and tattoos.Simulate wet surfaces on the ground or buildings for added realism, especially under streetlights.Add details like graffiti or signs of urban decay to walls or buildings for a gritty atmosphere.Include distant, blurred traffic lights for additional depth and urban context.\\n\\nShe leans back casually against a wall, with one hand in her pocket and the other resting by her side.\\n\\n\\n\\n\\n\\n\\n\\n\\n\", \"clip\": [\"51\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"107\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5}, \"class_type\": \"ModelSamplingFlux\"}, \"109\": {\"inputs\": {\"tile_size\": 512}, \"class_type\": \"VAEEncodeTiled\"}, \"134\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"141\": {\"inputs\": {\"model_name\": \"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"}, \"class_type\": \"Upscale Model Loader\"}, \"144\": {\"inputs\": {\"image\": \"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"upload\": \"image\"}, \"class_type\": \"LoadImage\", \"is_changed\": [\"d8be10ac28eae3c31993a040de6119372c7212eea4c3d9730a388689e074a974\"]}, \"147\": {\"inputs\": {\"samples\": [\"42\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"149\": {\"inputs\": {\"scale_method\": \"lanczos\", \"scale_factor\": 1.5, \"use_tiled_vae\": false}, \"class_type\": \"LatentPixelScale\"}}, \"workflow\": {\"last_node_id\": 149, \"last_link_id\": 313, \"nodes\": [{\"id\": 53, \"type\": \"Reroute\", \"pos\": {\"0\": 752, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 45, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 132}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [133, 135], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 55, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -88}, \"size\": [75, 26], \"flags\": {}, \"order\": 19, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 136}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [139], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 58, \"type\": \"Reroute\", \"pos\": {\"0\": 1300, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 18, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 141}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 48, \"type\": \"Reroute\", \"pos\": {\"0\": 295, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 38, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 157}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [152], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 46, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -299}, \"size\": [75, 26], \"flags\": {}, \"order\": 31, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 123}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [150], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 66, \"type\": \"Reroute\", \"pos\": {\"0\": 1295, \"1\": -200}, \"size\": [75, 26], \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 158}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": null}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 68, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": -234, \"1\": -196}, \"size\": {\"0\": 400, \"1\": 200}, \"flags\": {\"collapsed\": true}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 156}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [157], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 49, \"type\": \"Reroute\", \"pos\": {\"0\": 293, \"1\": -192}, \"size\": [75, 26], \"flags\": {}, \"order\": 28, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 153}], \"outputs\": [{\"name\": \"\", \"type\": \"CLIP\", \"links\": [156, 158, 211], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 67, \"type\": \"Reroute\", \"pos\": {\"0\": 1294, \"1\": -167}, \"size\": [75, 26], \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 160}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [161, 163], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 50, \"type\": \"Reroute\", \"pos\": {\"0\": 400, \"1\": -165}, \"size\": [75, 26], \"flags\": {}, \"order\": 22, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 149}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [160, 178], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 57, \"type\": \"Reroute\", \"pos\": {\"0\": 753, \"1\": -53}, \"size\": [75, 26], \"flags\": {}, \"order\": 0, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [141], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 54, \"type\": \"Reroute\", \"pos\": {\"0\": 1297, \"1\": -118}, \"size\": [75, 26], \"flags\": {}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 133}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [134, 194], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 56, \"type\": \"Reroute\", \"pos\": {\"0\": 1299, \"1\": -85}, \"size\": [75, 26], \"flags\": {}, \"order\": 23, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 139}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [196], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 63, \"type\": \"Reroute\", \"pos\": {\"0\": 1292, \"1\": -300}, \"size\": [75, 26], \"flags\": {}, \"order\": 37, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 150}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [209], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 47, \"type\": \"Reroute\", \"pos\": {\"0\": 294, \"1\": -266}, \"size\": [75, 26], \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 214}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [151], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": {\"0\": 892, \"1\": 13}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 178}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [144], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 87, \"type\": \"Reroute\", \"pos\": {\"0\": 2216, \"1\": -220}, \"size\": [75, 26], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 194}], \"outputs\": [{\"name\": \"\", \"type\": \"GUIDER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 88, \"type\": \"Reroute\", \"pos\": {\"0\": 2219, \"1\": -184}, \"size\": [75, 26], \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 196}], \"outputs\": [{\"name\": \"\", \"type\": \"SAMPLER\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 81, \"type\": \"Reroute\", \"pos\": {\"0\": 2217, \"1\": -259}, \"size\": [75, 26], \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 186}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [312], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 480, \"1\": 1152}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 27, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 126, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 122, 123, 180], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.1500000000000001, 0.5, 896, 1152]}, {\"id\": 43, \"type\": \"RandomNoise\", \"pos\": {\"0\": 1172, \"1\": 43}, \"size\": {\"0\": 245.11636352539062, \"1\": 82}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [130], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [4367, \"fixed\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 107, \"type\": \"ModelSamplingFlux\", \"pos\": {\"0\": 874, \"1\": 1451}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": null, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": null, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": null, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 69, \"type\": \"VAEDecode\", \"pos\": {\"0\": 1801, \"1\": 21}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 159}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 164}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [244], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 59, \"type\": \"VAEEncode\", \"pos\": {\"0\": 1512, \"1\": -35}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": 285}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 161}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [143], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncode\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": {\"0\": 355, \"1\": 764}, \"size\": {\"0\": 210, \"1\": 78}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 112, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [116], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [896, 1152, 1]}, {\"id\": 109, \"type\": \"VAEEncodeTiled\", \"pos\": {\"0\": -510, \"1\": 806}, \"size\": {\"0\": 248.89723205566406, \"1\": 78}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"inputs\": [{\"name\": \"pixels\", \"type\": \"IMAGE\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEEncodeTiled\"}, \"widgets_values\": [512]}, {\"id\": 134, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 1174, \"1\": 176}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [287], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 77, \"type\": \"ImageUpscaleWithModel\", \"pos\": {\"0\": 450, \"1\": 1353}, \"size\": {\"0\": 241.79998779296875, \"1\": 46}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 172}, {\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 289}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [183], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageUpscaleWithModel\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 61, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 892, \"1\": 713}, \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 145}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [146, 289], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [1, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 62, \"type\": \"FilmGrain\", \"pos\": {\"0\": 879, \"1\": 949}, \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 52, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 146}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [288], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.05, 10, 0, 0], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 141, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 2036, \"1\": 41}, \"size\": {\"0\": 428.9556884765625, \"1\": 78}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 72, \"type\": \"LayerFilter: HDREffects\", \"pos\": {\"0\": 1813, \"1\": 140}, \"size\": {\"0\": 210, \"1\": 178}, \"flags\": {}, \"order\": 60, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 244}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [260, 299], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 117, \"type\": \"SaveImagePlus\", \"pos\": {\"0\": 4366, \"1\": 456}, \"size\": {\"0\": 832.2413940429688, \"1\": 1183.025634765625}, \"flags\": {}, \"order\": 68, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 282}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImagePlus\"}, \"widgets_values\": [\"ComfyUI\", \"JPEG\", true]}, {\"id\": 144, \"type\": \"LoadImage\", \"pos\": {\"0\": 2156, \"1\": 435}, \"size\": {\"0\": 504.7402648925781, \"1\": 472.86358642578125}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"ec9570f7-ad06-452e-a12d-d75f905c7900.png\", \"image\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": {\"0\": 34, \"1\": 42}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [252], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": {\"0\": 474, \"1\": 893}, \"size\": {\"0\": 210, \"1\": 60.76282501220703}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 136], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 486, \"1\": 996}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 122, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [179], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 50, 1]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": {\"0\": 5, \"1\": 172}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [304], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 96, \"type\": \"Reroute\", \"pos\": {\"0\": 2218, \"1\": -289}, \"size\": [75, 26], \"flags\": {}, \"order\": 41, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 209}], \"outputs\": [{\"name\": \"\", \"type\": \"MODEL\", \"links\": [294, 305], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 64, \"type\": \"Reroute\", \"pos\": {\"0\": 2019, \"1\": -258}, \"size\": [75, 26], \"flags\": {}, \"order\": 44, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 151}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [295, 306], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 65, \"type\": \"Reroute\", \"pos\": {\"0\": 2017, \"1\": -230}, \"size\": [75, 26], \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 152}], \"outputs\": [{\"name\": \"\", \"type\": \"CONDITIONING\", \"links\": [296, 307], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 42, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 1480, \"1\": 57}, \"size\": {\"0\": 284.1048889160156, \"1\": 619.9912719726562}, \"flags\": {}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 130, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 134, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 287, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 181, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 143, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [159, 308], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 70, \"type\": \"Reroute\", \"pos\": {\"0\": 1711, \"1\": -172}, \"size\": [75, 26], \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 163}], \"outputs\": [{\"name\": \"\", \"type\": \"VAE\", \"links\": [164, 186, 297, 310], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 147, \"type\": \"VAEDecode\", \"pos\": {\"0\": 3079, \"1\": -575}, \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 61, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 311}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 312}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [313], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 148, \"type\": \"SaveImage\", \"pos\": {\"0\": 3061, \"1\": -483}, \"size\": {\"0\": 281.4468078613281, \"1\": 480.5931091308594}, \"flags\": {}, \"order\": 64, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 313}], \"outputs\": [], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 146, \"type\": \"DZ_Face_Detailer\", \"pos\": {\"0\": 2658, \"1\": -843}, \"size\": {\"0\": 309.8262939453125, \"1\": 842.9425659179688}, \"flags\": {}, \"order\": 59, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 305}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 306}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 307}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 308}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 310}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [311], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DZ_Face_Detailer\"}, \"widgets_values\": [1, \"fixed\", 20, 4, \"euler\", \"sgm_uniform\", 0.5, 32, \"face\", \"dilate\", 3, 3]}, {\"id\": 142, \"type\": \"SaveImage\", \"pos\": {\"0\": 3204, \"1\": 556}, \"size\": {\"0\": 813.5270385742188, \"1\": 1236.560546875}, \"flags\": {}, \"order\": 66, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 300}], \"outputs\": [], \"title\": \"FinalPass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 74, \"type\": \"SaveImage\", \"pos\": {\"0\": 2236, \"1\": 953}, \"size\": {\"0\": 848.405029296875, \"1\": 898.4495849609375}, \"flags\": {}, \"order\": 67, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 168}], \"outputs\": [], \"title\": \"2nd Pass\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 149, \"type\": \"LatentPixelScale\", \"pos\": {\"0\": 465, \"1\": 1483}, \"size\": {\"0\": 365.4000244140625, \"1\": 146}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": null}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": null}, {\"name\": \"upscale_model_opt\", \"type\": \"UPSCALE_MODEL\", \"link\": null}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3}, {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LatentPixelScale\"}, \"widgets_values\": [\"lanczos\", 1.5, false]}, {\"id\": 76, \"type\": \"Upscale Model Loader\", \"pos\": {\"0\": 841, \"1\": 1300}, \"size\": {\"0\": 415.8259582519531, \"1\": 78}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [172], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MODEL_NAME_TEXT\", \"type\": \"STRING\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Upscale Model Loader\"}, \"widgets_values\": [\"4x_UniversalUpscalerV2-Sharper_103000_G.pth\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 28, \"type\": \"Note\", \"pos\": {\"0\": 8, \"1\": 851}, \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 37, \"type\": \"Note\", \"pos\": {\"0\": 19, \"1\": 1194}, \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [], \"outputs\": [], \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 140, \"type\": \"UltimateSDUpscale\", \"pos\": {\"0\": 2769, \"1\": 86}, \"size\": {\"0\": 315, \"1\": 826}, \"flags\": {}, \"order\": 63, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 299}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 294}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 295}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 296}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 297}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 298}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [300], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [1.5, 1, \"fixed\", 25, 3, \"euler\", \"sgm_uniform\", 0.1, \"Linear\", 1344, 768, 24, 56, \"None\", 1, 64, 8, 16, true, false]}, {\"id\": 79, \"type\": \"BasicScheduler\", \"pos\": {\"0\": 1829, \"1\": 554}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 180, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [181], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"sgm_uniform\", 25, 0.15], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 41, \"type\": \"SaveImage\", \"pos\": {\"0\": 1323, \"1\": 963}, \"size\": {\"0\": 848.655029296875, \"1\": 899.4495849609375}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 288}], \"outputs\": [], \"title\": \"1st Pass\", \"properties\": {\"Node name for S&R\": \"Save Image\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": {\"0\": 568, \"1\": 768}, \"size\": {\"0\": 274.2129211425781, \"1\": 82}, \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [1222, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 374, \"1\": 646}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 15, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [112, 115], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [896, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": {\"0\": 617, \"1\": 645}, \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1152, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 73, \"type\": \"FilmGrain\", \"pos\": {\"0\": 1815, \"1\": 365}, \"size\": {\"0\": 210, \"1\": 130}, \"flags\": {}, \"order\": 65, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 246}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [168, 282], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.02, 10, 0, 0], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 71, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 2061, \"1\": 273}, \"size\": {\"0\": 210, \"1\": 106}, \"flags\": {\"collapsed\": false}, \"order\": 62, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 260}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [246], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.4, 0.4], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 75, \"type\": \"ImageScaleBy\", \"pos\": {\"0\": 883, \"1\": 1143}, \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 183}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [285], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageScaleBy\"}, \"widgets_values\": [\"lanczos\", 0.4], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 51, \"type\": \"LoraLoader\", \"pos\": {\"0\": -98, \"1\": 604}, \"size\": {\"0\": 462.208251953125, \"1\": 134.61793518066406}, \"flags\": {}, \"order\": 20, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 252}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 304}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [125], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [301], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\3D_render_flux.safetensors\", 0.5, 1]}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": {\"0\": 700, \"1\": 54}, \"size\": {\"0\": 161.1999969482422, \"1\": 46}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 42, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [132], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": {\"0\": 403, \"1\": 39}, \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 213}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [42], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [3], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 60, \"type\": \"ImageSharpen\", \"pos\": {\"0\": 892, \"1\": 547}, \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 144}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.45, 0.45], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": {\"0\": 133, \"1\": 321}, \"size\": [214.54766211692385, 58], \"flags\": {}, \"order\": 17, \"mode\": 0, \"inputs\": [], \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [149], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 52, \"type\": \"LoraLoader\", \"pos\": {\"0\": -116, \"1\": 432}, \"size\": {\"0\": 455.3192138671875, \"1\": 131.6434326171875}, \"flags\": {}, \"order\": 24, \"mode\": 4, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 125}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 301}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [126], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [153], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\Madison_Beer_For_Flux.safetensors\", 0.5, 1]}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": {\"0\": 891, \"1\": 105}, \"size\": {\"0\": 257.9351501464844, \"1\": 394.89031982421875}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 135, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 179, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 116, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 98, \"type\": \"CLIPTextEncode\", \"pos\": {\"0\": 379, \"1\": 141}, \"size\": {\"0\": 488.2522277832031, \"1\": 387.7407531738281}, \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 211}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [213, 214], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"A 3D render using Unreal Engine of a young woman with short blue hair, wearing a knit beanie and a black leather jacket, detailed with skull earrings, chokers, and skull-themed necklaces. The background is A large mural painted on the side of a building, showcasing vibrant street art and urban culture. focusing on cinematic photorealism.\\n\\nmicrodetail maps for extremely fine texture details, especially on the skin and clothing.Add roughness variation across materials to enhance realism, especially on skin and fabric. real-time tessellation for dynamic surface detail, such as on the fabric of the beanie.Add subtle wear and tear to materials like the leather jacket, giving it a more lived-in look.Introduce slight imperfections like freckles, pores, and subtle blemishes to enhance skin realism.4k resolution textures for detailed surfaces, especially for the skin, leather jacket, and tattoos.Simulate wet surfaces on the ground or buildings for added realism, especially under streetlights.Add details like graffiti or signs of urban decay to walls or buildings for a gritty atmosphere.Include distant, blurred traffic lights for additional depth and urban context.\\n\\nShe leans back casually against a wall, with one hand in her pocket and the other resting by her side.\\n\\n\\n\\n\\n\\n\\n\\n\\n\"]}], \"links\": [[19, 16, 0, 13, 2, \"SAMPLER\"], [24, 13, 0, 8, 0, \"LATENT\"], [37, 25, 0, 13, 0, \"NOISE\"], [42, 26, 0, 22, 1, \"CONDITIONING\"], [54, 30, 0, 22, 0, \"MODEL\"], [112, 34, 0, 27, 0, \"INT\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [116, 27, 0, 13, 4, \"LATENT\"], [122, 30, 0, 17, 0, \"MODEL\"], [123, 30, 0, 46, 0, \"*\"], [125, 51, 0, 52, 0, \"MODEL\"], [126, 52, 0, 30, 0, \"MODEL\"], [130, 43, 0, 42, 0, \"NOISE\"], [132, 22, 0, 53, 0, \"*\"], [133, 53, 0, 54, 0, \"*\"], [134, 54, 0, 42, 1, \"GUIDER\"], [135, 53, 0, 13, 1, \"GUIDER\"], [136, 16, 0, 55, 0, \"*\"], [139, 55, 0, 56, 0, \"*\"], [141, 57, 0, 58, 0, \"*\"], [143, 59, 0, 42, 4, \"LATENT\"], [144, 8, 0, 60, 0, \"IMAGE\"], [145, 60, 0, 61, 0, \"IMAGE\"], [146, 61, 0, 62, 0, \"IMAGE\"], [149, 10, 0, 50, 0, \"*\"], [150, 46, 0, 63, 0, \"*\"], [151, 47, 0, 64, 0, \"*\"], [152, 48, 0, 65, 0, \"*\"], [153, 52, 1, 49, 0, \"*\"], [156, 49, 0, 68, 0, \"CLIP\"], [157, 68, 0, 48, 0, \"*\"], [158, 49, 0, 66, 0, \"*\"], [159, 42, 0, 69, 0, \"LATENT\"], [160, 50, 0, 67, 0, \"*\"], [161, 67, 0, 59, 1, \"VAE\"], [163, 67, 0, 70, 0, \"*\"], [164, 70, 0, 69, 1, \"VAE\"], [168, 73, 0, 74, 0, \"IMAGE\"], [172, 76, 0, 77, 0, \"UPSCALE_MODEL\"], [178, 50, 0, 8, 1, \"VAE\"], [179, 17, 0, 13, 3, \"SIGMAS\"], [180, 30, 0, 79, 0, \"MODEL\"], [181, 79, 0, 42, 3, \"SIGMAS\"], [183, 77, 0, 75, 0, \"IMAGE\"], [186, 70, 0, 81, 0, \"*\"], [194, 54, 0, 87, 0, \"*\"], [196, 56, 0, 88, 0, \"*\"], [209, 63, 0, 96, 0, \"*\"], [211, 49, 0, 98, 0, \"CLIP\"], [213, 98, 0, 26, 0, \"CONDITIONING\"], [214, 98, 0, 47, 0, \"*\"], [244, 69, 0, 72, 0, \"IMAGE\"], [246, 71, 0, 73, 0, \"IMAGE\"], [252, 12, 0, 51, 0, \"MODEL\"], [260, 72, 0, 71, 0, \"IMAGE\"], [282, 73, 0, 117, 0, \"IMAGE\"], [285, 75, 0, 59, 0, \"IMAGE\"], [287, 134, 0, 42, 2, \"SAMPLER\"], [288, 62, 0, 41, 0, \"IMAGE\"], [289, 61, 0, 77, 1, \"IMAGE\"], [294, 96, 0, 140, 1, \"MODEL\"], [295, 64, 0, 140, 2, \"CONDITIONING\"], [296, 65, 0, 140, 3, \"CONDITIONING\"], [297, 70, 0, 140, 4, \"VAE\"], [298, 141, 0, 140, 5, \"UPSCALE_MODEL\"], [299, 72, 0, 140, 0, \"IMAGE\"], [300, 140, 0, 142, 0, \"IMAGE\"], [301, 51, 1, 52, 1, \"CLIP\"], [304, 11, 0, 51, 1, \"CLIP\"], [305, 96, 0, 146, 0, \"MODEL\"], [306, 64, 0, 146, 1, \"CONDITIONING\"], [307, 65, 0, 146, 2, \"CONDITIONING\"], [308, 42, 0, 146, 3, \"LATENT\"], [310, 70, 0, 146, 4, \"VAE\"], [311, 146, 0, 147, 0, \"LATENT\"], [312, 81, 0, 147, 1, \"VAE\"], [313, 147, 0, 148, 0, \"IMAGE\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.4641000000000013, \"offset\": [-264.4105273150479, 52.24257360102258]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"43\": {\"noise_seed\": 0}, \"79\": {\"scheduler\": 0}, \"134\": {\"sampler_name\": 0}, \"140\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"146\": {\"seed\": 0, \"sampler_name\": 4, \"scheduler\": 5}}, \"seed_widgets\": {\"25\": 0, \"43\": 0, \"140\": 1, \"146\": 0}}}",
            "steps": 50,
            "models": [],
            "prompt": "A 3D render using Unreal Engine of a young woman with short blue hair, wearing a knit beanie and a black leather jacket, detailed with skull earrings, chokers, and skull-themed necklaces. The background is A large mural painted on the side of a building, showcasing vibrant street art and urban culture. focusing on cinematic photorealism.\n\nmicrodetail maps for extremely fine texture details, especially on the skin and clothing.Add roughness variation across materials to enhance realism, especially on skin and fabric. real-time tessellation for dynamic surface detail, such as on the fabric of the beanie.Add subtle wear and tear to materials like the leather jacket, giving it a more lived-in look.Introduce slight imperfections like freckles, pores, and subtle blemishes to enhance skin realism.4k resolution textures for detailed surfaces, especially for the skin, leather jacket, and tattoos.Simulate wet surfaces on the ground or buildings for added realism, especially under streetlights.Add details like graffiti or signs of urban decay to walls or buildings for a gritty atmosphere.Include distant, blurred traffic lights for additional depth and urban context.\n\nShe leans back casually against a wall, with one hand in her pocket and the other resting by her side.\n\n\n\n\n\n\n\n\n",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 3,
            "modelIds": [],
            "scheduler": "sgm_uniform",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "flux1\\3D_render_flux.safetensors",
                    "type": "lora",
                    "strength": 0.5,
                    "strengthClip": 1
                }
            ]
        },
        "username": "salammy",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 29493788,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/241493c6-d9e6-4e9a-a13f-1fc808498685/width=1800/241493c6-d9e6-4e9a-a13f-1fc808498685.jpeg",
        "hash": "UXIqu;9G-o%L~Vn%kDR*9axtIpR*o}RjM{%2",
        "width": 2560,
        "height": 3712,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-15T04:24:43.396Z",
        "postId": 6598883,
        "stats": {
            "cryCount": 13,
            "laughCount": 25,
            "likeCount": 166,
            "dislikeCount": 0,
            "heartCount": 80,
            "commentCount": 1
        },
        "meta": {
            "seed": 582078239,
            "vaes": [],
            "extra": {},
            "steps": 10,
            "models": [],
            "prompt": "score_9, score_8_up, score_7_up, score_6_up, score_5_up, score_4_up, \n[][][][][] \nm0use_maximilla, cute, \n[][][][][] \n(solo), blue dress, (cute:2), upper body shot, (close up), (low angle view:1.5), outdoors, happy expression, (side view:1.5), village, look at viewer",
            "sampler": "Euler a",
            "cfgScale": 3.5,
            "modelIds": [],
            "workflow": "img2img-upscale",
            "upscalers": [
                "urn:air:multi:upscaler:civitai:147759@164821"
            ],
            "versionIds": [],
            "controlNets": [],
            "negativePrompt": "score_6, score_5, score_4, (loli, cub, young, child, chibi:1.5), busty, ugly face, low res, blurry face, ugly hands, pumped body, black and white, penis, breasts, ((hair)), nipples, belly, extra ears, human, ",
            "civitaiResources": [
                {
                    "strength": 1,
                    "modelVersionId": 686553
                },
                {
                    "strength": 1,
                    "modelVersionId": 686553
                },
                {
                    "strength": 0.7,
                    "modelVersionId": 793598
                },
                {
                    "type": "upscaler",
                    "modelVersionId": 164821
                }
            ],
            "additionalResources": []
        },
        "username": "JustAMouse",
        "baseModel": "Pony"
    },
    {
        "id": 28701573,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/867ae020-77a0-41f2-8a0a-0909b53a7050/width=1800/867ae020-77a0-41f2-8a0a-0909b53a7050.jpeg",
        "hash": "UDCj9GMx00E1Dh_NR*9Eb_9F-p-;00oz%Nxv",
        "width": 2496,
        "height": 3648,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-10T11:12:19.303Z",
        "postId": 6420007,
        "stats": {
            "cryCount": 10,
            "laughCount": 27,
            "likeCount": 171,
            "dislikeCount": 0,
            "heartCount": 76,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 2080625566,
            "Model": "flux_dev",
            "steps": 30,
            "hashes": {
                "model": "",
                "LORA:FluxDFaeTasticDetails": "4259dc3287",
                "LORA:aidmaImageUpgrader-FLUX-V0.1": "3a380fe818"
            },
            "prompt": "Close-up of a futuristic female android with a partially revealed mechanical structure. Her human-like face has pale, smooth skin with a natural makeup look, emphasizing soft pink lips and lightly blushed cheeks. Her striking bright blue eyes have a slight glow, framed by long, dark lashes and perfectly shaped dark eyebrows. The right side of her neck and jaw are exposed, revealing intricate mechanical parts, including metallic cables, joints, and panels. The android has shoulder-length dark brown hair, styled smoothly and pulled back, with no visible hair accessories. She wears a simple white garment, which is partially visible and minimalist in design. The mechanical details seamlessly blend with her human appearance, creating a harmonious contrast.   The lighting is soft, highlighting her face and the metallic parts, with subtle shadows adding depth. The background is dark and minimalistic, allowing full focus on the subject. The style is hyper-realistic with high detail in the textures of both human skin and the mechanical components, making the image feel lifelike yet futuristic.    <lora:FluxDFaeTasticDetails:0.8> <lora:aidmaImageUpgrader-FLUX-V0.1:0.33> detailmaximizer,",
            "Version": "ComfyUI",
            "sampler": "Euler",
            "cfgScale": 3.3,
            "resources": [
                {
                    "name": "FluxDFaeTasticDetails",
                    "type": "lora",
                    "weight": 0.8
                },
                {
                    "name": "aidmaImageUpgrader-FLUX-V0.1",
                    "type": "lora",
                    "weight": 0.33
                }
            ],
            "Model hash": ""
        },
        "username": "Rekano33",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 28537168,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/52b52a26-9abb-41ca-966d-2a9a5639d6e6/width=832/52b52a26-9abb-41ca-966d-2a9a5639d6e6.jpeg",
        "hash": "U;IMQm-pOYn,}T$ySga$wHWTocfkSiODoboI",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-09-09T11:36:14.929Z",
        "postId": 6383813,
        "stats": {
            "cryCount": 1,
            "laughCount": 2,
            "likeCount": 228,
            "dislikeCount": 0,
            "heartCount": 53,
            "commentCount": 1
        },
        "meta": null,
        "username": "Baryosynthesis",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 28287768,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/cd320de3-a61b-4161-a5af-7ca1caf272c5/width=832/cd320de3-a61b-4161-a5af-7ca1caf272c5.jpeg",
        "hash": "U6Dl4itl005701}?XR4:0kIC,;x]vL0#x],p",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-09-08T00:42:35.515Z",
        "postId": 6329015,
        "stats": {
            "cryCount": 9,
            "laughCount": 17,
            "likeCount": 180,
            "dislikeCount": 0,
            "heartCount": 78,
            "commentCount": 0
        },
        "meta": {
            "Size": "832x1216",
            "seed": 4245030194,
            "steps": 25,
            "prompt": "incredibly cute 18 year old woman, wearing a dress, huge smile, large radiant blue eyes, freckles,\nhuge sagging natural breasts,\nleaning forward, closeup on face while everything else is out of focus, shallow depth of field, bokeh",
            "sampler": "Undefined",
            "cfgScale": 3.5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-09-02T0414:31.6410601Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                }
            ]
        },
        "username": "LordTerror",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 26871085,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3aac2197-6be5-4007-9dec-248cdc9660e9/width=768/3aac2197-6be5-4007-9dec-248cdc9660e9.jpeg",
        "hash": "UFIW+Fo202xZ_Loe0NfQ+eoeacRksjayoyWC",
        "width": 768,
        "height": 1024,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-30T09:34:20.553Z",
        "postId": 6008642,
        "stats": {
            "cryCount": 8,
            "laughCount": 11,
            "likeCount": 209,
            "dislikeCount": 0,
            "heartCount": 56,
            "commentCount": 0
        },
        "meta": {
            "seed": 863679313542882,
            "vaes": [
                "ae.safetensors"
            ],
            "comfy": "{\"prompt\": {\"5\": {\"inputs\": {\"width\": 768, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptyLatentImage\"}, \"6\": {\"inputs\": {\"text\": \"Revised Poster Design Concept: Golden Buddha Statue\\nOverall Style:\\n\\nLuxurious and Serene with Vibrant Elements: The poster will showcase a Buddha statue made entirely of gold, emphasizing its metallic texture, but will now incorporate a colorful and intricate background to enhance visual appeal.\\nBuddha Statue Design:\\n\\nPose: The Buddha will remain in a classic seated pose, with a peaceful expression and gentle eyes, reflecting inner tranquility and wisdom.\\nMaterial Effect: The statue will have a smooth metallic finish, reflecting light to create a sense of opulence and divinity.\\nBackground Design:\\n\\nColorful Aura: The background will feature a radiant, multi-colored aura surrounding the Buddha, reminiscent of traditional Buddhist art, incorporating shades of blue, pink, green, and yellow to symbolize enlightenment and positivity.\\nComplex Patterns: Integrate intricate mandala designs or swirling patterns in the background, adding depth and complexity to the overall visual.\\nRadiant Light:\\n\\nHalo and Rays: Surrounding the Buddha, add a vibrant halo and dynamic rays of light in various colors, symbolizing wisdom and spirituality, enhancing the visual impact of the statue.\\nText:\\nAdditional Elements:\\nLotus Patterns: Incorporate detailed lotus motifs at the base of the statue or within the background, symbolizing purity and awakening, with a gradient of colors to match the overall theme.\\nDelicate Decorations: Add subtle geometric patterns or ornate golden embellishments in the background to enhance the overall artistic feel and richness of the design.\\nOverall Effect:\\nThis revised poster will blend wealth and spirituality through the luxurious golden Buddha statue while incorporating vibrant colors and intricate designs to create a more dynamic and captivating visual.  The colorful background and light effects will evoke a sacred atmosphere, while the text at the bottom reinforces the theme of prosperity.  The overall design will not only attract viewers' attention but also inspire contemplation and a sense of awe.\", \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"10\": {\"inputs\": {\"vae_name\": \"ae.safetensors\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_name2\": \"clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"5\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 20, \"denoise\": 1.0, \"model\": [\"12\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"12\", 0], \"conditioning\": [\"6\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 863679313542882}, \"class_type\": \"RandomNoise\"}}, \"workflow\": {\"last_node_id\": 25, \"last_link_id\": 40, \"nodes\": [{\"id\": 12, \"type\": \"UNETLoader\", \"pos\": [37, 46], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"pinned\": true}, \"order\": 0, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [38, 39], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u6a21\\u578b\"}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#332922\", \"bgcolor\": \"#593930\"}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": [40, 166], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"pinned\": true}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [10], \"slot_index\": 0, \"shape\": 3, \"label\": \"CLIP\"}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 5, \"type\": \"EmptyLatentImage\", \"pos\": [43, 317], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"pinned\": true}, \"order\": 2, \"mode\": 0, \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [23], \"slot_index\": 0, \"label\": \"Latent\"}], \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"}, \"widgets_values\": [768, 1024, 1], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 8, \"type\": \"VAEDecode\", \"pos\": [381, 160], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {\"pinned\": true}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 24, \"label\": \"Latent\"}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12, \"label\": \"VAE\"}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [9], \"slot_index\": 0, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": [48, 698], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"pinned\": true}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 38, \"slot_index\": 0, \"label\": \"\\u6a21\\u578b\"}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20], \"shape\": 3, \"label\": \"Sigmas\"}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 20, 1], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": [39, 597], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {\"pinned\": true}, \"order\": 3, \"mode\": 0, \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19], \"shape\": 3, \"label\": \"\\u91c7\\u6837\\u5668\"}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": [43, 464], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"pinned\": true}, \"order\": 4, \"mode\": 0, \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [37], \"shape\": 3, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [863679313542882, \"randomize\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": [392, 476], \"size\": {\"0\": 416.155029296875, \"1\": 326}, \"flags\": {\"pinned\": true}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 37, \"slot_index\": 0, \"label\": \"\\u566a\\u6ce2\\u751f\\u6210\"}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 30, \"slot_index\": 1, \"label\": \"\\u5f15\\u5bfc\"}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2, \"label\": \"\\u91c7\\u6837\\u5668\"}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3, \"label\": \"Sigmas\"}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 23, \"slot_index\": 4, \"label\": \"Latent\"}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [24], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u8f93\\u51fa\"}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": null, \"shape\": 3, \"label\": \"\\u964d\\u566a\\u8f93\\u51fa\"}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}, \"color\": \"#233\", \"bgcolor\": \"#355\", \"shape\": 1}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": [604, 161], \"size\": {\"0\": 202.94503784179688, \"1\": 46}, \"flags\": {\"pinned\": true}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 39, \"slot_index\": 0, \"label\": \"\\u6a21\\u578b\"}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 40, \"slot_index\": 1, \"label\": \"\\u6761\\u4ef6\"}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [30], \"slot_index\": 0, \"shape\": 3, \"label\": \"\\u5f15\\u5bfc\"}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": [386, 55], \"size\": {\"0\": 422.5250549316406, \"1\": 59.05733871459961}, \"flags\": {\"pinned\": true}, \"order\": 5, \"mode\": 0, \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12], \"slot_index\": 0, \"shape\": 3, \"label\": \"VAE\"}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"ae.safetensors\"]}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": [836, 51], \"size\": {\"0\": 856.820068359375, \"1\": 895.4721069335938}, \"flags\": {\"pinned\": true}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 9, \"label\": \"\\u56fe\\u50cf\"}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\", \"shape\": 1}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": [388, 263], \"size\": {\"0\": 422.84503173828125, \"1\": 164.31304931640625}, \"flags\": {\"pinned\": true}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 10, \"label\": \"CLIP\"}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [40], \"slot_index\": 0, \"label\": \"\\u6761\\u4ef6\"}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"Revised Poster Design Concept: Golden Buddha Statue\\nOverall Style:\\n\\nLuxurious and Serene with Vibrant Elements: The poster will showcase a Buddha statue made entirely of gold, emphasizing its metallic texture, but will now incorporate a colorful and intricate background to enhance visual appeal.\\nBuddha Statue Design:\\n\\nPose: The Buddha will remain in a classic seated pose, with a peaceful expression and gentle eyes, reflecting inner tranquility and wisdom.\\nMaterial Effect: The statue will have a smooth metallic finish, reflecting light to create a sense of opulence and divinity.\\nBackground Design:\\n\\nColorful Aura: The background will feature a radiant, multi-colored aura surrounding the Buddha, reminiscent of traditional Buddhist art, incorporating shades of blue, pink, green, and yellow to symbolize enlightenment and positivity.\\nComplex Patterns: Integrate intricate mandala designs or swirling patterns in the background, adding depth and complexity to the overall visual.\\nRadiant Light:\\n\\nHalo and Rays: Surrounding the Buddha, add a vibrant halo and dynamic rays of light in various colors, symbolizing wisdom and spirituality, enhancing the visual impact of the statue.\\nText:\\nAdditional Elements:\\nLotus Patterns: Incorporate detailed lotus motifs at the base of the statue or within the background, symbolizing purity and awakening, with a gradient of colors to match the overall theme.\\nDelicate Decorations: Add subtle geometric patterns or ornate golden embellishments in the background to enhance the overall artistic feel and richness of the design.\\nOverall Effect:\\nThis revised poster will blend wealth and spirituality through the luxurious golden Buddha statue while incorporating vibrant colors and intricate designs to create a more dynamic and captivating visual.  The colorful background and light effects will evoke a sacred atmosphere, while the text at the bottom reinforces the theme of prosperity.  The overall design will not only attract viewers' attention but also inspire contemplation and a sense of awe.\"], \"color\": \"#232\", \"bgcolor\": \"#353\", \"shape\": 1}], \"links\": [[9, 8, 0, 9, 0, \"IMAGE\"], [10, 11, 0, 6, 0, \"CLIP\"], [12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [23, 5, 0, 13, 4, \"LATENT\"], [24, 13, 0, 8, 0, \"LATENT\"], [30, 22, 0, 13, 1, \"GUIDER\"], [37, 25, 0, 13, 0, \"NOISE\"], [38, 12, 0, 17, 0, \"MODEL\"], [39, 12, 0, 22, 0, \"MODEL\"], [40, 6, 0, 22, 1, \"CONDITIONING\"]], \"groups\": [], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.7513148009015777, \"offset\": [415.4634794646501, 9.53258330679231]}, \"workspace_info\": {\"id\": \"L7ZoSc9K2Yo3rxKB0iBYv\", \"saveLock\": false, \"cloudID\": null, \"coverMediaPath\": null}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}}, \"seed_widgets\": {\"25\": 0}}}",
            "steps": 20,
            "width": 768,
            "height": 1024,
            "models": [],
            "prompt": "Revised Poster Design Concept: Golden Buddha Statue\nOverall Style:\n\nLuxurious and Serene with Vibrant Elements: The poster will showcase a Buddha statue made entirely of gold, emphasizing its metallic texture, but will now incorporate a colorful and intricate background to enhance visual appeal.\nBuddha Statue Design:\n\nPose: The Buddha will remain in a classic seated pose, with a peaceful expression and gentle eyes, reflecting inner tranquility and wisdom.\nMaterial Effect: The statue will have a smooth metallic finish, reflecting light to create a sense of opulence and divinity.\nBackground Design:\n\nColorful Aura: The background will feature a radiant, multi-colored aura surrounding the Buddha, reminiscent of traditional Buddhist art, incorporating shades of blue, pink, green, and yellow to symbolize enlightenment and positivity.\nComplex Patterns: Integrate intricate mandala designs or swirling patterns in the background, adding depth and complexity to the overall visual.\nRadiant Light:\n\nHalo and Rays: Surrounding the Buddha, add a vibrant halo and dynamic rays of light in various colors, symbolizing wisdom and spirituality, enhancing the visual impact of the statue.\nText:\nAdditional Elements:\nLotus Patterns: Incorporate detailed lotus motifs at the base of the statue or within the background, symbolizing purity and awakening, with a gradient of colors to match the overall theme.\nDelicate Decorations: Add subtle geometric patterns or ornate golden embellishments in the background to enhance the overall artistic feel and richness of the design.\nOverall Effect:\nThis revised poster will blend wealth and spirituality through the luxurious golden Buddha statue while incorporating vibrant colors and intricate designs to create a more dynamic and captivating visual.  The colorful background and light effects will evoke a sacred atmosphere, while the text at the bottom reinforces the theme of prosperity.  The overall design will not only attract viewers' attention but also inspire contemplation and a sense of awe.",
            "denoise": 1,
            "sampler": "Euler",
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": []
        },
        "username": "HS_hi",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 26625376,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bdadbe7a-f0ce-4d28-8001-a13c980fe9b4/width=1248/bdadbe7a-f0ce-4d28-8001-a13c980fe9b4.jpeg",
        "hash": "UXEfELOtpytS-@M|JWNIT2emJVn*M~rpRjof",
        "width": 1248,
        "height": 1824,
        "nsfwLevel": "Soft",
        "nsfw": true,
        "browsingLevel": 2,
        "createdAt": "2024-08-28T22:04:32.005Z",
        "postId": 5952126,
        "stats": {
            "cryCount": 0,
            "laughCount": 10,
            "likeCount": 199,
            "dislikeCount": 0,
            "heartCount": 75,
            "commentCount": 0
        },
        "meta": {
            "": {},
            "VAE": "sdxl_vae_fixed.safetensors",
            "Size": "1248x1824",
            "seed": 3249138425,
            "Model": "sym-pony_world.fp16",
            "steps": 20,
            "hashes": {
                "vae": "235745af8d",
                "model": "39590fcd2d",
                "lora:mavuika_genshin_impact_pdxl_goofy": "8739a90a8d3c"
            },
            "prompt": "score_9,score_8_up,core_7_up,   <lora:mavuika_genshin_impact_pdxl_goofy:1>mavuika-gi, 1girl, breasts, solo, long hair, cleavage, large breasts, sky, looking at viewer, blue sky, bangs, smile, outdoors, cloud, bodysuit, day, gloves, covered navel, earrings, jewelry, black bodysuit, clothing cutout, closed mouth, black gloves,full-length zipper,",
            "Version": "v1.10.1",
            "sampler": "DPM++ 2M",
            "{Method": {},
            "Upscaler": {},
            "cfgScale": 7,
            "resources": [
                {
                    "hash": "8739a90a8d3c",
                    "name": "mavuika_genshin_impact_pdxl_goofy",
                    "type": "lora",
                    "weight": 1
                },
                {
                    "hash": "39590fcd2d",
                    "name": "sym-pony_world.fp16",
                    "type": "model"
                }
            ],
            "Model hash": "39590fcd2d",
            "Tile Overlap": "48",
            "Schedule type": "Karras",
            "Upscale factor": "1.5",
            "negativePrompt": "realistic,monochrome,greyscale, artist name, signature, watermark,",
            "ADetailer model": "face_yolov8n.pt",
            "Keep input size": "true}",
            "Tile batch size": "6",
            "Tile tile width": "160",
            "Tiled Diffusion": {},
            "Tile tile height": "160",
            "ADetailer version": "24.8.0",
            "Denoising strength": "0.3",
            "ADetailer mask blur": "4",
            "ADetailer confidence": "0.3",
            "ADetailer dilate erode": "4",
            "Tiled Diffusion upscaler": "4x-UltraSharp",
            "ADetailer inpaint padding": "32",
            "ADetailer denoising strength": "0.4",
            "Tiled Diffusion scale factor": "1.5",
            "ADetailer inpaint only masked": "True"
        },
        "username": "Goofy_Ai",
        "baseModel": "Pony"
    },
    {
        "id": 25679481,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/227db2a4-06c5-40e2-9a5e-99278c6989f6/width=1664/227db2a4-06c5-40e2-9a5e-99278c6989f6.jpeg",
        "hash": "UfHwrd0Ms,tQ~VIBI@xZo#nhSiNG%KM|xaNG",
        "width": 1664,
        "height": 2432,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-23T02:05:17.646Z",
        "postId": 5740904,
        "stats": {
            "cryCount": 12,
            "laughCount": 11,
            "likeCount": 204,
            "dislikeCount": 0,
            "heartCount": 57,
            "commentCount": 0
        },
        "meta": {
            "seed": 7274,
            "vaes": [
                "FLUX1\\ae.sft"
            ],
            "comfy": "{\"prompt\": {\"6\": {\"inputs\": {\"text\": \"photorealistic, A woman in her 20s, platinum blonde hair, long eyelashes, thick eyelashes, makeup, glamourous, interesting black eyeliner, autumn attire, park scene, golden hour, serene expression, detailed facial features, warm smile, cozy clothing, autumn leaves, setting sun, warm, golden lighting, intricate fabric details, gentle breeze, peaceful atmosphere, ultra-high resolution, natural skin tone, light makeup, autumn hues, wide shot, medium shot, close-up, low-angle shot, high-angle shot, side profile, standing pose, walking through park, hair flowing in breeze, blurred autumn background, hyper-detailed environment, warm glow, tranquil park scene, falling leaves, balanced composition, dynamic stance, fluid motion, emotional connection, serene mood, background focus\\n\\nThe woman is leaning casually against a large, textured tree trunk, with one foot crossed over the other. She\\u2019s looking off into the distance with a soft smile, her hair cascading down over her shoulder, gently tousled by the breeze.\\n\\ncinematic lighting, extremely intricate detail character, accurate depiction of character, correct body anatomy,correct hands and fingers, extremely intricate skin and facial texture detail, intricate black bodysuit design,lifelike potrayal, extrememly realistic lighting, extreme dynamic pose \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", \"clip\": [\"86\", 1]}, \"class_type\": \"CLIPTextEncode\"}, \"8\": {\"inputs\": {\"samples\": [\"13\", 0], \"vae\": [\"10\", 0]}, \"class_type\": \"VAEDecode\"}, \"10\": {\"inputs\": {\"vae_name\": \"FLUX1\\\\ae.sft\"}, \"class_type\": \"VAELoader\"}, \"11\": {\"inputs\": {\"clip_name1\": \"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"clip_name2\": \"t5\\\\clip_l.safetensors\", \"type\": \"flux\"}, \"class_type\": \"DualCLIPLoader\"}, \"12\": {\"inputs\": {\"unet_name\": \"FLUX1\\\\flux1-dev-fp8.safetensors\", \"weight_dtype\": \"fp8_e4m3fn\"}, \"class_type\": \"UNETLoader\"}, \"13\": {\"inputs\": {\"noise\": [\"25\", 0], \"guider\": [\"22\", 0], \"sampler\": [\"16\", 0], \"sigmas\": [\"17\", 0], \"latent_image\": [\"266\", 0]}, \"class_type\": \"SamplerCustomAdvanced\"}, \"16\": {\"inputs\": {\"sampler_name\": \"euler\"}, \"class_type\": \"KSamplerSelect\"}, \"17\": {\"inputs\": {\"scheduler\": \"simple\", \"steps\": 80, \"denoise\": 1.0, \"model\": [\"30\", 0]}, \"class_type\": \"BasicScheduler\"}, \"22\": {\"inputs\": {\"model\": [\"30\", 0], \"conditioning\": [\"26\", 0]}, \"class_type\": \"BasicGuider\"}, \"25\": {\"inputs\": {\"noise_seed\": 7274}, \"class_type\": \"RandomNoise\"}, \"26\": {\"inputs\": {\"guidance\": 5.0, \"conditioning\": [\"6\", 0]}, \"class_type\": \"FluxGuidance\"}, \"27\": {\"inputs\": {\"width\": 832, \"height\": 1216, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}, \"30\": {\"inputs\": {\"max_shift\": 1.15, \"base_shift\": 0.5, \"width\": 832, \"height\": 1216, \"model\": [\"86\", 0]}, \"class_type\": \"ModelSamplingFlux\"}, \"42\": {\"inputs\": {\"sharpen_radius\": 1, \"sigma\": 0.35000000000000003, \"alpha\": 0.35000000000000003, \"image\": [\"8\", 0]}, \"class_type\": \"ImageSharpen\"}, \"43\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"72\", 0]}, \"class_type\": \"SaveImage\"}, \"70\": {\"inputs\": {\"lora_name\": \"flux1\\\\flux_realism_lora.safetensors\", \"strength_model\": 1.0, \"strength_clip\": 1.0, \"model\": [\"12\", 0], \"clip\": [\"11\", 0]}, \"class_type\": \"LoraLoader\"}, \"72\": {\"inputs\": {\"intensity\": 0.03, \"scale\": 10.0, \"temperature\": 0.0, \"vignette\": 0.0, \"image\": [\"127\", 0]}, \"class_type\": \"FilmGrain\"}, \"86\": {\"inputs\": {\"lora_name\": \"flux1\\\\AsirAsianPhotographyflux.safetensors\", \"strength_model\": 0.9500000000000001, \"strength_clip\": 1.0, \"model\": [\"70\", 0], \"clip\": [\"70\", 1]}, \"class_type\": \"LoraLoader\"}, \"104\": {\"inputs\": {\"text\": \"\", \"clip\": [\"11\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"111\": {\"inputs\": {\"upscale_by\": 2.0, \"seed\": 1, \"steps\": 20, \"cfg\": 1.0, \"sampler_name\": \"euler\", \"scheduler\": \"simple\", \"denoise\": 0.25, \"mode_type\": \"Linear\", \"tile_width\": 832, \"tile_height\": 1216, \"mask_blur\": 20, \"tile_padding\": 56, \"seam_fix_mode\": \"None\", \"seam_fix_denoise\": 1.0, \"seam_fix_width\": 64, \"seam_fix_mask_blur\": 16, \"seam_fix_padding\": 32, \"force_uniform_tiles\": true, \"tiled_decode\": false, \"image\": [\"72\", 0], \"model\": [\"30\", 0], \"positive\": [\"6\", 0], \"negative\": [\"104\", 0], \"vae\": [\"10\", 0], \"upscale_model\": [\"112\", 0]}, \"class_type\": \"UltimateSDUpscale\"}, \"112\": {\"inputs\": {\"model_name\": \"4x-UltraSharp.pth\"}, \"class_type\": \"UpscaleModelLoader\"}, \"119\": {\"inputs\": {\"sharpen_radius\": 2, \"sigma\": 0.4, \"alpha\": 0.4, \"image\": [\"111\", 0]}, \"class_type\": \"ImageSharpen\"}, \"120\": {\"inputs\": {\"scale\": 0.25, \"strength\": 0.05, \"saturation\": 0.7, \"toe\": 0.0, \"seed\": 1, \"image\": [\"125\", 0]}, \"class_type\": \"BetterFilmGrain\"}, \"125\": {\"inputs\": {\"hdr_intensity\": 0.8, \"shadow_intensity\": 0.75, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.13, \"enhance_color\": 0.3, \"image\": [\"119\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"127\": {\"inputs\": {\"hdr_intensity\": 0.85, \"shadow_intensity\": 0.45, \"highlight_intensity\": 0.75, \"gamma_intensity\": 0.25, \"contrast\": 0.1, \"enhance_color\": 0.35000000000000003, \"image\": [\"42\", 0]}, \"class_type\": \"LayerFilter: HDREffects\"}, \"173\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"120\", 0]}, \"class_type\": \"SaveImage\"}, \"198\": {\"inputs\": {\"anything\": [\"120\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}, \"199\": {\"inputs\": {\"anything\": [\"72\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}, \"201\": {\"inputs\": {\"anything\": [\"27\", 0]}, \"class_type\": \"easy cleanGpuUsed\"}, \"204\": {\"inputs\": {}, \"class_type\": \"Cute.Placeholder\"}, \"266\": {\"inputs\": {\"filter_size\": 1, \"factor\": 1.0, \"latents\": [\"27\", 0]}, \"class_type\": \"SharpenFilterLatent\"}}, \"workflow\": {\"last_node_id\": 267, \"last_link_id\": 431, \"nodes\": [{\"id\": 8, \"type\": \"VAEDecode\", \"pos\": [825, 48], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 42, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 180}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 12}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [296], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 10, \"type\": \"VAELoader\", \"pos\": [5, 322], \"size\": {\"0\": 311.81634521484375, \"1\": 60.429901123046875}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"outputs\": [{\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [12, 199], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"VAELoader\"}, \"widgets_values\": [\"FLUX1\\\\ae.sft\"]}, {\"id\": 34, \"type\": \"PrimitiveNode\", \"pos\": [331, 619], \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [115, 140], \"slot_index\": 0, \"widget\": {\"name\": \"width\"}}], \"title\": \"width\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [832, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 37, \"type\": \"Note\", \"pos\": [35, 1111], \"size\": {\"0\": 314.99755859375, \"1\": 117.98363494873047}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\\n\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 72, \"type\": \"FilmGrain\", \"pos\": [387, -565], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 47, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 302, \"slot_index\": 0}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [317, 323, 430], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FilmGrain\"}, \"widgets_values\": [0.03, 10, 0, 0]}, {\"id\": 120, \"type\": \"BetterFilmGrain\", \"pos\": [2518, 1260], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 55, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 332}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [398, 418], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BetterFilmGrain\"}, \"widgets_values\": [0.25, 0.05, 0.7, 0, 1, \"fixed\"]}, {\"id\": 127, \"type\": \"LayerFilter: HDREffects\", \"pos\": [730, -607], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {\"collapsed\": false}, \"order\": 46, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 298}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [302], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.85, 0.45, 0.75, 0.25, 0.1, 0.35000000000000003]}, {\"id\": 139, \"type\": \"LayerFilter: HDREffects\", \"pos\": [-114, -409], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {\"collapsed\": false}, \"order\": 3, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": null}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.5, 0.25, 0.75, 0.25, 0.1, 0.25]}, {\"id\": 182, \"type\": \"EnhanceDetail\", \"pos\": [420, -369], \"size\": {\"0\": 253.6738739013672, \"1\": 130}, \"flags\": {}, \"order\": 44, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 286}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [297], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EnhanceDetail\"}, \"widgets_values\": [2, 0.1, 0.1, 1.5]}, {\"id\": 192, \"type\": \"Image Filter Adjustments\", \"pos\": [721, -382], \"size\": {\"0\": 315, \"1\": 226}, \"flags\": {}, \"order\": 45, \"mode\": 4, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 297}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [298], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"Image Filter Adjustments\"}, \"widgets_values\": [0, 1, 1, 1, 0, 0, 0, \"true\"]}, {\"id\": 200, \"type\": \"Reroute\", \"pos\": [785, -778], \"size\": [75, 26], \"flags\": {}, \"order\": 48, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 317}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [318], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 201, \"type\": \"easy cleanGpuUsed\", \"pos\": [876, 1227], \"size\": {\"0\": 140, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 30, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 326}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 202, \"type\": \"Reroute\", \"pos\": [2735, 1457], \"size\": [75, 26], \"flags\": {}, \"order\": 56, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 398}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [336], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 203, \"type\": \"Reroute\", \"pos\": [1424, 1457], \"size\": [75, 26], \"flags\": {}, \"order\": 58, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": 336}], \"outputs\": [{\"name\": \"\", \"type\": \"IMAGE\", \"links\": [415], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 207, \"type\": \"LayerUtility: PurgeVRAM\", \"pos\": [-235, 753], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 28, \"mode\": 4, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 353}], \"properties\": {\"Node name for S&R\": \"LayerUtility: PurgeVRAM\"}, \"widgets_values\": [true, true]}, {\"id\": 212, \"type\": \"LayerUtility: PurgeVRAM\", \"pos\": [-236, 823], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 27, \"mode\": 4, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 355}], \"properties\": {\"Node name for S&R\": \"LayerUtility: PurgeVRAM\"}, \"widgets_values\": [true, true]}, {\"id\": 213, \"type\": \"LayerUtility: PurgeVRAM\", \"pos\": [-234, 902], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 38, \"mode\": 4, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 356}], \"properties\": {\"Node name for S&R\": \"LayerUtility: PurgeVRAM\"}, \"widgets_values\": [true, true]}, {\"id\": 214, \"type\": \"LayerUtility: PurgeVRAM\", \"pos\": [-236, 986], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 31, \"mode\": 4, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 357}], \"properties\": {\"Node name for S&R\": \"LayerUtility: PurgeVRAM\"}, \"widgets_values\": [true, true]}, {\"id\": 247, \"type\": \"Reroute\", \"pos\": [137, -1026], \"size\": [75, 26], \"flags\": {}, \"order\": 4, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": []}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 248, \"type\": \"Reroute\", \"pos\": [138, -1135], \"size\": [75, 26], \"flags\": {}, \"order\": 5, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": []}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 249, \"type\": \"Reroute\", \"pos\": [137, -1076], \"size\": [75, 26], \"flags\": {}, \"order\": 6, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": []}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 250, \"type\": \"Reroute\", \"pos\": [140, -1191], \"size\": [75, 26], \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": []}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 251, \"type\": \"Reroute\", \"pos\": [138, -1245], \"size\": [75, 26], \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": []}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 252, \"type\": \"Reroute\", \"pos\": [-85, -1244], \"size\": [75, 26], \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 253, \"type\": \"Reroute\", \"pos\": [-85, -1189], \"size\": [75, 26], \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 254, \"type\": \"Reroute\", \"pos\": [-85, -1136], \"size\": [75, 26], \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 255, \"type\": \"Reroute\", \"pos\": [-88, -1072], \"size\": [75, 26], \"flags\": {}, \"order\": 12, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 256, \"type\": \"Reroute\", \"pos\": [-86, -1024], \"size\": [75, 26], \"flags\": {}, \"order\": 13, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 257, \"type\": \"Reroute\", \"pos\": [2390, -70], \"size\": [75, 26], \"flags\": {}, \"order\": 14, \"mode\": 0, \"inputs\": [{\"name\": \"\", \"type\": \"*\", \"link\": null}], \"outputs\": [{\"name\": \"\", \"type\": \"*\", \"links\": [], \"slot_index\": 0}], \"properties\": {\"showOutputText\": false, \"horizontal\": false}}, {\"id\": 260, \"type\": \"LoadImage\", \"pos\": [2996, 493], \"size\": {\"0\": 315, \"1\": 314.0000305175781}, \"flags\": {}, \"order\": 15, \"mode\": 4, \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"MASK\", \"type\": \"MASK\", \"links\": null, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoadImage\"}, \"widgets_values\": [\"00002-3139130378.png\", \"image\"]}, {\"id\": 198, \"type\": \"easy cleanGpuUsed\", \"pos\": [2587, 853], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {\"collapsed\": true}, \"order\": 57, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 418}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 262, \"type\": \"EnhanceDetail\", \"pos\": [2177, 885], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 52, \"mode\": 4, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 420}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [421], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EnhanceDetail\"}, \"widgets_values\": [2, 0.1, 0.1, 2]}, {\"id\": 11, \"type\": \"DualCLIPLoader\", \"pos\": [3, 171], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 16, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [146, 340], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"t5\\\\google_t5-v1_1-xxl_encoderonly-fp8_e4m3fn.safetensors\", \"t5\\\\clip_l.safetensors\", \"flux\"]}, {\"id\": 12, \"type\": \"UNETLoader\", \"pos\": [-2, 44], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 17, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [145], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UNETLoader\"}, \"widgets_values\": [\"FLUX1\\\\flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\"], \"color\": \"#223\", \"bgcolor\": \"#335\"}, {\"id\": 215, \"type\": \"LayerUtility: PurgeVRAM\", \"pos\": [-231, 1057], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 41, \"mode\": 4, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 358}], \"properties\": {\"Node name for S&R\": \"LayerUtility: PurgeVRAM\"}, \"widgets_values\": [true, true]}, {\"id\": 216, \"type\": \"LayerUtility: PurgeVRAM\", \"pos\": [-193, 585], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {\"collapsed\": true}, \"order\": 37, \"mode\": 4, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 359}], \"properties\": {\"Node name for S&R\": \"LayerUtility: PurgeVRAM\"}, \"widgets_values\": [true, true]}, {\"id\": 199, \"type\": \"easy cleanGpuUsed\", \"pos\": [1160, 483], \"size\": {\"0\": 140, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 49, \"mode\": 0, \"inputs\": [{\"name\": \"anything\", \"type\": \"*\", \"link\": 323}], \"properties\": {\"Node name for S&R\": \"easy cleanGpuUsed\"}}, {\"id\": 42, \"type\": \"ImageSharpen\", \"pos\": [732, -113], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 43, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 296, \"slot_index\": 0}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [286], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [1, 0.35000000000000003, 0.35000000000000003]}, {\"id\": 43, \"type\": \"SaveImage\", \"pos\": [1086, -706], \"size\": {\"0\": 606.4337158203125, \"1\": 1111.24365234375}, \"flags\": {}, \"order\": 51, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 318}], \"title\": \"Save Image (sharp and enhance)\", \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 112, \"type\": \"UpscaleModelLoader\", \"pos\": [1411, 451], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 18, \"mode\": 0, \"outputs\": [{\"name\": \"UPSCALE_MODEL\", \"type\": \"UPSCALE_MODEL\", \"links\": [194], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UpscaleModelLoader\"}, \"widgets_values\": [\"4x-UltraSharp.pth\"]}, {\"id\": 70, \"type\": \"LoraLoader\", \"pos\": [0, 441], \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 25, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 145, \"slot_index\": 0}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 146, \"slot_index\": 1}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [344], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [343], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\flux_realism_lora.safetensors\", 1, 1]}, {\"id\": 26, \"type\": \"FluxGuidance\", \"pos\": [591, 42], \"size\": {\"0\": 211.60000610351562, \"1\": 58}, \"flags\": {}, \"order\": 36, \"mode\": 0, \"inputs\": [{\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 272}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [265], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"FluxGuidance\"}, \"widgets_values\": [5], \"color\": \"#233\", \"bgcolor\": \"#355\"}, {\"id\": 22, \"type\": \"BasicGuider\", \"pos\": [348, 50], \"size\": {\"0\": 222.3482666015625, \"1\": 46}, \"flags\": {}, \"order\": 39, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 54, \"slot_index\": 0}, {\"name\": \"conditioning\", \"type\": \"CONDITIONING\", \"link\": 265, \"slot_index\": 1}], \"outputs\": [{\"name\": \"GUIDER\", \"type\": \"GUIDER\", \"links\": [352, 358], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicGuider\"}}, {\"id\": 28, \"type\": \"Note\", \"pos\": [-3, 797], \"size\": {\"0\": 336, \"1\": 288}, \"flags\": {}, \"order\": 19, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"If you get an error in any of the nodes above make sure the files are in the correct directories.\\n\\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\\n\\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\\n\\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\\n\\nae.safetensors goes in: ComfyUI/models/vae/\\n\\n\\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 125, \"type\": \"LayerFilter: HDREffects\", \"pos\": [2511, 1039], \"size\": {\"0\": 315, \"1\": 178}, \"flags\": {}, \"order\": 54, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 329}], \"outputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"links\": [332], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LayerFilter: HDREffects\"}, \"widgets_values\": [0.8, 0.75, 0.75, 0.25, 0.13, 0.3]}, {\"id\": 204, \"type\": \"Cute.Placeholder\", \"pos\": [1768, 477], \"size\": {\"0\": 210, \"1\": 26}, \"flags\": {\"collapsed\": true}, \"order\": 20, \"mode\": 0, \"properties\": {\"Node name for S&R\": \"Cute.Placeholder\"}}, {\"id\": 111, \"type\": \"UltimateSDUpscale\", \"pos\": [1099, 460], \"size\": {\"0\": 264.3000183105469, \"1\": 980.3591918945312}, \"flags\": {}, \"order\": 50, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 430}, {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 325, \"slot_index\": 1}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 275, \"slot_index\": 2}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 191, \"slot_index\": 3}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 199, \"slot_index\": 4}, {\"name\": \"upscale_model\", \"type\": \"UPSCALE_MODEL\", \"link\": 194}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [420], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"UltimateSDUpscale\"}, \"widgets_values\": [2, 1, \"fixed\", 20, 1, \"euler\", \"simple\", 0.25, \"Linear\", 832, 1216, 20, 56, \"None\", 1, 64, 16, 32, true, false]}, {\"id\": 266, \"type\": \"SharpenFilterLatent\", \"pos\": [1720, 301], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 32, \"mode\": 0, \"inputs\": [{\"name\": \"latents\", \"type\": \"LATENT\", \"link\": 429}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [431], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SharpenFilterLatent\"}, \"widgets_values\": [1, 1]}, {\"id\": 104, \"type\": \"CLIPTextEncode\", \"pos\": [809, 689], \"size\": {\"0\": 210, \"1\": 76}, \"flags\": {\"collapsed\": true}, \"order\": 24, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 340, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [191], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"]}, {\"id\": 35, \"type\": \"PrimitiveNode\", \"pos\": [553, 621], \"size\": {\"0\": 210, \"1\": 82}, \"flags\": {}, \"order\": 21, \"mode\": 0, \"outputs\": [{\"name\": \"INT\", \"type\": \"INT\", \"links\": [113, 114], \"slot_index\": 0, \"widget\": {\"name\": \"height\"}}], \"title\": \"height\", \"properties\": {\"Run widget replace on values\": false}, \"widgets_values\": [1216, \"fixed\"], \"color\": \"#323\", \"bgcolor\": \"#535\"}, {\"id\": 13, \"type\": \"SamplerCustomAdvanced\", \"pos\": [775, 664], \"size\": {\"0\": 308.62738037109375, \"1\": 567.866943359375}, \"flags\": {}, \"order\": 40, \"mode\": 0, \"inputs\": [{\"name\": \"noise\", \"type\": \"NOISE\", \"link\": 354, \"slot_index\": 0}, {\"name\": \"guider\", \"type\": \"GUIDER\", \"link\": 352, \"slot_index\": 1}, {\"name\": \"sampler\", \"type\": \"SAMPLER\", \"link\": 19, \"slot_index\": 2}, {\"name\": \"sigmas\", \"type\": \"SIGMAS\", \"link\": 20, \"slot_index\": 3}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 431, \"slot_index\": 4}], \"outputs\": [{\"name\": \"output\", \"type\": \"LATENT\", \"links\": [180], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"denoised_output\", \"type\": \"LATENT\", \"links\": [], \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"SamplerCustomAdvanced\"}}, {\"id\": 173, \"type\": \"SaveImage\", \"pos\": [1404, 551], \"size\": [557.3128051757812, 897.0792846679688], \"flags\": {\"collapsed\": false}, \"order\": 59, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 415, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"SaveImage\"}, \"widgets_values\": [\"ComfyUI\"], \"locked\": true}, {\"id\": 86, \"type\": \"LoraLoader\", \"pos\": [9, 625], \"size\": {\"0\": 315, \"1\": 126}, \"flags\": {}, \"order\": 29, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 344, \"slot_index\": 0}, {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 343, \"slot_index\": 1}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [161], \"slot_index\": 0, \"shape\": 3}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [162], \"slot_index\": 1, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"LoraLoader\"}, \"widgets_values\": [\"flux1\\\\AsirAsianPhotographyflux.safetensors\", 0.9500000000000001, 1]}, {\"id\": 27, \"type\": \"EmptySD3LatentImage\", \"pos\": [396, 747], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 26, \"mode\": 0, \"inputs\": [{\"name\": \"width\", \"type\": \"INT\", \"link\": 140, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 113, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [326, 357, 429], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [832, 1216, 1]}, {\"id\": 16, \"type\": \"KSamplerSelect\", \"pos\": [398, 1023], \"size\": {\"0\": 315, \"1\": 58}, \"flags\": {}, \"order\": 22, \"mode\": 0, \"outputs\": [{\"name\": \"SAMPLER\", \"type\": \"SAMPLER\", \"links\": [19, 355], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"KSamplerSelect\"}, \"widgets_values\": [\"euler\"]}, {\"id\": 17, \"type\": \"BasicScheduler\", \"pos\": [397, 1123], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 35, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 55, \"slot_index\": 0}], \"outputs\": [{\"name\": \"SIGMAS\", \"type\": \"SIGMAS\", \"links\": [20, 356], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"BasicScheduler\"}, \"widgets_values\": [\"simple\", 80, 1]}, {\"id\": 30, \"type\": \"ModelSamplingFlux\", \"pos\": [405, 1279], \"size\": {\"0\": 315, \"1\": 130}, \"flags\": {}, \"order\": 33, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 161, \"slot_index\": 0}, {\"name\": \"width\", \"type\": \"INT\", \"link\": 115, \"slot_index\": 1, \"widget\": {\"name\": \"width\"}}, {\"name\": \"height\", \"type\": \"INT\", \"link\": 114, \"slot_index\": 2, \"widget\": {\"name\": \"height\"}}], \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [54, 55, 325], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ModelSamplingFlux\"}, \"widgets_values\": [1.15, 0.5, 832, 1216]}, {\"id\": 25, \"type\": \"RandomNoise\", \"pos\": [391, 897], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 23, \"mode\": 0, \"outputs\": [{\"name\": \"NOISE\", \"type\": \"NOISE\", \"links\": [353, 354], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"RandomNoise\"}, \"widgets_values\": [7274, \"increment\"], \"color\": \"#2a363b\", \"bgcolor\": \"#3f5159\"}, {\"id\": 119, \"type\": \"ImageSharpen\", \"pos\": [2512, 894], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 53, \"mode\": 0, \"inputs\": [{\"name\": \"image\", \"type\": \"IMAGE\", \"link\": 421, \"slot_index\": 0}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [329], \"slot_index\": 0, \"shape\": 3}], \"properties\": {\"Node name for S&R\": \"ImageSharpen\"}, \"widgets_values\": [2, 0.4, 0.4]}, {\"id\": 6, \"type\": \"CLIPTextEncode\", \"pos\": [337, 144], \"size\": {\"0\": 644.234375, \"1\": 423.40484619140625}, \"flags\": {}, \"order\": 34, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 162, \"slot_index\": 0}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [272, 275, 359], \"slot_index\": 0}], \"title\": \"CLIP Text Encode (Positive Prompt)\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"photorealistic, A woman in her 20s, platinum blonde hair, long eyelashes, thick eyelashes, makeup, glamourous, interesting black eyeliner, autumn attire, park scene, golden hour, serene expression, detailed facial features, warm smile, cozy clothing, autumn leaves, setting sun, warm, golden lighting, intricate fabric details, gentle breeze, peaceful atmosphere, ultra-high resolution, natural skin tone, light makeup, autumn hues, wide shot, medium shot, close-up, low-angle shot, high-angle shot, side profile, standing pose, walking through park, hair flowing in breeze, blurred autumn background, hyper-detailed environment, warm glow, tranquil park scene, falling leaves, balanced composition, dynamic stance, fluid motion, emotional connection, serene mood, background focus\\n\\nThe woman is leaning casually against a large, textured tree trunk, with one foot crossed over the other. She\\u2019s looking off into the distance with a soft smile, her hair cascading down over her shoulder, gently tousled by the breeze.\\n\\ncinematic lighting, extremely intricate detail character, accurate depiction of character, correct body anatomy,correct hands and fingers, extremely intricate skin and facial texture detail, intricate black bodysuit design,lifelike potrayal, extrememly realistic lighting, extreme dynamic pose \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}], \"links\": [[12, 10, 0, 8, 1, \"VAE\"], [19, 16, 0, 13, 2, \"SAMPLER\"], [20, 17, 0, 13, 3, \"SIGMAS\"], [54, 30, 0, 22, 0, \"MODEL\"], [55, 30, 0, 17, 0, \"MODEL\"], [113, 35, 0, 27, 1, \"INT\"], [114, 35, 0, 30, 2, \"INT\"], [115, 34, 0, 30, 1, \"INT\"], [140, 34, 0, 27, 0, \"INT\"], [145, 12, 0, 70, 0, \"MODEL\"], [146, 11, 0, 70, 1, \"CLIP\"], [161, 86, 0, 30, 0, \"MODEL\"], [162, 86, 1, 6, 0, \"CLIP\"], [180, 13, 0, 8, 0, \"LATENT\"], [191, 104, 0, 111, 3, \"CONDITIONING\"], [194, 112, 0, 111, 5, \"UPSCALE_MODEL\"], [199, 10, 0, 111, 4, \"VAE\"], [265, 26, 0, 22, 1, \"CONDITIONING\"], [272, 6, 0, 26, 0, \"CONDITIONING\"], [275, 6, 0, 111, 2, \"CONDITIONING\"], [286, 42, 0, 182, 0, \"IMAGE\"], [296, 8, 0, 42, 0, \"IMAGE\"], [297, 182, 0, 192, 0, \"IMAGE\"], [298, 192, 0, 127, 0, \"IMAGE\"], [302, 127, 0, 72, 0, \"IMAGE\"], [317, 72, 0, 200, 0, \"*\"], [318, 200, 0, 43, 0, \"IMAGE\"], [323, 72, 0, 199, 0, \"*\"], [325, 30, 0, 111, 1, \"MODEL\"], [326, 27, 0, 201, 0, \"*\"], [329, 119, 0, 125, 0, \"IMAGE\"], [332, 125, 0, 120, 0, \"IMAGE\"], [336, 202, 0, 203, 0, \"*\"], [340, 11, 0, 104, 0, \"CLIP\"], [343, 70, 1, 86, 1, \"CLIP\"], [344, 70, 0, 86, 0, \"MODEL\"], [352, 22, 0, 13, 1, \"GUIDER\"], [353, 25, 0, 207, 0, \"*\"], [354, 25, 0, 13, 0, \"NOISE\"], [355, 16, 0, 212, 0, \"*\"], [356, 17, 0, 213, 0, \"*\"], [357, 27, 0, 214, 0, \"*\"], [358, 22, 0, 215, 0, \"*\"], [359, 6, 0, 216, 0, \"*\"], [398, 120, 0, 202, 0, \"*\"], [415, 203, 0, 173, 0, \"IMAGE\"], [418, 120, 0, 198, 0, \"*\"], [420, 111, 0, 262, 0, \"IMAGE\"], [421, 262, 0, 119, 0, \"IMAGE\"], [429, 27, 0, 266, 0, \"LATENT\"], [430, 72, 0, 111, 0, \"IMAGE\"], [431, 266, 0, 13, 4, \"LATENT\"]], \"groups\": [{\"title\": \"FaceDetailer\", \"bounding\": [1797, -1481, 1702, 1398], \"color\": \"#3f789e\", \"font_size\": 24, \"locked\": false}, {\"title\": \"FaceDetailer Pipe 2 Pass\", \"bounding\": [3598, -1218, 1678, 1132], \"color\": \"#3f789e\", \"font_size\": 24, \"locked\": false}, {\"title\": \"UPSCALE\", \"bounding\": [5304, -1054, 477, 965], \"color\": \"#3f789e\", \"font_size\": 24, \"locked\": false}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 0.6830134553650705, \"offset\": [999.9771471311922, 331.3081846549502]}, \"groupNodes\": {}}, \"version\": 0.4, \"widget_idx_map\": {\"16\": {\"sampler_name\": 0}, \"17\": {\"scheduler\": 0}, \"25\": {\"noise_seed\": 0}, \"111\": {\"seed\": 1, \"sampler_name\": 5, \"scheduler\": 6}, \"120\": {\"seed\": 4}}, \"seed_widgets\": {\"25\": 0, \"111\": 1, \"120\": 4}}}",
            "steps": 80,
            "models": [],
            "prompt": "photorealistic, A woman in her 20s, platinum blonde hair, long eyelashes, thick eyelashes, makeup, glamourous, interesting black eyeliner, autumn attire, park scene, golden hour, serene expression, detailed facial features, warm smile, cozy clothing, autumn leaves, setting sun, warm, golden lighting, intricate fabric details, gentle breeze, peaceful atmosphere, ultra-high resolution, natural skin tone, light makeup, autumn hues, wide shot, medium shot, close-up, low-angle shot, high-angle shot, side profile, standing pose, walking through park, hair flowing in breeze, blurred autumn background, hyper-detailed environment, warm glow, tranquil park scene, falling leaves, balanced composition, dynamic stance, fluid motion, emotional connection, serene mood, background focus\n\nThe woman is leaning casually against a large, textured tree trunk, with one foot crossed over the other. She\u2019s looking off into the distance with a soft smile, her hair cascading down over her shoulder, gently tousled by the breeze.\n\ncinematic lighting, extremely intricate detail character, accurate depiction of character, correct body anatomy,correct hands and fingers, extremely intricate skin and facial texture detail, intricate black bodysuit design,lifelike potrayal, extrememly realistic lighting, extreme dynamic pose \n\n \n\n\n\n\n\n\n\n\n\n\n\n\n",
            "denoise": 1,
            "sampler": "Euler",
            "cfgScale": 5,
            "modelIds": [],
            "scheduler": "simple",
            "upscalers": [
                "4x-UltraSharp.pth"
            ],
            "versionIds": [],
            "controlNets": [],
            "additionalResources": [
                {
                    "name": "flux1\\flux_realism_lora.safetensors",
                    "type": "lora",
                    "strength": 1,
                    "strengthClip": 1
                },
                {
                    "name": "flux1\\AsirAsianPhotographyflux.safetensors",
                    "type": "lora",
                    "strength": 0.9500000000000001,
                    "strengthClip": 1
                }
            ]
        },
        "username": "salammy",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 25180790,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f9703be-29c9-4017-8a65-94cba83dee24/width=1800/0f9703be-29c9-4017-8a65-94cba83dee24.jpeg",
        "hash": "UJO__@,n~UGI~oo{Iua1TgV]XQtP?ZSiRj$L",
        "width": 3712,
        "height": 2560,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-20T00:43:39.924Z",
        "postId": 5627365,
        "stats": {
            "cryCount": 13,
            "laughCount": 30,
            "likeCount": 147,
            "dislikeCount": 0,
            "heartCount": 94,
            "commentCount": 1
        },
        "meta": {
            "Size": "1216x832",
            "seed": 250089416,
            "steps": 23,
            "prompt": "score_9, score_8_up, score_8, duo, (fluffy:0.8), claws, (fluffy cheeks:0.4), (feral:1.3), outdooes, furry, (((mouse))), female, in the style of beatrix potter, flat color, (cute), romantic, look at each other, (kissing:2), (head portrait, head focus, close up:2), nature, outdoors\nBREAK\n(mouse, female, (eyes closed), yellow fur, yellow ears, (short red dress)),\nBREAK\n(mouse, female, green eyes, grey fur, grey ears, (short blue dress)),",
            "sampler": "Euler a",
            "cfgScale": 5,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-08-16T1315:17.5708829Z",
            "negativePrompt": "score_6, score_5, score_4, (cub, young, child, chibi:1.4), busty, ugly face, low res, blurry face, ugly hands, pumped body, black and white, penis, clothing, breasts, big ears, ((hair)), nipples, green fur, belly, extra ears, human, blue fur, panties, simple background, (lower body, size difference:2),",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 290640,
                    "modelVersionName": "V6 (start with this one)"
                },
                {
                    "type": "lora",
                    "weight": 0.9,
                    "modelVersionId": 450029,
                    "modelVersionName": "LineArt Mono"
                },
                {
                    "type": "lora",
                    "weight": 0.3,
                    "modelVersionId": 423178,
                    "modelVersionName": "Beatrix potter drawing style"
                },
                {
                    "type": "lora",
                    "weight": 0.2,
                    "modelVersionId": 494676,
                    "modelVersionName": "Flat Color"
                }
            ]
        },
        "username": "JustAMouse",
        "baseModel": "Pony"
    },
    {
        "id": 25001639,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c75512d3-01d5-4afc-9026-30824640cb1e/width=1800/c75512d3-01d5-4afc-9026-30824640cb1e.jpeg",
        "hash": "UFF=dG?G0K4:_NIp4:t5^%D*xW-:bcadIpt7",
        "width": 1920,
        "height": 2560,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-19T00:01:15.954Z",
        "postId": 5587572,
        "stats": {
            "cryCount": 8,
            "laughCount": 19,
            "likeCount": 197,
            "dislikeCount": 0,
            "heartCount": 60,
            "commentCount": 2
        },
        "meta": {
            "": {
                "\\skip_factor\\": "0.4}]",
                "{\\backbone_factor\\": "1.2",
                "[{\\backbone_factor\\": "1.1"
            },
            "Eta": "0.5",
            "RNG": "CPU",
            "VAE": "sdxl_vae.safetensors",
            "Size": "960x1280",
            "seed": 88888888,
            "Model": "dever's_divine_diffusion-v1.1-xl",
            "steps": 72,
            "hashes": {
                "vae": "42a404c885",
                "model": "505966774f",
                "lora:more_artful-xl": "15e31fe2b6",
                "embed:ng-beyond_sdxl-v3": "7a11b7b2ad",
                "lora:envybetterhiresfixxl01-xl": "930e286cfd",
                "lora:midjourney_mimic-xl-by_andrexsel": "e526855052",
                "lora:lyco-style-envydramaticlightingxl01_digital_art-xl": "ecbbe6e3d9"
            },
            "prompt": "famous artwork inspired by (yoann lossel:1.4), (epic composition:1.2), oil painting with gold leaf, fairy tale from one thousand and one nights, a beautiful arabian princess with silky black hair, atmospheric fantasy, dappled light, back light, (intricate patterns:1.1), symmetrical architecture, expressive, melancholic, highly detailed, dark corners, <lora:midjourney_mimic-xl-by_andrexsel:0.48> <lora:more_artful-xl:0.4> <lora:lyco-style-envydramaticlightingxl01_digital_art-xl:0.6> <lora:envyzoomsliderxl01-xl:-0.4> <lora:envybetterhiresfixxl01-xl:0.0:hr=1.0>",
            "Version": "v1.10.1",
            "sampler": "DPM++ 3M SDE",
            "cfgScale": 12,
            "resources": [
                {
                    "name": "midjourney_mimic-xl-by_andrexsel",
                    "type": "lora",
                    "weight": 0.48
                },
                {
                    "name": "more_artful-xl",
                    "type": "lora",
                    "weight": 0.4
                },
                {
                    "name": "lyco-style-envydramaticlightingxl01_digital_art-xl",
                    "type": "lora",
                    "weight": 0.6
                },
                {
                    "hash": "505966774f",
                    "name": "dever's_divine_diffusion-v1.1-xl",
                    "type": "model"
                }
            ],
            "Model hash": "505966774f",
            "Hires steps": "36",
            "FreeU Stages": {},
            "FreeU Version": "2",
            "Hires upscale": "2",
            "Schedule type": "Exponential",
            "FreeU Schedule": {},
            "Hires upscaler": "4x_foolhardy_remacri",
            "negativePrompt": "ng-beyond_sdxl-v3, blonde, long neck, extra hand, extra arm, extra leg, deformed, crippled, worst quality, low quality, sloppy, simple, ugly, unsharp, blurry, cropped, margins, text, signature",
            "ADetailer model": "face_yolov8m.pt",
            "ADetailer prompt": {
                "lyco-style-envydramaticlightingxl01_digital_art-xl": "0.56>"
            },
            "ADetailer version": "24.6.0",
            "Denoising strength": "0.28",
            "ADetailer mask blur": "24",
            "ADetailer confidence": "0.22",
            "ADetailer dilate erode": "4",
            "ADetailer inpaint width": "832",
            "ADetailer model classes": "person",
            "ADetailer inpaint height": "1216",
            "ADetailer inpaint padding": "32",
            "ADetailer negative prompt": {},
            "ADetailer denoising strength": "0.36",
            "ADetailer inpaint only masked": "True",
            "ADetailer mask only top k largest": "1",
            "ADetailer use inpaint width height": "True"
        },
        "username": "OneViolentGentleman",
        "baseModel": "SDXL 1.0"
    },
    {
        "id": 24747488,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/edb9db48-935a-49c7-9430-b156ce65312a/width=832/edb9db48-935a-49c7-9430-b156ce65312a.jpeg",
        "hash": "UmEf+i%Mj]of_M%Lofofxts:ofoeRjf6j[j[",
        "width": 832,
        "height": 1216,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-17T11:47:46.823Z",
        "postId": 5529623,
        "stats": {
            "cryCount": 6,
            "laughCount": 19,
            "likeCount": 201,
            "dislikeCount": 0,
            "heartCount": 58,
            "commentCount": 1
        },
        "meta": {
            "Size": "832x1216",
            "seed": 4146662772,
            "steps": 28,
            "prompt": "a large city filled with lots of tall buildings, a detailed matte painting, by Rapha\u00ebl Collin, digital art, ufo flying over paris, world of war spaceships, wideshot, amazingly composed image, naboo, in the foreground paris, 2077, benjamin vnuk, alexey egorov, dirk dzimirsky, paris, futuristic",
            "sampler": "Undefined",
            "cfgScale": 2,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-08-16T2121:37.3041274Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 691639,
                    "modelVersionName": "Dev"
                }
            ]
        },
        "username": "VirgulFox",
        "baseModel": "Flux.1 D"
    },
    {
        "id": 24061604,
        "url": "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5256e06e-8f58-4548-9af2-6a1a709a6a8c/width=512/5256e06e-8f58-4548-9af2-6a1a709a6a8c.jpeg",
        "hash": "U8Hm+OV_00+c8^T}x]8{Bq0xXn?H00s;pI^i",
        "width": 512,
        "height": 512,
        "nsfwLevel": "None",
        "nsfw": false,
        "browsingLevel": 1,
        "createdAt": "2024-08-13T05:22:52.875Z",
        "postId": 5368980,
        "stats": {
            "cryCount": 2,
            "laughCount": 15,
            "likeCount": 215,
            "dislikeCount": 0,
            "heartCount": 52,
            "commentCount": 0
        },
        "meta": {
            "Size": "512x512",
            "seed": 3017150187,
            "steps": 17,
            "prompt": "Portrait of a beautiful Queen.\nOrange, red, green,  purple colors only.",
            "sampler": "Euler",
            "cfgScale": 4,
            "clipSkip": 2,
            "resources": [],
            "Created Date": "2024-08-13T0520:13.6891483Z",
            "civitaiResources": [
                {
                    "type": "checkpoint",
                    "modelVersionId": 128713,
                    "modelVersionName": "8"
                },
                {
                    "type": "lora",
                    "weight": 0.15,
                    "modelVersionId": 26660,
                    "modelVersionName": "Yoneyama Mai_V2 (LoCon)"
                },
                {
                    "type": "lora",
                    "weight": 1,
                    "modelVersionId": 113556,
                    "modelVersionName": "v1.0"
                }
            ]
        },
        "username": null,
        "baseModel": "SD 1.5"
    }
]